<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 9]
- [cs.LG](#cs.LG) [Total: 31]
- [cs.HC](#cs.HC) [Total: 7]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration](https://arxiv.org/abs/2512.21360)
*Shuide Wen,Yu Sun,Beier Ku,Zhi Gao,Lijun Ma,Yang Yang,Can Jiao*

Main category: cs.AI

TL;DR: 本研究开发了一个基于多模态大语言模型的多智能体系统，用于标准化HTP绘画测试分析，实现了与人类专家约0.75-0.85的语义相似度，为数字心理健康服务提供了新范式。


<details>
  <summary>Details</summary>
Motivation: HTP绘画测试作为临床心理学中广泛使用的投射技术，长期面临评分标准不统一、依赖评估者主观经验、缺乏统一量化编码系统等问题，需要开发标准化的分析工具。

Method: 采用多模态大语言模型构建多智能体协作系统，通过角色分工将特征识别与心理推理解耦，整合社会心理学视角和去污名化叙事，纠正视觉幻觉。

Result: 定量实验显示MLLM解释与人类专家解释的平均语义相似度约为0.75（标准差约0.05），在结构化专家数据集中相似度提升至0.85，达到专家级基线理解水平。定性分析表明系统能产生具有高生态效度和内部一致性的心理报告。

Conclusion: 研究证实了多模态大模型作为投射评估标准化工具的潜力，提出的多智能体框架为数字心理健康服务提供了新范式，通过角色分工实现了特征识别与心理推理的解耦。

Abstract: Background: The House-Tree-Person (HTP) drawing test, introduced by John Buck in 1948, remains a widely used projective technique in clinical psychology. However, it has long faced challenges such as heterogeneous scoring standards, reliance on examiners subjective experience, and a lack of a unified quantitative coding system.
  Results: Quantitative experiments showed that the mean semantic similarity between Multimodal Large Language Model (MLLM) interpretations and human expert interpretations was approximately 0.75 (standard deviation about 0.05). In structurally oriented expert data sets, this similarity rose to 0.85, indicating expert-level baseline comprehension. Qualitative analyses demonstrated that the multi-agent system, by integrating social-psychological perspectives and destigmatizing narratives, effectively corrected visual hallucinations and produced psychological reports with high ecological validity and internal coherence.
  Conclusions: The findings confirm the potential of multimodal large models as standardized tools for projective assessment. The proposed multi-agent framework, by dividing roles, decouples feature recognition from psychological inference and offers a new paradigm for digital mental-health services.
  Keywords: House-Tree-Person test; multimodal large language model; multi-agent collaboration; cosine similarity; computational psychology; artificial intelligence

</details>


### [2] [A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers](https://arxiv.org/abs/2512.21365)
*Chung-Chin Shih,Ti-Rong Wu,Ting Han Wei,Yu-Shan Hsu,Hung Guei,I-Chen Wu*

Main category: cs.AI

TL;DR: 该研究分析了使用基于相关区域搜索(RZS)和相关区域模式表的计算机围棋求解器解决死活题的行为，发现求解器能识别关键区域、发现罕见模式，但在两个问题上给出了与人类专家不同的答案，且存在对罕见模式价值误判和优先求活而非最大化地盘的问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机是分析当前最先进的计算机围棋求解器在解决死活题时的行为，特别是使用基于相关区域搜索和相关区域模式表这两种技术时，与人类专家解决方案的差异和局限性。

Method: 研究方法包括：1) 使用基于相关区域搜索(RZS)和相关区域模式表的计算机围棋求解器；2) 分析求解器对围棋大师赵治勋《死活辞典》中七个死活题的解决方案；3) 对比求解器解决方案与书中给定答案的差异。

Result: 研究结果发现：1) 求解器能为每个问题识别出关键的相关区域；2) 求解器发现了一系列模式，包括一些罕见模式；3) 在两个问题上，求解器给出了与书中答案不同的解决方案。同时识别出求解器的两个问题：a) 对罕见模式的价值判断错误；b) 倾向于优先求活而非最大化地盘，这与人类棋手行为不同。

Conclusion: 结论指出当前基于相关区域搜索的计算机围棋求解器在解决死活题时表现出与人类专家不同的行为模式，存在对罕见模式价值误判和策略偏好差异的问题，并提出了未来改进这些问题的可能方法。

Abstract: This paper analyzes the behavior of solving Life-and-Death (L&D) problems in the game of Go using current state-of-the-art computer Go solvers with two techniques: the Relevance-Zone Based Search (RZS) and the relevance-zone pattern table. We examined the solutions derived by relevance-zone based solvers on seven L&D problems from the renowned book "Life and Death Dictionary" written by Cho Chikun, a Go grandmaster, and found several interesting results. First, for each problem, the solvers identify a relevance-zone that highlights the critical areas for solving. Second, the solvers discover a series of patterns, including some that are rare. Finally, the solvers even find different answers compared to the given solutions for two problems. We also identified two issues with the solver: (a) it misjudges values of rare patterns, and (b) it tends to prioritize living directly rather than maximizing territory, which differs from the behavior of human Go players. We suggest possible approaches to address these issues in future work. Our code and data are available at https://rlg.iis.sinica.edu.tw/papers/study-LD-RZ.

</details>


### [3] [Three-way decision with incomplete information based on similarity and satisfiability](https://arxiv.org/abs/2512.21421)
*Junfang Luo,Mengjun Hu,Keyun Qin*

Main category: cs.AI

TL;DR: 本文基于对完整信息下三支决策计算和概念两种表述的回顾，将其推广到更实用的不完备信息场景，提出了相似度度量、α-相似类、可逼近性等新概念，以及基于α-意义集和公式置信度的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有三支决策方法主要处理完备信息，但在实际应用中不完备信息更为常见。需要将完备信息下的计算表述（基于等价关系）和概念表述（基于逻辑公式可满足性）推广到不完备信息场景，以增强方法的实用性。

Method: 1. 计算表述：提出对象相似度度量作为等价关系的推广，基于此讨论使用α-相似类和对象可逼近性的两种三支决策方法。
2. 概念表述：提出公式可满足度度量作为完备信息下可满足性的量化推广，基于此研究使用α-意义集和公式置信度的两种三支决策方法。

Result: 成功将三支决策的计算和概念两种表述推广到不完备信息场景。提出的可逼近性概念以及概念表述中的两种新方法为不完备信息分析指出了新的研究方向，相比文献中常用的相似类方法更具创新性。

Conclusion: 本文系统地将三支决策从完备信息推广到不完备信息，提出了多种新概念和新方法。特别是可逼近性概念和概念表述中的两种方法为不完备信息分析开辟了新的研究路径，增强了三支决策在实际应用中的实用性。

Abstract: Three-way decision is widely applied with rough set theory to learn classification or decision rules. The approaches dealing with complete information are well established in the literature, including the two complementary computational and conceptual formulations. The computational formulation uses equivalence relations, and the conceptual formulation uses satisfiability of logic formulas. In this paper, based on a briefly review of these two formulations, we generalize both formulations into three-way decision with incomplete information that is more practical in real-world applications. For the computational formulation, we propose a new measure of similarity degree of objects as a generalization of equivalence relations. Based on it, we discuss two approaches to three-way decision using alpha-similarity classes and approximability of objects, respectively. For the conceptual formulation, we propose a measure of satisfiability degree of formulas as a quantitative generalization of satisfiability with complete information. Based on it, we study two approaches to three-way decision using alpha-meaning sets of formulas and confidence of formulas, respectively. While using similarity classes is a common method of analyzing incomplete information in the literature, the proposed concept of approximability and the two approaches in conceptual formulation point out new promising directions.

</details>


### [4] [LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis](https://arxiv.org/abs/2512.21482)
*Fanwei Zeng,Changtao Miao,Jing Huang,Zhiya Tan,Shutao Gong,Xiaoming Yu,Yang Wang,Huazhe Tan,Weibin Yao,Jianshu Li*

Main category: cs.AI

TL;DR: LogicLens是一个统一的视觉-文本协同推理框架，用于分析文本中心伪造，通过交叉线索感知思维链机制实现深度推理，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前文本中心伪造分析方法通常局限于粗粒度的视觉分析，缺乏复杂推理能力，并且将检测、定位和解释视为离散的子任务，忽视了它们之间的内在联系，无法实现整体性能提升。

Method: 提出了LogicLens统一框架，采用交叉线索感知思维链机制进行迭代视觉-文本交叉验证；设计了加权多任务奖励函数进行GRPO优化；构建了PR²多智能体系统生成高质量标注；创建了包含5,397张图像的RealText数据集。

Result: 在T-IC13零样本评估中，比专门化框架高出41.4%，比GPT-4o高出23.4%的宏平均F1分数；在密集文本T-SROIE数据集上，在mF1、CSS和宏平均F1指标上显著领先其他MLLM方法。

Conclusion: LogicLens通过统一的视觉-文本协同推理框架，有效解决了文本中心伪造分析中的挑战，在检测、定位和解释任务上实现了卓越性能，为信息真实性验证提供了有力工具。

Abstract: Sophisticated text-centric forgeries, fueled by rapid AIGC advancements, pose a significant threat to societal security and information authenticity. Current methods for text-centric forgery analysis are often limited to coarse-grained visual analysis and lack the capacity for sophisticated reasoning. Moreover, they typically treat detection, grounding, and explanation as discrete sub-tasks, overlooking their intrinsic relationships for holistic performance enhancement. To address these challenges, we introduce LogicLens, a unified framework for Visual-Textual Co-reasoning that reformulates these objectives into a joint task. The deep reasoning of LogicLens is powered by our novel Cross-Cues-aware Chain of Thought (CCT) mechanism, which iteratively cross-validates visual cues against textual logic. To ensure robust alignment across all tasks, we further propose a weighted multi-task reward function for GRPO-based optimization. Complementing this framework, we first designed the PR$^2$ (Perceiver, Reasoner, Reviewer) pipeline, a hierarchical and iterative multi-agent system that generates high-quality, cognitively-aligned annotations. Then, we constructed RealText, a diverse dataset comprising 5,397 images with fine-grained annotations, including textual explanations, pixel-level segmentation, and authenticity labels for model training. Extensive experiments demonstrate the superiority of LogicLens across multiple benchmarks. In a zero-shot evaluation on T-IC13, it surpasses the specialized framework by 41.4% and GPT-4o by 23.4% in macro-average F1 score. Moreover, on the challenging dense-text T-SROIE dataset, it establishes a significant lead over other MLLM-based methods in mF1, CSS, and the macro-average F1. Our dataset, model, and code will be made publicly available.

</details>


### [5] [Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model](https://arxiv.org/abs/2512.21540)
*Yanhao Li,Lu Ma,Jiaran Zhang,Lexiang Tang,Wentao Zhang,Guibo Luo*

Main category: cs.AI

TL;DR: 提出Leash框架，通过自适应长度惩罚和奖励塑造，动态调整惩罚系数，在保持任务性能的同时将推理长度减少60%


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定长度惩罚，难以调优且无法适应LLM推理能力的演变，导致准确性和简洁性之间的次优权衡

Method: 将长度控制建模为约束优化问题，采用拉格朗日对偶方法动态调整惩罚系数：当生成超过目标长度时加强惩罚，较短时放松惩罚

Result: 在Deepseek-R1-Distill-Qwen-1.5B和Qwen3-4B-Thinking-2507上实验，平均推理长度减少60%，在数学推理、编码和指令遵循等任务中保持竞争力

Conclusion: Leash为开发可控高效LLM提供了实用有效范式，平衡推理能力与计算预算

Abstract: Existing approaches typically rely on fixed length penalties, but such penalties are hard to tune and fail to adapt to the evolving reasoning abilities of LLMs, leading to suboptimal trade-offs between accuracy and conciseness. To address this challenge, we propose Leash (adaptive LEngth penAlty and reward SHaping), a reinforcement learning framework for efficient reasoning in LLMs. We formulate length control as a constrained optimization problem and employ a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. When generations exceed the target length, the penalty is intensified; when they are shorter, it is relaxed. This adaptive mechanism guides models toward producing concise reasoning without sacrificing task performance. Experiments on Deepseek-R1-Distill-Qwen-1.5B and Qwen3-4B-Thinking-2507 show that Leash reduces the average reasoning length by 60% across diverse tasks - including in-distribution mathematical reasoning and out-of-distribution domains such as coding and instruction following - while maintaining competitive performance. Our work thus presents a practical and effective paradigm for developing controllable and efficient LLMs that balance reasoning capabilities with computational budgets.

</details>


### [6] [A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning](https://arxiv.org/abs/2512.21583)
*Zelin Zang,Wenyi Gu,Siqi Ma,Dan Yang,Yue Shen,Zhu Zhang,Guohui Fan,Wing-Kuen Ling,Fuji Yang*

Main category: cs.AI

TL;DR: 基于LLaVA构建的诊断框架，结合视觉语言对齐与逻辑正则化推理，提高医学多模态诊断的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着医学领域大语言模型和视觉语言模型的快速发展，单纯整合临床文本和医学影像并不能保证可靠的推理。现有的多模态模型经常产生幻觉或不一致的思维链，限制了临床信任度。

Method: 提出一个诊断框架，包括：1）文本和图像的输入编码器；2）跨模态对齐的投影模块；3）将诊断任务分解为步骤的推理控制器；4）将逐步前提组装成可验证结论的逻辑树生成器。

Result: 在MedXpertQA和其他基准测试上的评估显示，该方法提高了诊断准确性，在多模态任务上产生更可解释的推理轨迹，同时在纯文本设置上保持竞争力。

Conclusion: 这些结果表明，该方法朝着可信赖的多模态医学AI迈出了有希望的一步。

Abstract: With the rapid growth of large language models (LLMs) and vision-language models (VLMs) in medicine, simply integrating clinical text and medical imaging does not guarantee reliable reasoning. Existing multimodal models often produce hallucinations or inconsistent chains of thought, limiting clinical trust. We propose a diagnostic framework built upon LLaVA that combines vision-language alignment with logic-regularized reasoning. The system includes an input encoder for text and images, a projection module for cross-modal alignment, a reasoning controller that decomposes diagnostic tasks into steps, and a logic tree generator that assembles stepwise premises into verifiable conclusions. Evaluations on MedXpertQA and other benchmarks show that our method improves diagnostic accuracy and yields more interpretable reasoning traces on multimodal tasks, while remaining competitive on text-only settings. These results suggest a promising step toward trustworthy multimodal medical AI.

</details>


### [7] [Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design](https://arxiv.org/abs/2512.21623)
*Takahide Suzuki,Kazuki Nakanishi,Takashi Fujiwara,Hideyuki Shimizu*

Main category: cs.AI

TL;DR: OrchestRA是一个人类在环的多智能体平台，将生物学、化学和药理学统一为自主发现引擎，通过自主执行模拟和推理结果来驱动迭代优化，将药物发现从随机搜索转变为可编程的循证工程学科。


<details>
  <summary>Details</summary>
Motivation: 当前治疗发现面临专业领域碎片化以及计算设计与生理验证之间的执行差距等挑战。虽然生成式AI有潜力，但现有模型通常只是被动助手而非自主执行者，需要更强大的自主发现平台。

Method: OrchestRA采用人类在环的多智能体架构，由Orchestrator协调三个专业智能体：1) Biologist Agent利用大规模知识图谱(>1000万关联)进行深度推理识别高置信度靶点；2) Chemist Agent自主检测结构口袋进行从头设计或药物重定位；3) Pharmacologist Agent通过基于生理的药代动力学(PBPK)模拟评估候选药物。建立动态反馈循环，药代动力学和毒性特征直接触发结构重新优化。

Result: OrchestRA平台实现了自主执行与人类指导的无缝集成，建立了动态反馈循环，能够将药代动力学和毒性特征直接转化为结构优化指令，使治疗设计民主化。

Conclusion: OrchestRA通过统一生物学、化学和药理学为自主发现引擎，将药物发现从随机搜索转变为可编程的循证工程学科，解决了当前治疗发现中的碎片化和执行差距问题。

Abstract: Therapeutic discovery remains a formidable challenge, impeded by the fragmentation of specialized domains and the execution gap between computational design and physiological validation. Although generative AI offers promise, current models often function as passive assistants rather than as autonomous executors. Here, we introduce OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine. Unlike static code generators, our agents actively execute simulations and reason the results to drive iterative optimization. Governed by an Orchestrator, a Biologist Agent leverages deep reasoning over a massive knowledge graph (>10 million associations) to pinpoint high-confidence targets; a Chemist Agent autonomously detects structural pockets for de novo design or drug repositioning; and a Pharmacologist Agent evaluates candidates via rigorous physiologically based pharmacokinetic (PBPK) simulations. This architecture establishes a dynamic feedback loop where pharmacokinetic and toxicity profiles directly trigger structural reoptimization. By seamlessly integrating autonomous execution with human guidance, OrchestRA democratizes therapeutic design, transforming drug discovery from a stochastic search to a programmable evidence-based engineering discipline.

</details>


### [8] [Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing](https://arxiv.org/abs/2512.21626)
*Hong Xie,Haoran Gu,Yanying Huang,Tao Tan,Defu Lian*

Main category: cs.AI

TL;DR: 该论文提出了一种针对LLM应用、边缘智能等资源分配问题的多臂赌博机变体，包含M个臂和K个玩法，每个臂有随机容量，容量单位有奖励函数，玩法有优先级权重，容量按优先级分配。证明了独立于实例和依赖于实例的遗憾下界，设计了MSB-PRS-OffOpt算法寻找最优分配策略，并基于此设计了近似UCB算法，其遗憾上界与下界匹配。


<details>
  <summary>Details</summary>
Motivation: 解决LLM应用、边缘智能等场景中的资源分配问题，这些场景中资源容量是随机的，不同任务有优先级权重，需要按优先级分配有限资源。传统多臂赌博机模型无法处理这种带优先级权重的资源分配问题。

Method: 提出多臂随机赌博机变体模型，每个臂有随机容量，每个容量单位关联奖励函数，每个玩法有优先级权重。容量按优先级权重从大到小分配。设计MSB-PRS-OffOpt算法（计算复杂度O(MK^3)）寻找最优分配策略，并以此为基础设计近似UCB算法进行在线学习。

Result: 证明了独立于实例的遗憾下界Ω(α₁σ√(KMT))和依赖于实例的遗憾下界Ω(α₁σ²(M/Δ)lnT)。设计的近似UCB算法具有匹配的遗憾上界（分别相差√(KlnKT)和α₁K²因子）。MSB-PRS-OffOpt算法能以O(MK^3)复杂度找到最优分配策略。

Conclusion: 该论文成功解决了优先级资源共享机制下的非线性组合效用函数优化和学习问题，为LLM应用和边缘智能中的资源分配提供了理论框架和有效算法，实现了理论下界匹配的遗憾性能。

Abstract: This paper proposes a variant of multiple-play stochastic bandits tailored to resource allocation problems arising from LLM applications, edge intelligence, etc. The model is composed of $M$ arms and $K$ plays. Each arm has a stochastic number of capacities, and each unit of capacity is associated with a reward function. Each play is associated with a priority weight. When multiple plays compete for the arm capacity, the arm capacity is allocated in a larger priority weight first manner. Instance independent and instance dependent regret lower bounds of $Ω( α_1 σ\sqrt{KM T} )$ and $Ω(α_1 σ^2 \frac{M}Δ \ln T)$ are proved, where $α_1$ is the largest priority weight and $σ$ characterizes the reward tail. When model parameters are given, we design an algorithm named \texttt{MSB-PRS-OffOpt} to locate the optimal play allocation policy with a computational complexity of $O(MK^3)$. Utilizing \texttt{MSB-PRS-OffOpt} as a subroutine, an approximate upper confidence bound (UCB) based algorithm is designed, which has instance independent and instance dependent regret upper bounds matching the corresponding lower bound up to factors of $ \sqrt{K \ln KT }$ and $α_1 K^2$ respectively. To this end, we address nontrivial technical challenges arising from optimizing and learning under a special nonlinear combinatorial utility function induced by the prioritized resource sharing mechanism.

</details>


### [9] [Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets](https://arxiv.org/abs/2512.21775)
*Matyas Bohacek,Ignacio Vilanova Echavarri*

Main category: cs.AI

TL;DR: 提出了一个评估数据集合规性的框架（CRS）和开源Python库，用于解决生成式AI数据集在透明度、问责制和安全性方面的伦理法律问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展依赖于大规模开源数据集，但这些数据集通常采用不透明、不受限制的数据收集方式。现有研究多关注模型开发和应用，而忽略了数据集创建的伦理法律考量。数据集在共享、编辑和复制过程中，其来源、合法性和安全性信息往往丢失。

Method: 提出了合规评级方案（CRS）框架，基于数据溯源技术开发了开源Python库，该框架评估数据集在透明度、问责制和安全性方面的合规性，并能集成到现有数据处理和AI训练流程中。

Result: 开发了一个既能反应性评估现有数据集CRS，又能前瞻性指导负责任数据抓取和构建新数据集的双重功能库，实现了对数据集合规性的系统性评估。

Conclusion: CRS框架和开源库填补了生成式AI数据集伦理法律评估的空白，为数据集的合规性提供了系统化评估工具，有助于促进更负责任的数据集创建和使用。

Abstract: Generative Artificial Intelligence (GAI) has experienced exponential growth in recent years, partly facilitated by the abundance of large-scale open-source datasets. These datasets are often built using unrestricted and opaque data collection practices. While most literature focuses on the development and applications of GAI models, the ethical and legal considerations surrounding the creation of these datasets are often neglected. In addition, as datasets are shared, edited, and further reproduced online, information about their origin, legitimacy, and safety often gets lost. To address this gap, we introduce the Compliance Rating Scheme (CRS), a framework designed to evaluate dataset compliance with critical transparency, accountability, and security principles. We also release an open-source Python library built around data provenance technology to implement this framework, allowing for seamless integration into existing dataset-processing and AI training pipelines. The library is simultaneously reactive and proactive, as in addition to evaluating the CRS of existing datasets, it equally informs responsible scraping and construction of new datasets.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [10] [A Reinforcement Learning Approach to Synthetic Data Generation](https://arxiv.org/abs/2512.21395)
*Natalia Espinosa-Dice,Nicholas J. Jackson,Chao Yan,Aaron Lee,Bradley A. Malin*

Main category: cs.LG

TL;DR: RLSyn：将合成数据生成重构为强化学习问题，在小样本生物医学数据场景中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有生成模型需要大量数据和复杂训练，限制了在小样本生物医学研究中的应用，需要更高效、稳定的合成数据生成方法

Method: 将合成数据生成重构为强化学习问题，使用随机策略建模数据生成器，通过近端策略优化和判别器奖励进行优化

Result: 在MIMIC-IV数据集上与扩散模型相当且优于GANs，在更小的AI-READI数据集上优于扩散模型和GANs

Conclusion: 强化学习为生物医学合成数据生成提供了原则性有效替代方案，特别适用于数据稀缺场景

Abstract: Synthetic data generation (SDG) is a promising approach for enabling data sharing in biomedical studies while preserving patient privacy. Yet, state-of-the-art generative models often require large datasets and complex training procedures, limiting their applicability in small-sample settings. In this work, we reframe SDG as a reinforcement learning (RL) problem and introduce RLSyn, a novel framework that models the data generator as a stochastic policy over patient records and optimizes it using Proximal Policy Optimization with discriminator-derived rewards, yielding more stable and data-efficient training. We evaluate RLSyn on two biomedical datasets - AI-READI and MIMIC-IV- and benchmark it against state-of-the-art generative adversarial networks (GANs) and diffusion-based methods across extensive privacy, utility, and fidelity evaluations. RL-Syn performs comparably to diffusion models and outperforms GANs on MIMIC-IV, while outperforming both diffusion models and GANs on the smaller AI-READI dataset. These results demonstrate that reinforcement learning provides a principled and effective alternative for synthetic biomedical data generation, particularly in data-scarce regimes.

</details>


### [11] [kooplearn: A Scikit-Learn Compatible Library of Algorithms for Evolution Operator Learning](https://arxiv.org/abs/2512.21409)
*Giacomo Turri,Grégoire Pacreau,Giacomo Meanti,Timothée Devergne,Daniel Ordonez,Erfan Mirzaei,Bruno Belucci,Karim Lounici,Vladimir Kostic,Massimiliano Pontil,Pietro Novelli*

Main category: cs.LG

TL;DR: kooplearn是一个机器学习库，实现了动态算子及其谱分解的线性、核和深度学习估计器，可用于分析动态系统、构建降阶模型和预测未来状态。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的机器学习库，用于估计动态系统的演化算子（Koopman/Transfer算子）和无穷小生成元，支持谱分析方法、数据驱动的降阶模型构建以及状态和可观测量的预测。

Method: 实现线性、核和深度学习估计器来学习离散时间演化算子和连续时间无穷小生成元，提供与scikit-learn兼容的API接口，并包含精选的基准数据集。

Result: 开发了kooplearn库，支持动态算子的估计和谱分解，能够分析动态系统、构建降阶模型并进行预测，同时提供了与现有机器学习工作流集成的标准化接口。

Conclusion: kooplearn为动态系统分析提供了一个全面的机器学习工具包，通过统一的API和基准数据集促进了算法的公平比较和可重复性研究。

Abstract: kooplearn is a machine-learning library that implements linear, kernel, and deep-learning estimators of dynamical operators and their spectral decompositions. kooplearn can model both discrete-time evolution operators (Koopman/Transfer) and continuous-time infinitesimal generators. By learning these operators, users can analyze dynamical systems via spectral methods, derive data-driven reduced-order models, and forecast future states and observables. kooplearn's interface is compliant with the scikit-learn API, facilitating its integration into existing machine learning and data science workflows. Additionally, kooplearn includes curated benchmark datasets to support experimentation, reproducibility, and the fair comparison of learning algorithms. The software is available at https://github.com/Machine-Learning-Dynamical-Systems/kooplearn.

</details>


### [12] [MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding](https://arxiv.org/abs/2512.21506)
*Aiwei Zhang,Arvind Pillai,Andrew Campbell,Nicholas C. Jacobson*

Main category: cs.LG

TL;DR: MotionTeller是一个将可穿戴设备活动数据转换为自然语言摘要的生成框架，通过预训练的活动记录编码器和轻量级投影模块，将行为嵌入映射到冻结LLM的token空间，实现自由文本生成。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴传感技术日益普及，如何从原始生理信号（如加速度计收集的分钟级运动数据）生成自然语言摘要成为一个关键挑战。需要将原始传感器数据转化为人类可理解的行为描述。

Method: MotionTeller结合了预训练的活动记录编码器和轻量级投影模块，将行为嵌入映射到冻结解码器LLM的token空间。使用从真实世界NHANES记录构建的54383个（活动记录，文本）对数据集，仅对语言token进行交叉熵损失监督训练。

Result: MotionTeller实现了高语义保真度（BERTScore-F1 = 0.924）和词汇准确性（ROUGE-1 = 0.722），比基于提示的基线方法在ROUGE-1上高出7%。平均训练损失在第15个epoch收敛到0.38，表明优化稳定。定性分析确认模型能捕捉昼夜节律结构和行为转换。

Conclusion: MotionTeller作为一个可扩展、可解释的系统，能够将可穿戴传感器数据转化为流畅、以人为中心的描述，为行为监测、临床审查和个性化健康干预开辟了新途径。

Abstract: As wearable sensing becomes increasingly pervasive, a key challenge remains: how can we generate natural language summaries from raw physiological signals such as actigraphy - minute-level movement data collected via accelerometers? In this work, we introduce MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs). MotionTeller combines a pretrained actigraphy encoder with a lightweight projection module that maps behavioral embeddings into the token space of a frozen decoder-only LLM, enabling free-text, autoregressive generation of daily behavioral summaries. We construct a novel dataset of 54383 (actigraphy, text) pairs derived from real-world NHANES recordings, and train the model using cross-entropy loss with supervision only on the language tokens. MotionTeller achieves high semantic fidelity (BERTScore-F1 = 0.924) and lexical accuracy (ROUGE-1 = 0.722), outperforming prompt-based baselines by 7 percent in ROUGE-1. The average training loss converges to 0.38 by epoch 15, indicating stable optimization. Qualitative analysis confirms that MotionTeller captures circadian structure and behavioral transitions, while PCA plots reveal enhanced cluster alignment in embedding space post-training. Together, these results position MotionTeller as a scalable, interpretable system for transforming wearable sensor data into fluent, human-centered descriptions, introducing new pathways for behavioral monitoring, clinical review, and personalized health interventions.

</details>


### [13] [dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning](https://arxiv.org/abs/2512.21446)
*Shirui Chen,Jiantao Jiao,Lillian J. Ratliff,Banghua Zhu*

Main category: cs.LG

TL;DR: dUltra是一个基于强化学习的框架，通过优化去掩码策略实现扩散语言模型的高效并行解码，在数学推理和代码生成任务上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的掩码扩散语言模型虽然具有并行生成潜力，但实际解码效率有限（通常每轮少于5个token），采样速度与自回归模型+推测解码方案相当。现有的蒸馏加速方法存在离策略问题，且性能受限于基础模型的样本质量。

Method: 提出dUltra框架，基于组相对策略优化（GRPO）进行在策略强化学习。引入去掩码规划器头，在独立伯努利分布下预测每个token的去掩码概率。联合优化基础扩散LLM和去掩码顺序规划器，使用可验证奖励、蒸馏奖励和去掩码步骤数组合的奖励信号。

Result: 在数学推理和代码生成任务上，dUltra在准确率-效率权衡方面超越了最先进的启发式和蒸馏基线方法，朝着实现"扩散模型对自回归模型的优势"迈进。

Conclusion: dUltra通过强化学习框架有效解决了掩码扩散语言模型的并行解码效率问题，为扩散模型超越自回归模型提供了有前景的技术路径。

Abstract: Masked diffusion language models (MDLMs) offer the potential for parallel token generation, but most open-source MDLMs decode fewer than 5 tokens per model forward pass even with sophisticated sampling strategies. As a result, their sampling speeds are often comparable to AR + speculative decoding schemes, limiting their advantage over mainstream autoregressive approaches. Existing distillation-based accelerators (dParallel, d3LLM) finetune MDLMs on trajectories generated by a base model, which can become off-policy during finetuning and restrict performance to the quality of the base model's samples. We propose \texttt{dUltra}, an on-policy reinforcement learning framework based on Group Relative Policy Optimization (GRPO) that learns unmasking strategies for efficient parallel decoding. dUltra introduces an unmasking planner head that predicts per-token unmasking likelihoods under independent Bernoulli distributions. We jointly optimize the base diffusion LLM and the unmasking order planner using reward signals combining verifiable reward, distillation reward, and the number of unmasking steps. Across mathematical reasoning and code generation tasks, dUltra improves the accuracy--efficiency trade-off over state-of-the-art heuristic and distillation baselines, moving towards achieving ``diffusion supremacy'' over autoregressive models.

</details>


### [14] [RLLaVA: An RL-central Framework for Language and Vision Assistants](https://arxiv.org/abs/2512.21450)
*Lei Zhao,Zihao Ma,Boyu Lin,Yuhe Liu,Wenjun Wu,Lei Huang*

Main category: cs.LG

TL;DR: RLLaVA是一个将强化学习算法逻辑与模型架构和分布式执行解耦的框架，支持研究人员用最少的代码实现新RL算法，并兼容广泛的RL方法和视觉语言模型，使1B-7B模型在普通GPU上的资源高效训练成为可能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言助手训练框架通常将RL算法与特定模型架构和训练引擎紧密耦合，这限制了研究人员快速实验新算法和利用不同视觉语言模型的能力。需要一种更灵活、资源高效的框架来支持多模态和智能体任务的RL训练。

Method: RLLaVA采用马尔可夫决策过程（MDP）的表述，将RL算法逻辑从模型架构和分布式执行中解耦。框架支持广泛的RL方法和视觉语言模型，保持对特定训练和推理引擎的不可知性，使研究人员能够用最少的代码实现新算法。

Result: RLLaVA使1B-7B规模模型在普通GPU上的资源高效训练成为可能，特别是4B规模的模型可以在单个24GB GPU上进行端到端的全参数更新训练。在多模态和智能体任务上的实验表明，RLLaVA具有任务可扩展性，使用它训练的模型性能始终优于基础模型，与其他专门设计的RL框架竞争力相当。

Conclusion: RLLaVA提供了一个灵活、高效的RL框架，支持视觉语言助手的训练，使研究人员能够轻松实验新算法并利用不同模型，同时保持资源效率。该框架为多模态RL研究提供了有价值的工具。

Abstract: We present an RL-central framework for Language and Vision Assistants (RLLaVA) with its formulation of Markov decision process (MDP). RLLaVA decouples RL algorithmic logic from model architecture and distributed execution, supporting researchers in implementing new RL algorithms with minimal code, and to plug in a broad family of RL methods and vision-language models (VLMs) while remaining agnostic to specific training and inference engines. RLLaVA makes resource-efficient training of 1B--7B models feasible on common GPUs; notably, 4B-scale models can be trained end-to-end with full-parameter updates on a single 24GB GPU. Experiments on multi-modal and agentic tasks demonstrate that RLLaVA has task extensibility, and the models trained with it consistently improve performance over base models, competitive with other specially engineered RL frameworks. The code is available at https://github.com/TinyLoopX/RLLaVA.

</details>


### [15] [Statistical vs. Deep Learning Models for Estimating Substance Overdose Excess Mortality in the US](https://arxiv.org/abs/2512.21456)
*Sukanya Krishna,Marie-Laure Charpignon,Maimuna Majumder*

Main category: cs.LG

TL;DR: 该研究系统比较了SARIMA与三种深度学习模型在预测美国药物过量死亡率方面的表现，发现LSTM在疫情导致的体制变化下具有更优的预测准确性和不确定性校准能力。


<details>
  <summary>Details</summary>
Motivation: 美国药物过量死亡率在2023年超过8万人，COVID-19大流行通过医疗中断和行为改变加剧了现有趋势。传统统计方法如SARIMA假设线性、平稳性和固定季节性，这些假设在结构性中断下可能不成立，需要更有效的预测方法来评估大流行影响并指导干预策略。

Method: 使用CDC国家数据（2015-2019年用于训练/验证，2020-2023年用于预测），系统比较SARIMA与三种深度学习架构（LSTM、Seq2Seq和Transformer）。研究采用可重复的流程，包含符合预测区间和60多次试验的收敛分析，并提供了可部署于15个州卫生部门的开源框架。

Result: LSTM在点估计方面表现最优（MAPE为17.08%，而SARIMA为23.88%），并且在不确定性校准方面更好（预测区间覆盖率为68.8%，而SARIMA为47.9%）。基于注意力的模型（Seq2Seq、Transformer）表现不佳，因为它们过度拟合历史均值而非捕捉新兴趋势。

Conclusion: 经过仔细验证的深度学习模型可以为公共卫生规划提供比传统方法更可靠的反事实估计，同时强调了在高风险领域部署神经预测时需要校准技术的重要性。

Abstract: Substance overdose mortality in the United States claimed over 80,000 lives in 2023, with the COVID-19 pandemic exacerbating existing trends through healthcare disruptions and behavioral changes. Estimating excess mortality, defined as deaths beyond expected levels based on pre-pandemic patterns, is essential for understanding pandemic impacts and informing intervention strategies. However, traditional statistical methods like SARIMA assume linearity, stationarity, and fixed seasonality, which may not hold under structural disruptions. We present a systematic comparison of SARIMA against three deep learning (DL) architectures (LSTM, Seq2Seq, and Transformer) for counterfactual mortality estimation using national CDC data (2015-2019 for training/validation, 2020-2023 for projection). We contribute empirical evidence that LSTM achieves superior point estimation (17.08% MAPE vs. 23.88% for SARIMA) and better-calibrated uncertainty (68.8% vs. 47.9% prediction interval coverage) when projecting under regime change. We also demonstrate that attention-based models (Seq2Seq, Transformer) underperform due to overfitting to historical means rather than capturing emergent trends. Ourreproducible pipeline incorporates conformal prediction intervals and convergence analysis across 60+ trials per configuration, and we provide an open-source framework deployable with 15 state health departments. Our findings establish that carefully validated DL models can provide more reliable counterfactual estimates than traditional methods for public health planning, while highlighting the need for calibration techniques when deploying neural forecasting in high-stakes domains.

</details>


### [16] [Missing Pattern Tree based Decision Grouping and Ensemble for Deep Incomplete Multi-View Clustering](https://arxiv.org/abs/2512.21510)
*Wenyuan Yang,Jie Xu,Hongqing He,Jiangzhang Gan,Xiaofeng Zhu*

Main category: cs.LG

TL;DR: TreeEIC：基于缺失模式树的IMVC框架，通过分组决策集、决策集成和知识蒸馏，解决多视图聚类中不一致缺失模式导致的配对利用不足问题


<details>
  <summary>Details</summary>
Motivation: 现实世界多视图数据通常存在高度不一致的缺失模式，现有IMVC方法（基于填补和免填补）忽视了配对利用不足问题，即不一致缺失模式使得可用的多视图配对无法被充分利用，限制了模型性能

Method: 1) 定义缺失模式树模型，根据不同缺失模式将数据分组到多个决策集；2) 在每个决策集内进行多视图聚类；3) 提出多视图决策集成模块，基于不确定性权重抑制不可靠聚类决策；4) 设计集成到个体的知识蒸馏模块，通过优化跨视图一致性和簇间区分度损失实现相互促进

Result: 在多个基准数据集上的广泛实验表明，TreeEIC实现了最先进的IMVC性能，并在高度不一致缺失模式下表现出优越的鲁棒性

Conclusion: TreeEIC通过充分利用可用多视图配对、集成可靠决策和知识蒸馏，有效解决了不完全多视图聚类中的配对利用不足问题，提升了聚类性能和鲁棒性

Abstract: Real-world multi-view data usually exhibits highly inconsistent missing patterns which challenges the effectiveness of incomplete multi-view clustering (IMVC). Although existing IMVC methods have made progress from both imputation-based and imputation-free routes, they have overlooked the pair under-utilization issue, i.e., inconsistent missing patterns make the incomplete but available multi-view pairs unable to be fully utilized, thereby limiting the model performance. To address this, we propose a novel missing-pattern tree based IMVC framework entitled TreeEIC. Specifically, to achieve full exploitation of available multi-view pairs, TreeEIC first defines the missing-pattern tree model to group data into multiple decision sets according to different missing patterns, and then performs multi-view clustering within each set. Furthermore, a multi-view decision ensemble module is proposed to aggregate clustering results from all decision sets, which infers uncertainty-based weights to suppress unreliable clustering decisions and produce robust decisions. Finally, an ensemble-to-individual knowledge distillation module transfers the ensemble knowledge to view-specific clustering models, which enables ensemble and individual modules to promote each other by optimizing cross-view consistency and inter-cluster discrimination losses. Extensive experiments on multiple benchmark datasets demonstrate that our TreeEIC achieves state-of-the-art IMVC performance and exhibits superior robustness under highly inconsistent missing patterns.

</details>


### [17] [Global-Graph Guided and Local-Graph Weighted Contrastive Learning for Unified Clustering on Incomplete and Noise Multi-View Data](https://arxiv.org/abs/2512.21516)
*Hongqing He,Jie Xu,Wenyuan Yang,Yonghua Zhu,Guoqiu Wen,Xiaofeng Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种统一的对比学习多视图聚类框架，通过全局图引导和局部图加权对比学习来解决不完整和噪声多视图数据中的样本配对问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多视图数据常常存在不完整或噪声问题，导致样本配对稀少或错误配对，这严重影响了基于对比学习的多视图聚类效果。稀少配对问题阻碍了多视图互补信息的充分提取，而错误配对问题则导致对比学习在错误方向上优化模型。

Method: 提出统一的对比学习多视图聚类框架：1) 针对稀少配对问题，设计全局图引导对比学习，所有视图样本构建全局视图亲和图以形成新的样本对；2) 针对错误配对问题，提出局部图加权对比学习，利用局部邻居生成配对权重来自适应增强或减弱配对对比学习。该方法无需插补，可集成到统一的全局-局部图引导对比学习框架中。

Result: 在不完整和噪声设置下的多视图数据上进行广泛实验，结果表明该方法相比现有最先进方法取得了优越的性能。

Conclusion: 提出的统一对比学习框架有效解决了不完整和噪声多视图数据中的样本配对问题，通过全局图引导和局部图加权机制显著提升了多视图聚类效果。

Abstract: Recently, contrastive learning (CL) plays an important role in exploring complementary information for multi-view clustering (MVC) and has attracted increasing attention. Nevertheless, real-world multi-view data suffer from data incompleteness or noise, resulting in rare-paired samples or mis-paired samples which significantly challenges the effectiveness of CL-based MVC. That is, rare-paired issue prevents MVC from extracting sufficient multi-view complementary information, and mis-paired issue causes contrastive learning to optimize the model in the wrong direction. To address these issues, we propose a unified CL-based MVC framework for enhancing clustering effectiveness on incomplete and noise multi-view data. First, to overcome the rare-paired issue, we design a global-graph guided contrastive learning, where all view samples construct a global-view affinity graph to form new sample pairs for fully exploring complementary information. Second, to mitigate the mis-paired issue, we propose a local-graph weighted contrastive learning, which leverages local neighbors to generate pair-wise weights to adaptively strength or weaken the pair-wise contrastive learning. Our method is imputation-free and can be integrated into a unified global-local graph-guided contrastive learning framework. Extensive experiments on both incomplete and noise settings of multi-view data demonstrate that our method achieves superior performance compared with state-of-the-art approaches.

</details>


### [18] [First Provable Guarantees for Practical Private FL: Beyond Restrictive Assumptions](https://arxiv.org/abs/2512.21521)
*Egor Shulgin,Grigory Malinovsky,Sarit Khirirat,Peter Richtárik*

Main category: cs.LG

TL;DR: Fed-α-NormEC是首个在标准假设下提供可证明收敛性和差分隐私保证的联邦学习框架，支持本地更新、部分客户端参与等实际特性


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私联邦学习方法依赖不现实的假设（如有界梯度或同质性），且通常忽略实际FL特性如多轮本地更新和部分客户端参与，阻碍了实际应用

Method: 提出Fed-α-NormEC框架，整合本地更新（完整和增量梯度步骤）、独立的服务器和客户端步长，关键支持部分客户端参与，这对实际部署至关重要且有助于隐私放大

Result: 理论分析提供了收敛性和差分隐私保证，实验在私有深度学习任务上验证了框架的有效性

Conclusion: Fed-α-NormEC是首个在标准假设下同时支持实际FL特性并提供可证明隐私保证的框架，为实际部署提供了可行的解决方案

Abstract: Federated Learning (FL) enables collaborative training on decentralized data. Differential privacy (DP) is crucial for FL, but current private methods often rely on unrealistic assumptions (e.g., bounded gradients or heterogeneity), hindering practical application. Existing works that relax these assumptions typically neglect practical FL features, including multiple local updates and partial client participation. We introduce Fed-$α$-NormEC, the first differentially private FL framework providing provable convergence and DP guarantees under standard assumptions while fully supporting these practical features. Fed-$α$-NormE integrates local updates (full and incremental gradient steps), separate server and client stepsizes, and, crucially, partial client participation, which is essential for real-world deployment and vital for privacy amplification. Our theoretical guarantees are corroborated by experiments on private deep learning tasks.

</details>


### [19] [Generative Actor Critic](https://arxiv.org/abs/2512.21527)
*Aoyang Qin,Deqian Kong,Wei Wang,Ying Nian Wu,Song-Chun Zhu,Sirui Xie*

Main category: cs.LG

TL;DR: GAC框架将序列决策解耦为学习轨迹-回报联合分布的生成模型和基于该模型的推理，通过潜在计划向量实现利用和探索，在离线到在线学习中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习算法主要关注估计或最大化期望回报，在将离线预训练模型与在线经验结合时面临挑战，需要新的框架来更好地处理离线到在线的学习过程。

Method: 提出生成式演员评论家(GAC)框架：1) 将策略评估重构为学习轨迹和回报的联合分布p(τ,y)；2) 将策略改进重构为对该学习模型进行灵活推理；3) 基于潜在变量模型实现，使用连续潜在计划向量；4) 开发新颖推理策略：利用阶段优化潜在计划以最大化期望回报，探索阶段采样条件于动态调整目标回报的潜在计划。

Result: 在Gym-MuJoCo和Maze2D基准测试中，GAC展现出强大的离线性能，并且在离线到在线的改进方面显著优于最先进方法，即使在缺乏逐步奖励的情况下也表现良好。

Conclusion: GAC通过将序列决策解耦为生成建模和推理，提供了一种有效的离线到在线学习框架，能够同时处理利用和探索，在强化学习任务中表现出优越性能。

Abstract: Conventional Reinforcement Learning (RL) algorithms, typically focused on estimating or maximizing expected returns, face challenges when refining offline pretrained models with online experiences. This paper introduces Generative Actor Critic (GAC), a novel framework that decouples sequential decision-making by reframing \textit{policy evaluation} as learning a generative model of the joint distribution over trajectories and returns, $p(τ, y)$, and \textit{policy improvement} as performing versatile inference on this learned model. To operationalize GAC, we introduce a specific instantiation based on a latent variable model that features continuous latent plan vectors. We develop novel inference strategies for both \textit{exploitation}, by optimizing latent plans to maximize expected returns, and \textit{exploration}, by sampling latent plans conditioned on dynamically adjusted target returns. Experiments on Gym-MuJoCo and Maze2D benchmarks demonstrate GAC's strong offline performance and significantly enhanced offline-to-online improvement compared to state-of-the-art methods, even in absence of step-wise rewards.

</details>


### [20] [AVP-Fusion: Adaptive Multi-Modal Fusion and Contrastive Learning for Two-Stage Antiviral Peptide Identification](https://arxiv.org/abs/2512.21544)
*Xinru Wen,Weizhong Lin,Xuan Xiao*

Main category: cs.LG

TL;DR: AVP-Fusion是一个用于识别抗病毒肽的两阶段深度学习框架，通过自适应特征融合和对比学习，在基准数据集上实现了0.9531的准确率和0.9064的MCC，优于现有方法，并能预测病毒家族和特定病毒。


<details>
  <summary>Details</summary>
Motivation: 当前计算方法难以捕捉复杂的序列依赖关系，也无法有效处理模糊、难以分类的样本，这阻碍了抗病毒肽的准确识别和新型药物开发。

Method: 提出AVP-Fusion两阶段深度学习框架：1）构建包含10种描述符的全景特征空间；2）引入自适应门控机制动态调节CNN提取的局部基序和BiLSTM捕获的全局依赖权重；3）采用基于在线难例挖掘和BLOSUM62数据增强的对比学习策略；4）第二阶段利用迁移学习进行病毒家族和特定病毒的子类预测。

Result: 在基准数据集Set 1上，AVP-Fusion实现了0.9531的准确率和0.9064的MCC，显著优于现有最先进方法。即使在样本量有限的情况下，也能精确预测6个病毒家族和8种特定病毒。

Conclusion: AVP-Fusion作为一个强大且可解释的工具，能够用于高通量抗病毒药物筛选，解决了传统方法在序列依赖性和模糊样本处理方面的局限性。

Abstract: Accurate identification of antiviral peptides (AVPs) is critical for accelerating novel drug development. However, current computational methods struggle to capture intricate sequence dependencies and effectively handle ambiguous, hard-to-classify samples. To address these challenges, we propose AVP-Fusion, a novel two-stage deep learning framework integrating adaptive feature fusion and contrastive learning. Unlike traditional static feature concatenation, we construct a panoramic feature space using 10 distinct descriptors and introduce an Adaptive Gating Mechanism.This mechanism dynamically regulates the weights of local motifs extracted by CNNs and global dependencies captured by BiLSTMs based on sequence context. Furthermore, to address data distribution challenges, we employ a contrastive learning strategy driven by Online Hard Example Mining (OHEM) and BLOSUM62-based data augmentation, which significantly sharpens the model's decision boundaries. Experimental results on the benchmark Set 1 dataset demonstrate that AVP-Fusion achieves an accuracy of 0.9531 and an MCC of 0.9064, significantly outperforming state-of-the-art methods. In the second stage, leveraging transfer learning, the model enables precise subclass prediction for six viral families and eight specific viruses, even under limited sample sizes. In summary, AVP-Fusion serves as a robust and interpretable tool for high-throughput antiviral drug screening.

</details>


### [21] [Discovering Sparse Recovery Algorithms Using Neural Architecture Search](https://arxiv.org/abs/2512.21563)
*Patrick Yubeaton,Sarthak Gupta,M. Salman Asif,Chinmay Hegde*

Main category: cs.LG

TL;DR: 本文提出使用元学习工具（如神经架构搜索）自动发现信号处理中的逆问题求解算法，以ISTA和FISTA算法为案例，展示了框架能够从超过5万个变量的搜索空间中重新发现这些算法的关键元素。


<details>
  <summary>Details</summary>
Motivation: 设计信号处理中逆问题求解的新算法是一项极其困难、依赖启发式方法且耗时的工作，需要寻找更自动化的算法发现方法。

Method: 开发了一个元学习框架，利用神经架构搜索（NAS）等工具，在包含超过50,000个变量的搜索空间中重新发现ISTA和FISTA算法的关键元素。

Result: 框架成功重新发现了ISTA和FISTA算法的多个关键元素，并展示了该框架可以应用于除ISTA/FISTA之外的各种数据分布和算法。

Conclusion: 元学习框架为信号处理中的算法自动发现提供了有效途径，能够显著减少算法设计的时间和启发式依赖，具有扩展到更广泛算法类别的潜力。

Abstract: The design of novel algorithms for solving inverse problems in signal processing is an incredibly difficult, heuristic-driven, and time-consuming task. In this short paper, we the idea of automated algorithm discovery in the signal processing context through meta-learning tools such as Neural Architecture Search (NAS). Specifically, we examine the Iterative Shrinkage Thresholding Algorithm (ISTA) and its accelerated Fast ISTA (FISTA) variant as candidates for algorithm rediscovery. We develop a meta-learning framework which is capable of rediscovering (several key elements of) the two aforementioned algorithms when given a search space of over 50,000 variables. We then show how our framework can apply to various data distributions and algorithms besides ISTA/FISTA.

</details>


### [22] [Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search](https://arxiv.org/abs/2512.21648)
*Maximilian Weichart*

Main category: cs.LG

TL;DR: 该论文提出了Inverse-RPO方法，能够系统地从任何无先验UCB推导出基于先验的UCT树策略，并应用于方差感知的UCB-V，得到两种新的基于先验的树策略，在多个基准测试中优于PUCT。


<details>
  <summary>Details</summary>
Motivation: AlphaZero的成功部分归功于PUCT中引入的先验项，但PUCT是经验性推导而非基于第一原理。虽然存在许多理论保证更强的UCB变体，但将它们扩展到基于先验的UCT一直很困难。最近的研究通过将MCTS框架化为正则化策略优化问题来回顾性证明PUCT，这为系统化推导基于先验的UCT提供了理论基础。

Method: 提出了Inverse-RPO方法，这是一种从任何无先验UCB系统推导基于先验UCT的通用方法。将该方法应用于方差感知的UCB-V，得到了两种新的基于先验的树策略：一种使用先验方差估计，另一种使用后验方差估计。这些策略将方差信息整合到搜索过程中。

Result: 实验表明，这些方差感知的基于先验UCT在多个基准测试中优于PUCT，且没有增加额外的计算成本。作者还扩展了mctx库以支持方差感知UCT，代码改动最小，便于进一步研究。

Conclusion: Inverse-RPO为从任何无先验UCB推导基于先验的UCT提供了系统化方法，得到的方差感知UCT在性能上优于PUCT，为MCTS搜索策略的设计提供了新的理论框架和实用工具。

Abstract: Monte Carlo Tree Search (MCTS) has profoundly influenced reinforcement learning (RL) by integrating planning and learning in tasks requiring long-horizon reasoning, exemplified by the AlphaZero family of algorithms. Central to MCTS is the search strategy, governed by a tree policy based on an upper confidence bound (UCB) applied to trees (UCT). A key factor in the success of AlphaZero is the introduction of a prior term in the UCB1-based tree policy PUCT, which improves exploration efficiency and thus accelerates training. While many alternative UCBs with stronger theoretical guarantees than UCB1 exist, extending them to prior-based UCTs has been challenging, since PUCT was derived empirically rather than from first principles. Recent work retrospectively justified PUCT by framing MCTS as a regularized policy optimization (RPO) problem. Building on this perspective, we introduce Inverse-RPO, a general methodology that systematically derives prior-based UCTs from any prior-free UCB. Applying this method to the variance-aware UCB-V, we obtain two new prior-based tree policies that incorporate variance estimates into the search. Experiments indicate that these variance-aware prior-based UCTs outperform PUCT across multiple benchmarks without incurring additional computational cost. We also provide an extension of the mctx library supporting variance-aware UCTs, showing that the required code changes are minimal and intended to facilitate further research on principled prior-based UCTs. Code: github.com/Max-We/inverse-rpo.

</details>


### [23] [Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations](https://arxiv.org/abs/2512.21586)
*Xin Liu,Haoran Li,Dongbin Zhao*

Main category: cs.LG

TL;DR: BCV-LR：通过潜在表示从视频中进行行为克隆的无监督框架，仅需少量交互即可实现高效模仿学习


<details>
  <summary>Details</summary>
Motivation: 人类能从少量视频中高效学习技能，但自主智能体面临视觉输入复杂、缺乏动作/奖励信号、交互步骤有限等挑战，需要开发无监督、样本高效的视频模仿学习方法

Method: BCV-LR框架：1) 通过自监督任务从高维视频提取动作相关潜在特征；2) 基于动态的无监督目标预测连续帧间的潜在动作；3) 在线微调潜在动作与真实动作空间对齐；4) 克隆策略丰富智能体经验，形成迭代策略改进循环

Result: 在离散和连续控制任务上，BCV-LR仅需少量交互即可达到有效（部分任务达到专家级）策略性能，在24/28任务上样本效率超越现有ILV基线和强化学习方法

Conclusion: 首次证明视频可在无需专家监督的情况下支持极端样本高效的视觉策略学习，为无监督模仿学习提供了新范式

Abstract: Humans can efficiently extract knowledge and learn skills from the videos within only a few trials and errors. However, it poses a big challenge to replicate this learning process for autonomous agents, due to the complexity of visual input, the absence of action or reward signals, and the limitations of interaction steps. In this paper, we propose a novel, unsupervised, and sample-efficient framework to achieve imitation learning from videos (ILV), named Behavior Cloning from Videos via Latent Representations (BCV-LR). BCV-LR extracts action-related latent features from high-dimensional video inputs through self-supervised tasks, and then leverages a dynamics-based unsupervised objective to predict latent actions between consecutive frames. The pre-trained latent actions are fine-tuned and efficiently aligned to the real action space online (with collected interactions) for policy behavior cloning. The cloned policy in turn enriches the agent experience for further latent action finetuning, resulting in an iterative policy improvement that is highly sample-efficient.
  We conduct extensive experiments on a set of challenging visual tasks, including both discrete control and continuous control. BCV-LR enables effective (even expert-level on some tasks) policy performance with only a few interactions, surpassing state-of-the-art ILV baselines and reinforcement learning methods (provided with environmental rewards) in terms of sample efficiency across 24/28 tasks. To the best of our knowledge, this work for the first time demonstrates that videos can support extremely sample-efficient visual policy learning, without the need to access any other expert supervision.

</details>


### [24] [An Information Theoretic Perspective on Agentic System Design](https://arxiv.org/abs/2512.21720)
*Shizhe He,Avanika Narayan,Ishan S. Khare,Scott W. Linderman,Christopher Ré,Dan Biderman*

Main category: cs.LG

TL;DR: 该论文提出了一种信息论框架来分析压缩器-预测器语言模型系统，通过互信息量化压缩质量，发现更大的压缩器不仅更准确，而且更高效，能够显著降低API成本。


<details>
  <summary>Details</summary>
Motivation: 当前基于多语言模型的智能系统（如"深度研究"和"Claude Code"）普遍采用压缩器-预测器架构，但系统设计缺乏理论指导，性能评估需要昂贵的任务特定配对扫描。需要一种任务无关的方法来量化压缩质量并指导系统设计。

Method: 将压缩器语言模型视为噪声信道，引入上下文与其压缩之间互信息的简单估计器来量化压缩质量。通过信息论框架，在五个数据集和三个模型家族上进行全面的实证分析。

Result: 互信息强烈预测下游性能，与具体任务无关。更大的压缩器不仅更准确，而且更令牌高效，每个令牌传递更多比特的互信息。例如，7B Qwen-2.5压缩器比其1.5B版本准确度提高1.6倍，简洁度提高4.6倍，每个令牌传递的互信息提高5.5倍。压缩器扩展比预测器扩展更有效，使更大的本地压缩器能与更小的云预测器配对。

Conclusion: 信息论框架为压缩器-预测器系统设计提供了理论指导，使本地小至3B参数的压缩器能够恢复前沿语言模型99%的准确度，同时降低74%的API成本，为高效智能系统设计提供了实用原则。

Abstract: Agentic language model (LM) systems power modern applications like "Deep Research" and "Claude Code," and leverage multi-LM architectures to overcome context limitations. Beneath their apparent diversity lies a recurring pattern: smaller "compressor" LMs (that can even run locally) distill raw context into compact text that is then consumed by larger "predictor" LMs. Despite their popularity, the design of compressor-predictor systems remains largely ad hoc, with little guidance on how compressor and predictor choices shape downstream performance. In practice, attributing gains to compression versus prediction requires costly, task-specific pairwise sweeps. We argue that these agentic system design questions are, at root, information-theoretic. Viewing the compressor LM as a noisy channel, we introduce a simple estimator of mutual information between the context and its compression to quantify compression quality in a task-independent way. We show that mutual information strongly predicts downstream performance, independent of any specific task. Through an information-theoretic framework, we perform a comprehensive empirical analysis across five datasets and three model families. Results reveal that larger compressors not only are more accurate, but also more token-efficient, conveying more bits of information per token. A 7B Qwen-2.5 compressor, for instance, is $1.6\times$ more accurate, $4.6\times$ more concise, and conveys $5.5\times$ more bits of mutual information per token than its 1.5B sibling. Across datasets, scaling compressors is substantially more effective than scaling predictors, enabling larger on-device compressors to pair with smaller cloud predictors. Applied to a Deep Research system, these principles enable local compressors as small as 3B parameters to recover $99\%$ of frontier-LM accuracy at $26\%$ of API costs.

</details>


### [25] [A Data-Driven Multi-Objective Approach for Predicting Mechanical Performance, Flowability, and Porosity in Ultra-High-Performance Concrete (UHPC)](https://arxiv.org/abs/2512.21610)
*Jagaran Chakma,Zhiguang Zhou,Jyoti Chakma,Cao YuSen*

Main category: cs.LG

TL;DR: 提出基于XGBoost的数据驱动多目标框架，用于预测超高性能混凝土的力学性能、流动性和孔隙率，通过特征工程和模型优化显著提高预测精度，并开发GUI界面辅助材料设计。


<details>
  <summary>Details</summary>
Motivation: 超高性能混凝土的混合设计通常需要大量实验测试，成本高且耗时。本研究旨在开发一个数据驱动的预测框架，减少实验需求，提高设计效率。

Method: 采用两阶段方法：1）从21种机器学习算法中筛选出XGBoost作为最佳模型；2）数据清洗包括去除多重共线性特征、使用孤立森林识别异常值、SHAP分析进行特征选择；3）使用随机搜索和K折交叉验证进行超参数调优；4）开发图形用户界面。

Result: XGBoost模型在所有输出指标上均达到高预测精度，经过特征工程优化后的模型2性能进一步提升。该框架显著减少了超高性能混凝土设计所需的实验测试量。

Conclusion: 提出的数据驱动多目标框架能够准确预测超高性能混凝土性能，为材料设计师提供有效工具，降低实验成本，提高混合设计效率。

Abstract: This study presents a data-driven, multi-objective approach to predict the mechanical performance, flow ability, and porosity of Ultra-High-Performance Concrete (UHPC). Out of 21 machine learning algorithms tested, five high-performing models are selected, with XGBoost showing the best accuracy after hyperparameter tuning using Random Search and K-Fold Cross-Validation. The framework follows a two-stage process: the initial XGBoost model is built using raw data, and once selected as the final model, the dataset is cleaned by (1) removing multicollinear features, (2) identifying outliers with Isolation Forest, and (3) selecting important features using SHAP analysis. The refined dataset as model 2 is then used to retrain XGBoost, which achieves high prediction accuracy across all outputs. A graphical user interface (GUI) is also developed to support material designers. Overall, the proposed framework significantly improves the prediction accuracy and minimizes the need for extensive experimental testing in UHPC mix design.

</details>


### [26] [A Comedy of Estimators: On KL Regularization in RL Training of LLMs](https://arxiv.org/abs/2512.21852)
*Vedant Shah,Johan Obando-Ceron,Vineet Jain,Brian Bartoldson,Bhavya Kailkhura,Sarthak Mittal,Glen Berseth,Pablo Samuel Castro,Yoshua Bengio,Nikolay Malkin,Moksh Jain,Siddarth Venkatraman,Aaron Courville*

Main category: cs.LG

TL;DR: 本文系统分析了LLM强化学习中KL散度估计器的不同配置方式对梯度偏差的影响，发现梯度无偏的估计器配置能带来更好的训练稳定性和性能表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLM强化学习训练中广泛使用KL散度正则化项，但实践中使用的各种KL估计器配置缺乏系统研究，且现有实践存在目标函数与实现之间的梯度偏差问题，需要深入分析不同配置对训练效果的影响。

Method: 通过理论分析不同KL估计器配置的梯度特性，揭示设计选择如何影响梯度偏差；然后通过实验验证，使用Qwen2.5-7B、Llama-3.1-8B-Instruct和Qwen3-4B-Instruct-2507等模型进行RL微调，在不同配置下评估其在分布内和分布外任务上的性能表现。

Result: 在在线策略设置中：(1)梯度有偏的估计器配置会导致训练不稳定；(2)使用梯度无偏的估计器配置在分布内和分布外任务上都能获得更好的性能。在离线策略设置中，KL正则化有助于稳定异步设置导致的离线策略RL训练。

Conclusion: KL估计器配置的选择对LLM强化学习训练效果有重要影响，梯度无偏的配置能带来更好的训练稳定性和泛化性能，为实际应用提供了指导原则。

Abstract: The reasoning performance of large language models (LLMs) can be substantially improved by training them with reinforcement learning (RL). The RL objective for LLM training involves a regularization term, which is the reverse Kullback-Leibler (KL) divergence between the trained policy and the reference policy. Since computing the KL divergence exactly is intractable, various estimators are used in practice to estimate it from on-policy samples. Despite its wide adoption, including in several open-source libraries, there is no systematic study analyzing the numerous ways of incorporating KL estimators in the objective and their effect on the downstream performance of RL-trained models. Recent works show that prevailing practices for incorporating KL regularization do not provide correct gradients for stated objectives, creating a discrepancy between the objective and its implementation. In this paper, we further analyze these practices and study the gradients of several estimators configurations, revealing how design choices shape gradient bias. We substantiate these findings with empirical observations by RL fine-tuning \texttt{Qwen2.5-7B}, \texttt{Llama-3.1-8B-Instruct} and \texttt{Qwen3-4B-Instruct-2507} with different configurations and evaluating their performance on both in- and out-of-distribution tasks. Through our analysis, we observe that, in on-policy settings: (1) estimator configurations with biased gradients can result in training instabilities; and (2) using estimator configurations resulting in unbiased gradients leads to better performance on in-domain as well as out-of-domain tasks. We also investigate the performance resulting from different KL configurations in off-policy settings and observe that KL regularization can help stabilize off-policy RL training resulting from asynchronous setups.

</details>


### [27] [Mechanical Strength Prediction of Steel-Polypropylene Fiber-based High-Performance Concrete Using Hybrid Machine Learning Algorithms](https://arxiv.org/abs/2512.21638)
*Jagaran Chakma,Zhiguang Zhou,Badhan Chakma*

Main category: cs.LG

TL;DR: 该研究开发并评估了三种机器学习模型（ET-XGB、RF-LGBM、Transformer-XGB）来预测钢-聚丙烯纤维增强高性能混凝土的力学性能，其中ET-XGB模型整体精度最高，RF-LGBM对弯曲强度预测最稳定，SHAP分析揭示了纤维长径比、硅灰和钢纤维含量是关键影响因素。


<details>
  <summary>Details</summary>
Motivation: 传统混凝土力学性能预测方法存在局限性，需要开发更准确、可解释的机器学习模型来预测钢-聚丙烯纤维增强高性能混凝土的压缩强度、弯曲强度和拉伸强度，以优化配合比设计和工程应用。

Method: 研究采用三种集成机器学习模型：Extra Trees与XGBoost组合（ET-XGB）、随机森林与LightGBM组合（RF-LGBM）、Transformer与XGBoost组合（Transformer-XGB）。使用k折交叉验证、超参数优化、SHAP可解释性分析和不确定性分析，基于已发表实验研究构建的广泛数据集进行训练。

Result: ET-XGB模型整体精度最高，测试R²值分别为：压缩强度0.994、弯曲强度0.944、拉伸强度0.978，对压缩强度和拉伸强度的不确定性最低（约13-16%和30.4%）。RF-LGBM模型对弯曲强度预测最稳定可靠（R² 0.977），不确定性最低（约5-33%）。Transformer-XGB模型预测能力强但不确定性最高。SHAP分析显示纤维长径比、硅灰和钢纤维含量是最有影响力的预测因子。

Conclusion: 机器学习模型能够为高性能混凝土力学性能提供准确、可解释和可泛化的预测，这些模型为优化混凝土配合比设计和提高结构性能评估提供了有价值的工具，其中ET-XGB和RF-LGBM模型在工程应用中表现出色。

Abstract: This research develops and evaluates machine learning models to predict the mechanical properties of steel-polypropylene fiber-reinforced high-performance concrete (HPC). Three model families were investigated: Extra Trees with XGBoost (ET-XGB), Random Forest with LightGBM (RF-LGBM), and Transformer with XGBoost (Transformer-XGB). The target properties included compressive strength (CS), flexural strength (FS), and tensile strength (TS), based on an extensive dataset compiled from published experimental studies. Model training involved k-fold cross-validation, hyperparameter optimization, Shapley additive explanations (SHAP), and uncertainty analysis to ensure both robustness and interpretability. Among the tested approaches, the ET-XGB model achieved the highest overall accuracy, with testing R^2 values of 0.994 for CS, 0.944 for FS, and 0.978 for TS and exhibited lowest uncertainty for CS and TS (approximately 13-16% and 30.4%, respectively). The RF-LGBM model provided the most stable and reliable predictions for FS (R^2 0.977), yielding the lowest uncertainty for FS (approximately 5-33%). The Transformer-XGB model demonstrated strong predictive capability (R^2 0.978 for TS and 0.967 for FS) but consistently showed the highest uncertainty, indicating reduced generalization reliability. SHAP analysis further indicated that fiber aspect ratios (AR1 and AR2), silica fume (Sfu), and steel fiber content (SF) were the most influential predictors of strength, whereas water content (W) and the water-binder ratio (w/b) consistently had negative effects. The findings confirm that machine learning models can provide accurate, interpretable, and generalizable predictions of HPC mechanical properties. These models offer valuable tools for optimizing concrete mix design and enhancing structural performance evaluation in engineering applications.

</details>


### [28] [Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation](https://arxiv.org/abs/2512.21866)
*Yiming Qian,Thorsten Neumann,Xueyining Huang,David Hardoon,Fei Gao,Yong Liu,Siow Mong Rick Goh*

Main category: cs.LG

TL;DR: 提出一种可解释、保护隐私的数据集蒸馏框架，用于协作式金融欺诈检测。通过将训练好的随机森林转换为透明、轴对齐的规则区域，并在每个区域内均匀采样生成合成交易，创建紧凑、可审计的替代数据集，保护原始敏感记录隐私。


<details>
  <summary>Details</summary>
Motivation: 解决金融欺诈检测中多机构协作时的数据隐私保护问题，同时保持模型的可解释性和性能。传统方法在共享敏感交易数据时存在隐私泄露风险，且缺乏透明度和可审计性。

Method: 将训练好的随机森林转换为轴对齐的规则区域（叶超矩形），在每个区域内均匀采样生成合成交易。利用规则区域支持可解释性：聚合规则统计量描述全局模式，为每个案例分配生成区域提供简洁的人类可读理由和基于树投票分歧的校准不确定性。

Result: 在IEEE-CIS欺诈数据集上，蒸馏数据集将数据量减少85%-93%（通常低于原始数据的15%），同时保持竞争力的精确率和微F1分数，AUC仅有适度下降。跨机构共享和增强合成数据提高了跨集群的精确率、召回率和AUC。真实与合成数据结构高度相似（最近邻余弦分析超过93%）。成员推理攻击性能接近随机水平（约0.50），表明记忆风险低。使用分歧分数移除高不确定性合成点可进一步提升AUC（最高达0.687）并改善校准。

Conclusion: 树区域蒸馏实现了可信、可部署的欺诈分析，具有可解释的全局规则、带量化不确定性的个案理由以及适用于多机构设置和监管审计的强大隐私特性。

Abstract: We propose an explainable, privacy-preserving dataset distillation framework for collaborative financial fraud detection. A trained random forest is converted into transparent, axis-aligned rule regions (leaf hyperrectangles), and synthetic transactions are generated by uniformly sampling within each region. This produces a compact, auditable surrogate dataset that preserves local feature interactions without exposing sensitive original records. The rule regions also support explainability: aggregated rule statistics (for example, support and lift) describe global patterns, while assigning each case to its generating region gives concise human-readable rationales and calibrated uncertainty based on tree-vote disagreement.
  On the IEEE-CIS fraud dataset (590k transactions across three institution-like clusters), distilled datasets reduce data volume by 85% to 93% (often under 15% of the original) while maintaining competitive precision and micro-F1, with only a modest AUC drop. Sharing and augmenting with synthesized data across institutions improves cross-cluster precision, recall, and AUC. Real vs. synthesized structure remains highly similar (over 93% by nearest-neighbor cosine analysis). Membership-inference attacks perform at chance level (about 0.50) when distinguishing training from hold-out records, suggesting low memorization risk. Removing high-uncertainty synthetic points using disagreement scores further boosts AUC (up to 0.687) and improves calibration. Sensitivity tests show weak dependence on the distillation ratio (AUC about 0.641 to 0.645 from 6% to 60%).
  Overall, tree-region distillation enables trustworthy, deployable fraud analytics with interpretable global rules, per-case rationales with quantified uncertainty, and strong privacy properties suitable for multi-institution settings and regulatory audit.

</details>


### [29] [Causal-HM: Restoring Physical Generative Logic in Multimodal Anomaly Detection via Hierarchical Modulation](https://arxiv.org/abs/2512.21650)
*Xiao Liu,Junchen Jin,Yanjie Zhao,Zhixuan Xing*

Main category: cs.LG

TL;DR: 提出Causal-HM框架，通过显式建模物理过程到结果的因果关系，解决多模态无监督异常检测中的因果盲点和异质性差距问题，在焊接质量检测中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态无监督异常检测方法存在因果盲点，将过程模态（实时视频、音频、传感器）和结果模态（焊后图像）视为同等特征源，忽略了物理生成逻辑；同时高维视觉数据与低维传感器信号之间的异质性差距导致关键过程上下文被淹没。

Method: 提出Causal-HM统一框架，包含两个关键创新：1）传感器引导的CHM调制机制，利用低维传感器信号作为上下文指导高维视听特征提取；2）因果分层架构，强制执行单向生成映射以识别违反物理一致性的异常。

Result: 在新构建的Weld-4M基准测试中，Causal-HM在四个模态上实现了90.7%的SOTA I-AUROC性能。

Conclusion: 通过显式建模物理过程到结果的依赖关系，Causal-HM有效解决了多模态异常检测中的因果盲点和异质性差距问题，在智能制造质量保证中具有重要应用价值。

Abstract: Multimodal Unsupervised Anomaly Detection (UAD) is critical for quality assurance in smart manufacturing, particularly in complex processes like robotic welding. However, existing methods often suffer from causal blindness, treating process modalities (e.g., real-time video, audio, and sensors) and result modalities (e.g., post-weld images) as equal feature sources, thereby ignoring the inherent physical generative logic. Furthermore, the heterogeneity gap between high-dimensional visual data and low-dimensional sensor signals frequently leads to critical process context being drowned out. In this paper, we propose Causal-HM, a unified multimodal UAD framework that explicitly models the physical Process to Result dependency. Specifically, our framework incorporates two key innovations: a Sensor-Guided CHM Modulation mechanism that utilizes low-dimensional sensor signals as context to guide high-dimensional audio-visual feature extraction , and a Causal-Hierarchical Architecture that enforces a unidirectional generative mapping to identify anomalies that violate physical consistency. Extensive experiments on our newly constructed Weld-4M benchmark across four modalities demonstrate that Causal-HM achieves a state-of-the-art (SOTA) I-AUROC of 90.7%. Code will be released after the paper is accepted.

</details>


### [30] [Rethinking Output Alignment For 1-bit Post-Training Quantization of Large Language Models](https://arxiv.org/abs/2512.21651)
*Dung Anh Hoang,Cuong Pham,Cuong Nguyen,Trung le,Jianfei Cai,Thanh-Toan Do*

Main category: cs.LG

TL;DR: 本文研究了1位LLM量化中输出匹配方法失败的原因，并提出了一种数据感知的PTQ方法，能有效减少激活误差累积，在保持优化效率的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然性能强大，但参数量大难以在资源受限设备上部署。1位量化（将浮点权重转换为±1）尤其具有挑战性，现有的1位PTQ方法通常会导致显著的性能下降。现有方法主要关注权重对齐而非输出对齐，而输出匹配方法虽然更直观且符合量化目标，但在1位LLM中直接应用会导致性能显著下降。

Method: 本文首先研究1位LLM量化中输出匹配方法失败的原因和条件。基于研究发现，提出了一种新颖的数据感知PTQ方法，该方法明确考虑激活误差累积，同时保持优化效率。该方法在1位量化过程中特别关注数据分布对误差传播的影响。

Result: 实验结果表明，该方法在1位LLM量化中始终优于现有的1位PTQ方法，且额外开销最小。相比现有方法，能够显著减少性能下降，更接近全精度模型的性能。

Conclusion: 本文通过分析1位LLM量化中输出匹配失败的原因，提出了一种有效的数据感知PTQ方法，解决了现有1位量化方法的局限性，为资源受限设备上的高效LLM部署提供了更好的解决方案。

Abstract: Large Language Models (LLMs) deliver strong performance across a wide range of NLP tasks, but their massive sizes hinder deployment on resource-constrained devices. To reduce their computational and memory burden, various compression techniques have been proposed, including quantization, pruning, and knowledge distillation. Among these, post-training quantization (PTQ) is widely adopted for its efficiency, as it requires no retraining and only a small dataset for calibration, enabling low-cost deployment. Recent advances for post-training quantization have demonstrated that even sub-4-bit methods can maintain most of the original model performance. However, 1-bit quantization that converts floating-point weights to \(\pm\)1, remains particularly challenging, as existing 1-bit PTQ methods often suffer from significant performance degradation compared to the full-precision models. Specifically, most of existing 1-bit PTQ approaches focus on weight alignment, aligning the full-precision model weights with those of the quantized models, rather than directly aligning their outputs. Although the output-matching approach objective is more intuitive and aligns with the quantization goal, naively applying it in 1-bit LLMs often leads to notable performance degradation. In this paper, we investigate why and under what conditions output-matching fails, in the context of 1-bit LLM quantization. Based on our findings, we propose a novel data-aware PTQ approach for 1-bit LLMs that explicitly accounts for activation error accumulation while keeping optimization efficient. Empirical experiments demonstrate that our solution consistently outperforms existing 1-bit PTQ methods with minimal overhead.

</details>


### [31] [LibContinual: A Comprehensive Library towards Realistic Continual Learning](https://arxiv.org/abs/2512.22029)
*Wenbin Li,Shangge Liu,Borui Kang,Yiyang Chen,KaXuan Lew,Yang Chen,Yinghuan Shi,Lei Wang,Yang Gao,Jiebo Luo*

Main category: cs.LG

TL;DR: LibContinual是一个用于持续学习的统一框架库，解决了现有方法碎片化、评估不一致的问题，并通过严格在线设置揭示了主流方法在现实约束下的性能下降。


<details>
  <summary>Details</summary>
Motivation: 持续学习领域方法多样但研究碎片化，缺乏统一框架，存在实现不一致、依赖冲突、评估协议不统一等问题，导致公平比较和可复现研究困难。

Method: 提出LibContinual库，采用高内聚、低耦合的模块化架构，整合了5个主要方法类别的19种代表性算法，提供标准化执行环境。基于此框架，系统识别并研究了主流评估中的三个隐含假设。

Result: 通过严格在线CL设置、统一内存预算协议和类别随机化设置的综合分析，发现许多代表性CL方法在现实约束下性能显著下降，揭示了资源感知和语义鲁棒策略的必要性。

Conclusion: LibContinual为现实持续学习研究提供了基础工具包，强调了资源感知和语义鲁棒CL策略的重要性，推动了该领域向更实际应用方向发展。

Abstract: A fundamental challenge in Continual Learning (CL) is catastrophic forgetting, where adapting to new tasks degrades the performance on previous ones. While the field has evolved with diverse methods, this rapid surge in diverse methodologies has culminated in a fragmented research landscape. The lack of a unified framework, including inconsistent implementations, conflicting dependencies, and varying evaluation protocols, makes fair comparison and reproducible research increasingly difficult. To address this challenge, we propose LibContinual, a comprehensive and reproducible library designed to serve as a foundational platform for realistic CL. Built upon a high-cohesion, low-coupling modular architecture, LibContinual integrates 19 representative algorithms across five major methodological categories, providing a standardized execution environment. Meanwhile, leveraging this unified framework, we systematically identify and investigate three implicit assumptions prevalent in mainstream evaluation: (1) offline data accessibility, (2) unregulated memory resources, and (3) intra-task semantic homogeneity. We argue that these assumptions often overestimate the real-world applicability of CL methods. Through our comprehensive analysis using strict online CL settings, a novel unified memory budget protocol, and a proposed category-randomized setting, we reveal significant performance drops in many representative CL methods when subjected to these real-world constraints. Our study underscores the necessity of resource-aware and semantically robust CL strategies, and offers LibContinual as a foundational toolkit for future research in realistic continual learning. The source code is available from \href{https://github.com/RL-VIG/LibContinual}{https://github.com/RL-VIG/LibContinual}.

</details>


### [32] [From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation](https://arxiv.org/abs/2512.22031)
*Nagham Osman,Vittorio Lembo,Giovanni Bottegoni,Laura Toni*

Main category: cs.LG

TL;DR: 本文研究生成模型能否替代药物发现流程中的命中化合物生成步骤，提出了专门评估框架，测试了三种生成模型在多个靶点上的表现，并成功合成了活性GSK-3β命中化合物。


<details>
  <summary>Details</summary>
Motivation: 药物发现中的命中化合物识别步骤传统上依赖高通量筛选，资源消耗大。虽然深度学习生成模型能生成新分子，但用ML替代整个药物发现流程极具挑战。本研究探索生成模型能否专门替代命中化合物生成这一特定步骤。

Method: 将命中化合物生成作为独立任务，提出专门评估框架，整合物理化学、结构和生物活性标准，建立多阶段过滤流程定义命中化合物化学空间。测试了两种自回归模型和一种扩散模型在不同数据集和训练设置下的表现，使用标准指标和靶点特异性对接评分进行评估。

Result: 模型能够生成有效、多样且具有生物相关性的化合物，覆盖多个靶点。成功合成了部分GSK-3β命中化合物并在体外实验中确认了活性。同时发现了当前评估指标和可用训练数据的关键局限性。

Conclusion: 这是首个将命中化合物生成作为独立任务并实证测试生成模型能否直接支持药物发现流程的研究。结果表明生成模型确实能够替代传统命中化合物识别工作流程，但需要改进评估指标和训练数据。

Abstract: Hit identification is a critical yet resource-intensive step in the drug discovery pipeline, traditionally relying on high-throughput screening of large compound libraries. Despite advancements in virtual screening, these methods remain time-consuming and costly. Recent progress in deep learning has enabled the development of generative models capable of learning complex molecular representations and generating novel compounds de novo. However, using ML to replace the entire drug-discovery pipeline is highly challenging. In this work, we rather investigate whether generative models can replace one step of the pipeline: hit-like molecule generation. To the best of our knowledge, this is the first study to explicitly frame hit-like molecule generation as a standalone task and empirically test whether generative models can directly support this stage of the drug discovery pipeline. Specifically, we investigate if such models can be trained to generate hit-like molecules, enabling direct incorporation into, or even substitution of, traditional hit identification workflows. We propose an evaluation framework tailored to this task, integrating physicochemical, structural, and bioactivity-related criteria within a multi-stage filtering pipeline that defines the hit-like chemical space. Two autoregressive and one diffusion-based generative models were benchmarked across various datasets and training settings, with outputs assessed using standard metrics and target-specific docking scores. Our results show that these models can generate valid, diverse, and biologically relevant compounds across multiple targets, with a few selected GSK-3$β$ hits synthesized and confirmed active in vitro. We also identify key limitations in current evaluation metrics and available training data.

</details>


### [33] [Unifying Learning Dynamics and Generalization in Transformers Scaling Law](https://arxiv.org/abs/2512.22088)
*Chiwun Yang*

Main category: cs.LG

TL;DR: 该论文为LLM缩放定律提供了理论框架，将transformer训练过程建模为ODE系统，揭示了泛化误差随计算资源变化的相变规律：优化阶段指数衰减，统计阶段幂律衰减Θ(C^{-1/6})。


<details>
  <summary>Details</summary>
Motivation: 尽管缩放定律在LLM开发中经验上有效，但其理论基础仍然薄弱。现有研究多基于简化模型，缺乏对真实条件下多层transformer训练的理论分析。

Method: 将transformer语言模型的学习动态形式化为常微分方程系统，近似为核行为。严格分析多层transformer在任意数据分布下的SGD训练，建立泛化误差收敛到不可约风险的理论上界。

Result: 发现泛化误差存在明显的相变：优化阶段指数衰减，统计阶段遵循幂律衰减Θ(C^{-1/6})。同时推导出模型大小、训练时间和数据集大小各自的独立缩放定律。

Conclusion: 该工作为LLM缩放定律提供了坚实的理论基础，揭示了计算资源分配阈值对训练动态的关键影响，并为模型开发中的资源优化提供了理论指导。

Abstract: The scaling law, a cornerstone of Large Language Model (LLM) development, predicts improvements in model performance with increasing computational resources. Yet, while empirically validated, its theoretical underpinnings remain poorly understood. This work formalizes the learning dynamics of transformer-based language models as an ordinary differential equation (ODE) system, then approximates this process to kernel behaviors. Departing from prior toy-model analyses, we rigorously analyze stochastic gradient descent (SGD) training for multi-layer transformers on sequence-to-sequence data with arbitrary data distribution, closely mirroring real-world conditions. Our analysis characterizes the convergence of generalization error to the irreducible risk as computational resources scale with data, especially during the optimization process.
  We establish a theoretical upper bound on excess risk characterized by a distinct phase transition. In the initial optimization phase, the excess risk decays exponentially relative to the computational cost ${\sf C}$. However, once a specific resource allocation threshold is crossed, the system enters a statistical phase, where the generalization error follows a power-law decay of $Θ(\mathsf{C}^{-1/6})$. Beyond this unified framework, our theory derives isolated scaling laws for model size, training time, and dataset size, elucidating how each variable independently governs the upper bounds of generalization.

</details>


### [34] [Dynamic Feedback Engines: Layer-Wise Control for Self-Regulating Continual Learning](https://arxiv.org/abs/2512.21743)
*Hengyi Wu,Zhenyi Wang,Heng Huang*

Main category: cs.LG

TL;DR: 提出一种基于熵感知的持续学习方法，通过动态反馈机制根据各层熵值调节模型，缓解高熵层欠拟合和低熵层过拟合问题，提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法通常对所有层进行统一处理，在稳定性和可塑性之间进行权衡，但不同层在分类任务时表现出不同的不确定性（熵）。高熵层容易欠拟合，无法捕捉任务特定模式；低熵层容易过拟合，变得过于自信和专门化。

Method: 提出熵感知的持续学习方法，采用动态反馈机制根据每层的熵值进行调节：降低高熵层的熵以缓解欠拟合，增加过于自信层的熵以缓解过拟合。这种自适应调节促使模型收敛到更宽的局部最小值，从而改善泛化能力。该方法具有通用性，可无缝集成到基于重放和正则化的方法中。

Result: 在多个数据集上的实验表明，该方法相比最先进的持续学习基线方法取得了显著的性能提升。

Conclusion: 通过熵感知的动态层调节机制，能够有效平衡持续学习中的稳定性和可塑性，缓解欠拟合和过拟合问题，提升模型在持续学习任务中的整体性能。

Abstract: Continual learning aims to acquire new tasks while preserving performance on previously learned ones, but most methods struggle with catastrophic forgetting. Existing approaches typically treat all layers uniformly, often trading stability for plasticity or vice versa. However, different layers naturally exhibit varying levels of uncertainty (entropy) when classifying tasks. High-entropy layers tend to underfit by failing to capture task-specific patterns, while low-entropy layers risk overfitting by becoming overly confident and specialized. To address this imbalance, we propose an entropy-aware continual learning method that employs a dynamic feedback mechanism to regulate each layer based on its entropy. Specifically, our approach reduces entropy in high-entropy layers to mitigate underfitting and increases entropy in overly confident layers to alleviate overfitting. This adaptive regulation encourages the model to converge to wider local minima, which have been shown to improve generalization. Our method is general and can be seamlessly integrated with both replay- and regularization-based approaches. Experiments on various datasets demonstrate substantial performance gains over state-of-the-art continual learning baselines.

</details>


### [35] [GQ-VAE: A gated quantized VAE for learning variable length tokens](https://arxiv.org/abs/2512.21913)
*Theo Datta,Kayla Huang,Sham Kakade,David Brandfonbrener*

Main category: cs.LG

TL;DR: GQ-VAE是一种新型神经分词器架构，可作为现有分词器的即插即用替代方案，通过变长离散标记编码提升压缩和语言建模性能。


<details>
  <summary>Details</summary>
Motivation: 当前前沿模型主要使用确定性频率分词算法如BPE，而现有的神经分词器方案通常增加语言模型复杂度并需要大幅架构改动，难以大规模实施。

Method: 提出门控量化变分自编码器(GQ-VAE)，可独立预训练作为现有分词器的替代方案，关键创新是学习编码变长离散标记。

Result: GQ-VAE在压缩和语言建模性能上优于标准VQ-VAE分词器，接近BPE的性能。当压缩率相同时，GQ-VAE能改善下游语言模型学习效果。

Conclusion: GQ-VAE为现有分词器提供了有效的神经替代方案，并指出了多个未来研究方向。

Abstract: While most frontier models still use deterministic frequency-based tokenization algorithms such as byte-pair encoding (BPE), there has been significant recent work to design learned neural tokenizers. However, these schemes generally add to underlying language model complexity and force large changes to architecture, making them hard to implement at large scales. To overcome these challenges, we propose the gated quantized variational autoencoder (GQ-VAE), a novel architecture that can be independently pre-trained to serve as a drop-in replacement for existing tokenizers. The key innovation of the architecture is to learn to encode variable-length discrete tokens. GQ-VAE improves compression and language modeling performance over a standard VQ-VAE tokenizer, and approaches the compression rate and language modeling performance of BPE. Interestingly, if we use BPE with a smaller vocabulary, such that the compression is equivalent between GQ-VAE and BPE, we find that GQ-VAE improves downstream language model learning. We conclude with a discussion of several exciting avenues for future work. Code can be found at https://github.com/Theo-Datta-115/gq-vae.

</details>


### [36] [Exploring the Heterogeneity of Tabular Data: A Diversity-aware Data Generator via LLMs](https://arxiv.org/abs/2512.21915)
*Yafeng Tang,Xiaoou Ding,Jianzhuo Du,Zishuo Yan,Zhuang Ma,Zheng Liang,Zekai Qian,Hongzhi Wang*

Main category: cs.LG

TL;DR: DATE框架通过数据分区、LLM生成和MAB采样算法，在保持多样性的同时生成高质量表格数据，显著提升机器学习性能


<details>
  <summary>Details</summary>
Motivation: 现实世界表格数据具有异质性分布，现有生成模型难以同时处理多样分布，需要一种能平衡多样性和质量的生成方法

Method: 1) 将异质数据分区为多个分布不同的子集；2) 利用LLM通过决策树推理生成每个子集的高质量标注数据；3) 设计多臂老虎机采样算法平衡生成数据的多样性和质量

Result: 在表格分类和回归基准测试中，DATE优于最先进的GAN和LLM方法，平均减少23.75%错误率；生成的数据能提升DPO准确性和LLM推理能力

Conclusion: DATE框架通过结合数据分区、LLM生成和智能采样算法，有效解决了表格数据生成中多样性与质量的平衡问题，为机器学习应用提供了高质量数据增强方案

Abstract: Tabular data generation has become increasingly essential for enabling robust machine learning applications, which require large-scale, high-quality data. Existing solutions leverage generative models to learn original data distributions. However, real-world data are naturally heterogeneous with diverse distributions, making it challenging to obtain a universally good model for diverse data generation. To address this limitation, we introduce Diversity-Aware Tabular data gEnerator (DATE), a framework that (i) prepares high-quality and distributionally distinct examples for in-context learning by effectively partitioning the original heterogeneous data into multiple diverse subsets; (ii) harnesses Large Language Models (LLMs) to explore the diversity of the partitioned distribution with decision tree reasoning as feedback, generating high-quality labeled data for each subset. However, the massive generated data inherently involves a trade-off between diversity and quality. To integrate this issue, existing solutions greedily select the validation-best data. However, we prove that the selection in heterogeneous settings does not possess the greedy-choice property, and design a Multi-Arm Bandit-based sampling algorithm that balances the diversity and quality of generated data. Extensive experiments on tabular classification and regression benchmarks demonstrate that DATE consistently outperforms state-of-the-art GAN-based and LLM-based methods. On average, DATE achieves a 23.75% reduction in error rate with just 100 generated data. Empirically, we demonstrate that data generated by DATE can improve the accuracy of Direct Preference Optimization (DPO) and enhance the reasoning capability of LLMs on the target data. Code is available at https://github.com/windblow32/DATE.

</details>


### [37] [Hybrid Combinatorial Multi-armed Bandits with Probabilistically Triggered Arms](https://arxiv.org/abs/2512.21925)
*Kongchang Zhou,Tingyu Zhang,Wei Chen,Fang Kong*

Main category: cs.LG

TL;DR: 本文提出了一种混合CMAB-T框架，结合离线数据和在线交互来解决组合多臂老虎机问题，通过混合CUCB算法利用离线数据指导探索并加速收敛，同时通过在线交互纠正离线数据的偏差。


<details>
  <summary>Details</summary>
Motivation: 传统的在线CMAB-T算法存在交互成本高、适应速度慢的问题，而离线方法受限于数据集质量和缺乏探索能力。为了弥补这两种方法的不足，需要一种能够整合离线数据和在线交互的新框架。

Method: 提出了混合CMAB-T框架和混合CUCB算法，该算法利用离线数据指导探索和加速收敛，同时策略性地结合在线交互来纠正离线数据集的覆盖不足或分布偏差。

Result: 理论分析证明了算法的遗憾界，表明当有高质量离线数据时，混合CUCB显著优于纯在线方法；当数据有限或存在偏差时，能有效纠正纯离线方法的偏差。实证结果进一步验证了算法的优势。

Conclusion: 混合CMAB-T框架成功整合了离线数据和在线交互的优势，通过混合CUCB算法在理论和实证上都表现出优于纯在线或纯离线方法的性能，为解决组合多臂老虎机问题提供了更有效的方案。

Abstract: The problem of combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) has been extensively studied. Prior work primarily focuses on either the online setting where an agent learns about the unknown environment through iterative interactions, or the offline setting where a policy is learned solely from logged data. However, each of these paradigms has inherent limitations: online algorithms suffer from high interaction costs and slow adaptation, while offline methods are constrained by dataset quality and lack of exploration capabilities. To address these complementary weaknesses, we propose hybrid CMAB-T, a new framework that integrates offline data with online interaction in a principled manner. Our proposed hybrid CUCB algorithm leverages offline data to guide exploration and accelerate convergence, while strategically incorporating online interactions to mitigate the insufficient coverage or distributional bias of the offline dataset. We provide theoretical guarantees on the algorithm's regret, demonstrating that hybrid CUCB significantly outperforms purely online approaches when high-quality offline data is available, and effectively corrects the bias inherent in offline-only methods when the data is limited or misaligned. Empirical results further demonstrate the consistent advantage of our algorithm.

</details>


### [38] [Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing](https://arxiv.org/abs/2512.22024)
*Wesley S. Leite,Rodrigo C. de Lamare,Yuriy Zakharov,Wei Liu,Martin Haardt*

Main category: cs.LG

TL;DR: 提出可变窗口尺寸空间平滑框架，提升稀疏线性阵列的协阵列DOA估计性能，通过压缩平滑孔径改善信号与噪声子空间分离


<details>
  <summary>Details</summary>
Motivation: 传统固定窗口协阵列MUSIC方法在处理稀疏线性阵列时存在性能限制，需要改进协阵列数据平滑技术以提升DOA估计精度

Method: 提出可变窗口尺寸空间平滑框架，开发VWS-CA-MUSIC和VWS-CA-rMUSIC算法，通过压缩平滑孔径，用未扰动的低秩附加项替换部分扰动的秩一外积

Result: 仿真显示相对于固定窗口协阵列MUSIC方法，在稀疏几何结构下获得显著性能提升和复杂度降低

Conclusion: 可变窗口尺寸空间平滑框架有效增强了协阵列DOA估计性能，同时保持了信号子空间跨度，为稀疏阵列处理提供了新方法

Abstract: In this work, we introduce a variable window size (VWS) spatial smoothing framework that enhances coarray-based direction of arrival (DOA) estimation for sparse linear arrays. By compressing the smoothing aperture, the proposed VWS Coarray MUSIC (VWS-CA-MUSIC) and VWS Coarray root-MUSIC (VWS-CA-rMUSIC) algorithms replace part of the perturbed rank-one outer products in the smoothed coarray data with unperturbed low-rank additional terms, increasing the separation between signal and noise subspaces, while preserving the signal subspace span. We also derive the bounds that guarantees identifiability, by limiting the values that can be assumed by the compression parameter. Simulations with sparse geometries reveal significant performance improvements and complexity savings relative to the fixed-window coarray MUSIC method.

</details>


### [39] [Scaling Adversarial Training via Data Selection](https://arxiv.org/abs/2512.22069)
*Youran Ye,Dejin Wang,Ajinkya Bhandare*

Main category: cs.LG

TL;DR: 提出选择性对抗训练，通过仅扰动关键样本子集来减少PGD对抗训练的计算成本，同时保持或提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: PGD对抗训练计算成本高，所有训练样本都经过相同的迭代优化，但不同样本对鲁棒性的贡献不同。这种效率低下促使研究者开发更高效的对抗训练方法。

Method: 提出选择性对抗训练，在每个小批量中只扰动关键样本子集。引入两种选择标准：1）基于边界距离的采样，优先选择靠近决策边界的样本；2）梯度匹配采样，选择梯度与批量优化主导方向对齐的样本。对选定样本生成对抗样本，其余样本使用混合目标进行干净训练。

Result: 在MNIST和CIFAR-10上的实验表明，该方法达到与完整PGD对抗训练相当甚至更好的鲁棒性，同时将对抗计算减少高达50%。

Conclusion: 有选择的样本选择足以实现可扩展的对抗鲁棒性，选择性对抗训练在保持鲁棒性的同时显著降低了计算成本。

Abstract: Projected Gradient Descent (PGD) is a strong and widely used first-order adversarial attack, yet its computational cost scales poorly, as all training samples undergo identical iterative inner-loop optimization despite contributing unequally to robustness. Motivated by this inefficiency, we propose \emph{Selective Adversarial Training}, which perturbs only a subset of critical samples in each minibatch. Specifically, we introduce two principled selection criteria: (1) margin-based sampling, which prioritizes samples near the decision boundary, and (2) gradient-matching sampling, which selects samples whose gradients align with the dominant batch optimization direction. Adversarial examples are generated only for the selected subset, while the remaining samples are trained cleanly using a mixed objective. Experiments on MNIST and CIFAR-10 show that the proposed methods achieve robustness comparable to, or even exceeding, full PGD adversarial training, while reducing adversarial computation by up to $50\%$, demonstrating that informed sample selection is sufficient for scalable adversarial robustness.

</details>


### [40] [Explainable Multimodal Regression via Information Decomposition](https://arxiv.org/abs/2512.22102)
*Zhaozhao Ma,Shujian Yu*

Main category: cs.LG

TL;DR: 提出基于偏信息分解的多模态回归框架，通过高斯性假设解析计算模态间独特、冗余和协同信息，提升预测精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态回归方法缺乏量化各模态贡献及其交互作用的原理性工具，限制了多模态融合的可解释性。

Method: 基于偏信息分解框架，通过高斯性假设对潜在表示和响应变量的联合分布进行建模，引入解析计算PID项的方法，并推导闭式条件独立性正则化器来促进独特信息的分离。

Result: 在六个真实世界数据集（包括大规模脑年龄预测）上的实验表明，该方法在预测准确性和可解释性方面优于现有方法，并能支持高效的模态选择。

Conclusion: 提出的PID框架为多模态回归提供了原理性的可解释性工具，能够量化模态贡献并支持高效的推理决策。

Abstract: Multimodal regression aims to predict a continuous target from heterogeneous input sources and typically relies on fusion strategies such as early or late fusion. However, existing methods lack principled tools to disentangle and quantify the individual contributions of each modality and their interactions, limiting the interpretability of multimodal fusion. We propose a novel multimodal regression framework grounded in Partial Information Decomposition (PID), which decomposes modality-specific representations into unique, redundant, and synergistic components. The basic PID framework is inherently underdetermined. To resolve this, we introduce inductive bias by enforcing Gaussianity in the joint distribution of latent representations and the transformed response variable (after inverse normal transformation), thereby enabling analytical computation of the PID terms. Additionally, we derive a closed-form conditional independence regularizer to promote the isolation of unique information within each modality. Experiments on six real-world datasets, including a case study on large-scale brain age prediction from multimodal neuroimaging data, demonstrate that our framework outperforms state-of-the-art methods in both predictive accuracy and interpretability, while also enabling informed modality selection for efficient inference. Implementation is available at https://github.com/zhaozhaoma/PIDReg.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [41] [Human-AI Interaction Alignment: Designing, Evaluating, and Evolving Value-Centered AI For Reciprocal Human-AI Futures](https://arxiv.org/abs/2512.21551)
*Hua Shen,Tiffany Knearem,Divy Thakkar,Pat Pataranutaporn,Anoop Sinha,Yike,Shi,Jenny T. Liang,Lama Ahmad,Tanu Mitra,Brad A. Myers,Yang Li*

Main category: cs.HC

TL;DR: 该研讨会聚焦于双向人机对齐，超越单向AI适应人类价值的模式，强调人类与AI通过互动、评估和价值中心设计的相互适应过程。


<details>
  <summary>Details</summary>
Motivation: 生成式AI快速融入日常生活，需要超越单向对齐模型，建立动态、互惠的人机对齐机制，促进人类与AI的共同适应和演化。

Method: 通过研讨会形式，汇集HCI、AI、社会科学等多学科研究者，通过演讲、跨学科讨论和协作活动，探索交互式对齐方法、社会影响评估框架和动态情境下的对齐策略。

Result: 建立跨学科合作平台，推动价值中心AI和互惠人机协作研究，弥合学科差距，为负责任、互惠的人机未来制定共同议程。

Conclusion: 双向人机对齐是未来AI发展的关键方向，需要多学科协作将人类和社会价值嵌入对齐研究，实现人类与AI系统的共同演化。

Abstract: The rapid integration of generative AI into everyday life underscores the need to move beyond unidirectional alignment models that only adapt AI to human values. This workshop focuses on bidirectional human-AI alignment, a dynamic, reciprocal process where humans and AI co-adapt through interaction, evaluation, and value-centered design. Building on our past CHI 2025 BiAlign SIG and ICLR 2025 Workshop, this workshop will bring together interdisciplinary researchers from HCI, AI, social sciences and more domains to advance value-centered AI and reciprocal human-AI collaboration. We focus on embedding human and societal values into alignment research, emphasizing not only steering AI toward human values but also enabling humans to critically engage with and evolve alongside AI systems. Through talks, interdisciplinary discussions, and collaborative activities, participants will explore methods for interactive alignment, frameworks for societal impact evaluation, and strategies for alignment in dynamic contexts. This workshop aims to bridge the disciplines' gaps and establish a shared agenda for responsible, reciprocal human-AI futures.

</details>


### [42] [Emotion-Aware Smart Home Automation Based on the eBICA Model](https://arxiv.org/abs/2512.21589)
*Masaaki Yamauchi,Yiyuan Liang,Hiroko Hara,Hideyuki Shimonishi,Masayuki Murata*

Main category: cs.HC

TL;DR: 基于情感生物启发认知架构(eBICA)的智能家居自动化框架，通过情绪感知和适应性控制来增强心理安全，实验证明能有效降低焦虑水平。


<details>
  <summary>Details</summary>
Motivation: 智能家居自动化如果能适应用户的情绪状态，可以增强日常居住环境的心理安全性。当前需要一种基于情感认知架构的自动化框架来有效提升用户体验。

Method: 提出基于eBICA的情感感知自动化框架，整合评估、躯体反应和行为选择。在伪智能家居环境中进行概念验证实验，参与者经历焦虑诱发事件后接受舒适诱导自动化，通过状态焦虑量表(STAI-S)测量焦虑水平变化。

Result: 引入回避自动化后，STAI-S显著降低，表明基于情绪的控制能有效促进心理安全。个体特征分析显示人格和焦虑相关特质调节缓解程度，表明个性化情绪适应自动化的潜力。

Conclusion: 研究为eBICA情感控制能在智能家居环境中有效运行提供了实证证据，为下一代情感家庭自动化系统奠定了基础。

Abstract: Smart home automation that adapts to a user's emotional state can enhance psychological safety in daily living environments. This study proposes an emotion-aware automation framework guided by the emotional Biologically Inspired Cognitive Architecture (eBICA), which integrates appraisal, somatic responses, and behavior selection. We conducted a proof-of-concept experiment in a pseudo-smart-home environment, where participants were exposed to an anxiety-inducing event followed by a comfort-inducing automation. State anxiety (STAI-S) was measured throughout the task sequence. The results showed a significant reduction in STAI-S immediately after introducing the avoidance automation, demonstrating that emotion-based control can effectively promote psychological safety. Furthermore, an analysis of individual characteristics suggested that personality and anxiety-related traits modulate the degree of relief, indicating the potential for personalized emotion-adaptive automation. Overall, this study provides empirical evidence that eBICA-based emotional control can function effectively in smart home environments and offers a foundation for next-generation affective home automation systems.

</details>


### [43] [Modified TSception for Analyzing Driver Drowsiness and Mental Workload from EEG](https://arxiv.org/abs/2512.21747)
*Gourav Siddhad,Anurag Singh,Rajkumar Saini,Partha Pratim Roy*

Main category: cs.HC

TL;DR: 提出改进的TSception架构用于基于EEG的驾驶员疲劳检测，通过五层时间细化策略和自适应平均池化处理不同维度EEG输入，在SEED-VIG数据集上达到83.46%准确率，性能稳定性显著提升。


<details>
  <summary>Details</summary>
Motivation: 驾驶员疲劳是交通事故的主要原因，需要开发实时可靠的检测系统来确保道路安全。现有方法在性能稳定性和泛化能力方面存在不足。

Method: 提出改进的TSception架构：1）引入五层时间细化策略捕捉多尺度脑动态；2）使用自适应平均池化处理不同维度EEG输入；3）采用两阶段融合机制优化时空特征集成。

Result: 在SEED-VIG数据集上达到83.46%准确率（原版83.15%），置信区间从0.36降至0.24，性能稳定性显著提升。在STEW心理负荷数据集上，2类和3类分类分别达到95.93%和95.35%的SOTA结果。

Conclusion: 改进的TSception架构在性能稳定性和跨任务泛化能力方面显著提升，为基于EEG的疲劳和心理负荷监测提供了更可靠的解决方案。

Abstract: Driver drowsiness remains a primary cause of traffic accidents, necessitating the development of real-time, reliable detection systems to ensure road safety. This study presents a Modified TSception architecture designed for the robust assessment of driver fatigue using Electroencephalography (EEG). The model introduces a novel hierarchical architecture that surpasses the original TSception by implementing a five-layer temporal refinement strategy to capture multi-scale brain dynamics. A key innovation is the use of Adaptive Average Pooling, which provides the structural flexibility to handle varying EEG input dimensions, and a two - stage fusion mechanism that optimizes the integration of spatiotemporal features for improved stability. When evaluated on the SEED-VIG dataset and compared against established methods - including SVM, Transformer, EEGNet, ConvNeXt, LMDA-Net, and the original TSception - the Modified TSception achieves a comparable accuracy of 83.46% (vs. 83.15% for the original). Critically, the proposed model exhibits a substantially reduced confidence interval (0.24 vs. 0.36), signifying a marked improvement in performance stability. Furthermore, the architecture's generalizability is validated on the STEW mental workload dataset, where it achieves state-of-the-art results with 95.93% and 95.35% accuracy for 2-class and 3-class classification, respectively. These improvements in consistency and cross-task generalizability underscore the effectiveness of the proposed modifications for reliable EEG-based monitoring of drowsiness and mental workload.

</details>


### [44] [Generative Lecture: Making Lecture Videos Interactive with LLMs and AI Clone Instructors](https://arxiv.org/abs/2512.21796)
*Hye-Young Jo,Ada Zhao,Xiaoan Liu,Ryo Suzuki*

Main category: cs.HC

TL;DR: Generative Lecture系统通过生成式AI和AI克隆讲师，将现有讲座视频转化为交互式学习体验，支持个性化提问和定制化解释。


<details>
  <summary>Details</summary>
Motivation: 传统讲座视频缺乏互动性，学生无法在观看过程中提问或获得个性化解释，限制了学习效果。需要一种能让讲座视频支持双向交流的解决方案。

Method: 使用HeyGen、ElevenLabs和GPT-5等技术创建AI克隆讲师，将AI讲师嵌入视频中，并根据学生问题动态增强视频内容。通过设计启发研究(N=8)确定了8个系统功能，然后进行用户研究(N=12)和专家反馈(N=5)评估系统。

Result: 系统支持有效的双向交流，促进个性化学习。用户研究表明系统在可用性和有效性方面表现良好，专家反馈也证实了其教育价值。

Conclusion: Generative Lecture系统成功地将传统讲座视频转化为交互式学习体验，通过AI克隆讲师实现个性化教学，为在线教育提供了创新的解决方案。

Abstract: We introduce Generative Lecture, a concept that makes existing lecture videos interactive through generative AI and AI clone instructors. By leveraging interactive avatars powered by HeyGen, ElevenLabs, and GPT-5, we embed an AI instructor into the video and augment the video content in response to students' questions. This allows students to personalize the lecture material, directly ask questions in the video, and receive tailored explanations generated and delivered by the AI-cloned instructor. From a design elicitation study (N=8), we identified four goals that guided the development of eight system features: 1) on-demand clarification, 2) enhanced visuals, 3) interactive example, 4) personalized explanation, 5) adaptive quiz, 6) study summary, 7) automatic highlight, and 8) adaptive break. We then conducted a user study (N=12) to evaluate the usability and effectiveness of the system and collected expert feedback (N=5). The results suggest that our system enables effective two-way communication and supports personalized learning.

</details>


### [45] [Positive Narrativity Enhances Sense of Agency toward a VR Avatar](https://arxiv.org/abs/2512.21968)
*Kureha Hamagashira,Miyuki Azuma,Sotaro Shimada*

Main category: cs.HC

TL;DR: 研究探讨了虚拟化身叙事性如何影响全身错觉，发现正面叙事能增强能动感，且能动感与对化身的熟悉度正相关


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究表明具有特定特征的虚拟化身可以通过激活内隐刻板印象影响用户行为，但很少有研究通过引入叙事背景来明确操纵用户对化身的印象。本研究旨在探讨通过情境叙事诱导的化身叙事性如何影响全身错觉。

Method: 健康参与者在VR中化身一个强大的人工生命体化身，在听取正面叙事（化身用能力保护他人）或负面叙事（滥用权力）后，评估他们对化身的印象和身体自我意识指标。

Result: 正面叙事显著增强了能动感，且能动感与参与者对化身的个人熟悉度感知呈正相关。

Conclusion: 化身叙事性可以调节VR中的具身化体验，正面叙事背景能增强用户对虚拟化身的能动感和熟悉度。

Abstract: The full-body illusion (FBI) refers to the experience of perceiving a virtual avatar as one's own body. In virtual reality (VR) environments, inducing the FBI has been shown to modulate users' bodily experiences and behavior. Previous studies have demonstrated that embodying avatars with specific characteristics can influence users' actions, largely through the activation of implicit stereotypes. However, few studies have explicitly manipulated users' impressions of an avatar by introducing narrative context. The present study investigated how avatar narrativity, induced through contextual narratives, affects the FBI. Healthy participants embodied a powerful artificial lifeform avatar in VR after listening to either a positive narrative, in which the avatar used its abilities to protect others, or a negative narrative, in which it misused its power. Participants' impressions of the avatar and indices of bodily self-consciousness were subsequently assessed. The results showed that positive narratives significantly enhanced the sense of agency (SoA), and that SoA was positively correlated with participants' perceived personal familiarity with the avatar. These findings suggest that the avatar narrativity can modulate embodiment in VR.

</details>


### [46] [SketchPlay: Intuitive Creation of Physically Realistic VR Content with Gesture-Driven Sketching](https://arxiv.org/abs/2512.22016)
*Xiangwen Zhang,Xiaowei Dai,Runnan Chen,Xiaoming Chen,Zeke Zexi Hu*

Main category: cs.HC

TL;DR: SketchPlay是一个VR交互框架，通过空中绘画和手势将用户输入转化为具有物理真实感的动态场景，降低非专业用户的创作门槛。


<details>
  <summary>Details</summary>
Motivation: 传统VR内容创作需要复杂的建模工具或预定义的3D模型、纹理和动画，对非专业用户存在显著障碍。需要一种更直观、易用的创作方式。

Method: 结合空中绘画和手势两种互补输入形式：绘画捕捉物体和场景的结构与空间布局，手势传达速度、方向和力等物理线索来定义运动和行为。

Result: 能够生成广泛的复杂物理现象，如刚体运动、弹性变形和布料动力学。相比传统文本驱动方法，在表达性和用户体验方面具有显著优势。

Conclusion: SketchPlay通过直观有趣的创作过程降低了非专业用户的入门门槛，在教育、艺术和沉浸式叙事等领域具有强大应用潜力。

Abstract: Creating physically realistic content in VR often requires complex modeling tools or predefined 3D models, textures, and animations, which present significant barriers for non-expert users. In this paper, we propose SketchPlay, a novel VR interaction framework that transforms humans' air-drawn sketches and gestures into dynamic, physically realistic scenes, making content creation intuitive and playful like drawing. Specifically, sketches capture the structure and spatial arrangement of objects and scenes, while gestures convey physical cues such as velocity, direction, and force that define movement and behavior. By combining these complementary forms of input, SketchPlay captures both the structure and dynamics of user-created content, enabling the generation of a wide range of complex physical phenomena, such as rigid body motion, elastic deformation, and cloth dynamics. Experimental results demonstrate that, compared to traditional text-driven methods, SketchPlay offers significant advantages in expressiveness, and user experience. By providing an intuitive and engaging creation process, SketchPlay lowers the entry barrier for non-expert users and shows strong potential for applications in education, art, and immersive storytelling.

</details>


### [47] [Context-Aware Intelligent Chatbot Framework Leveraging Mobile Sensing](https://arxiv.org/abs/2512.22032)
*Ziyan Zhang,Nan Gao,Zhiqiang Nie,Shantanu Pal,Haining Zhang*

Main category: cs.HC

TL;DR: 提出基于移动感知数据的上下文敏感对话助手框架，通过智能手机收集用户行为和环境数据，抽象为16种上下文场景并转换为自然语言提示，提升LLM对用户状态的理解，实现个性化对话


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型对话助手主要依赖显式文本输入，不了解用户的真实世界行为，无法提供真正个性化的上下文相关对话

Method: 通过智能手机收集用户行为和环境数据，抽象为16种上下文场景，转换为自然语言提示，设计结构化提示系统指导LLM生成个性化对话

Result: 展示了移动感知数据与大型语言模型结合在智能对话中的潜力，为数字健康和个性化交互提供了可行路径

Conclusion: 提出的框架能够利用被动行为数据增强对话助手的上下文理解能力，实现更个性化和情境相关的智能对话

Abstract: With the rapid advancement of large language models (LLMs), intelligent conversational assistants have demonstrated remarkable capabilities across various domains. However, they still mainly rely on explicit textual input and do not know the real world behaviors of users. This paper proposes a context-sensitive conversational assistant framework grounded in mobile sensing data. By collecting user behavior and environmental data through smartphones, we abstract these signals into 16 contextual scenarios and translate them into natural language prompts, thus improving the model's understanding of the user's state. We design a structured prompting system to guide the LLM in generating a more personalized and contextually relevant dialogue. This approach integrates mobile sensing with large language models, demonstrating the potential of passive behavioral data in intelligent conversation and offering a viable path toward digital health and personalized interaction.

</details>
