<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]
- [cs.LG](#cs.LG) [Total: 41]
- [cs.HC](#cs.HC) [Total: 14]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems](https://arxiv.org/abs/2601.10738)
*Percy Jardine*

Main category: cs.AI

TL;DR: 本文提出了一种约束时间分层架构（CTHA），通过结构化流形投影和仲裁机制解决多时间尺度智能体架构中的协调稳定性问题，显著减少了故障级联并提高了样本效率。


<details>
  <summary>Details</summary>
Motivation: 多时间尺度智能体架构虽然通过引入时间分层带来了性能提升，但破坏了统一智能体系统固有的协调稳定性，导致严重的层间冲突、无界错误传播和可扩展性受限。

Method: 提出了约束时间分层架构（CTHA），通过三个关键约束：1）消息契约约束，通过类型化摘要、计划和策略包形式化层间信息流；2）权限流形约束，根据时间范围限定每层的决策空间；3）仲裁解决约束，保证多层决策的无冲突组合。

Result: 实验证明CTHA在复杂任务执行中有效，相比无约束分层基线减少了47%的故障级联，提高了2.3倍的样本效率，并展现出优越的可扩展性。

Conclusion: CTHA作为时间分层架构的原则性扩展，有助于深入理解多智能体协调，并为稳健自主系统的演进提供了有前景的方向。

Abstract: Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.

</details>


### [2] [Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration](https://arxiv.org/abs/2601.10744)
*Sen Wang,Bangwei Liu,Zhenkun Gao,Lizhuang Ma,Xuhong Wang,Yuan Xie,Xin Tan*

Main category: cs.AI

TL;DR: LMEE框架通过统一探索认知与决策行为来促进具身智能体的终身学习，提出MemoryExplorer方法增强记忆检索和主动探索能力，在长时程具身任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有主流的一次性具身任务主要关注任务完成结果，忽视了探索过程和记忆利用这一关键环节。理想的具身智能体应具备终身学习能力来处理长时程复杂任务，这需要智能体不仅能准确完成任务，还能利用长期情景记忆来优化决策。

Method: 提出长期记忆具身探索（LMEE）框架，构建LMEE-Bench数据集和基准，包含多目标导航和基于记忆的问题回答任务。提出MemoryExplorer方法，通过强化学习微调多模态大语言模型，鼓励主动记忆查询，采用包含动作预测、边界选择和问题回答的多任务奖励函数来实现主动探索。

Result: 与最先进的具身探索模型进行广泛实验对比，证明该方法在长时程具身任务中取得了显著优势。

Conclusion: LMEE框架成功统一了智能体的探索认知和决策行为，MemoryExplorer方法有效增强了记忆检索和主动探索能力，为具身智能体的终身学习提供了有效解决方案。

Abstract: An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks.

</details>


### [3] [Optimisation of complex product innovation processes based on trend models with three-valued logic](https://arxiv.org/abs/2601.10768)
*Nina Bočková,Barbora Volná,Mirko Dohnal*

Main category: cs.AI

TL;DR: 该研究使用基于启发式的趋势模型分析复杂产品创新过程，通过简单趋势（增加、减少、恒定）作为最小信息密集量化器，避免依赖数值或粗糙集。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一种分析复杂产品创新过程的方法，该方法不依赖传统数值分析或粗糙集理论，而是使用更简单、信息密集度更低的趋势表示来理解和建模创新动态。

Method: 研究方法基于一组启发式规则，每个启发式通过简单趋势（增加、减少、恒定）表达。这些趋势作为最小信息密集量化器，构建趋势模型。解决方案定义为包含可能场景及其间转换的集合，用转换图表示，系统的任何可能未来或过去行为都可通过图中的路径描绘。

Result: 该方法能够为复杂产品创新过程构建转换图表示，其中每个路径对应系统的一种可能行为轨迹，提供了一种不依赖数值数据的系统动态分析框架。

Conclusion: 基于趋势的启发式模型为分析复杂产品创新过程提供了一种有效的替代方法，通过最小信息密集量化器和转换图表示，能够捕捉系统动态而无需依赖传统数值分析。

Abstract: This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.

</details>


### [4] [ARC Prize 2025: Technical Report](https://arxiv.org/abs/2601.10904)
*François Chollet,Mike Knoop,Gregory Kamradt,Bryan Landers*

Main category: cs.AI

TL;DR: ARC-AGI-2竞赛显示当前AI推理仍受限于知识覆盖，精炼循环成为2025年关键方法，前沿AI实验室开始将ARC-AGI作为行业标准基准


<details>
  <summary>Details</summary>
Motivation: 分析ARC-AGI-2竞赛结果，研究精炼循环在AGI进展中的作用，探讨知识依赖过拟合问题，为ARC-AGI-3交互推理挑战做准备

Method: 调查竞赛中表现最佳的方法，分析精炼循环（包括进化程序合成和商业AI系统应用层优化）的作用，研究零预训练深度学习方法

Result: 竞赛最高得分24%，精炼循环成为主流方法，前沿AI实验室开始报告ARC-AGI性能，但当前AI推理仍受知识覆盖限制

Conclusion: 精炼循环推动了AGI进展，但知识依赖过拟合成为新挑战，ARC-AGI-3将引入需要探索、规划、记忆、目标获取和对齐能力的交互推理挑战

Abstract: The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities.

</details>


### [5] [What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge](https://arxiv.org/abs/2601.10922)
*Yosub Shin,Michael Buriek,Boris Sobolev,Pavel Bushuyeu,Vikas Kumar,Haoyang Xu,Samuel Watson,Igor Molybog*

Main category: cs.AI

TL;DR: 该研究通过NeurIPS 2025 DCVLR挑战赛探讨多模态推理的数据策展，发现基于难度的样本选择是性能提升的主要因素，数据集大小增加仅减少方差而非提升平均准确率，多样性增强和合成数据反而可能降低性能。


<details>
  <summary>Details</summary>
Motivation: 研究多模态推理中的数据策展问题，通过DCVLR挑战赛隔离数据集选择的影响（固定模型和训练协议），探索如何通过有效的数据选择提升多模态推理性能。

Method: 使用基于Walton多模态冷启动的紧凑策展数据集参与DCVLR挑战赛，赛后进行消融实验，分析难度选择、数据集大小、多样性增强和合成数据增强等因素的影响。

Result: 基于难度的样本选择是性能提升的主要驱动力；增加数据集大小不能可靠提高平均准确率，但能减少运行间方差；常用的多样性和合成增强启发式方法无额外益处且常降低性能。

Conclusion: DCVLR是一个饱和状态评估，强调了对齐和难度在多模态推理数据效率中的核心作用，为数据策展提供了重要指导。

Abstract: We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.

</details>


### [6] [ReCreate: Reasoning and Creating Domain Agents Driven by Experience](https://arxiv.org/abs/2601.11100)
*Zhezheng Hao,Hong Wang,Jian Luo,Jianqing Zhang,Yuyan Zhou,Qiang Lin,Can Wang,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: ReCreate是一个基于经验的自动化领域智能体创建框架，通过分析智能体交互历史来改进智能体设计，相比传统方法更高效且性能更好。


<details>
  <summary>Details</summary>
Motivation: 当前大多数实用智能体仍需要人工设计，因为任务差异大且构建成本高。现有自动化方法将智能体生成视为黑盒过程，仅依赖最终性能指标，忽略了成功/失败的关键证据，且计算成本高。

Method: 提出ReCreate框架，采用智能体即优化器范式，包含三个关键组件：1) 经验存储和检索机制用于按需检查；2) 推理-创建协同管道将执行经验映射到脚手架编辑；3) 分层更新将实例级细节抽象为可重用的领域模式。

Result: 在多个不同领域的实验中，ReCreate始终优于人工设计的智能体和现有的自动化智能体生成方法，即使从最小的种子脚手架开始也能取得良好效果。

Conclusion: ReCreate通过系统利用智能体交互历史中的具体信号，提供了一种更有效、更高效的自动化领域智能体创建方法，解决了现有方法的局限性。

Abstract: Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.

</details>


### [7] [Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems](https://arxiv.org/abs/2601.11147)
*Zixu Wang,Bingbing Xu,Yige Yuan,Huawei Shen,Xueqi Cheng*

Main category: cs.AI

TL;DR: SCALE框架通过任务级工作流生成和自预测评估，在保持性能的同时大幅降低多智能体系统的token消耗


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统工作流生成方法在任务级和查询级各有优劣，但相对成本和效益不明确。查询级工作流生成并非总是必要，而基于执行的任务级评估token成本高且不可靠。

Method: 提出SCALE框架：通过少量样本校准的自预测优化器进行任务级工作流生成，替代昂贵的完整验证执行。结合自演化和生成式奖励建模思想，实现低成本评估。

Result: SCALE在多个数据集上保持竞争力，平均性能仅下降0.61%，同时将总体token使用量减少高达83%。

Conclusion: 任务级工作流生成结合自预测评估是高效的多智能体系统解决方案，能够在保持性能的同时显著降低计算成本。

Abstract: Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \textbf{SCALE}, which means \underline{\textbf{S}}elf prediction of the optimizer with few shot \underline{\textbf{CAL}}ibration for \underline{\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\%.

</details>


### [8] [TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech](https://arxiv.org/abs/2601.11178)
*Girish A. Koushik,Helen Treharne,Diptesh Kanojia*

Main category: cs.AI

TL;DR: TANDEM框架将音视频仇恨检测从二元分类转变为结构化推理问题，通过跨模态强化学习实现可解释的仇恨内容识别，在目标识别和时序定位上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体长格式多模态内容中，有害叙事通过音视频文本复杂交互构建，而现有自动化系统多为"黑盒"，缺乏人类审核所需的细粒度可解释证据（如精确时间戳和目标身份）。

Method: 提出TANDEM统一框架，采用新颖的串联强化学习策略，视觉-语言和音频-语言模型通过自约束跨模态上下文相互优化，稳定处理长时序序列而无需密集帧级监督。

Result: 在三个基准数据集上，TANDEM显著优于零样本和上下文增强基线，在HateMM数据集上目标识别F1达到0.73（比最先进方法提升30%），同时保持精确的时序定位能力。

Conclusion: 结构化可解释对齐在复杂多模态环境中可实现，为下一代透明可操作的在线安全审核工具提供了蓝图，但区分冒犯性和仇恨内容在多类设置中仍具挑战性。

Abstract: Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as "black boxes" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.

</details>


### [9] [Beyond Model Scaling: Test-Time Intervention for Efficient Deep Reasoning](https://arxiv.org/abs/2601.11252)
*Qianyue Wang,Jinwu Hu,Yufeng Wang,Huanxiang Lin,Bolin Chen,Zhiquan Wen,Yaofo Chen,Mingkui Tan*

Main category: cs.AI

TL;DR: Think-with-Me是一种新颖的测试时交互式推理范式，通过外部反馈干预来优化大型推理模型的推理过程，减少冗余推理同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在多步推理中表现出色，但存在过度思考和推理偏移问题，导致计算成本增加和性能下降。现有高效推理方法缺乏外部干预机制来引导推理过程。

Method: 提出Think-with-Me范式，在过渡连词处暂停推理以引入外部反馈，通过多标准评估（合理性和完整性）生成反馈，使用GRPO训练目标模型适应交互模式。

Result: 在有限上下文窗口下，Think-with-Me在准确性和推理长度之间取得优越平衡。在AIME24上，比QwQ-32B准确率提高7.19%，同时平均推理长度减少81%（8K窗口）。

Conclusion: Think-with-Me通过外部反馈干预有效优化推理过程，减少冗余推理同时保持准确性，该范式对安全和创造性任务也有益处。

Abstract: Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks.

</details>


### [10] [XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making](https://arxiv.org/abs/2601.11286)
*Weihong Qi,Fan Huang,Rasika Muralidharan,Jisun An,Haewoon Kwak*

Main category: cs.AI

TL;DR: XChoice是一个可解释的框架，用于评估约束决策中AI与人类的对齐程度，通过机制建模而非表面结果匹配来诊断不对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要关注结果一致性（如准确率、F1分数），但缺乏对决策机制的深入理解，无法诊断AI与人类在约束决策中的根本不对齐问题。

Method: XChoice通过拟合基于机制的决策模型到人类数据和LLM生成的决策中，恢复可解释参数（决策因素相对重要性、约束敏感性、隐含权衡），通过比较这些参数向量来评估对齐程度。

Result: 在美国人日常时间分配研究中，发现不同模型和活动之间存在异质性对齐，黑人和已婚群体的不对齐问题尤为突出；通过不变性分析验证了框架的鲁棒性，并通过RAG干预实现了针对性缓解。

Conclusion: XChoice提供了基于机制的评估指标，能够诊断不对齐问题并支持超越表面结果匹配的知情改进，为AI与人类对齐评估提供了更深入的分析工具。

Abstract: We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.

</details>


### [11] [AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems](https://arxiv.org/abs/2601.11354)
*Weiyi Wang,Xinchi Chen,Jingjing Gong,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: AstroReason-Bench是一个用于评估智能体在空间规划问题中规划能力的基准测试，发现当前智能体在物理约束下的真实世界规划中表现不佳


<details>
  <summary>Details</summary>
Motivation: 现有智能体基准测试主要关注符号化或弱基础环境，缺乏对物理约束真实世界领域中智能体规划性能的评估

Method: 引入AstroReason-Bench基准测试，整合多种调度机制（地面站通信和敏捷地球观测），提供统一的智能体导向交互协议

Result: 评估多种最先进的开源和闭源智能体LLM系统，发现当前智能体在专业求解器面前表现显著不足

Conclusion: AstroReason-Bench为未来智能体研究提供了一个具有挑战性和诊断性的测试平台，突显了在现实约束下通用规划的关键局限性

Abstract: Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.

</details>


### [12] [Hyperparameter Optimization of Constraint Programming Solvers](https://arxiv.org/abs/2601.11389)
*Hedieh Haddad,Thibault Falque,Pierre Talbot,Pascal Bouvry*

Main category: cs.AI

TL;DR: 提出"探针与求解"两阶段框架，用于约束规划求解器的自动超参数优化，通过贝叶斯优化在有限时间内显著提升求解性能


<details>
  <summary>Details</summary>
Motivation: 约束规划求解器的性能对超参数选择高度敏感，手动调参困难耗时且需要专业知识，需要自动化方法来优化求解器配置

Method: 提出两阶段框架：1)探针阶段使用可配置的超参数优化方法（贝叶斯优化或汉明距离搜索）探索不同超参数集；2)求解阶段使用找到的最佳配置在剩余时间内解决问题

Result: 贝叶斯优化在ACE求解器上25.4%的实例中提升解质量，57.9%的实例中匹配默认性能；在Choco求解器上38.6%的实例中取得更好结果。贝叶斯优化始终优于汉明距离搜索

Conclusion: 探针与求解算法提供了一种实用、资源感知的约束求解器调优方法，能够跨不同问题类型获得稳健的性能提升，模型化探索优于简单局部搜索

Abstract: The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.
  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.
  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.

</details>


### [13] [Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs](https://arxiv.org/abs/2601.11468)
*Alessandro Padella,Massimiliano de Leoni,Marlon Dumas*

Main category: cs.AI

TL;DR: 本文扩展了基于大语言模型的预测性过程监控框架，在数据稀缺场景下（仅100条轨迹）评估其泛化能力、语义利用和推理机制，并在多个关键绩效指标上验证其优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 预测性过程监控旨在预测进行中过程的结果，传统方法使用机器学习和深度学习架构。本文旨在扩展先前基于大语言模型的框架，全面评估其在不同关键绩效指标上的表现，特别是在数据稀缺环境下的有效性。

Method: 扩展了基于大语言模型的预测性过程监控框架，通过提示机制进行预测。在三个不同事件日志上进行实证评估，涵盖总时间和活动发生两个关键绩效指标。特别关注数据稀缺设置（仅100条轨迹），分析大语言模型如何利用其先验知识和训练轨迹间的内部相关性。

Result: 在数据稀缺设置（仅100条轨迹）下，大语言模型在总时间和活动发生预测方面超越了基准方法。实验表明大语言模型既利用了其内在的先验知识，也利用了训练轨迹间的内部相关性。模型不简单复制现有预测方法，而是进行高阶推理来生成预测。

Conclusion: 基于大语言模型的预测性过程监控框架在数据稀缺环境下表现优异，能够有效利用先验知识和数据相关性，并通过高阶推理机制生成预测，展示了在预测性过程监控任务中的潜力和优势。

Abstract: Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.

</details>


### [14] [Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning](https://arxiv.org/abs/2601.11479)
*Yohai Trabelsi,Guojun Xiong,Fentabil Getnet,Stéphane Verguet,Milind Tambe*

Main category: cs.AI

TL;DR: 该研究提出了一个结合大语言模型和扩展贪心算法的混合框架（LEG），用于优化埃塞俄比亚农村地区卫生站升级的优先排序，在保证人口覆盖理论保证的同时纳入专家定性指导。


<details>
  <summary>Details</summary>
Motivation: 埃塞俄比亚卫生部正在升级卫生站以改善基本医疗服务可及性，但资源有限需要优先排序。传统优化方法需要明确的量化目标，而利益相关者的标准通常用自然语言表达难以形式化，需要一种能结合专家知识和优化技术的解决方案。

Method: 提出了LEG框架：结合用于人口覆盖优化的可证明近似算法与基于大语言模型的迭代精炼。通过人机对齐确保解决方案反映专家定性指导，同时保持覆盖保证。框架系统地将专家知识整合到优化过程中。

Result: 在埃塞俄比亚三个地区的真实数据上进行实验，证明了该框架的有效性。能够生成既满足人口覆盖优化理论保证，又符合专家定性指导的卫生站升级优先排序方案。

Conclusion: LEG框架为公平、数据驱动的卫生系统规划提供了有效工具，能够平衡定量优化目标与专家定性偏好，在资源有限的情况下最大化卫生服务覆盖。

Abstract: Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.

</details>


### [15] [BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics](https://arxiv.org/abs/2601.11492)
*Kaiwen Wang,Kaili Zheng,Rongrong Deng,Qingmin Fan,Milin Zhang,Zongrui Li,Xuesi Zhou,Bo Han,Liren Chen,Chenyi Guo,Ji Wu*

Main category: cs.AI

TL;DR: BoxMind是一个用于拳击战术分析的闭环AI专家系统，通过定义原子击打事件、构建层次化技术战术指标，并基于图模型预测比赛结果，最终将获胜概率梯度转化为可执行的战术调整建议。


<details>
  <summary>Details</summary>
Motivation: 格斗类运动如拳击在AI驱动的战术分析方面发展不足，主要原因是动作动态复杂且缺乏结构化的战术表示。需要将非结构化视频数据转化为战略智能，弥合计算机视觉与竞技体育决策支持之间的差距。

Method: 1) 定义具有精确时间边界、空间和技术属性的原子击打事件；2) 将比赛视频解析为18个层次化技术战术指标；3) 提出基于图的预测模型，融合显性技术战术特征与可学习的时间变化潜在嵌入；4) 将比赛结果建模为技术战术指标的可微函数，将获胜概率梯度转化为可执行的战术调整。

Result: 1) 结果预测模型在BoxerGraph测试集上达到69.8%的准确率，在奥运比赛上达到87.5%的准确率；2) 系统生成的战略建议与人类专家水平相当；3) 在2024年巴黎奥运会闭环部署中，直接助力中国国家队获得3金2银的历史性成绩。

Conclusion: BoxMind建立了一个可复制的范式，将非结构化视频数据转化为战略智能，弥合了计算机视觉与竞技体育决策支持之间的差距，为格斗类运动的AI驱动战术分析提供了新途径。

Abstract: Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [16] [Analytic Bijections for Smooth and Interpretable Normalizing Flows](https://arxiv.org/abs/2601.10774)
*Mathis Gerdes,Miranda C. N. Cheng*

Main category: cs.LG

TL;DR: 提出了三种全局平滑、定义在全实数域且具有解析逆的双射函数族（三次有理、sinh和三次多项式），以及径向流架构，在保持训练稳定性的同时大幅减少参数数量。


<details>
  <summary>Details</summary>
Motivation: 现有归一化流方法存在权衡：仿射变换平滑且可解析求逆但表达能力有限；单调样条有局部控制但分段平滑且定义在有界域；残差流平滑但需要数值求逆。需要结合这些方法优点的解决方案。

Method: 1. 引入三种解析双射函数族：三次有理、sinh和三次多项式，全局平滑、定义在全实数域、具有闭式解析逆。2. 开发径向流架构：通过直接参数化变换径向坐标同时保持角度方向，实现几何可解释的变换。

Result: 1. 新双射函数在耦合流中作为即插即用替换，匹配或超越样条性能。2. 径向流表现出卓越的训练稳定性，产生几何可解释的变换，对于具有径向结构的目标，能以1000倍更少的参数达到与耦合流相当的质量。3. 在φ⁴晶格场理论的高维物理问题中，新双射函数超越仿射基线并解决模式崩溃问题。

Conclusion: 提出的三种解析双射函数族和径向流架构结合了现有方法的优点，提供了平滑、可解析求逆且表达能力强的归一化流设计，在训练稳定性、参数效率和问题特定设计方面均有显著优势。

Abstract: A key challenge in designing normalizing flows is finding expressive scalar bijections that remain invertible with tractable Jacobians. Existing approaches face trade-offs: affine transformations are smooth and analytically invertible but lack expressivity; monotonic splines offer local control but are only piecewise smooth and act on bounded domains; residual flows achieve smoothness but need numerical inversion. We introduce three families of analytic bijections -- cubic rational, sinh, and cubic polynomial -- that are globally smooth ($C^\infty$), defined on all of $\mathbb{R}$, and analytically invertible in closed form, combining the favorable properties of all prior approaches. These bijections serve as drop-in replacements in coupling flows, matching or exceeding spline performance. Beyond coupling layers, we develop radial flows: a novel architecture using direct parametrization that transforms the radial coordinate while preserving angular direction. Radial flows exhibit exceptional training stability, produce geometrically interpretable transformations, and on targets with radial structure can achieve comparable quality to coupling flows with $1000\times$ fewer parameters. We provide comprehensive evaluation on 1D and 2D benchmarks, and demonstrate applicability to higher-dimensional physics problems through experiments on $φ^4$ lattice field theory, where our bijections outperform affine baselines and enable problem-specific designs that address mode collapse.

</details>


### [17] [Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework](https://arxiv.org/abs/2601.10779)
*Qingyue Zhang,Chang Chu,Haohao Fu,Tianren Peng,Yanru Wu,Guanbo Huang,Yang Li,Shao-Lun Huang*

Main category: cs.LG

TL;DR: 本文提出了UOWQ框架，通过联合优化源任务权重和转移数量来解决多源迁移学习中的负迁移问题，理论证明在权重调整后使用所有可用源样本是最优的，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统迁移学习方法通常只单独优化源任务权重或转移样本数量，忽略了二者的联合考虑，导致在多源迁移学习中可能出现负迁移问题。需要一种统一框架来同时优化权重和数量，以平衡异构源任务的贡献。

Method: 提出UOWQ理论框架，将多源迁移学习建模为基于Kullback-Leibler散度泛化误差度量的参数估计问题。框架联合确定每个源任务的最优权重和最优转移数量，在单源情况下提供闭式解，在多源情况下开发基于凸优化的数值求解方法，并进一步提出实用的多源迁移学习和多任务学习算法。

Result: 理论证明了在权重适当调整后，使用所有可用源样本总是最优的。在DomainNet和Office-Home等真实世界基准测试上的大量实验表明，UOWQ始终优于强基线方法，验证了理论预测和框架的实际有效性。

Conclusion: UOWQ框架通过联合优化源任务权重和转移数量，有效解决了多源迁移学习中的负迁移问题，提供了理论保证和实用算法，在多个基准数据集上表现出优越性能。

Abstract: Transfer learning plays a vital role in improving model performance in data-scarce scenarios. However, naive uniform transfer from multiple source tasks may result in negative transfer, highlighting the need to properly balance the contributions of heterogeneous sources. Moreover, existing transfer learning methods typically focus on optimizing either the source weights or the amount of transferred samples, while largely neglecting the joint consideration of the other. In this work, we propose a theoretical framework, Unified Optimization of Weights and Quantities (UOWQ), which formulates multi-source transfer learning as a parameter estimation problem grounded in an asymptotic analysis of a Kullback-Leibler divergence-based generalization error measure. The proposed framework jointly determines the optimal source weights and optimal transfer quantities for each source task. Firstly, we prove that using all available source samples is always optimal once the weights are properly adjusted, and we provide a theoretical explanation for this phenomenon. Moreover, to determine the optimal transfer weights, our analysis yields closed-form solutions in the single-source setting and develops a convex optimization-based numerical procedure for the multi-source case. Building on the theoretical results, we further propose practical algorithms for both multi-source transfer learning and multi-task learning settings. Extensive experiments on real-world benchmarks, including DomainNet and Office-Home, demonstrate that UOWQ consistently outperforms strong baselines. The results validate both the theoretical predictions and the practical effectiveness of our framework.

</details>


### [18] [Mugi: Value Level Parallelism For Efficient LLMs](https://arxiv.org/abs/2601.10823)
*Daniel Price,Prabhu Vellaisamy,John Shen,Di Wu*

Main category: cs.LG

TL;DR: 本文提出Mugi架构，通过值级并行性优化大语言模型中的非线性操作和小批量GEMM，显著提升性能、能效和可持续性。


<details>
  <summary>Details</summary>
Motivation: 现有值级并行性主要针对大批量、低精度的一般矩阵乘法，但在基于Transformer的大语言模型中存在更复杂的非线性操作，需要探索VLP如何全面优化LLM。

Method: 1. 将VLP推广到非线性近似，采用以值为中心的方法；2. 优化小批量GEMM中的VLP，结合权重量化、KV缓存量化等技术；3. 设计新的Mugi架构来封装这些创新。

Result: Mugi在非线性softmax操作上实现吞吐量提升45倍、能效提升668倍；在LLM上实现吞吐量提升2.07倍、能效提升3.11倍；运行碳排放降低1.45倍，硬件碳排放降低1.48倍。

Conclusion: Mugi架构通过值级并行性有效优化大语言模型的复杂操作，在性能、能效和可持续性方面均取得显著改进，为LLM硬件加速提供了新方案。

Abstract: Value level parallelism (VLP) has been proposed to improve the efficiency of large-batch, low-precision general matrix multiply (GEMM) between symmetric activations and weights. In transformer based large language models (LLMs), there exist more sophisticated operations beyond activation-weight GEMM. In this paper, we explore how VLP benefits LLMs. First, we generalize VLP for nonlinear approximations, outperforming existing nonlinear approximations in end-to-end LLM accuracy, performance, and efficiency. Our VLP approximation follows a value-centric approach, where important values are assigned with greater accuracy. Second, we optimize VLP for small-batch GEMMs with asymmetric inputs efficiently, which leverages timely LLM optimizations, including weight-only quantization, key-value (KV) cache quantization, and group query attention. Finally, we design a new VLP architecture, Mugi, to encapsulate the innovations above and support full LLM workloads, while providing better performance, efficiency and sustainability. Our experimental results show that Mugi can offer significant improvements on throughput and energy efficiency, up to $45\times$ and $668\times$ for nonlinear softmax operations, and $2.07\times$ and $3.11\times$ for LLMs, and also decrease operational carbon for LLM operation by $1.45\times$ and embodied carbon by $1.48\times$.

</details>


### [19] [AI-Guided Human-In-the-Loop Inverse Design of High Performance Engineering Structures](https://arxiv.org/abs/2601.10859)
*Dat Quoc Ha,Md Ferdous Alam,Markus J. Buehler,Faez Ahmed,Josephine V. Carstensen*

Main category: cs.LG

TL;DR: 提出一种AI协同拓扑优化方法，使用U-Net预测用户偏好的修改区域，减少迭代次数，提高设计效率


<details>
  <summary>Details</summary>
Motivation: 传统拓扑优化计算时间长且黑箱操作，人机交互式方法依赖耗时的迭代区域选择，需要减少迭代试验次数

Method: 采用U-Net架构的图像分割模型，在合成数据集上训练预测用户偏好区域（最长拓扑构件或最复杂结构连接），作为AI推荐呈现给用户

Result: 模型成功预测合理的修改区域，在多样化非标准拓扑优化问题中具有泛化能力，人机协同方法可将线性屈曲载荷提高39%，总设计时间仅增加15秒

Conclusion: AI协同拓扑优化方法有效整合人类直觉与机器学习预测，显著提高设计性能同时保持时间效率，为人机交互优化提供新思路

Abstract: Inverse design tools such as Topology Optimization (TO) can achieve new levels of improvement for high-performance engineered structures. However, widespread use is hindered by high computational times and a black-box nature that inhibits user interaction. Human-in-the-loop TO approaches are emerging that integrate human intuition into the design generation process. However, these rely on the time-consuming bottleneck of iterative region selection for design modifications. To reduce the number of iterative trials, this contribution presents an AI co-pilot that uses machine learning to predict the user's preferred regions. The prediction model is configured as an image segmentation task with a U-Net architecture. It is trained on synthetic datasets where human preferences either identify the longest topological member or the most complex structural connection. The model successfully predicts plausible regions for modification and presents them to the user as AI recommendations. The human preference model demonstrates generalization across diverse and non-standard TO problems and exhibits emergent behavior outside the single-region selection training data. Demonstration examples show that the new human-in-the-loop TO approach that integrates the AI co-pilot can improve manufacturability or improve the linear buckling load by 39% while only increasing the total design time by 15 sec compared to conventional simplistic TO.

</details>


### [20] [Beyond Accuracy: A Stability-Aware Metric for Multi-Horizon Forecasting](https://arxiv.org/abs/2601.10863)
*Chutian Ma,Grigorii Pomazkin,Giacinto Paolo Saggese,Paul Smith*

Main category: cs.LG

TL;DR: 该论文提出了一个结合预测准确性和时间一致性的新评分标准（forecast AC score），用于评估概率性多步预测质量，并在季节性ARIMA模型上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测方法只优化准确性，忽略了时间一致性（即模型在不同预测起点对同一未来事件的预测稳定性）。这在实际应用中可能导致预测结果波动过大，影响决策可靠性。

Method: 提出了forecast AC score评分标准，同时考虑多步预测准确性和稳定性，并允许用户自定义准确性与一致性的权重平衡。将该评分实现为可微分的目标函数，用于训练季节性ARIMA模型。

Result: 在M4 Hourly基准数据集上的实验表明，与传统最大似然估计相比，AC优化模型在保持相当或改进的点预测准确性的同时，对相同目标时间戳的预测波动性降低了75%。

Conclusion: forecast AC score能够有效平衡预测准确性和时间一致性，为概率性多步预测提供了更全面的质量评估框架，并在实际应用中显著降低了预测波动性。

Abstract: Traditional time series forecasting methods optimize for accuracy alone. This objective neglects temporal consistency, in other words, how consistently a model predicts the same future event as the forecast origin changes. We introduce the forecast accuracy and coherence score (forecast AC score for short) for measuring the quality of probabilistic multi-horizon forecasts in a way that accounts for both multi-horizon accuracy and stability. Our score additionally provides for user-specified weights to balance accuracy and consistency requirements. As an example application, we implement the score as a differentiable objective function for training seasonal ARIMA models and evaluate it on the M4 Hourly benchmark dataset. Results demonstrate substantial improvements over traditional maximum likelihood estimation. Our AC-optimized models achieve a 75\% reduction in forecast volatility for the same target timestamps while maintaining comparable or improved point forecast accuracy.

</details>


### [21] [Action Shapley: A Training Data Selection Metric for World Model in Reinforcement Learning](https://arxiv.org/abs/2601.10905)
*Rajat Ghosh,Debojyoti Dutta*

Main category: cs.LG

TL;DR: 提出Action Shapley作为训练数据选择的公平度量标准，并设计随机动态算法降低计算复杂度，在数据受限场景中提升世界模型性能


<details>
  <summary>Details</summary>
Motivation: 在强化学习中，世界模型对于模拟环境至关重要，特别是在与真实环境交互成本高或危险的场景。现有世界模型的效能和可解释性严重依赖于训练数据质量，需要一种公平、无偏的数据选择方法。

Method: 提出Action Shapley作为训练数据选择的通用度量标准，并设计了随机动态算法来降低传统Shapley值计算的指数复杂度。该方法通过随机化策略有效减少了计算负担。

Result: 在五个数据受限的真实世界案例研究中，该算法相比传统指数时间计算实现了超过80%的计算效率提升。基于Action Shapley的训练数据选择策略始终优于临时性数据选择方法。

Conclusion: Action Shapley为世界模型的训练数据选择提供了有效的公平度量标准，其配套的随机动态算法显著降低了计算复杂度，在实际应用中表现出优越的性能和效率。

Abstract: Numerous offline and model-based reinforcement learning systems incorporate world models to emulate the inherent environments. A world model is particularly important in scenarios where direct interactions with the real environment is costly, dangerous, or impractical. The efficacy and interpretability of such world models are notably contingent upon the quality of the underlying training data. In this context, we introduce Action Shapley as an agnostic metric for the judicious and unbiased selection of training data. To facilitate the computation of Action Shapley, we present a randomized dynamic algorithm specifically designed to mitigate the exponential complexity inherent in traditional Shapley value computations. Through empirical validation across five data-constrained real-world case studies, the algorithm demonstrates a computational efficiency improvement exceeding 80\% in comparison to conventional exponential time computations. Furthermore, our Action Shapley-based training data selection policy consistently outperforms ad-hoc training data selection.

</details>


### [22] [FAConvLSTM: Factorized-Attention ConvLSTM for Efficient Feature Extraction in Multivariate Climate Data](https://arxiv.org/abs/2601.10914)
*Francis Ndikum Nji,Jianwu Wang*

Main category: cs.LG

TL;DR: FAConvLSTM：一种用于地球观测数据的因子化注意力ConvLSTM层，通过轻量级瓶颈和共享深度空间混合提高效率，同时增强空间表达能力和物理可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统ConvLSTM2D在处理高分辨率多元地球观测数据时面临挑战：密集卷积门控计算成本高，局部感受野限制了对长程空间结构和解耦气候动态的建模。

Method: 提出FAConvLSTM作为ConvLSTM2D的即插即用替代方案，采用因子化门控计算、多尺度扩张深度分支、挤压激励重校准、窥视孔连接、轻量级轴向空间注意力机制，以及带固定季节性位置编码的时间自注意力子空间头。

Result: 在多元时空气候数据实验中，FAConvLSTM比标准ConvLSTM产生更稳定、可解释和鲁棒的潜在表示，同时显著降低计算开销。

Conclusion: FAConvLSTM通过因子化注意力机制有效解决了地球观测数据处理中的效率、空间表达能力和物理可解释性问题，为气候动态建模提供了更优的解决方案。

Abstract: Learning physically meaningful spatiotemporal representations from high-resolution multivariate Earth observation data is challenging due to strong local dynamics, long-range teleconnections, multi-scale interactions, and nonstationarity. While ConvLSTM2D is a commonly used baseline, its dense convolutional gating incurs high computational cost and its strictly local receptive fields limit the modeling of long-range spatial structure and disentangled climate dynamics. To address these limitations, we propose FAConvLSTM, a Factorized-Attention ConvLSTM layer designed as a drop-in replacement for ConvLSTM2D that simultaneously improves efficiency, spatial expressiveness, and physical interpretability. FAConvLSTM factorizes recurrent gate computations using lightweight [1 times 1] bottlenecks and shared depthwise spatial mixing, substantially reducing channel complexity while preserving recurrent dynamics. Multi-scale dilated depthwise branches and squeeze-and-excitation recalibration enable efficient modeling of interacting physical processes across spatial scales, while peephole connections enhance temporal precision. To capture teleconnection-scale dependencies without incurring global attention cost, FAConvLSTM incorporates a lightweight axial spatial attention mechanism applied sparsely in time. A dedicated subspace head further produces compact per timestep embeddings refined through temporal self-attention with fixed seasonal positional encoding. Experiments on multivariate spatiotemporal climate data shows superiority demonstrating that FAConvLSTM yields more stable, interpretable, and robust latent representations than standard ConvLSTM, while significantly reducing computational overhead.

</details>


### [23] [HOSL: Hybrid-Order Split Learning for Memory-Constrained Edge Training](https://arxiv.org/abs/2601.10940)
*Aakriti,Zhe Li,Dandan Liang,Chao Huang,Rui Li,Haibo Yang*

Main category: cs.LG

TL;DR: HOSL提出了一种混合阶分割学习框架，通过在客户端使用零阶优化减少内存开销，在服务器端使用一阶优化保证收敛性能，解决了分割学习中内存效率与优化效果之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有分割学习系统主要依赖一阶优化，需要客户端存储激活等中间量，导致内存开销大，削弱了模型分割的优势。而零阶优化虽能减少内存使用，但收敛慢且性能下降。需要解决内存效率与优化效果之间的根本权衡。

Method: HOSL采用混合阶优化策略：客户端使用内存高效的零阶梯度估计，消除反向传播和激活存储；服务器端使用一阶优化确保快速收敛和竞争性能。理论分析表明收敛率取决于客户端模型维度而非完整模型维度。

Result: 在OPT模型（125M和1.3B参数）的6个任务实验中，HOSL相比一阶方法减少客户端GPU内存达3.7倍，同时准确率仅比基线低0.20%-4.23%。相比零阶基线，HOSL性能提升达15.55%，验证了混合策略在边缘设备内存高效训练中的有效性。

Conclusion: HOSL通过客户端零阶优化和服务器端一阶优化的混合策略，有效解决了分割学习中内存效率与优化性能的权衡问题，为资源受限边缘设备上的大语言模型协作训练提供了实用解决方案。

Abstract: Split learning (SL) enables collaborative training of large language models (LLMs) between resource-constrained edge devices and compute-rich servers by partitioning model computation across the network boundary. However, existing SL systems predominantly rely on first-order (FO) optimization, which requires clients to store intermediate quantities such as activations for backpropagation. This results in substantial memory overhead, largely negating benefits of model partitioning. In contrast, zeroth-order (ZO) optimization eliminates backpropagation and significantly reduces memory usage, but often suffers from slow convergence and degraded performance. In this work, we propose HOSL, a novel Hybrid-Order Split Learning framework that addresses this fundamental trade-off between memory efficiency and optimization effectiveness by strategically integrating ZO optimization on the client side with FO optimization on the server side. By employing memory-efficient ZO gradient estimation at the client, HOSL eliminates backpropagation and activation storage, reducing client memory consumption. Meanwhile, server-side FO optimization ensures fast convergence and competitive performance. Theoretically, we show that HOSL achieves a $\mathcal{O}(\sqrt{d_c/TQ})$ rate, which depends on client-side model dimension $d_c$ rather than the full model dimension $d$, demonstrating that convergence improves as more computation is offloaded to the server. Extensive experiments on OPT models (125M and 1.3B parameters) across 6 tasks demonstrate that HOSL reduces client GPU memory by up to 3.7$\times$ compared to the FO method while achieving accuracy within 0.20%-4.23% of this baseline. Furthermore, HOSL outperforms the ZO baseline by up to 15.55%, validating the effectiveness of our hybrid strategy for memory-efficient training on edge devices.

</details>


### [24] [Transient learning dynamics drive escape from sharp valleys in Stochastic Gradient Descent](https://arxiv.org/abs/2601.10962)
*Ning Yang,Yikuan Zhang,Qi Ouyang,Chao Tang,Yuhai Tu*

Main category: cs.LG

TL;DR: SGD通过非平衡机制选择平坦解：噪声重塑损失景观为有效势能，偏好平坦区域；训练过程中能量壁垒增长导致"瞬态冻结"机制，最终将动态困在单个盆地中。


<details>
  <summary>Details</summary>
Motivation: 虽然SGD在深度学习中至关重要，但其偏好平坦、更可泛化解的动态起源仍不清楚。研究旨在揭示SGD学习动态中控制解选择的非平衡机制。

Method: 通过分析SGD学习动态，使用数值实验观察SGD轨迹的瞬态探索阶段，并采用可处理的物理模型展示SGD噪声如何重塑损失景观为有效势能。

Result: 发现SGD轨迹在训练初期会反复逃离尖锐谷底并转向平坦区域；SGD噪声将损失景观重塑为偏好平坦解的有效势能；训练过程中能量壁垒增长导致"瞬态冻结"机制，最终将动态困在单个盆地中。

Conclusion: 研究提供了连接学习动态、损失景观几何和泛化的统一物理框架，并提出了设计更有效优化算法的原则，表明增加SGD噪声强度可以延迟冻结并增强向平坦最小值的收敛。

Abstract: Stochastic gradient descent (SGD) is central to deep learning, yet the dynamical origin of its preference for flatter, more generalizable solutions remains unclear. Here, by analyzing SGD learning dynamics, we identify a nonequilibrium mechanism governing solution selection. Numerical experiments reveal a transient exploratory phase in which SGD trajectories repeatedly escape sharp valleys and transition toward flatter regions of the loss landscape. By using a tractable physical model, we show that the SGD noise reshapes the landscape into an effective potential that favors flat solutions. Crucially, we uncover a transient freezing mechanism: as training proceeds, growing energy barriers suppress inter-valley transitions and ultimately trap the dynamics within a single basin. Increasing the SGD noise strength delays this freezing, which enhances convergence to flatter minima. Together, these results provide a unified physical framework linking learning dynamics, loss-landscape geometry, and generalization, and suggest principles for the design of more effective optimization algorithms.

</details>


### [25] [Toward Adaptive Grid Resilience: A Gradient-Free Meta-RL Framework for Critical Load Restoration](https://arxiv.org/abs/2601.10973)
*Zain ul Abdeen,Waris Gill,Ming Jin*

Main category: cs.LG

TL;DR: 提出MGF-RL框架，结合元学习和无梯度进化策略，用于配电网故障恢复，能快速适应新场景且减少重训练需求


<details>
  <summary>Details</summary>
Motivation: 极端事件后恢复关键负荷需要自适应控制，但可再生能源不确定性、可调度资源有限和非线性动态使恢复困难；传统RL泛化能力差且需要大量重训练

Method: 提出MGF-RL框架，结合一阶元学习和进化策略，从历史故障经验学习可迁移初始化，无需梯度计算即可快速适应新场景

Result: 在IEEE 13和123节点测试系统中，MGF-RL在可靠性、恢复速度和适应效率上优于标准RL、MAML元RL和模型预测控制，泛化能力强且需要更少微调

Conclusion: MGF-RL框架适用于可再生能源丰富的配电网实时负荷恢复，提供次线性遗憾界限证明适应效率与任务相似度和环境变化的关系

Abstract: Restoring critical loads after extreme events demands adaptive control to maintain distribution-grid resilience, yet uncertainty in renewable generation, limited dispatchable resources, and nonlinear dynamics make effective restoration difficult. Reinforcement learning (RL) can optimize sequential decisions under uncertainty, but standard RL often generalizes poorly and requires extensive retraining for new outage configurations or generation patterns. We propose a meta-guided gradient-free RL (MGF-RL) framework that learns a transferable initialization from historical outage experiences and rapidly adapts to unseen scenarios with minimal task-specific tuning. MGF-RL couples first-order meta-learning with evolutionary strategies, enabling scalable policy search without gradient computation while accommodating nonlinear, constrained distribution-system dynamics. Experiments on IEEE 13-bus and IEEE 123-bus test systems show that MGF-RL outperforms standard RL, MAML-based meta-RL, and model predictive control across reliability, restoration speed, and adaptation efficiency under renewable forecast errors. MGF-RL generalizes to unseen outages and renewable patterns while requiring substantially fewer fine-tuning episodes than conventional RL. We also provide sublinear regret bounds that relate adaptation efficiency to task similarity and environmental variation, supporting the empirical gains and motivating MGF-RL for real-time load restoration in renewable-rich distribution grids.

</details>


### [26] [Reasoning Distillation for Lightweight Automated Program Repair](https://arxiv.org/abs/2601.10987)
*Aanand Balasubramanian,Sashank Silwal*

Main category: cs.LG

TL;DR: 轻量级符号推理监督能提升紧凑型自动程序修复模型的修复类型分类性能，通过大型教师模型提供结构化符号推理标签来改进小型学生模型的学习效果。


<details>
  <summary>Details</summary>
Motivation: 小型代码模型在资源受限环境中具有吸引力，但它们通常只产生单一预测，不清楚它们是否学习了有意义的程序结构还是依赖浅层相关性。需要提升轻量级程序修复模型的可解释性和鲁棒性。

Method: 提出推理蒸馏方法：大型教师模型提供结构化符号推理标签和修复类型标签，这些标签捕获错误的高层因果属性而不依赖自由形式解释。在IntroClass基准上训练基于CodeT5的学生模型，比较标签单独训练和推理蒸馏训练的效果。

Result: 推理监督持续提升宏观平均性能，特别是在较少出现的错误类别上，且不增加模型大小或复杂度。正确推理轨迹与正确预测强相关，但不完全决定预测结果。

Conclusion: 符号推理蒸馏是改进轻量级程序修复模型可解释性和鲁棒性的实用方法，能帮助小型模型学习更有意义的程序结构而非浅层相关性。

Abstract: We study whether lightweight symbolic reasoning supervision can improve fix type classification in compact automated program repair models. Small code models are attractive for resource-constrained settings, but they typically produce only a single prediction, making it unclear whether they learn meaningful program structure or rely on shallow correlations. We propose a reasoning distillation approach in which a large teacher model provides structured symbolic reasoning tags alongside fix-type labels. These tags capture high-level causal properties of bugs without relying on free-form explanations. We train a CodeT5-based student model under label-only and reasoning-distilled settings on the IntroClass benchmark. Reasoning supervision consistently improves macro averaged performance, particularly on less frequent bug categories, without increasing model size or complexity. We further analyze the relationship between reasoning accuracy and fix-type prediction, showing that correct reasoning traces strongly correlate with correct predictions, while not fully determining them. Our results suggest that symbolic reasoning distillation is a practical way to improve interpretability and robustness in lightweight program repair models.

</details>


### [27] [Constant Metric Scaling in Riemannian Computation](https://arxiv.org/abs/2601.10992)
*Kisung You*

Main category: cs.LG

TL;DR: 这篇论文探讨了黎曼度量常数缩放对几何量和优化算法的影响，区分了哪些量会变化、哪些几何结构保持不变。


<details>
  <summary>Details</summary>
Motivation: 在计算应用中经常出现黎曼度量的常数缩放操作，但这一操作的影响在实践中并不总是清晰，有时会与曲率变化、流形结构变化或坐标表示变化混淆。作者希望通过系统分析澄清常数度量缩放的影响。

Method: 作者对任意黎曼流形上的常数度量缩放进行了系统的理论分析，区分了在缩放下变化的量（如范数、距离、体积元、梯度大小）和保持不变的几何对象（如Levi-Civita联络、测地线、指数和对数映射、平行移动）。

Result: 分析表明，常数度量缩放主要影响度量相关的量，但不改变流形的内在几何结构。在黎曼优化中，这种缩放通常可以解释为步长的全局重缩放，而不是底层几何的修改。

Conclusion: 这篇说明性文章旨在澄清如何在黎曼计算中引入全局度量尺度参数，而不改变这些方法所依赖的几何结构。常数度量缩放是一个有用的工具，但需要清楚理解其对不同几何量的影响。

Abstract: Constant rescaling of a Riemannian metric appears in many computational settings, often through a global scale parameter that is introduced either explicitly or implicitly. Although this operation is elementary, its consequences are not always made clear in practice and may be confused with changes in curvature, manifold structure, or coordinate representation. In this note we provide a short, self-contained account of constant metric scaling on arbitrary Riemannian manifolds. We distinguish between quantities that change under such a scaling, including norms, distances, volume elements, and gradient magnitudes, and geometric objects that remain invariant, such as the Levi--Civita connection, geodesics, exponential and logarithmic maps, and parallel transport. We also discuss implications for Riemannian optimization, where constant metric scaling can often be interpreted as a global rescaling of step sizes rather than a modification of the underlying geometry. The goal of this note is purely expository and is intended to clarify how a global metric scale parameter can be introduced in Riemannian computation without altering the geometric structures on which these methods rely.

</details>


### [28] [Backdoor Attacks on Multi-modal Contrastive Learning](https://arxiv.org/abs/2601.11006)
*Simi D Kuniyilh,Rita Machacy*

Main category: cs.LG

TL;DR: 本文对对比学习中的后门攻击进行了全面比较性综述，分析了威胁模型、攻击方法、目标领域和现有防御措施，强调了对比学习特有的脆弱性，并讨论了安全部署的挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 对比学习已成为跨领域自监督表示学习的主流方法，但最近研究表明对比学习容易受到后门和数据中毒攻击。攻击者可以通过操纵预训练数据或模型更新来植入隐藏的恶意行为，这对工业化和分布式环境中的系统安全部署构成了严重威胁。

Method: 本文采用系统性综述方法，对对比学习中的后门攻击进行全面的比较分析。研究内容包括：威胁模型分析、攻击方法分类、目标领域识别、现有防御措施评估。通过总结该领域的最新进展，揭示对比学习特有的脆弱性。

Result: 研究发现对比学习在多个领域（视觉、多模态、图学习、联邦学习）都存在后门攻击的脆弱性。攻击者可以通过数据投毒或模型更新操纵来植入恶意后门。现有防御措施有限，需要更有效的安全机制来保护对比学习系统。

Conclusion: 对比学习虽然在各领域取得了显著成功，但其固有的脆弱性使其容易受到后门攻击。本文强调了在工业化和分布式环境中安全部署对比学习系统的重要性，指出了当前研究的不足，并提出了未来研究方向，包括开发更鲁棒的防御机制和评估框架。

Abstract: Contrastive learning has become a leading self- supervised approach to representation learning across domains, including vision, multimodal settings, graphs, and federated learning. However, recent studies have shown that contrastive learning is susceptible to backdoor and data poisoning attacks. In these attacks, adversaries can manipulate pretraining data or model updates to insert hidden malicious behavior. This paper offers a thorough and comparative review of backdoor attacks in contrastive learning. It analyzes threat models, attack methods, target domains, and available defenses. We summarize recent advancements in this area, underline the specific vulnerabilities inherent to contrastive learning, and discuss the challenges and future research directions. Our findings have significant implications for the secure deployment of systems in industrial and distributed environments.

</details>


### [29] [Combating Spurious Correlations in Graph Interpretability via Self-Reflection](https://arxiv.org/abs/2601.11021)
*Kecheng Cai,Chenyang Xu,Chao Peng*

Main category: cs.LG

TL;DR: 该论文提出了一种自反思框架，用于提升图学习模型在具有虚假相关性的Spurious-Motif基准数据集上的可解释性表现。


<details>
  <summary>Details</summary>
Motivation: Spurious-Motif基准数据集因故意设计虚假相关性而极具挑战性，现有方法在该数据集上表现显著较差。作者旨在提升图学习模型在这种具有强虚假相关性数据集上的可解释性。

Method: 提出一个自反思框架，可与现有可解释图学习方法集成。该框架将方法生成的节点和边重要性分数反馈回原始方法进行第二轮评估，形成迭代过程。还提出基于此反馈机制的微调训练方法。

Result: 自反思技术能有效提升模型在具有强虚假相关性数据集上的可解释性表现，该框架可增强现有方法区分真正相关结构与误导模式的能力。

Conclusion: 自反思技术不仅适用于大语言模型处理复杂任务，也能有效提升图学习模型在具有虚假相关性数据集上的可解释性，为图表示学习提供了新的改进方向。

Abstract: Interpretable graph learning has recently emerged as a popular research topic in machine learning. The goal is to identify the important nodes and edges of an input graph that are crucial for performing a specific graph reasoning task. A number of studies have been conducted in this area, and various benchmark datasets have been proposed to facilitate evaluation. Among them, one of the most challenging is the Spurious-Motif benchmark, introduced at ICLR 2022. The datasets in this synthetic benchmark are deliberately designed to include spurious correlations, making it particularly difficult for models to distinguish truly relevant structures from misleading patterns. As a result, existing methods exhibit significantly worse performance on this benchmark compared to others.
  In this paper, we focus on improving interpretability on the challenging Spurious-Motif datasets. We demonstrate that the self-reflection technique, commonly used in large language models to tackle complex tasks, can also be effectively adapted to enhance interpretability in datasets with strong spurious correlations. Specifically, we propose a self-reflection framework that can be integrated with existing interpretable graph learning methods. When such a method produces importance scores for each node and edge, our framework feeds these predictions back into the original method to perform a second round of evaluation. This iterative process mirrors how large language models employ self-reflective prompting to reassess their previous outputs. We further analyze the reasons behind this improvement from the perspective of graph representation learning, which motivates us to propose a fine-tuning training method based on this feedback mechanism.

</details>


### [30] [AVP-Pro: An Adaptive Multi-Modal Fusion and Contrastive Learning Approach for Comprehensive Two-Stage Antiviral Peptide Identification](https://arxiv.org/abs/2601.11028)
*Xinru Wen,Weizhong Lin,zi liu,Xuan Xiao*

Main category: cs.LG

TL;DR: AVP-Pro是一个用于抗病毒肽识别的两阶段预测框架，通过自适应特征融合和对比学习提高识别准确性，在一般AVP识别和功能亚型预测方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有抗病毒肽识别方法在捕捉复杂序列依赖性和区分高相似度样本方面存在局限性，需要开发更准确的预测工具来支持新型药物开发。

Method: 提出AVP-Pro两阶段框架：1)构建包含10种描述符的全景特征空间，设计分层融合架构整合自注意力和自适应门控机制；2)采用基于BLOSUM62增强的在线难例挖掘对比学习策略；3)结合迁移学习策略进行功能亚型预测。

Result: 在一般AVP识别阶段，准确率达到0.9531，MCC为0.9064，优于现有SOTA方法；在功能亚型预测阶段，实现了6个病毒家族和8种特定病毒在小样本条件下的准确分类。

Conclusion: AVP-Pro为抗病毒药物高通量筛选提供了强大且可解释的新工具，并开发了用户友好的Web界面，可访问https://wwwy1031-avp-pro.hf.space。

Abstract: The accurate identification of antiviral peptides (AVPs) is crucial for novel drug development. However, existing methods still have limitations in capturing complex sequence dependencies and distinguishing confusing samples with high similarity. To address these challenges, we propose AVP-Pro, a novel two-stage predictive framework that integrates adaptive feature fusion and contrastive learning. To comprehensively capture the physicochemical properties and deep-seated patterns of peptide sequences, we constructed a panoramic feature space encompassing 10 distinct descriptors and designed a hierarchical fusion architecture. This architecture integrates self-attention and adaptive gating mechanisms to dynamically modulate the weights of local motifs extracted by CNNs and global dependencies captured by BiLSTMs based on sequence context. Targeting the blurred decision boundary caused by the high similarity between positive and negative sample sequences, we adopted an Online Hard Example Mining (OHEM)-driven contrastive learning strategy enhanced by BLOSUM62. This approach significantly sharpened the model's discriminative power. Model evaluation results show that in the first stage of general AVP identification, the model achieved an accuracy of 0.9531 and an MCC of 0.9064, outperforming existing state-of-the-art (SOTA) methods. In the second stage of functional subtype prediction, combined with a transfer learning strategy, the model realized accurate classification of 6 viral families and 8 specific viruses under small-sample conditions. AVP-Pro provides a powerful and interpretable new tool for the high-throughput screening of antiviral drugs. To further enhance accessibility for users, we have developed a user-friendly web interface, which is available at https://wwwy1031-avp-pro.hf.space.

</details>


### [31] [OpFML: Pipeline for ML-based Operational Forecasting](https://arxiv.org/abs/2601.11046)
*Shahbaz Alvi,Giusy Fedele,Gabriele Accarino,Italo Epicoco,Ilenia Manco,Pasquale Schiano*

Main category: cs.LG

TL;DR: OpFML是一个用于机器学习周期性预测的可配置管道，应用于火灾危险指数预测


<details>
  <summary>Details</summary>
Motivation: 机器学习在气候和地球科学中应用广泛，传统野火风险评估方法常常高估风险，需要更有效的操作预测系统

Method: 开发了OpFML（操作预测机器学习）管道，这是一个可配置和可适应的机器学习模型服务框架，用于周期性预测

Result: 通过每日火灾危险指数预测应用展示了OpFML管道的功能和特性

Conclusion: OpFML为机器学习在操作预测系统中的部署提供了一个灵活、可配置的解决方案，特别适用于野火危险评估等周期性预测任务

Abstract: Machine learning is finding its application in a multitude of areas in science and research, and Climate and Earth Sciences is no exception to this trend. Operational forecasting systems based on data-driven approaches and machine learning methods deploy models for periodic forecasting. Wildfire danger assessment using machine learning has garnered significant interest in the last decade, as conventional methods often overestimate the risk of wildfires. In this work, we present the code OpFML: Operational Forecasting with Machine Learning. OpFML is a configurable and adaptable pipeline that can be utilized to serve a machine learning model for periodic forecasting. We further demonstrate the capabilities of the pipeline through its application to daily Fire Danger Index forecasting and outline its various features.

</details>


### [32] [Soft Bayesian Context Tree Models for Real-Valued Time Series](https://arxiv.org/abs/2601.11079)
*Shota Saito,Yuta Nakahara,Toshiyasu Matsushima*

Main category: cs.LG

TL;DR: 提出Soft-BCT模型，一种用于实值时间序列的新型贝叶斯上下文树模型，采用软（概率性）分割而非硬（确定性）分割，基于变分推断进行学习，在真实数据集上表现优于或与先前BCT相当。


<details>
  <summary>Details</summary>
Motivation: 先前用于实值时间序列的贝叶斯上下文树模型采用硬分割方法，限制了模型的表达能力。为了克服这一限制，需要开发能够进行软概率分割的模型，以更好地捕捉时间序列的复杂依赖关系。

Method: 提出Soft-BCT模型，采用软（概率性）上下文空间分割方法替代传统的硬分割。基于变分推断开发了相应的学习算法，实现了对模型参数的高效学习和推理。

Result: 在多个真实世界数据集上的实验表明，Soft-BCT模型能够达到与先前BCT模型几乎相同或更优的性能表现，验证了软分割方法的有效性。

Conclusion: Soft-BCT模型通过引入软分割机制扩展了贝叶斯上下文树模型的能力，为实值时间序列建模提供了更灵活有效的工具，变分推断方法确保了算法的实际可行性。

Abstract: This paper proposes the soft Bayesian context tree model (Soft-BCT), which is a novel BCT model for real-valued time series. The Soft-BCT considers soft (probabilistic) splits of the context space, instead of hard (deterministic) splits of the context space as in the previous BCT for real-valued time series. A learning algorithm of the Soft-BCT is proposed based on the variational inference. For some real-world datasets, the Soft-BCT demonstrates almost the same or superior performance to the previous BCT.

</details>


### [33] [Differentially Private Subspace Fine-Tuning for Large Language Models](https://arxiv.org/abs/2601.11113)
*Lele Zheng,Xiang Wang,Tao Zhang,Yang Cao,Ke Cheng,Yulong Shen*

Main category: cs.LG

TL;DR: DP-SFT：一种两阶段子空间微调方法，通过将DP噪声限制在低维任务特定子空间来减少噪声幅度，在保持差分隐私保证的同时提升模型性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在下游任务上的微调通常依赖敏感数据，存在隐私风险。差分隐私(DP)提供了严格的隐私保证，但在高维参数空间中注入噪声会产生大范数扰动，导致性能下降和训练不稳定。

Method: 提出DP-SFT两阶段子空间微调方法：第一阶段通过分析主梯度方向识别低维任务特定子空间；第二阶段将完整梯度投影到该子空间，添加DP噪声，然后将扰动后的梯度映射回原始参数空间进行模型更新。

Result: 在多个数据集上的实验表明，DP-SFT在严格的DP约束下提高了准确性和稳定性，加速了收敛速度，相比DP微调基线实现了显著性能提升。

Conclusion: DP-SFT通过将DP噪声限制在任务相关子空间，显著降低了噪声影响，在保持正式DP隐私保证的同时改善了微调性能，为解决隐私保护与模型性能之间的权衡提供了有效方案。

Abstract: Fine-tuning large language models on downstream tasks is crucial for realizing their cross-domain potential but often relies on sensitive data, raising privacy concerns. Differential privacy (DP) offers rigorous privacy guarantees and has been widely adopted in fine-tuning; however, naively injecting noise across the high-dimensional parameter space creates perturbations with large norms, degrading performance and destabilizing training. To address this issue, we propose DP-SFT, a two-stage subspace fine-tuning method that substantially reduces noise magnitude while preserving formal DP guarantees. Our intuition is that, during fine-tuning, significant parameter updates lie within a low-dimensional, task-specific subspace, while other directions change minimally. Hence, we only inject DP noise into this subspace to protect privacy without perturbing irrelevant parameters. In phase one, we identify the subspace by analyzing principal gradient directions to capture task-specific update signals. In phase two, we project full gradients onto this subspace, add DP noise, and map the perturbed gradients back to the original parameter space for model updates, markedly lowering noise impact. Experiments on multiple datasets demonstrate that DP-SFT enhances accuracy and stability under rigorous DP constraints, accelerates convergence, and achieves substantial gains over DP fine-tuning baselines.

</details>


### [34] [Context-aware Graph Causality Inference for Few-Shot Molecular Property Prediction](https://arxiv.org/abs/2601.11135)
*Van Thuy Hoang,O-Joun Lee*

Main category: cs.LG

TL;DR: CaMol是一个基于因果推理的上下文感知图学习框架，用于少样本分子性质预测，通过编码化学知识、解耦因果子结构和应用后门调整来提高预测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前基于上下文学习的分子性质预测方法存在两个主要限制：1）未能充分利用与性质因果相关的官能团先验知识；2）难以识别与性质直接相关的关键子结构。需要一种能够从因果推理角度解决这些挑战的方法。

Method: CaMol框架包含三个核心组件：1）编码化学知识的上下文图，连接官能团、分子和性质；2）可学习的原子掩码策略，从混杂结构中解耦因果子结构；3）分布干预器，通过结合因果子结构和化学基础的混杂因子应用后门调整。

Result: 在多个分子数据集上的实验表明，CaMol在少样本任务中实现了优越的准确性和样本效率，展示了对未见性质的泛化能力。发现的因果子结构与官能团的化学知识高度一致，支持模型的可解释性。

Conclusion: CaMol通过因果推理视角有效解决了少样本分子性质预测中的关键挑战，不仅提高了预测性能，还增强了模型的可解释性，为基于Web的分子服务提供了有力的工具。

Abstract: Molecular property prediction is becoming one of the major applications of graph learning in Web-based services, e.g., online protein structure prediction and drug discovery. A key challenge arises in few-shot scenarios, where only a few labeled molecules are available for predicting unseen properties. Recently, several studies have used in-context learning to capture relationships among molecules and properties, but they face two limitations in: (1) exploiting prior knowledge of functional groups that are causally linked to properties and (2) identifying key substructures directly correlated with properties. We propose CaMol, a context-aware graph causality inference framework, to address these challenges by using a causal inference perspective, assuming that each molecule consists of a latent causal structure that determines a specific property. First, we introduce a context graph that encodes chemical knowledge by linking functional groups, molecules, and properties to guide the discovery of causal substructures. Second, we propose a learnable atom masking strategy to disentangle causal substructures from confounding ones. Third, we introduce a distribution intervener that applies backdoor adjustment by combining causal substructures with chemically grounded confounders, disentangling causal effects from real-world chemical variations. Experiments on diverse molecular datasets showed that CaMol achieved superior accuracy and sample efficiency in few-shot tasks, showing its generalizability to unseen properties. Also, the discovered causal substructures were strongly aligned with chemical knowledge about functional groups, supporting the model interpretability.

</details>


### [35] [Optimized Algorithms for Text Clustering with LLM-Generated Constraints](https://arxiv.org/abs/2601.11118)
*Chaoqi Jia,Weihong Wu,Longkun Guo,Zhigang Lu,Chao Chen,Kok-Leong Ong*

Main category: cs.LG

TL;DR: 本文提出了一种基于大语言模型的约束生成方法，通过生成约束集而非传统成对约束来减少资源消耗，并结合置信度阈值和惩罚机制处理可能不准确的约束，在文本聚类中实现了与最先进算法相当的准确性，同时将LLM查询次数减少20倍以上。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法通过人工提供成对约束（必须链接和不能链接）来提高准确性，但这种方法成本高昂且效率低下。随着大语言模型的发展，研究者开始探索利用LLM自动生成约束，但现有方法在查询效率和约束准确性方面仍有改进空间。

Method: 提出了一种新颖的约束生成方法，生成约束集而非传统的成对约束，以提高查询效率和约束准确性。同时设计了一个专门针对LLM生成约束特性的约束聚类算法，该算法包含置信度阈值和惩罚机制来处理可能不准确的约束。

Result: 在五个文本数据集上的评估显示，该方法在约束生成成本和整体聚类性能方面表现优异。与最先进的算法相比，在达到相当聚类准确性的同时，将LLM查询次数减少了20倍以上。

Conclusion: 该方法通过创新的约束生成策略和专门设计的聚类算法，有效解决了LLM约束生成中的资源消耗问题，在保持聚类质量的同时显著提高了效率，为文本聚类中的约束学习方法提供了新的解决方案。

Abstract: Clustering is a fundamental tool that has garnered significant interest across a wide range of applications including text analysis. To improve clustering accuracy, many researchers have incorporated background knowledge, typically in the form of must-link and cannot-link constraints, to guide the clustering process. With the recent advent of large language models (LLMs), there is growing interest in improving clustering quality through LLM-based automatic constraint generation. In this paper, we propose a novel constraint-generation approach that reduces resource consumption by generating constraint sets rather than using traditional pairwise constraints. This approach improves both query efficiency and constraint accuracy compared to state-of-the-art methods. We further introduce a constrained clustering algorithm tailored to the characteristics of LLM-generated constraints. Our method incorporates a confidence threshold and a penalty mechanism to address potentially inaccurate constraints. We evaluate our approach on five text datasets, considering both the cost of constraint generation and the overall clustering performance. The results show that our method achieves clustering accuracy comparable to the state-of-the-art algorithms while reducing the number of LLM queries by more than 20 times.

</details>


### [36] [Clustering High-dimensional Data: Balancing Abstraction and Representation Tutorial at AAAI 2026](https://arxiv.org/abs/2601.11160)
*Claudia Plant,Lena G. M. Bauer,Christian Böhm*

Main category: cs.LG

TL;DR: 该论文探讨聚类算法中抽象与表示之间的平衡问题，分析不同聚类方法如何在这两个目标间进行权衡，并展望未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 聚类需要平衡抽象与表示：既要抽象掉个体对象的冗余细节，又需要丰富的表示来突出区分不同群体的关键特征。现有聚类算法在这两个目标间存在不同权衡，需要系统分析如何优化这种平衡。

Method: 分析不同聚类方法的抽象-表示权衡：经典K-means采用高度抽象（平均细节）和简单表示（高斯分布）；子空间聚类和深度聚类通过更丰富的表示支持高维复杂数据；深度聚类方法通过基于质心和密度的聚类损失来强制抽象。

Result: 不同聚类算法在抽象与表示间存在不同权衡：子空间聚类通过学习两个潜在空间来分离聚类相关信息和其他信息；深度聚类通过特定损失函数强制抽象，避免仅进行表示学习；平衡这两个目标对聚类性能至关重要。

Conclusion: 未来聚类研究需要更自适应地平衡抽象与表示，以提高性能、能效和可解释性。人类大脑在聚类和单次学习等任务中能自动找到抽象与表示的最佳平衡点，这为算法改进提供了重要启示。

Abstract: How to find a natural grouping of a large real data set? Clustering requires a balance between abstraction and representation. To identify clusters, we need to abstract from superfluous details of individual objects. But we also need a rich representation that emphasizes the key features shared by groups of objects that distinguish them from other groups of objects.
  Each clustering algorithm implements a different trade-off between abstraction and representation. Classical K-means implements a high level of abstraction - details are simply averaged out - combined with a very simple representation - all clusters are Gaussians in the original data space. We will see how approaches to subspace and deep clustering support high-dimensional and complex data by allowing richer representations. However, with increasing representational expressiveness comes the need to explicitly enforce abstraction in the objective function to ensure that the resulting method performs clustering and not just representation learning. We will see how current deep clustering methods define and enforce abstraction through centroid-based and density-based clustering losses. Balancing the conflicting goals of abstraction and representation is challenging. Ideas from subspace clustering help by learning one latent space for the information that is relevant to clustering and another latent space to capture all other information in the data.
  The tutorial ends with an outlook on future research in clustering. Future methods will more adaptively balance abstraction and representation to improve performance, energy efficiency and interpretability. By automatically finding the sweet spot between abstraction and representation, the human brain is very good at clustering and other related tasks such as single-shot learning. So, there is still much room for improvement.

</details>


### [37] [Shape-morphing programming of soft materials on complex geometries via neural operator](https://arxiv.org/abs/2601.11126)
*Lu Chen,Gengxiang Chen,Xu Liu,Jingyan Su,Xuhao Lyu,Lihui Wang,Yingguang Li*

Main category: cs.LG

TL;DR: 提出S2NO神经算子，通过谱空间卷积实现复杂几何体上的高保真形变预测，结合进化算法优化材料分布，实现超分辨率形变设计


<details>
  <summary>Details</summary>
Motivation: 现有形状变形设计主要针对简单几何体，难以实现复杂几何体上的精确多样形变，限制了在共形植入部署、空气动力学变形等高级应用中的潜力

Method: 提出谱空间神经算子(S2NO)，集成拉普拉斯本征函数编码和空间卷积，捕捉不规则计算域上的全局和局部形变行为；结合进化算法优化体素级材料分布

Result: S2NO能在不规则边界形状、多孔结构和薄壁结构等复杂几何体上实现高保真形变预测；神经算子的离散不变性支持超分辨率材料分布设计

Conclusion: S2NO显著提升了复杂形状变形编程的效率和能力，扩展了形变设计的多样性和复杂性，为高级应用提供了有效工具

Abstract: Shape-morphing soft materials can enable diverse target morphologies through voxel-level material distribution design, offering significant potential for various applications. Despite progress in basic shape-morphing design with simple geometries, achieving advanced applications such as conformal implant deployment or aerodynamic morphing requires accurate and diverse morphing designs on complex geometries, which remains challenging. Here, we present a Spectral and Spatial Neural Operator (S2NO), which enables high-fidelity morphing prediction on complex geometries. S2NO effectively captures global and local morphing behaviours on irregular computational domains by integrating Laplacian eigenfunction encoding and spatial convolutions. Combining S2NO with evolutionary algorithms enables voxel-level optimisation of material distributions for shape morphing programming on various complex geometries, including irregular-boundary shapes, porous structures, and thin-walled structures. Furthermore, the neural operator's discretisation-invariant property enables super-resolution material distribution design, further expanding the diversity and complexity of morphing design. These advancements significantly improve the efficiency and capability of programming complex shape morphing.

</details>


### [38] [FAQ: Mitigating Quantization Error via Regenerating Calibration Data with Family-Aware Quantization](https://arxiv.org/abs/2601.11200)
*Haiyang Xiao,Weiqing Li,Jinyue Guo,Guochao Jiang,Guohua Liu,Yuewei Zhang*

Main category: cs.LG

TL;DR: FAQ提出了一种基于家族知识的校准数据再生框架，通过利用同家族大模型的先验知识生成高质量校准样本，显著提升后训练量化的精度。


<details>
  <summary>Details</summary>
Motivation: 传统后训练量化方法依赖有限校准样本，难以捕捉推理阶段的激活分布，导致量化参数存在偏差。校准数据的代表性和普适性是决定量化精度的核心瓶颈。

Method: FAQ框架首先将原始校准样本输入到目标模型同家族的更大规模LLM中，利用高度一致的知识系统再生一系列高保真校准数据。这些数据携带思维链推理并符合预期激活分布，随后在专家指导下进行组间竞争以选择最佳样本，最后进行重新归一化以增强标准PTQ效果。

Result: 在包括Qwen3-8B在内的多个模型系列上的实验表明，FAQ相比使用原始校准数据的基线方法，将精度损失降低了高达28.5%。

Conclusion: FAQ框架通过利用同家族LLM的先验知识生成高质量校准数据，有效解决了传统PTQ方法中校准数据代表性不足的问题，显著提升了量化精度，展示了强大的应用潜力。

Abstract: Although post-training quantization (PTQ) provides an efficient numerical compression scheme for deploying large language models (LLMs) on resource-constrained devices, the representativeness and universality of calibration data remain a core bottleneck in determining the accuracy of quantization parameters. Traditional PTQ methods typically rely on limited samples, making it difficult to capture the activation distribution during the inference phase, leading to biases in quantization parameters. To address this, we propose \textbf{FAQ} (Family-Aware Quantization), a calibration data regeneration framework that leverages prior knowledge from LLMs of the same family to generate high-fidelity calibration samples. Specifically, FAQ first inputs the original calibration samples into a larger LLM from the same family as the target model, regenerating a series of high-fidelity calibration data using a highly consistent knowledge system. Subsequently, this data, carrying Chain-of-Thought reasoning and conforming to the expected activation distribution, undergoes group competition under expert guidance to select the best samples, which are then re-normalized to enhance the effectiveness of standard PTQ. Experiments on multiple model series, including Qwen3-8B, show that FAQ reduces accuracy loss by up to 28.5\% compared to the baseline with original calibration data, demonstrating its powerful potential and contribution.

</details>


### [39] [FSL-BDP: Federated Survival Learning with Bayesian Differential Privacy for Credit Risk Modeling](https://arxiv.org/abs/2601.11134)
*Sultan Amed,Tanmay Sen,Sayantan Banerjee*

Main category: cs.LG

TL;DR: 论文提出了联邦生存学习框架FSL-BDP，用于在保护隐私的前提下进行跨机构信用风险建模，解决了传统违约预测忽略违约时间和数据共享限制的问题。


<details>
  <summary>Details</summary>
Motivation: 信用风险模型对金融机构至关重要，但数据保护法规（如GDPR、CCPA）限制了跨境借款人数据共享。传统违约预测存在两个局限：1）二元分类忽略了违约时间，将早期违约者（高损失）与晚期违约者（低损失）同等对待；2）集中式训练违反了新兴的监管约束。

Method: 提出了联邦生存学习框架FSL-BDP，该框架结合了贝叶斯差分隐私（BDP），在不集中敏感数据的情况下建模违约时间轨迹。该框架提供贝叶斯（数据依赖）差分隐私保证，同时使机构能够联合学习风险动态。

Result: 在三个真实信用数据集（LendingClub、SBA、Bondora）上的实验表明，联邦学习从根本上改变了隐私机制的相对有效性。在集中式设置中，经典差分隐私优于贝叶斯差分隐私，但在联邦学习中，贝叶斯差分隐私受益更大（+7.0% vs +1.4%），达到接近非私有性能的水平，并在大多数参与客户端中优于经典差分隐私。

Conclusion: 隐私机制的选择应在目标部署架构中评估，而不是基于集中式基准。这些发现为在受监管的多机构环境中设计隐私保护决策支持系统的从业者提供了可操作的指导。

Abstract: Credit risk models are a critical decision-support tool for financial institutions, yet tightening data-protection rules (e.g., GDPR, CCPA) increasingly prohibit cross-border sharing of borrower data, even as these models benefit from cross-institution learning. Traditional default prediction suffers from two limitations: binary classification ignores default timing, treating early defaulters (high loss) equivalently to late defaulters (low loss), and centralized training violates emerging regulatory constraints. We propose a Federated Survival Learning framework with Bayesian Differential Privacy (FSL-BDP) that models time-to-default trajectories without centralizing sensitive data. The framework provides Bayesian (data-dependent) differential privacy (DP) guarantees while enabling institutions to jointly learn risk dynamics. Experiments on three real-world credit datasets (LendingClub, SBA, Bondora) show that federation fundamentally alters the relative effectiveness of privacy mechanisms. While classical DP performs better than Bayesian DP in centralized settings, the latter benefits substantially more from federation (+7.0\% vs +1.4\%), achieving near parity of non-private performance and outperforming classical DP in the majority of participating clients. This ranking reversal yields a key decision-support insight: privacy mechanism selection should be evaluated in the target deployment architecture, rather than centralized benchmarks. These findings provide actionable guidance for practitioners designing privacy-preserving decision support systems in regulated, multi-institutional environments.

</details>


### [40] [SDFLoRA: Selective Dual-Module LoRA for Federated Fine-tuning with Heterogeneous Clients](https://arxiv.org/abs/2601.11219)
*Zhikang Shen,Jianrong Lu,Haiyuan Wan,Jianhai Chen*

Main category: cs.LG

TL;DR: SDFLoRA：一种针对大语言模型联邦学习的参数高效方法，通过将客户端适配器分解为全局模块和本地模块，解决了LoRA在联邦学习中面临的秩异构性问题，实现了更好的隐私-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）用于大语言模型（LLMs）因其隐私保护特性而受到关注，但实际部署中存在秩异构性问题——不同客户端使用不同的低秩配置，导致LoRA更新聚合存在偏差和不稳定。现有解决方案通常强制统一秩或将异构更新对齐到共享子空间，这会过度约束客户端特定语义、限制个性化，并在差分隐私噪声下对本地客户端信息提供弱保护。

Method: 提出选择性双模块联邦LoRA（SDFLoRA），将每个客户端适配器分解为：1）全局模块——捕获可迁移知识；2）本地模块——保留客户端特定适配。全局模块在客户端间选择性对齐和聚合，而本地模块保持私有。该设计支持在秩异构性下的鲁棒学习，并通过仅向全局模块注入差分隐私噪声来实现隐私感知优化。

Result: 在GLUE基准测试上的实验表明，SDFLoRA优于代表性的联邦LoRA基线方法，并实现了更好的效用-隐私权衡。

Conclusion: SDFLoRA通过将客户端适配器分解为全局和本地模块，有效解决了联邦学习中LoRA的秩异构性问题，在保持隐私保护的同时实现了更好的性能，为联邦大语言模型训练提供了实用解决方案。

Abstract: Federated learning (FL) for large language models (LLMs) has attracted increasing attention as a way to enable privacy-preserving adaptation over distributed data. Parameter-efficient methods such as LoRA are widely adopted to reduce communication and memory costs. Despite these advances, practical FL deployments often exhibit rank heterogeneity, since different clients may use different low-rank configurations. This makes direct aggregation of LoRA updates biased and unstable. Existing solutions typically enforce unified ranks or align heterogeneous updates into a shared subspace, which over-constrains client-specific semantics, limits personalization, and provides weak protection of local client information under differential privacy noise. To address this issue, we propose Selective Dual-module Federated LoRA (SDFLoRA), which decomposes each client adapter into a global module that captures transferable knowledge and a local module that preserves client-specific adaptations. The global module is selectively aligned and aggregated across clients, while local modules remain private. This design enables robust learning under rank heterogeneity and supports privacy-aware optimization by injecting differential privacy noise exclusively into the global module. Experiments on GLUE benchmarks demonstrate that SDFLoRA outperforms representative federated LoRA baselines and achieves a better utility-privacy trade-off.

</details>


### [41] [Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation](https://arxiv.org/abs/2601.11258)
*Pingzhi Tang,Yiding Wang,Muhan Zhang*

Main category: cs.LG

TL;DR: PaST框架通过提取领域无关的技能向量，实现模块化技能转移，有效解决LLM知识更新问题，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型面临"知识截止"挑战，其冻结的参数化记忆无法直接内化新信息。监督微调虽然能更新事实内容，但无法可靠提升模型使用新信息进行问答或决策的能力。强化学习能获取推理技能，但计算成本过高，不适合高效的在线适应。

Method: 提出参数化技能转移（PaST）框架，基于SFT和RL参数更新几乎正交的观察，从源域提取领域无关的技能向量，在目标模型经过轻量级SFT后，线性注入知识操作技能。

Result: 在SQuAD上比最先进的自编辑SFT基线高出9.9分；在LooGLE长上下文问答中获得8.0分的绝对准确率提升；在ToolBench工具使用基准测试中平均零样本成功率提升+10.3分，跨工具类别一致提升。

Conclusion: PaST框架通过模块化技能转移实现了高效有效的知识适应，技能向量展现出强大的可扩展性和跨领域可转移性，为解决LLM知识更新问题提供了新思路。

Abstract: Large Language Models (LLMs) face the "knowledge cutoff" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector.

</details>


### [42] [Assesing the Viability of Unsupervised Learning with Autoencoders for Predictive Maintenance in Helicopter Engines](https://arxiv.org/abs/2601.11154)
*P. Sánchez,K. Reyes,B. Radu,E. Fernández*

Main category: cs.LG

TL;DR: 比较直升机发动机预测性维护的两种方法：有监督分类与无监督异常检测（基于自编码器），评估它们在真实数据上的表现和适用场景。


<details>
  <summary>Details</summary>
Motivation: 直升机发动机的意外故障会导致严重的运营中断、安全隐患和昂贵的维修成本，需要有效的预测性维护策略来降低这些风险。

Method: 比较两种方法：1）有监督分类管道，依赖正常和故障行为的标记示例；2）基于自编码器的无监督异常检测方法，仅使用健康发动机数据学习正常操作模型，将偏差标记为潜在故障。

Result: 有监督模型在有标注故障数据时表现强劲，而自编码器无需故障标签即可实现有效检测，特别适用于故障数据稀缺或不完整的场景。

Conclusion: 比较揭示了准确性、数据可用性和部署可行性之间的实际权衡，强调了无监督学习作为航空航天应用早期故障检测可行解决方案的潜力。

Abstract: Unplanned engine failures in helicopters can lead to severe operational disruptions, safety hazards, and costly repairs. To mitigate these risks, this study compares two predictive maintenance strategies for helicopter engines: a supervised classification pipeline and an unsupervised anomaly detection approach based on autoencoders (AEs). The supervised method relies on labelled examples of both normal and faulty behaviour, while the unsupervised approach learns a model of normal operation using only healthy engine data, flagging deviations as potential faults. Both methods are evaluated on a real-world dataset comprising labelled snapshots of helicopter engine telemetry. While supervised models demonstrate strong performance when annotated failures are available, the AE achieves effective detection without requiring fault labels, making it particularly well suited for settings where failure data are scarce or incomplete. The comparison highlights the practical trade-offs between accuracy, data availability, and deployment feasibility, and underscores the potential of unsupervised learning as a viable solution for early fault detection in aerospace applications.

</details>


### [43] [FEATHer: Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting](https://arxiv.org/abs/2601.11350)
*Jaehoon Lee,Seungwoo Lee,Younghwi Kim,Dohee Kim,Sunghyun Sim*

Main category: cs.LG

TL;DR: FEATHer是一种超轻量级时间序列预测模型，专为边缘设备设计，仅需数百参数即可实现准确的长时预测，在8个基准测试中取得60项第一


<details>
  <summary>Details</summary>
Motivation: 工业领域（如制造和智能工厂）需要时间序列预测模型能够在边缘设备（PLC、微控制器）上运行，这些设备有严格的延迟和内存限制，通常只能容纳几千个参数，传统深度架构在此场景下不实用

Method: 提出FEATHer模型，包含四个关键组件：1）超轻量级多尺度频率路径分解；2）共享密集时间核（使用投影-深度卷积-投影结构，无循环或注意力机制）；3）频率感知分支门控，基于频谱特征自适应融合表示；4）稀疏周期核，通过周期下采样重构输出以捕捉季节性

Result: 在8个基准测试中取得最佳排名，获得60项第一，平均排名为2.05，模型参数最少可压缩至400个，在严格约束下仍优于基线方法

Conclusion: 可靠的长时预测在受限的边缘硬件上是可行的，FEATHer为工业实时推理提供了实用方向，证明了超轻量级架构在边缘设备上的有效性

Abstract: Time-series forecasting is fundamental in industrial domains like manufacturing and smart factories. As systems evolve toward automation, models must operate on edge devices (e.g., PLCs, microcontrollers) with strict constraints on latency and memory, limiting parameters to a few thousand. Conventional deep architectures are often impractical here. We propose the Fourier-Efficient Adaptive Temporal Hierarchy Forecaster (FEATHer) for accurate long-term forecasting under severe limits. FEATHer introduces: (i) ultra-lightweight multiscale decomposition into frequency pathways; (ii) a shared Dense Temporal Kernel using projection-depthwise convolution-projection without recurrence or attention; (iii) frequency-aware branch gating that adaptively fuses representations based on spectral characteristics; and (iv) a Sparse Period Kernel reconstructing outputs via period-wise downsampling to capture seasonality. FEATHer maintains a compact architecture (as few as 400 parameters) while outperforming baselines. Across eight benchmarks, it achieves the best ranking, recording 60 first-place results with an average rank of 2.05. These results demonstrate that reliable long-range forecasting is achievable on constrained edge hardware, offering a practical direction for industrial real-time inference.

</details>


### [44] [GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling](https://arxiv.org/abs/2601.11161)
*Pascal Schlachter,Bin Yang*

Main category: cs.LG

TL;DR: 该论文提出了首个持续源自由通用域适应（continual SF-UniDA）方法GMM-COMET，用于处理多个不同未标记目标域的连续适应问题。


<details>
  <summary>Details</summary>
Motivation: 现实场景中，源数据在适应期间可能不再可用，且目标域标签空间可能与源域不同。现有SF-UniDA方法仅假设单一域偏移，而实际应用中模型需要连续适应多个不同目标域，这是当前研究的空白。

Method: 基于先前在线SF-UniDA方法，将高斯混合模型伪标签与均值教师框架结合，提高长期适应序列的稳定性，并引入一致性损失增强鲁棒性。

Result: GMM-COMET在所有评估场景中持续改进源模型性能，是实验中唯一在所有场景中始终优于源模型的方法。

Conclusion: 该方法为持续SF-UniDA提供了强大的首个基线，解决了多目标域连续适应的实际问题，代码已开源。

Abstract: Unsupervised domain adaptation tackles the problem that domain shifts between training and test data impair the performance of neural networks in many real-world applications. Thereby, in realistic scenarios, the source data may no longer be available during adaptation, and the label space of the target domain may differ from the source label space. This setting, known as source-free universal domain adaptation (SF-UniDA), has recently gained attention, but all existing approaches only assume a single domain shift from source to target. In this work, we present the first study on continual SF-UniDA, where the model must adapt sequentially to a stream of multiple different unlabeled target domains. Building upon our previous methods for online SF-UniDA, we combine their key ideas by integrating Gaussian mixture model-based pseudo-labeling within a mean teacher framework for improved stability over long adaptation sequences. Additionally, we introduce consistency losses for further robustness. The resulting method GMM-COMET provides a strong first baseline for continual SF-UniDA and is the only approach in our experiments to consistently improve upon the source-only model across all evaluated scenarios. Our code is available at https://github.com/pascalschlachter/GMM-COMET.

</details>


### [45] [MetaboNet: The Largest Publicly Available Consolidated Dataset for Type 1 Diabetes Management](https://arxiv.org/abs/2601.11505)
*Miriam K. Wolff,Peter Calhoun,Eleonora Maria Aiello,Yao Qin,Sam F. Royston*

Main category: cs.LG

TL;DR: 研究者整合了多个公开的1型糖尿病数据集，创建了统一的MetaboNet数据集，包含3135名患者和1228患者年的连续血糖监测与胰岛素泵数据，旨在解决现有数据集碎片化和标准化不足的问题。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病算法开发受到现有数据集碎片化和缺乏标准化的限制。不同数据集结构差异大，访问和处理耗时，阻碍了数据整合，降低了算法开发的可比性和泛化性。

Method: 整合多个公开的1型糖尿病数据集，要求同时包含连续血糖监测数据和相应的胰岛素泵剂量记录，保留碳水化合物摄入和体力活动等辅助信息。数据集分为完全公开子集和需要数据使用协议限制的子集，并为后者提供数据处理管道以转换为标准化格式。

Result: 创建了包含3135名受试者和1228患者年重叠CGM与胰岛素数据的MetaboNet数据集，规模远超现有独立基准数据集。数据集覆盖广泛的血糖谱和人口统计学特征，可通过https://metabo-net.org/立即下载公开部分，受限部分需通过申请流程获取。

Conclusion: MetaboNet为1型糖尿病研究提供了统一的公共数据集，通过标准化格式和两种访问途径（完全公开和DUA限制），能够产生比单个数据集更具泛化性的算法性能评估。

Abstract: Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. Current datasets differ substantially in structure and are time-consuming to access and process, which impedes data integration and reduces the comparability and generalizability of algorithmic developments. This work aims to establish a unified and accessible data resource for T1D algorithm development. Multiple publicly available T1D datasets were consolidated into a unified resource, termed the MetaboNet dataset. Inclusion required the availability of both continuous glucose monitoring (CGM) data and corresponding insulin pump dosing records. Additionally, auxiliary information such as reported carbohydrate intake and physical activity was retained when present. The MetaboNet dataset comprises 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download at https://metabo-net.org/ , and with a Data Use Agreement (DUA)-restricted subset accessible through their respective application processes. For the datasets in the latter subset, processing pipelines are provided to automatically convert the data into the standardized MetaboNet format. A consolidated public dataset for T1D research is presented, and the access pathways for both its unrestricted and DUA-governed components are described. The resulting dataset covers a broad range of glycemic profiles and demographics and thus can yield more generalizable algorithmic performance than individual datasets.

</details>


### [46] [TimeMar: Multi-Scale Autoregressive Modeling for Unconditional Time Series Generation](https://arxiv.org/abs/2601.11184)
*Xiangyu Xu,Qingsong Zhong,Jilin Hu*

Main category: cs.LG

TL;DR: 提出了一种结构解耦的多尺度时间序列生成框架，通过多分辨率离散编码和粗到细的自回归生成，有效处理时间序列的结构复杂性和异质性。


<details>
  <summary>Details</summary>
Motivation: 时间序列分析面临数据稀缺和隐私挑战，而现有方法未能充分处理时间序列的多尺度时间模式和异质结构特性。

Method: 1. 多分辨率离散编码和粗到细自回归生成；2. 双路径VQ-VAE解耦趋势和季节性成分；3. 基于指导的重建策略，利用粗粒度季节性信号指导细粒度模式重建。

Result: 在六个数据集上的实验表明，该方法比现有方法生成更高质量的时间序列，参数数量显著减少，且在生成长序列方面表现优异。

Conclusion: 该框架有效解决了时间序列的结构复杂性问题，为数据稀缺和隐私保护场景下的时间序列分析提供了高质量的生成解决方案。

Abstract: Generative modeling offers a promising solution to data scarcity and privacy challenges in time series analysis. However, the structural complexity of time series, characterized by multi-scale temporal patterns and heterogeneous components, remains insufficiently addressed. In this work, we propose a structure-disentangled multiscale generation framework for time series. Our approach encodes sequences into discrete tokens at multiple temporal resolutions and performs autoregressive generation in a coarse-to-fine manner, thereby preserving hierarchical dependencies. To tackle structural heterogeneity, we introduce a dual-path VQ-VAE that disentangles trend and seasonal components, enabling the learning of semantically consistent latent representations. Additionally, we present a guidance-based reconstruction strategy, where coarse seasonal signals are utilized as priors to guide the reconstruction of fine-grained seasonal patterns. Experiments on six datasets show that our approach produces higher-quality time series than existing methods. Notably, our model achieves strong performance with a significantly reduced parameter count and exhibits superior capability in generating high-quality long-term sequences. Our implementation is available at https://anonymous.4open.science/r/TimeMAR-BC5B.

</details>


### [47] [Operator learning on domain boundary through combining fundamental solution-based artificial data and boundary integral techniques](https://arxiv.org/abs/2601.11222)
*Haochen Wu,Heng Wu,Benzhuo Lu*

Main category: cs.LG

TL;DR: 提出MAD-BNO框架，仅使用边界数据学习偏微分方程算子，无需全区域采样，通过基本解合成训练数据，实现高效边界到边界映射学习


<details>
  <summary>Details</summary>
Motivation: 针对已知基本解的线性偏微分方程，传统方法需要全区域采样数据，而实际应用中边界数据更易获取。希望开发仅依赖边界数据的算子学习方法，避免昂贵的外部测量或数值模拟

Method: 结合MAD方法，从目标问题的基本解直接合成训练数据，学习边界到边界映射（Dirichlet-Neumann数据对）。训练后通过边界积分公式高效恢复内部解，支持多种边界条件和源项

Result: 在二维Laplace、Poisson和Helmholtz方程的基准测试中，MAD-BNO达到或优于现有神经算子方法的精度，同时显著减少训练时间。框架可扩展到三维问题和复杂几何

Conclusion: MAD-BNO为已知基本解的线性偏微分方程提供了一种高效、完全数据驱动的算子学习框架，仅需边界数据，避免了全区域采样的成本，具有良好的扩展性和应用前景

Abstract: For linear partial differential equations with known fundamental solutions, this work introduces a novel operator learning framework that relies exclusively on domain boundary data, including solution values and normal derivatives, rather than full-domain sampling. By integrating the previously developed Mathematical Artificial Data (MAD) method, which enforces physical consistency, all training data are synthesized directly from the fundamental solutions of the target problems, resulting in a fully data-driven pipeline without the need for external measurements or numerical simulations. We refer to this approach as the Mathematical Artificial Data Boundary Neural Operator (MAD-BNO), which learns boundary-to-boundary mappings using MAD-generated Dirichlet-Neumann data pairs. Once trained, the interior solution at arbitrary locations can be efficiently recovered through boundary integral formulations, supporting Dirichlet, Neumann, and mixed boundary conditions as well as general source terms. The proposed method is validated on benchmark operator learning tasks for two-dimensional Laplace, Poisson, and Helmholtz equations, where it achieves accuracy comparable to or better than existing neural operator approaches while significantly reducing training time. The framework is naturally extensible to three-dimensional problems and complex geometries.

</details>


### [48] [Sample-Near-Optimal Agnostic Boosting with Improved Running Time](https://arxiv.org/abs/2601.11265)
*Arthur da Cunha,Miakel Møller Høgsgaard,Andrea Paudice*

Main category: cs.LG

TL;DR: 提出了第一个具有接近最优样本复杂度的不可知增强算法，在固定其他参数时，运行时间与样本大小呈多项式关系。


<details>
  <summary>Details</summary>
Motivation: 虽然增强方法在经典设置下已有很好理解，但在不可知设置（不对数据做任何假设）中理解较少。最近才基本解决了不可知增强的样本复杂度问题，但已知算法具有指数运行时间。

Method: 提出新的不可知增强算法，在固定其他参数的情况下，运行时间与样本大小呈多项式关系。

Result: 该算法具有接近最优的样本复杂度，是第一个在多项式时间内实现这一目标的不可知增强算法。

Conclusion: 这项工作填补了不可知增强领域的空白，提供了第一个既具有接近最优样本复杂度又能在多项式时间内运行的算法。

Abstract: Boosting is a powerful method that turns weak learners, which perform only slightly better than random guessing, into strong learners with high accuracy. While boosting is well understood in the classic setting, it is less so in the agnostic case, where no assumptions are made about the data. Indeed, only recently was the sample complexity of agnostic boosting nearly settled arXiv:2503.09384, but the known algorithm achieving this bound has exponential running time. In this work, we propose the first agnostic boosting algorithm with near-optimal sample complexity, running in time polynomial in the sample size when considering the other parameters of the problem fixed.

</details>


### [49] [Metabolomic Biomarker Discovery for ADHD Diagnosis Using Interpretable Machine Learning](https://arxiv.org/abs/2601.11283)
*Nabil Belacel,Mohamed Rachid Boulassel*

Main category: cs.LG

TL;DR: 该研究结合尿液代谢组学和可解释机器学习框架，识别与ADHD相关的生物化学特征，开发了一种基于14种代谢物的客观诊断工具，AUC超过0.97。


<details>
  <summary>Details</summary>
Motivation: ADHD是一种普遍存在的神经发育障碍，目前缺乏客观的诊断工具，迫切需要基于生物学的客观诊断框架来推进精准精神病学。

Method: 研究整合尿液代谢组学与可解释机器学习框架，使用最相似度分类器分析52名ADHD患者和46名对照参与者的靶向代谢组学数据，并嵌入特征选择功能。

Result: 最相似度分类器表现优于随机森林和K近邻分类器，基于14种代谢物实现了AUC > 0.97。这些代谢物包括多巴胺4-硫酸盐、N-乙酰天冬氨酸谷氨酸和瓜氨酸，映射到多巴胺能神经传递和氨基酸代谢通路。

Conclusion: 该研究展示了一个结合代谢组学和可解释机器学习的转化框架，为ADHD提供了客观、基于生物学的诊断策略，其透明决策边界和低计算成本支持整合到靶向代谢组学检测和未来即时诊断平台中。

Abstract: Attention Deficit Hyperactivity Disorder (ADHD) is a prevalent neurodevelopmental disorder with limited objective diagnostic tools, highlighting the urgent need for objective, biology-based diagnostic frameworks in precision psychiatry. We integrate urinary metabolomics with an interpretable machine learning framework to identify biochemical signatures associated with ADHD. Targeted metabolomic profiles from 52 ADHD and 46 control participants were analyzed using a Closest Resemblance (CR) classifier with embedded feature selection. The CR model outperformed Random Forest and K-Nearest Neighbor classifiers, achieving an AUC > 0.97 based on a reduced panel of 14 metabolites. These metabolites including dopamine 4-sulfate, N-acetylaspartylglutamic acid, and citrulline map to dopaminergic neurotransmission and amino acid metabolism pathways, offering mechanistic insight into ADHD pathophysiology. The CR classifier's transparent decision boundaries and low computational cost support integration into targeted metabolomic assays and future point of care diagnostic platforms. Overall, this work demonstrates a translational framework combining metabolomics and interpretable machine learning to advance objective, biologically informed diagnostic strategies for ADHD.

</details>


### [50] [FORESTLLM: Large Language Models Make Random Forest Great on Few-shot Tabular Learning](https://arxiv.org/abs/2601.11311)
*Zhihan Yang,Jiaqi Wei,Xiang Zhang,Haoyu Dong,Yiwen Wang,Xiaoke Guo,Pengkun Zhang,Yiwei Xu,Chenyu You*

Main category: cs.LG

TL;DR: FORESTLLM是一个将决策树结构偏置与LLM语义推理能力结合的新框架，仅训练时使用LLM作为离线模型设计器，在少样本场景下实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 表格数据在金融、医疗等关键领域决策中很重要，但少样本场景下学习面临挑战：传统树方法依赖统计纯度指标，在有限监督下不稳定易过拟合；直接应用LLM又忽略了表格数据结构。需要结合两者的优势。

Method: 1. 语义分割准则：LLM基于标注和未标注数据评估候选分割的连贯性，在少样本监督下诱导更鲁棒的树结构。2. 一次性上下文推理机制：LLM将决策路径和支持样本提炼为简洁的确定性预测，用语义信息输出替代噪声经验估计。

Result: 在多样化的少样本分类和回归基准测试中，FORESTLLM实现了最先进的性能。

Conclusion: FORESTLLM成功统一了决策树的结构偏置和LLM的语义推理能力，仅训练时使用LLM，消除了测试时LLM推理需求，在少样本表格数据学习中表现出色。

Abstract: Tabular data high-stakes critical decision-making in domains such as finance, healthcare, and scientific discovery. Yet, learning effectively from tabular data in few-shot settings, where labeled examples are scarce, remains a fundamental challenge. Traditional tree-based methods often falter in these regimes due to their reliance on statistical purity metrics, which become unstable and prone to overfitting with limited supervision. At the same time, direct applications of large language models (LLMs) often overlook its inherent structure, leading to suboptimal performance. To overcome these limitations, we propose FORESTLLM, a novel framework that unifies the structural inductive biases of decision forests with the semantic reasoning capabilities of LLMs. Crucially, FORESTLLM leverages the LLM only during training, treating it as an offline model designer that encodes rich, contextual knowledge into a lightweight, interpretable forest model, eliminating the need for LLM inference at test time. Our method is two-fold. First, we introduce a semantic splitting criterion in which the LLM evaluates candidate partitions based on their coherence over both labeled and unlabeled data, enabling the induction of more robust and generalizable tree structures under few-shot supervision. Second, we propose a one-time in-context inference mechanism for leaf node stabilization, where the LLM distills the decision path and its supporting examples into a concise, deterministic prediction, replacing noisy empirical estimates with semantically informed outputs. Across a diverse suite of few-shot classification and regression benchmarks, FORESTLLM achieves state-of-the-art performance.

</details>


### [51] [Unlocking the Potentials of Retrieval-Augmented Generation for Diffusion Language Models](https://arxiv.org/abs/2601.11342)
*Chuanyue Yu,Jiahui Wang,Yuhan Li,Heng Chang,Ge Lan,Qingyun Sun,Jia Li,Jianxin Li,Ziwei Zhang*

Main category: cs.LG

TL;DR: 本文提出SPREAD框架，通过查询相关性引导的去噪策略解决扩散语言模型在检索增强生成中的语义漂移问题，显著提升生成精度。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在自然语言处理任务中表现出色，但检索增强生成技术虽然在增强大语言模型方面取得巨大成功，却未在DLMs中得到充分探索。这是由于LLM和DLM解码机制存在根本差异，导致DLMs在RAG框架中生成精度有限，存在响应语义漂移问题。

Method: 提出SPREAD（Semantic-Preserving REtrieval-Augmented Diffusion）框架，引入查询相关性引导的去噪策略。该策略主动引导去噪轨迹，确保生成过程始终锚定查询语义，有效抑制语义漂移。

Result: 实验结果表明，SPREAD显著提升了RAG框架中生成答案的精度，有效缓解了响应语义漂移问题。DLMs与RAG结合显示出对上下文信息更强的依赖性，但需要解决语义漂移问题才能充分发挥潜力。

Conclusion: SPREAD框架成功解决了扩散语言模型在检索增强生成中的语义漂移问题，通过查询相关性引导的去噪策略确保了生成内容与查询语义的一致性，为DLMs在RAG框架中的应用提供了有效解决方案。

Abstract: Diffusion Language Models (DLMs) have recently demonstrated remarkable capabilities in natural language processing tasks. However, the potential of Retrieval-Augmented Generation (RAG), which shows great successes for enhancing large language models (LLMs), has not been well explored, due to the fundamental difference between LLM and DLM decoding. To fill this critical gap, we systematically test the performance of DLMs within the RAG framework. Our findings reveal that DLMs coupled with RAG show promising potentials with stronger dependency on contextual information, but suffer from limited generation precision. We identify a key underlying issue: Response Semantic Drift (RSD), where the generated answer progressively deviates from the query's original semantics, leading to low precision content. We trace this problem to the denoising strategies in DLMs, which fail to maintain semantic alignment with the query throughout the iterative denoising process. To address this, we propose Semantic-Preserving REtrieval-Augmented Diffusion (SPREAD), a novel framework that introduces a query-relevance-guided denoising strategy. By actively guiding the denoising trajectory, SPREAD ensures the generation remains anchored to the query's semantics and effectively suppresses drift. Experimental results demonstrate that SPREAD significantly enhances the precision and effectively mitigates RSD of generated answers within the RAG framework.

</details>


### [52] [Offline Reinforcement-Learning-Based Power Control for Application-Agnostic Energy Efficiency](https://arxiv.org/abs/2601.11352)
*Akhilesh Raj,Swann Perarnau,Aniruddha Gokhale,Solomon Bekele Abera*

Main category: cs.LG

TL;DR: 使用离线强化学习设计CPU功耗控制器，通过历史数据集训练而非在线学习，在保证性能可接受下降的前提下显著降低并行应用的能耗。


<details>
  <summary>Details</summary>
Motivation: 现代计算基础设施设计中能效已成为关键因素，虽然强化学习适合设计能效控制系统，但在线训练面临缺乏合适模拟环境模型、噪声干扰和可靠性等问题。

Method: 采用离线强化学习方法，利用任意策略收集的状态转移数据集进行训练，结合灰盒方法使用在线应用无关性能数据（如心跳）和硬件性能计数器，通过Intel的RAPL控制实时系统功耗。

Result: 在多种计算密集型和内存密集型基准测试中评估，离线训练的智能体能在可容忍的性能下降成本下显著降低能耗。

Conclusion: 离线强化学习是设计自主CPU功耗控制器的有效替代方案，能够在不严重影响性能的情况下提高并行应用的运行时能效。

Abstract: Energy efficiency has become an integral aspect of modern computing infrastructure design, impacting the performance, cost, scalability, and durability of production systems. The incorporation of power actuation and sensing capabilities in CPU designs is indicative of this, enabling the deployment of system software that can actively monitor and adjust energy consumption and performance at runtime. While reinforcement learning (RL) would seem ideal for the design of such energy efficiency control systems, online training presents challenges ranging from the lack of proper models for setting up an adequate simulated environment, to perturbation (noise) and reliability issues, if training is deployed on a live system.
  In this paper we discuss the use of offline reinforcement learning as an alternative approach for the design of an autonomous CPU power controller, with the goal of improving the energy efficiency of parallel applications at runtime without unduly impacting their performance. Offline RL sidesteps the issues incurred by online RL training by leveraging a dataset of state transitions collected from arbitrary policies prior to training.
  Our methodology applies offline RL to a gray-box approach to energy efficiency, combining online application-agnostic performance data (e.g., heartbeats) and hardware performance counters to ensure that the scientific objectives are met with limited performance degradation. Evaluating our method on a variety of compute-bound and memory-bound benchmarks and controlling power on a live system through Intel's Running Average Power Limit, we demonstrate that such an offline-trained agent can substantially reduce energy consumption at a tolerable performance degradation cost.

</details>


### [53] [Factored Value Functions for Graph-Based Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.11401)
*Ahmed Rashwan,Keith Briggs,Chris Budd,Lisa Kreusser*

Main category: cs.LG

TL;DR: 论文提出扩散价值函数（DVF），一种用于图马尔可夫决策过程的分解价值函数，通过在图结构上扩散奖励来解决多智能体强化学习中的信用分配问题，并在此基础上开发了DA2C算法和LD-GNN架构。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的信用分配问题在具有结构化局部交互的大规模系统中尤为突出。现有的全局价值函数提供的学习信号较弱，而局部构造方法在无限时域设置中难以估计且表现不佳，需要一种与图结构对齐的价值函数表示方法。

Method: 提出扩散价值函数（DVF），通过在图影响结构上结合时间折扣和空间衰减来扩散奖励，为每个智能体分配价值分量。基于DVF开发了Diffusion A2C（DA2C）算法，并设计了Learned DropEdge GNN（LD-GNN）稀疏消息传递执行器来处理通信成本。

Result: 在消防基准测试和三个分布式计算任务（向量图着色和两个传输功率优化问题）上，DA2C持续优于局部和全局批评器基线，平均奖励提升高达11%。DVF被证明具有良好的定义性、存在贝尔曼不动点，并能通过平均性质分解全局折扣价值。

Conclusion: 扩散价值函数为图马尔可夫决策过程提供了一种结构对齐的信用分配方法，能够有效解决大规模多智能体系统中的信用分配问题，并通过DA2C算法在实际任务中展现出显著性能优势。

Abstract: Credit assignment is a core challenge in multi-agent reinforcement learning (MARL), especially in large-scale systems with structured, local interactions. Graph-based Markov decision processes (GMDPs) capture such settings via an influence graph, but standard critics are poorly aligned with this structure: global value functions provide weak per-agent learning signals, while existing local constructions can be difficult to estimate and ill-behaved in infinite-horizon settings. We introduce the Diffusion Value Function (DVF), a factored value function for GMDPs that assigns to each agent a value component by diffusing rewards over the influence graph with temporal discounting and spatial attenuation. We show that DVF is well-defined, admits a Bellman fixed point, and decomposes the global discounted value via an averaging property. DVF can be used as a drop-in critic in standard RL algorithms and estimated scalably with graph neural networks. Building on DVF, we propose Diffusion A2C (DA2C) and a sparse message-passing actor, Learned DropEdge GNN (LD-GNN), for learning decentralised algorithms under communication costs. Across the firefighting benchmark and three distributed computation tasks (vector graph colouring and two transmit power optimisation problems), DA2C consistently outperforms local and global critic baselines, improving average reward by up to 11%.

</details>


### [54] [Forcing and Diagnosing Failure Modes of Fourier Neural Operators Across Diverse PDE Families](https://arxiv.org/abs/2601.11428)
*Lennon Shikhman*

Main category: cs.LG

TL;DR: FNOs在PDE求解中表现良好，但在分布偏移、长期推演和结构扰动下的鲁棒性不足。研究通过系统压力测试框架，在五种不同类型PDE上揭示了FNO的脆弱性模式。


<details>
  <summary>Details</summary>
Motivation: 尽管傅里叶神经算子在偏微分方程求解中表现出色，但其在分布偏移、长期推演和结构扰动下的鲁棒性尚未得到充分理解。研究旨在系统性地探索FNO的失效模式，为算子学习的鲁棒性改进提供基础。

Method: 提出了一个系统压力测试框架，在五种不同类型的PDE家族（色散、椭圆、多尺度流体、金融和混沌系统）上进行大规模评估（1000个训练模型）。设计了受控压力测试，包括参数偏移、边界或终端条件变化、分辨率外推与谱分析、迭代推演等，以暴露谱偏差、累积积分误差和边界条件过拟合等脆弱性。

Result: 参数或边界条件的分布偏移可使误差增加一个数量级以上；分辨率变化主要将误差集中在高频模式；输入扰动通常不会放大误差，但最坏情况（如局部泊松扰动）仍然具有挑战性。研究提供了比较性的失效模式图谱。

Conclusion: 该研究系统地揭示了FNO在多种PDE场景下的鲁棒性缺陷，为改进算子学习的鲁棒性提供了可操作的见解和比较性的失效模式图谱，强调了在分布偏移和边界条件变化等实际场景中需要特别关注的问题。

Abstract: Fourier Neural Operators (FNOs) have shown strong performance in learning solution maps of partial differential equations (PDEs), but their robustness under distribution shifts, long-horizon rollouts, and structural perturbations remains poorly understood. We present a systematic stress-testing framework that probes failure modes of FNOs across five qualitatively different PDE families: dispersive, elliptic, multi-scale fluid, financial, and chaotic systems. Rather than optimizing in-distribution accuracy, we design controlled stress tests--including parameter shifts, boundary or terminal condition changes, resolution extrapolation with spectral analysis, and iterative rollouts--to expose vulnerabilities such as spectral bias, compounding integration errors, and overfitting to restricted boundary regimes. Our large-scale evaluation (1{,}000 trained models) reveals that distribution shifts in parameters or boundary conditions can inflate errors by more than an order of magnitude, while resolution changes primarily concentrate error in high-frequency modes. Input perturbations generally do not amplify error, though worst-case scenarios (e.g., localized Poisson perturbations) remain challenging. These findings provide a comparative failure-mode atlas and actionable insights for improving robustness in operator learning.

</details>


### [55] [When Are Two Scores Better Than One? Investigating Ensembles of Diffusion Models](https://arxiv.org/abs/2601.11444)
*Raphaël Razafindralambo,Rémy Sun,Frédéric Precioso,Damien Garreau,Pierre-Alexandre Mattei*

Main category: cs.LG

TL;DR: 扩散模型集成虽然能改善评分匹配损失和模型似然，但无法稳定提升图像生成质量指标如FID


<details>
  <summary>Details</summary>
Motivation: 尽管集成方法在监督学习中已被证明有效，但在无条件评分扩散模型中的应用仍未被充分探索，研究团队希望验证集成是否能为生成建模带来实际好处

Method: 使用深度集成、蒙特卡洛Dropout等方法，在CIFAR-10和FFHQ数据集上进行实验，探索多种聚合规则，同时通过随机森林研究表格数据

Result: 集成评分通常能改善评分匹配损失和模型似然，但无法一致提升感知质量指标如FID；在表格数据中发现某种聚合策略优于其他方法

Conclusion: 扩散模型集成存在评分估计与图像质量之间的脱节现象，研究为模型集成和组合技术（如引导）提供了理论见解

Abstract: Diffusion models now generate high-quality, diverse samples, with an increasing focus on more powerful models. Although ensembling is a well-known way to improve supervised models, its application to unconditional score-based diffusion models remains largely unexplored. In this work we investigate whether it provides tangible benefits for generative modelling. We find that while ensembling the scores generally improves the score-matching loss and model likelihood, it fails to consistently enhance perceptual quality metrics such as FID on image datasets. We confirm this observation across a breadth of aggregation rules using Deep Ensembles, Monte Carlo Dropout, on CIFAR-10 and FFHQ. We attempt to explain this discrepancy by investigating possible explanations, such as the link between score estimation and image quality. We also look into tabular data through random forests, and find that one aggregation strategy outperforms the others. Finally, we provide theoretical insights into the summing of score models, which shed light not only on ensembling but also on several model composition techniques (e.g. guidance).

</details>


### [56] [Low-Rank Key Value Attention](https://arxiv.org/abs/2601.11471)
*James O'Neill,Robert Clancy,Mariia Matskevichus,Fergal Reid*

Main category: cs.LG

TL;DR: LRKV是一种通过低秩KV适应来减少Transformer KV缓存内存的方法，在保持完整token级分辨率的同时利用注意力头间的冗余性，显著降低训练和推理的计算需求。


<details>
  <summary>Details</summary>
Motivation: Transformer预训练越来越受内存和计算资源的限制，其中键值（KV）缓存在训练和自回归解码过程中成为主要瓶颈。需要一种既能减少KV缓存内存占用，又能保持模型性能的解决方案。

Method: 提出低秩KV适应（LRKV），对多头注意力进行简单修改：每层使用共享的全秩KV投影，并添加低秩、头特定的残差项。这种方法在完全共享和完全独立注意力之间提供连续权衡，是标准多头注意力的即插即用替代方案。

Result: 在大规模预训练实验中，LRKV相比标准注意力、MQA/GQA和MLA，实现了更快的损失下降、更低的验证困惑度和更强的下游任务性能。在25亿参数规模下，LRKV使用约一半的KV缓存就能超越标准注意力性能，达到相同模型质量时训练计算量减少20-25%。

Conclusion: LRKV是一种实用有效的注意力机制，特别适用于内存和计算受限的Transformer预训练扩展场景。分析表明LRKV几乎保留了所有功能性头多样性，而更激进的KV共享机制则需要查询专业化来补偿。

Abstract: Transformer pretraining is increasingly constrained by memory and compute requirements, with the key-value (KV) cache emerging as a dominant bottleneck during training and autoregressive decoding. We propose \textit{low-rank KV adaptation} (LRKV), a simple modification of multi-head attention that reduces KV cache memory by exploiting redundancy across attention heads while preserving full token-level resolution. Each layer uses a shared full-rank KV projection augmented with low-rank, head-specific residuals, yielding a continuous trade-off between complete sharing and fully independent attention.
  LRKV is a drop-in replacement for standard multi-head attention and directly subsumes query-sharing approaches such as multi-query and grouped-query attention, while remaining distinct from latent-compression methods such as multi-latent attention (MLA). Across large-scale pretraining experiments, LRKV consistently achieves faster loss reduction, lower validation perplexity, and stronger downstream task performance than standard attention, MQA/GQA, and MLA. At the 2.5B scale, LRKV outperforms standard attention while using roughly half the KV cache, and reaches equivalent model quality with up to \textbf{20-25\% less training compute} when measured in cumulative FLOPs. To explain these gains, we analyze attention head structure in operator space and show that LRKV preserves nearly all functional head diversity relative to standard attention, whereas more aggressive KV-sharing mechanisms rely on compensatory query specialization. Together, these results establish LRKV as a practical and effective attention mechanism for scaling Transformer pretraining under memory- and compute-constrained regimes.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [57] ["My Brother Is a School Principal, Earns About $80,000 Per Year... But When the Kids See Me, 'Wow, Uncle, You Have 1500 Followers on TikTok!'": A Study of Blind TikTokers' Alternative Professional Development Experiences](https://arxiv.org/abs/2601.10956)
*Yao Lyu,Tawanna Dillahunt,Jiaying Liu,John M. Carroll*

Main category: cs.HC

TL;DR: 本研究通过访谈60位视障人士在TikTok上的职业发展经历，揭示了他们通过社交媒体平台进行职业发展的新路径，这种路径比传统模式更灵活、包容、个性化和多样化。


<details>
  <summary>Details</summary>
Motivation: 传统职业发展模式常常排斥残障人士，特别是视障人士面临不成比例的低就业率。随着社交媒体平台作为更公平职业发展空间的研究增多，本研究旨在探索视障人士在TikTok上的职业发展经验。

Method: 采用访谈研究方法，对60位在TikTok上活跃的视障人士（被称为"BlindTokers"）进行深入访谈，分析他们的职业发展目标、策略和挑战。

Result: 研究发现BlindTokers的实践展示了一种替代性的职业发展模式，比传统模式更灵活、包容、个性化和多样化。研究还识别了新兴数字技能，并提出了促进更公平包容职业机会的设计启示。

Conclusion: 社交媒体平台如TikTok为视障人士提供了传统职业发展之外的替代路径，这种数字化的职业发展模式具有更大的包容性和灵活性，为促进更公平的职业机会提供了新思路。

Abstract: One's profession is an essential part of modern life. Traditionally, professional development has been criticized for excluding people with disabilities. People with visual impairments, for example, face disproportionately low employment rates, highlighting persistent gaps in professional opportunities. Recently, there has been growing research on social media platforms as spaces for more equitable career development approaches. In this paper, we present an interview study on the professional development experiences of 60 people with visual impairments on TikTok (also known as "BlindTokers"). We report BlindTokers' goals, strategies, and challenges, supported by detailed examples and in-depth analysis. Based on the findings, we identify that BlindTokers' practices reveal an alternative professional development approach that is more flexible, inclusive, personalized, and diversified than traditional models. Our study also extends professional development research by foregrounding emerging digital skills and proposing design implications to foster more equitable and inclusive professional opportunities.

</details>


### [58] [Haptic Light-Emitting Diodes: Miniature, Luminous Tactile Actuators](https://arxiv.org/abs/2601.11043)
*Max Linnander,Yon Visell*

Main category: cs.HC

TL;DR: HLEDs是一种将脉冲光直接转换为机械力和位移的发光热致动器，可用于触觉反馈等人机界面应用。


<details>
  <summary>Details</summary>
Motivation: 开发一种简单、高效且能提供触觉反馈的致动器，用于人机界面、可穿戴计算等领域。

Method: 将微型表面贴装LED封装在充满气体的腔体中，腔体包含低惯性石墨光吸收剂，并由弹性膜密封。光脉冲加热光吸收剂，进而加热气体产生压力变化，驱动工作膜片产生力和位移。

Result: 毫米级HLEDs在低电压下产生超过0.4N的力和1mm的位移，响应时间为5-100ms。感知测试显示触觉反馈强度与光功率呈线性关系。

Conclusion: HLEDs是机械简单、制造高效的光机械致动器，具有发光特性，在触觉显示、人机界面工程、可穿戴计算等领域有广泛应用前景。

Abstract: We present Haptic Light-Emitting Diodes (HLEDs), luminous thermopneumatic actuators that directly convert pulsed light into mechanical forces and displacements. Each device packages a miniature surface-mount LED in a gas-filled cavity that contains a low-inertia graphite photoabsorber. The cavity is sealed by an elastic membrane, which functions as a working diaphragm. Brief optical pulses heat the photoabsorber, which heats the gas. The resulting rapid pressure increases generate forces and displacements at the working diaphragm. Millimeter-scale HLEDs produce forces exceeding 0.4 N and displacements of 1 mm at low voltages, with 5 to 100 ms response times, making them attractive as actuators providing tactile feedback in human-machine interfaces. Perceptual testing revealed that the strength of tactile feedback increased linearly with optical power. HLEDs devices are mechanically simple and efficient to fabricate. Unusually, these actuators are also light-emitting, as a fraction of optical energy is transmitted through the membrane. These opto-mechanical actuators have many potential applications in tactile displays, human interface engineering, wearable computing, and other areas.

</details>


### [59] [Children's Expectations, Engagement, and Evaluation of an LLM-enabled Spherical Visualization Platform in the Classroom](https://arxiv.org/abs/2601.11060)
*Emelie Fälton,Isabelle Strömstedt,Mathis Brossier,Andreas Göransson,Konrad Schönborn,Amy Loutfi,Erik Sunden,Mujtaba Fadhil Jawad,Yadgar Suleiman,Johanna Björklund,Mario Romero,Anders Ynnerman,Lonni Besançon*

Main category: cs.HC

TL;DR: 研究在小学课堂环境中部署LLM增强的可视化软件，让9-10岁儿童通过语音交互探索地球相关数据集，考察儿童对语音LLM界面的期望、参与度和评价。


<details>
  <summary>Details</summary>
Motivation: 随着对话式AI在支持探究式学习方面的兴趣日益增长，研究者希望在正式教育环境中探索儿童对语音LLM界面与共享沉浸式可视化系统的期望、参与度和评价。

Method: 系统整合了支持语音的大型语言模型与交互式球形显示器，允许儿童用自然语言提问，获得协调的语音解释和实时更新的可视化响应。研究采用课堂研究法，结合结构化观察和小组讨论，收集瑞典9-10岁儿童在互动前、互动中和互动后的数据。

Result: 研究提供了儿童在课堂环境中首次接触LLM增强可视化平台的实证见解，包括他们对系统的期望、互动模式和评价，为技术在教育中的应用潜力提供了依据。

Conclusion: 研究结果揭示了LLM增强可视化系统在教育应用中的潜力，并指出了未来研究的重要方向，特别是在儿童与AI增强学习环境互动方面。

Abstract: We present our first stage results from deploying an LLM-augmented visualization software in a classroom setting to engage primary school children with earth-related datasets. Motivated by the growing interest in conversational AI as a means to support inquiry-based learning, we investigate children's expectations, engagement, and evaluation of a spoken LLM interface with a shared, immersive visualization system in a formal educational context. Our system integrates a speech-capable large language model with an interactive spherical display. It enables children to ask natural-language questions and receive coordinated verbal explanations and visual responses through the LLM-augmented visualization updating in real time based on spoken queries. We report on a classroom study with Swedish children aged 9-10, combining structured observation and small-group discussions to capture expectations prior to interaction, interaction patterns during facilitated sessions, and children's reflections on their encounter afterward. Our results provide empirical insights into children's initial encounters with an LLM-enabled visualization platform within a classroom setting and their expectations, interactions, and evaluations of the system. These findings inform the technology's potential for educational use and highlight important directions for future research.

</details>


### [60] [More Human or More AI? Visualizing Human-AI Collaboration Disclosures in Journalistic News Production](https://arxiv.org/abs/2601.11072)
*Amber Kusters,Pooja Prajod,Pablo Cesar,Abdallah El Ali*

Main category: cs.HC

TL;DR: 研究通过协同设计开发了四种可视化披露方案，评估了它们在新闻文章中披露人机协作的效果，发现文本披露效果最差，聊天机器人披露信息最深入，不同可视化方案会改变读者对AI实际贡献的感知。


<details>
  <summary>Details</summary>
Motivation: 当前新闻编辑过程中AI使用披露仅限于简单标签，无法准确反映人类与AI在新闻文章创作中的实际协作关系，需要更细致的披露方式来传达人机协作的复杂性。

Method: 通过协同设计会议（N=10）产生69个披露设计方案，实现4个原型（文本、基于角色的时间线、基于任务的时间线、聊天机器人），然后进行实验室研究（N=32）评估不同可视化方案和协作比例对感知、眼动模式和后续反应的影响。

Result: 文本披露在传达人机协作方面效果最差，聊天机器人提供的信息最深入；基于角色的时间线会放大AI在主要由人类创作文章中的贡献，而基于任务的时间线则会让主要由AI创作的文章更偏向人类参与感知。

Conclusion: 贡献了人机协作披露可视化方案及其评估，警示可视化设计可能改变读者对AI在新闻创作中实际角色的感知，需要谨慎设计披露方式以避免误导。

Abstract: Within journalistic editorial processes, disclosing AI usage is currently limited to simplistic labels, which misses the nuance of how humans and AI collaborated on a news article. Through co-design sessions (N=10), we elicited 69 disclosure designs and implemented four prototypes that visually disclose human-AI collaboration in journalism. We then ran a within-subjects lab study (N=32) to examine how disclosure visualizations (Textual, Role-based Timeline, Task-based Timeline, Chatbot) and collaboration ratios (Primarily Human vs. Primarily AI) influenced visualization perceptions, gaze patterns, and post-experience responses. We found that textual disclosures were least effective in communicating human-AI collaboration, whereas Chatbot offered the most in-depth information. Furthermore, while role-based timelines amplified AI contribution in primarily human articles, task-based timeline shifted perceptions toward human involvement in primarily AI articles. We contribute Human-AI collaboration disclosure visualizations and their evaluation, and cautionary considerations on how visualizations can alter perceptions of AI's actual role during news article creation.

</details>


### [61] [AI Twin: Enhancing ESL Speaking Practice through AI Self-Clones of a Better Me](https://arxiv.org/abs/2601.11103)
*Minju Park,Seunghyun Lee,Juhwan Ma,Dongwook Yoon*

Main category: cs.HC

TL;DR: AI Twin系统通过将ESL学习者的话语重新表述为更流利的英语并用学习者自己的声音播放，以隐含反馈方式提升学习动机和情感参与度，相比显式纠正效果更好。


<details>
  <summary>Details</summary>
Motivation: 现有ESL学习工具大多依赖显式纠正，这会打断对话流程并削弱学习者信心。基于第二语言习得和动机心理学理论，需要一种能保持对话流畅性并提供情感支持的学习系统。

Method: 开发了AI Twin系统，它能将学习者的话语重新表述为更流利的英语，并用学习者自己的声音播放，代表一个更自信、更熟练的学习者版本。系统通过隐含反馈（重新表述）而非显式纠正来保持对话流畅性，并与学习者的理想二语自我对齐来强化动机。

Result: 在20名成人ESL学习者的受试者内研究中，与显式纠正和非个性化重新表述系统相比，AI Twin引发了更高的情感参与度，参与者描述体验更具激励性。

Conclusion: AI Twin展示了自我代表性AI在ESL学习中提供个性化、心理学基础支持的潜力，通过隐含反馈和与理想自我对齐来增强学习动机和情感参与。

Abstract: Advances in AI have enabled ESL learners to practice speaking through conversational systems. However, most tools rely on explicit correction, which can interrupt the conversation and undermine confidence. Grounded in second language acquisition and motivational psychology, we present AI Twin, a system that rephrases learner utterances into more fluent English and delivers them in the learner's voice. Embodying a more confident and proficient version of the learner, AI Twin reinforces motivation through alignment with their aspirational Ideal L2 Self. Also, its use of implicit feedback through rephrasing preserves conversational flow and fosters an emotionally supportive environment. In a within-subject study with 20 adult ESL learners, we compared AI Twin with explicit correction and a non-personalized rephrasing agent. Results show that AI Twin elicited higher emotional engagement, with participants describing the experience as more motivating. These findings highlight the potential of self-representative AI for personalized, psychologically grounded support in ESL learning.

</details>


### [62] [Noisy Graph Patterns via Ordered Matrices](https://arxiv.org/abs/2601.11171)
*Jules Wulms,Wouter Meulemans,Bettina Speckmann*

Main category: cs.HC

TL;DR: 该论文提出使用有序矩阵作为工具来定义和检测图中的噪声模式，通过Moran's I优化排序邻接矩阵，将标准图模式转化为矩形子矩阵，并定义噪声容忍度，结合精确算法和启发式方法高效分解矩阵为噪声模式。


<details>
  <summary>Details</summary>
Motivation: 图的高级结构对于关系数据的分析和可视化至关重要，但发现形成这种结构的显著图模式面临两大挑战：1）寻找重要模式（如团和双团）在计算上很困难；2）现实世界图包含噪声，不总是以纯粹形式展现模式。定义有意义的噪声模式并有效检测是当前未解决的挑战。

Method: 将图表示为邻接矩阵，使用Moran's I进行最优排序，使标准图模式（团、双团、星）转化为矩形子矩阵。定义噪声模式的允许噪声水平，结合精确算法和启发式方法高效分解矩阵为噪声模式，并引入新的motif简化方法来可视化噪声模式，同时明确编码噪声水平。

Result: 在多个真实世界数据集上展示了该技术的有效性，能够有效检测和可视化图中的噪声模式。

Conclusion: 有序矩阵是定义和检测图中噪声模式的有效工具，通过Moran's I排序和噪声容忍度定义，结合算法分解和可视化技术，解决了现实图分析中噪声模式检测的挑战。

Abstract: The high-level structure of a graph is a crucial ingredient for the analysis and visualization of relational data. However, discovering the salient graph patterns that form this structure is notoriously difficult for two reasons. (1) Finding important patterns, such as cliques and bicliques, is computationally hard. (2) Real-world graphs contain noise, and therefore do not always exhibit patterns in their pure form. Defining meaningful noisy patterns and detecting them efficiently is a currently unsolved challenge. In this paper, we propose to use well-ordered matrices as a tool to both define and effectively detect noisy patterns. Specifically, we represent a graph as its adjacency matrix and optimally order it using Moran's $I$. Standard graph patterns (cliques, bicliques, and stars) now translate to rectangular submatrices. Using Moran's $I$, we define a permitted level of noise for such patterns. A combination of exact algorithms and heuristics allows us to efficiently decompose the matrix into noisy patterns. We also introduce a novel motif simplification that visualizes noisy patterns while explicitly encoding the level of noise. We showcase our techniques on several real-world data sets.

</details>


### [63] [Game Accessibility Through Shared Control for People With Upper-Limb Impairments](https://arxiv.org/abs/2601.11218)
*Sergio Mascetti,Matteo Manzoni,Filippo Corti,Dragan Ahmetovic*

Main category: cs.HC

TL;DR: 该研究比较了上肢障碍玩家在人类合作与部分自动化两种辅助方式下的游戏体验，开发了GamePals框架支持两种模式在现有第三方游戏中的应用。


<details>
  <summary>Details</summary>
Motivation: 上肢障碍人士在需要快速连续多输入的视频游戏中面临挑战。虽然人类合作（副驾驶协助）是一种解决方案，但依赖人类助手存在可用性和共处限制。需要探索替代方案。

Method: 开发了GamePals模块化框架，支持在现有第三方游戏中实现人类合作和部分自动化。对13名上肢障碍参与者进行了比较研究，评估他们在两种协作模式下的体验。

Result: 研究结果展示了上肢障碍玩家在人类合作与部分自动化两种辅助方式下的协作表现和体验差异，为辅助游戏技术提供了实证数据。

Conclusion: 部分自动化作为人类合作的替代方案，为上肢障碍玩家提供了新的辅助可能性，GamePals框架为实现这种辅助提供了技术支持。

Abstract: Accessing video games is challenging for people with upper-limb impairments, especially when multiple inputs are required in rapid succession. Human cooperation, where a copilot assists the main player, has been proposed as a solution, but relying on a human assistant poses limitations in terms of availability and co-location. An alternative solution is to use partial automation, where the player is assisted by a software agent. In this work, we present a study with 13 participants with upper-limb impairments, comparatively evaluating how participants collaborate with their copilot in human cooperation and partial automation. The experiment is supported by GamePals, a modular framework that enables both human cooperation and partial automation on existing third-party video games.

</details>


### [64] ["Can You Tell Me?": Designing Copilots to Support Human Judgement in Online Information Seeking](https://arxiv.org/abs/2601.11284)
*Markus Bink,Marten Risius,Udo Kruschwitz,David Elsweiler*

Main category: cs.HC

TL;DR: 这篇论文研究了基于LLM的对话式副驾驶如何支持信息评估而非直接提供答案，以培养数字素养技能。通过随机对照试验发现，虽然用户与副驾驶深度互动并展现出元认知反思，但副驾驶并未显著提高答案正确性或搜索参与度，主要受"聊天时间与探索"的权衡以及用户对正面信息的偏见影响。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具正在改变信息获取方式，但其流畅、权威的响应可能导致用户过度依赖，阻碍独立验证和推理能力的发展。论文认为GenAI系统不应取代用户的认知工作，而应支持和搭建认知脚手架。

Method: 引入基于LLM的对话式副驾驶，旨在搭建信息评估的脚手架而非直接提供答案。通过预注册的随机对照试验（N=261），比较三种界面条件（包括基于聊天的副驾驶），采用混合方法分析用户行为。

Result: 用户与副驾驶深度互动并展现出元认知反思，但副驾驶并未显著提高答案正确性或搜索参与度。主要原因是"聊天时间与探索"的权衡以及用户对正面信息的偏见。定性研究发现副驾驶的苏格拉底式方法与用户追求效率之间存在张力。

Conclusion: 研究揭示了教学副驾驶的潜力和陷阱，需要设计路径来协调素养培养目标与效率需求之间的矛盾。虽然副驾驶能促进元认知反思，但需要更好的设计来平衡教学目标和用户的实际需求。

Abstract: Generative AI (GenAI) tools are transforming information seeking, but their fluent, authoritative responses risk overreliance and discourage independent verification and reasoning. Rather than replacing the cognitive work of users, GenAI systems should be designed to support and scaffold it. Therefore, this paper introduces an LLM-based conversational copilot designed to scaffold information evaluation rather than provide answers and foster digital literacy skills. In a pre-registered, randomised controlled trial (N=261) examining three interface conditions including a chat-based copilot, our mixed-methods analysis reveals that users engaged deeply with the copilot, demonstrating metacognitive reflection. However, the copilot did not significantly improve answer correctness or search engagement, largely due to a "time-on-chat vs. exploration" trade-off and users' bias toward positive information. Qualitative findings reveal tension between the copilot's Socratic approach and users' desire for efficiency. These results highlight both the promise and pitfalls of pedagogical copilots, and we outline design pathways to reconcile literacy goals with efficiency demands.

</details>


### [65] [Seek and You Shall Find: Design & Evaluation of a Context-Aware Interactive Search Companion](https://arxiv.org/abs/2601.11287)
*Markus Bink,Marten Risius,Udo Kruschwitz,David Elsweiler*

Main category: cs.HC

TL;DR: 本文展示了一个交互式搜索伴侣，将专家搜索策略集成到现有搜索引擎结果页面中，通过上下文提示帮助用户改进搜索行为，用户研究表明它能显著提升搜索活跃度和任务表现。


<details>
  <summary>Details</summary>
Motivation: 许多用户（特别是在健康等高风险领域）在有效在线搜索和批判性评估方面存在困难，同时往往高估自己的数字素养能力，需要工具来帮助他们改进搜索行为。

Method: 开发了一个交互式搜索伴侣，无缝集成到现有搜索引擎结果页面中，提供上下文感知的提示，包括：澄清信息需求、改进查询表述、鼓励结果探索和减轻偏见，旨在促进反思性搜索行为同时最小化认知负担。

Result: 用户研究表明，该搜索伴侣成功鼓励了更积极和探索性的搜索行为：用户提交了75%更多的查询，查看了大约两倍的结果，并且在困难任务中表现出性能提升。

Conclusion: 轻量级、上下文相关的指导可以通过微学习机会增强搜索素养并赋能用户。虽然愿景涉及实时LLM适应性，但本研究使用受控实现来测试基础干预策略。

Abstract: Many users struggle with effective online search and critical evaluation, especially in high-stakes domains like health, while often overestimating their digital literacy. Thus, in this demo, we present an interactive search companion that seamlessly integrates expert search strategies into existing search engine result pages. Providing context-aware tips on clarifying information needs, improving query formulation, encouraging result exploration, and mitigating biases, our companion aims to foster reflective search behaviour while minimising cognitive burden. A user study demonstrates the companion's successful encouragement of more active and exploratory search, leading users to submit 75 % more queries and view roughly twice as many results, as well as performance gains in difficult tasks. This demo illustrates how lightweight, contextual guidance can enhance search literacy and empower users through micro-learning opportunities. While the vision involves real-time LLM adaptivity, this study utilises a controlled implementation to test the underlying intervention strategies.

</details>


### [66] [ProjecTA: A Semi-Humanoid Robotic Teaching Assistant with In-Situ Projection for Guided Tours](https://arxiv.org/abs/2601.11328)
*Hanqing Zhou,Yichuan Zhang,Zihan Zhang,Wei Zhang,Chao Wang,Pengcheng An*

Main category: cs.HC

TL;DR: ProjecTA是一个使用原位投影而非屏幕的半人形机器人教学助手，在移动学习中能减少认知负荷并提升学习效果


<details>
  <summary>Details</summary>
Motivation: 当前机器人教学助手通常使用身体安装的屏幕来传递内容，但在移动式边走边学的场景中（如创客空间导览），这些屏幕会分散学习者对现实世界物体的注意力，增加额外的认知负荷。HCI研究缺乏对潜在替代方案（如使用原位投影的机器人）的实证比较，也缺乏设计此类替代方案的知识。

Method: 研究者开发了ProjecTA——一个半人形、具备手势能力的教学助手，它能在引导学习者的同时，在物体附近投影与语音和手势协调的覆盖层。在一项混合方法研究中（N=24），在大学的创客空间比较了ProjecTA与其基于屏幕的对应版本。

Result: ProjecTA显著减少了额外认知负荷，在感知可用性、视觉显示的有用性和跨模态互补性方面优于基于屏幕的对应版本。定性分析显示，ProjecTA协调的投影、手势和语音将解释锚定在特定的地点和时间，以屏幕无法实现的方式增强了理解。

Conclusion: 研究为未来利用空间投影支持物理环境中移动学习的机器人教学助手提供了关键的设计启示。原位投影技术能够更好地支持移动学习，减少认知负荷，提升学习体验。

Abstract: Robotic teaching assistants (TAs) often use body-mounted screens to deliver content. In nomadic, walk-and-talk learning, such as tours in makerspaces, these screens can distract learners from real-world objects, increasing extraneous cognitive load. HCI research lacks empirical comparisons of potential alternatives, such as robots with in-situ projection versus screen-based counterparts; little knowledge has been derived for designing such alternatives. We introduce ProjecTA, a semi-humanoid, gesture-capable TA that guides learners while projecting near-object overlays coordinated with speech and gestures. In a mixed-method study (N=24) in a university makerspace, ProjecTA significantly reduced extraneous load and outperformed its screen-based counterpart in perceived usability, usefulness of visual display, and cross-modal complementarity. Qualitative analyses revealed how ProjecTA's coordinated projections, gestures, and speech anchored explanations in place and time, enhancing understanding in ways a screen could not. We derive key design implications for future robotic TAs leveraging spatial projection to support mobile learning in physical environments.

</details>


### [67] [Human Factors in Immersive Analytics](https://arxiv.org/abs/2601.11365)
*Yi Li,Kadek Ananta Satriadi,Jiazhou Liu,Anjali Khurana,Zhiqing Wu,Benjamin Tag,Tim Dwyer*

Main category: cs.HC

TL;DR: 沉浸式分析研究十年回顾：探索从人因工程角度评估沉浸式分析系统的新方法和标准实践


<details>
  <summary>Details</summary>
Motivation: 沉浸式分析研究已发展十年，虽然取得了理论和实践进展，但缺乏真正符合物理和心理工效学的技术，以及标准化的人本验证协议，这阻碍了沉浸式分析系统在广泛应用中的普及。

Method: 通过一系列沉浸式分析研讨会，聚集研究人员和实践者，从人因工程角度（包括认知和生理功能、行为和表现）探索评估沉浸式分析系统的新方法，并建立标准实践。

Result: 该研讨会旨在建立评估沉浸式分析系统的标准化人本验证协议，为未来研究和系统设计提供指导。

Conclusion: 需要从人因工程角度建立标准化的评估方法，以推动沉浸式分析技术的实际应用和未来发展。

Abstract: It has been ten years since the term ''Immersive Analytics'' (IA) was coined and research interest in the topic remains strong. Researchers in this field have produced practical and conceptual knowledge concerning the use of emerging immersive spatial display and interaction technologies for sense-making tasks through a number of papers, surveys, and books. However, a lack of truly physically and psychologically ergonomic techniques, as well as standardized human-centric validation protocols for these, remains a significant barrier to wider acceptance of practical IA systems in ubiquitous applications. Building upon a series of workshops on immersive analytics at various conferences, this workshop aims to explore new approaches and establish standard practices for evaluating immersive analytics systems from a human factors perspective. We will gather immersive analytics researchers and practitioners to look closely at these human factors -- including cognitive and physical functions as well as behaviour and performance -- to see how they inform the design and deployment of immersive analytics techniques and applications and to inform future research.

</details>


### [68] [Show me the evidence: Evaluating the role of evidence and natural language explanations in AI-supported fact-checking](https://arxiv.org/abs/2601.11387)
*Greta Warren,Jingyi Sun,Irina Shklovski,Isabelle Augenstein*

Main category: cs.HC

TL;DR: 研究发现证据在AI解释中的重要性：用户会依赖证据验证AI声明，即使有自然语言解释，当解释不足或有缺陷时仍会使用证据。证据是评估AI信息可靠性的关键因素。


<details>
  <summary>Details</summary>
Motivation: 尽管大量研究关注AI解释在复杂信息检索任务（如事实核查）中的作用，但证据的作用却被严重忽视。本研究旨在探索证据在非专家用户评估AI系统预测时的作用。

Method: 研究系统性地变化了三个因素：解释类型、AI预测确定性、AI系统建议的正确性。非专家参与者评估声明的真实性及AI系统预测，并可以选择轻松检查底层证据。收集了定量和定性数据。

Result: 参与者始终依赖证据来验证AI声明，在所有实验条件下都如此。当提供自然语言解释时，证据使用频率降低，但当解释显得不足或有缺陷时仍会依赖证据。定性数据显示参与者试图推断证据来源的可靠性，尽管来源身份被故意省略。

Conclusion: 证据是评估AI系统信息可靠性的关键因素，与自然语言解释结合能为决策提供宝贵支持。迫切需要进一步研究证据应如何呈现以及人们在实际中如何与证据互动。

Abstract: Although much research has focused on AI explanations to support decisions in complex information-seeking tasks such as fact-checking, the role of evidence is surprisingly under-researched. In our study, we systematically varied explanation type, AI prediction certainty, and correctness of AI system advice for non-expert participants, who evaluated the veracity of claims and AI system predictions. Participants were provided the option of easily inspecting the underlying evidence. We found that participants consistently relied on evidence to validate AI claims across all experimental conditions. When participants were presented with natural language explanations, evidence was used less frequently although they relied on it when these explanations seemed insufficient or flawed. Qualitative data suggests that participants attempted to infer evidence source reliability, despite source identities being deliberately omitted. Our results demonstrate that evidence is a key ingredient in how people evaluate the reliability of information presented by an AI system and, in combination with natural language explanations, offers valuable support for decision-making. Further research is urgently needed to understand how evidence ought to be presented and how people engage with it in practice.

</details>


### [69] [Sociotechnical Challenges of Machine Learning in Healthcare and Social Welfare](https://arxiv.org/abs/2601.11417)
*Tyler Reinmund,Lars Kunze,Marina Jirotka*

Main category: cs.HC

TL;DR: 该论文提出了一个分析医疗和社会福利领域机器学习社会技术挑战的框架，包括11类挑战的分类和基于实践的成因解释。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常将医疗和社会福利领域的机器学习挑战归因于设计者有限的社会理解或固有的技术限制，缺乏系统描述和跨场景比较的支持。需要更精确的分析框架来理解机器学习工具在现实护理实践中的功能和故障。

Method: 基于定性田野调查、纵向部署研究回顾以及与医疗和社会福利从业者的共同设计研讨会，开发了一个概念化框架。该框架包括：(1) 沿着ML赋能护理路径组织的11类社会技术挑战分类；(2) 这些挑战在设计和使用过程中出现的条件的过程导向解释。

Result: 提出了一个包含11类社会技术挑战的分类框架，这些挑战沿着机器学习赋能的护理路径组织。同时提供了一个关注实践的解释性视角，分析这些挑战在设计和实施过程中出现的条件。

Conclusion: 通过提供简洁的词汇和以实践为中心的解释性视角，这项工作支持对机器学习工具在现实护理服务中如何运作和故障进行更精确的分析，有助于系统性地描述和比较不同场景下的社会技术挑战。

Abstract: Sociotechnical challenges of machine learning in healthcare and social welfare are mismatches between how a machine learning tool functions and the structure of care practices. While prior research has documented many such issues, existing accounts often attribute them either to designers' limited social understanding or to inherent technical constraints, offering limited support for systematic description and comparison across settings. In this paper, we present a framework for conceptualizing sociotechnical challenges of machine learning grounded in qualitative fieldwork, a review of longitudinal deployment studies, and co-design workshops with healthcare and social welfare practitioners. The framework comprises (1) a categorization of eleven sociotechnical challenges organized along an ML-enabled care pathway, and (2) a process-oriented account of the conditions through which these challenges emerge across design and use. By providing a parsimonious vocabulary and an explanatory lens focused on practice, this work supports more precise analysis of how machine learning tools function and malfunction within real-world care delivery.

</details>


### [70] [Interactive Narrative Analytics: Bridging Computational Narrative Extraction and Human Sensemaking](https://arxiv.org/abs/2601.11459)
*Brian Keith*

Main category: cs.HC

TL;DR: 本文定义了交互式叙事分析（INA）这一新兴领域，结合计算叙事提取与交互式可视分析，支持从大规模新闻数据中进行意义建构。


<details>
  <summary>Details</summary>
Motivation: 信息过载和错误信息给从大规模新闻集合中提取有意义的叙事带来了重大挑战，需要新的方法来支持意义建构。

Method: 结合计算叙事提取与交互式可视分析，通过计算方法和可视化界面实现叙事结构的交互式探索，促进人类解释。

Result: 定义了交互式叙事分析（INA）这一新兴领域，识别了该领域在可扩展性、交互性、知识整合和评估标准化方面的挑战，以及在新闻分析、情报、科学文献探索和社交媒体分析等领域的应用机会。

Conclusion: 通过计算与人类洞察的结合，交互式叙事分析能够解决叙事意义建构中的复杂挑战，为多个应用领域提供有前景的解决方案。

Abstract: Information overload and misinformation create significant challenges in extracting meaningful narratives from large news collections. This paper defines the nascent field of Interactive Narrative Analytics (INA), which combines computational narrative extraction with interactive visual analytics to support sensemaking. INA approaches enable the interactive exploration of narrative structures through computational methods and visual interfaces that facilitate human interpretation. The field faces challenges in scalability, interactivity, knowledge integration, and evaluation standardization, yet offers promising opportunities across news analysis, intelligence, scientific literature exploration, and social media analysis. Through the combination of computational and human insight, INA addresses complex challenges in narrative sensemaking.

</details>
