<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 53]
- [cs.HC](#cs.HC) [Total: 14]
- [cs.AI](#cs.AI) [Total: 20]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Blurred Encoding for Trajectory Representation Learning](https://arxiv.org/abs/2511.13741)
*Silin Zhou,Yao Chen,Shuo Shang,Lisi Chen,Bingsheng He,Ryosuke Shibasaki*

Main category: cs.LG

TL;DR: BLUE是一种轨迹表示学习方法，通过逐步降低GPS坐标精度创建多级层次化补丁，在保留细粒度时空细节的同时捕获整体出行模式。


<details>
  <summary>Details</summary>
Motivation: 现有SOTA方法将原始GPS轨迹转换为网格或道路轨迹来捕获高级旅行语义，但会丢失细粒度时空细节，因为多个GPS点被分组到单个网格单元或道路段中。

Method: 提出BLUrred Encoding方法，创建具有多个级别的层次化补丁。使用具有金字塔结构的编码器-解码器模型，在每个补丁级别使用Transformer学习当前级别的轨迹嵌入，通过池化准备编码器中更高级别的输入，通过上采样为解码器中较低级别提供指导。使用MSE损失的轨迹重建任务进行训练。

Result: 与8个SOTA TRL方法在3个下游任务上进行比较，BLUE始终比所有基线获得更高准确率，平均优于最佳基线30.90%。

Conclusion: BLUE方法通过层次化补丁结构有效平衡了细粒度时空细节和整体出行模式的捕获，在轨迹表示学习任务中表现出色。

Abstract: Trajectory representation learning (TRL) maps trajectories to vector embeddings and facilitates tasks such as trajectory classification and similarity search. State-of-the-art (SOTA) TRL methods transform raw GPS trajectories to grid or road trajectories to capture high-level travel semantics, i.e., regions and roads. However, they lose fine-grained spatial-temporal details as multiple GPS points are grouped into a single grid cell or road segment. To tackle this problem, we propose the BLUrred Encoding method, dubbed BLUE, which gradually reduces the precision of GPS coordinates to create hierarchical patches with multiple levels. The low-level patches are small and preserve fine-grained spatial-temporal details, while the high-level patches are large and capture overall travel patterns. To complement different patch levels with each other, our BLUE is an encoder-decoder model with a pyramid structure. At each patch level, a Transformer is used to learn the trajectory embedding at the current level, while pooling prepares inputs for the higher level in the encoder, and up-resolution provides guidance for the lower level in the decoder. BLUE is trained using the trajectory reconstruction task with the MSE loss. We compare BLUE with 8 SOTA TRL methods for 3 downstream tasks, the results show that BLUE consistently achieves higher accuracy than all baselines, outperforming the best-performing baselines by an average of 30.90%. Our code is available at https://github.com/slzhou-xy/BLUE.

</details>


### [2] [SCALEX: Scalable Concept and Latent Exploration for Diffusion Models](https://arxiv.org/abs/2511.13750)
*E. Zhixuan Zeng,Yuhao Chen,Alexander Wong*

Main category: cs.LG

TL;DR: SCALEX是一个可扩展的自动化框架，用于探索扩散模型的潜在空间，通过自然语言提示提取语义方向，实现零样本解释，无需重新训练或标注。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型偏见分析方法要么局限于预定义类别，要么依赖潜在方向的手动解释，限制了可扩展性并阻碍了发现微妙或意外模式的能力。

Method: SCALEX从H空间提取语义上有意义的方向，仅使用自然语言提示，实现零样本解释，无需重新训练或标注。

Result: SCALEX能够检测职业提示中的性别偏见，对身份描述符的语义对齐进行排序，并在无监督情况下揭示聚类的概念结构。

Conclusion: 通过直接将提示与潜在方向关联，SCALEX使扩散模型中的偏见分析比先前方法更具可扩展性、可解释性和可扩展性。

Abstract: Image generation models frequently encode social biases, including stereotypes tied to gender, race, and profession. Existing methods for analyzing these biases in diffusion models either focus narrowly on predefined categories or depend on manual interpretation of latent directions. These constraints limit scalability and hinder the discovery of subtle or unanticipated patterns.
  We introduce SCALEX, a framework for scalable and automated exploration of diffusion model latent spaces. SCALEX extracts semantically meaningful directions from H-space using only natural language prompts, enabling zero-shot interpretation without retraining or labelling. This allows systematic comparison across arbitrary concepts and large-scale discovery of internal model associations. We show that SCALEX detects gender bias in profession prompts, ranks semantic alignment across identity descriptors, and reveals clustered conceptual structure without supervision. By linking prompts to latent directions directly, SCALEX makes bias analysis in diffusion models more scalable, interpretable, and extensible than prior approaches.

</details>


### [3] [Robustness of LLM-enabled vehicle trajectory prediction under data security threats](https://arxiv.org/abs/2511.13753)
*Feilong Wang,Fuqiang Liu*

Main category: cs.LG

TL;DR: 本文对基于大语言模型的车辆轨迹预测模型进行了系统性漏洞分析，提出了一种单特征差分进化攻击方法，揭示了此类模型在对抗性攻击下的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 尽管微调后的大语言模型在预测车辆轨迹和变道意图方面表现出色，但其在安全关键驾驶系统中的鲁棒性尚未得到充分研究，特别是在对抗性攻击下的表现。

Method: 提出了一种单特征差分进化攻击方法，在黑色盒设置下扰动周围车辆的单个运动学特征，通过实验验证攻击效果。

Result: 实验表明，即使在物理上合理的微小扰动也能显著破坏模型输出，揭示了基于大语言模型的预测器对对抗性操纵的敏感性。

Conclusion: 研究首次揭示了LLM驱动的自动驾驶模型在车辆交互场景中的对抗性漏洞，强调了未来基于LLM的智能交通系统需要关注鲁棒性设计。

Abstract: The integration of large language models (LLMs) into automated driving systems has opened new possibilities for reasoning and decision-making by transforming complex driving contexts into language-understandable representations. Recent studies demonstrate that fine-tuned LLMs can accurately predict vehicle trajectories and lane-change intentions by gathering and transforming data from surrounding vehicles. However, the robustness of such LLM-based prediction models for safety-critical driving systems remains unexplored, despite the increasing concerns about the trustworthiness of LLMs. This study addresses this gap by conducting a systematic vulnerability analysis of LLM-enabled vehicle trajectory prediction. We propose a one-feature differential evolution attack that perturbs a single kinematic feature of surrounding vehicles within the LLM's input prompts under a black-box setting. Experiments on the highD dataset reveal that even minor, physically plausible perturbations can significantly disrupt model outputs, underscoring the susceptibility of LLM-based predictors to adversarial manipulation. Further analyses reveal a trade-off between accuracy and robustness, examine the failure mechanism, and explore potential mitigation solutions. The findings provide the very first insights into adversarial vulnerabilities of LLM-driven automated vehicle models in the context of vehicular interactions and highlight the need for robustness-oriented design in future LLM-based intelligent transportation systems.

</details>


### [4] [Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement](https://arxiv.org/abs/2511.13755)
*Zhe Yang,Wenrui Li,Hongtao Chen,Penghong Wang,Ruiqin Xiong,Xiaopeng Fan*

Main category: cs.LG

TL;DR: 本文提出RedReg方法，通过自适应冗余调节来解决多模态学习中模态偏差导致的优化不平衡问题，利用信息瓶颈原理构建冗余阶段监控器和共信息门控机制，在保持模态特定信息的同时抑制冗余梯度。


<details>
  <summary>Details</summary>
Motivation: 多模态学习中，优势模态在反向传播中占据主导地位，导致优化不平衡。现有方法存在两个问题：优势模态的长期主导削弱了表示-输出耦合，导致冗余信息积累；直接统一调整优势模态梯度忽略了模态间的语义和方向性。

Method: 提出RedReg方法：1) 构建冗余阶段监控器，使用有效增益增长率和冗余的联合标准来触发干预；2) 设计共信息门控机制，基于跨模态语义估计当前优势模态的贡献；3) 将优势模态梯度投影到联合多模态梯度子空间的正交补空间，并根据冗余进行梯度抑制。

Result: 实验表明，该方法在大多数场景下优于当前主流方法，消融实验验证了方法的有效性。

Conclusion: RedReg方法通过自适应冗余调节有效解决了多模态学习中的优化不平衡问题，在保持模态特定信息的同时抑制了冗余梯度积累，提升了多模态学习性能。

Abstract: Multimodal learning aims to improve performance by leveraging data from multiple sources. During joint multimodal training, due to modality bias, the advantaged modality often dominates backpropagation, leading to imbalanced optimization. Existing methods still face two problems: First, the long-term dominance of the dominant modality weakens representation-output coupling in the late stages of training, resulting in the accumulation of redundant information. Second, previous methods often directly and uniformly adjust the gradients of the advantaged modality, ignoring the semantics and directionality between modalities. To address these limitations, we propose Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement (RedReg), which is inspired by information bottleneck principle. Specifically, we construct a redundancy phase monitor that uses a joint criterion of effective gain growth rate and redundancy to trigger intervention only when redundancy is high. Furthermore, we design a co-information gating mechanism to estimate the contribution of the current dominant modality based on cross-modal semantics. When the task primarily relies on a single modality, the suppression term is automatically disabled to preserve modality-specific information. Finally, we project the gradient of the dominant modality onto the orthogonal complement of the joint multimodal gradient subspace and suppress the gradient according to redundancy. Experiments show that our method demonstrates superiority among current major methods in most scenarios. Ablation experiments verify the effectiveness of our method. The code is available at https://github.com/xia-zhe/RedReg.git

</details>


### [5] [VitalBench: A Rigorous Multi-Center Benchmark for Long-Term Vital Sign Prediction in Intraoperative Care](https://arxiv.org/abs/2511.13757)
*Xiuding Cai,Xueyao Wang,Sen Wang,Yaoyao Zhu,Jiao Chen,Yu Yao*

Main category: cs.LG

TL;DR: VitalBench是一个专门用于术中生命体征预测的新基准，包含来自两个独立医疗中心的4000多台手术数据，提供完整数据、不完整数据和跨中心泛化三个评估轨道，旨在解决医疗时间序列预测中缺乏标准化基准、数据不完整和跨中心验证有限的问题。


<details>
  <summary>Details</summary>
Motivation: 解决医疗时间序列预测中缺乏标准化基准、数据不完整和跨中心验证有限的问题，为术中生命体征监测和预测提供更可靠的评估框架。

Method: 引入VitalBench基准，包含来自两个独立医疗中心的4000多台手术数据，提供三个评估轨道，采用掩码损失技术进行稳健和无偏的模型评估，最小化对广泛预处理的依赖。

Result: 开发了一个标准化的统一平台，使研究人员能够专注于架构创新，同时确保数据处理的一致性，为推进术中生命体征预测模型奠定了基础。

Conclusion: VitalBench通过提供标准化基准，确保预测模型不仅准确，而且在不同临床环境中具有鲁棒性和适应性，为术中生命体征预测模型的进一步发展奠定了基础。

Abstract: Intraoperative monitoring and prediction of vital signs are critical for ensuring patient safety and improving surgical outcomes. Despite recent advances in deep learning models for medical time-series forecasting, several challenges persist, including the lack of standardized benchmarks, incomplete data, and limited cross-center validation. To address these challenges, we introduce VitalBench, a novel benchmark specifically designed for intraoperative vital sign prediction. VitalBench includes data from over 4,000 surgeries across two independent medical centers, offering three evaluation tracks: complete data, incomplete data, and cross-center generalization. This framework reflects the real-world complexities of clinical practice, minimizing reliance on extensive preprocessing and incorporating masked loss techniques for robust and unbiased model evaluation. By providing a standardized and unified platform for model development and comparison, VitalBench enables researchers to focus on architectural innovation while ensuring consistency in data handling. This work lays the foundation for advancing predictive models for intraoperative vital sign forecasting, ensuring that these models are not only accurate but also robust and adaptable across diverse clinical environments. Our code and data are available at https://github.com/XiudingCai/VitalBench.

</details>


### [6] [ChemFixer: Correcting Invalid Molecules to Unlock Previously Unseen Chemical Space](https://arxiv.org/abs/2511.13758)
*Jun-Hyoung Park,Ho-Jun Song,Seong-Whan Lee*

Main category: cs.LG

TL;DR: ChemFixer是一个基于Transformer的框架，用于将深度学习生成的无效分子修正为有效分子，提高分子有效性并扩展可用的化学空间。


<details>
  <summary>Details</summary>
Motivation: 深度学习分子生成模型经常产生化学无效分子，限制了学习到的化学空间的实际应用范围，需要解决这一关键问题。

Method: 基于Transformer架构，采用掩码技术进行预训练，并在构建的大规模有效/无效分子对数据集上进行微调。

Result: ChemFixer显著提高了分子有效性，同时保持了原始输出的化学和生物学分布特性，在药物-靶点相互作用预测任务中也表现良好。

Conclusion: ChemFixer作为基于深度学习的药物发现各阶段的实用工具，能够增强分子有效性并扩展可访问的化学空间。

Abstract: Deep learning-based molecular generation models have shown great potential in efficiently exploring vast chemical spaces by generating potential drug candidates with desired properties. However, these models often produce chemically invalid molecules, which limits the usable scope of the learned chemical space and poses significant challenges for practical applications. To address this issue, we propose ChemFixer, a framework designed to correct invalid molecules into valid ones. ChemFixer is built on a transformer architecture, pre-trained using masking techniques, and fine-tuned on a large-scale dataset of valid/invalid molecular pairs that we constructed. Through comprehensive evaluations across diverse generative models, ChemFixer improved molecular validity while effectively preserving the chemical and biological distributional properties of the original outputs. This indicates that ChemFixer can recover molecules that could not be previously generated, thereby expanding the diversity of potential drug candidates. Furthermore, ChemFixer was effectively applied to a drug-target interaction (DTI) prediction task using limited data, improving the validity of generated ligands and discovering promising ligand-protein pairs. These results suggest that ChemFixer is not only effective in data-limited scenarios, but also extensible to a wide range of downstream tasks. Taken together, ChemFixer shows promise as a practical tool for various stages of deep learning-based drug discovery, enhancing molecular validity and expanding accessible chemical space.

</details>


### [7] [Multi-Agent VLMs Guided Self-Training with PNU Loss for Low-Resource Offensive Content Detection](https://arxiv.org/abs/2511.13759)
*Han Wang,Deyi Ji,Junyu Lu,Lanyun Zhu,Hailong Zhang,Haiyang Wu,Liqun Liu,Peng Shu,Roy Ka-Wei Lee*

Main category: cs.LG

TL;DR: 提出了一种自训练框架，通过协作伪标记利用未标记数据来解决社交媒体冒犯内容检测中的低资源挑战。


<details>
  <summary>Details</summary>
Motivation: 社交媒体冒犯内容检测需要高质量标注数据，但由于冒犯实例稀少且人工标注成本高，这类数据往往稀缺。

Method: 使用轻量级分类器和多智能体视觉语言模型(MA-VLMs)进行协作伪标记，通过模拟监管者和用户双重视角增强标签可靠性，并采用PNU损失函数优化分类器。

Result: 在基准数据集上的实验表明，该框架在有限监督下显著优于基线方法，并接近大规模模型的性能。

Conclusion: 所提出的自训练框架能够有效利用未标记数据，在低资源环境下实现高质量的冒犯内容检测。

Abstract: Accurate detection of offensive content on social media demands high-quality labeled data; however, such data is often scarce due to the low prevalence of offensive instances and the high cost of manual annotation. To address this low-resource challenge, we propose a self-training framework that leverages abundant unlabeled data through collaborative pseudo-labeling. Starting with a lightweight classifier trained on limited labeled data, our method iteratively assigns pseudo-labels to unlabeled instances with the support of Multi-Agent Vision-Language Models (MA-VLMs). Un-labeled data on which the classifier and MA-VLMs agree are designated as the Agreed-Unknown set, while conflicting samples form the Disagreed-Unknown set. To enhance label reliability, MA-VLMs simulate dual perspectives, moderator and user, capturing both regulatory and subjective viewpoints. The classifier is optimized using a novel Positive-Negative-Unlabeled (PNU) loss, which jointly exploits labeled, Agreed-Unknown, and Disagreed-Unknown data while mitigating pseudo-label noise. Experiments on benchmark datasets demonstrate that our framework substantially outperforms baselines under limited supervision and approaches the performance of large-scale models

</details>


### [8] [MoETTA: Test-Time Adaptation Under Mixed Distribution Shifts with MoE-LayerNorm](https://arxiv.org/abs/2511.13760)
*Xiao Fan,Jingyan Jiang,Zhaoru Chen,Fanding Huang,Xiao Chen,Qinting Jiang,Bowen Zhang,Xing Tang,Zhi Wang*

Main category: cs.LG

TL;DR: MoETTA是一个基于熵的测试时自适应框架，通过集成混合专家架构来处理现实世界中的混合分布偏移问题，在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界部署中常遇到混合分布偏移，现有测试时自适应方法依赖统一的适应路径，无法处理不同域间可能冲突的最优梯度方向，且当前基准测试仅关注合成或同质偏移，无法捕捉真实世界异构混合分布偏移的复杂性。

Method: 提出MoETTA框架，集成混合专家架构，引入结构解耦的专家集合，使模型能够沿着不同的梯度方向进行适应，通过灵活和解耦的参数更新来更好地适应异构偏移。

Result: 在三个混合分布偏移设置上的广泛实验表明，MoETTA始终优于强基线方法，建立了最先进的性能，并突显了通过专家级多样性建模多个适应方向的好处。

Conclusion: MoETTA通过混合专家架构有效解决了现实世界混合分布偏移问题，引入的新基准更真实地模拟了部署条件，证明了多适应方向建模的重要性。

Abstract: Test-Time adaptation (TTA) has proven effective in mitigating performance drops under single-domain distribution shifts by updating model parameters during inference. However, real-world deployments often involve mixed distribution shifts, where test samples are affected by diverse and potentially conflicting domain factors, posing significant challenges even for SOTA TTA methods. A key limitation in existing approaches is their reliance on a unified adaptation path, which fails to account for the fact that optimal gradient directions can vary significantly across different domains. Moreover, current benchmarks focus only on synthetic or homogeneous shifts, failing to capture the complexity of real-world heterogeneous mixed distribution shifts. To address this, we propose MoETTA, a novel entropy-based TTA framework that integrates the Mixture-of-Experts (MoE) architecture. Rather than enforcing a single parameter update rule for all test samples, MoETTA introduces a set of structurally decoupled experts, enabling adaptation along diverse gradient directions. This design allows the model to better accommodate heterogeneous shifts through flexible and disentangled parameter updates. To simulate realistic deployment conditions, we introduce two new benchmarks: potpourri and potpourri+. While classical settings focus solely on synthetic corruptions, potpourri encompasses a broader range of domain shifts--including natural, artistic, and adversarial distortions--capturing more realistic deployment challenges. Additionally, potpourri+ further includes source-domain samples to evaluate robustness against catastrophic forgetting. Extensive experiments across three mixed distribution shifts settings show that MoETTA consistently outperforms strong baselines, establishing SOTA performance and highlighting the benefit of modeling multiple adaptation directions via expert-level diversity.

</details>


### [9] [Gene Incremental Learning for Single-Cell Transcriptomics](https://arxiv.org/abs/2511.13762)
*Jiaxin Qi,Yan Cui,Jianqiang Huang,Gaogang Xie*

Main category: cs.LG

TL;DR: 本文研究了基因标记的增量学习问题，在单细胞转录组学数据上建立了基因增量学习框架和评估体系，发现遗忘问题存在并提出了解决方案。


<details>
  <summary>Details</summary>
Motivation: 标记在计算机视觉等领域具有重要作用，但在增量学习方面的研究严重不足，特别是在语言标记的整体性特征给增量学习框架设计带来挑战。

Method: 转向生物数据中的基因标记，建立基因增量学习流程和评估体系，并调整现有的类增量学习方法来解决基因遗忘问题。

Result: 通过大量实验验证了框架设计和评估的合理性，以及方法调整的有效性。

Conclusion: 为单细胞转录组学中的基因增量学习提供了一个完整的基准测试平台。

Abstract: Classes, as fundamental elements of Computer Vision, have been extensively studied within incremental learning frameworks. In contrast, tokens, which play essential roles in many research fields, exhibit similar characteristics of growth, yet investigations into their incremental learning remain significantly scarce. This research gap primarily stems from the holistic nature of tokens in language, which imposes significant challenges on the design of incremental learning frameworks for them. To overcome this obstacle, in this work, we turn to a type of token, gene, for a large-scale biological dataset--single-cell transcriptomics--to formulate a pipeline for gene incremental learning and establish corresponding evaluations. We found that the forgetting problem also exists in gene incremental learning, thus we adapted existing class incremental learning methods to mitigate the forgetting of genes. Through extensive experiments, we demonstrated the soundness of our framework design and evaluations, as well as the effectiveness of our method adaptations. Finally, we provide a complete benchmark for gene incremental learning in single-cell transcriptomics.

</details>


### [10] [Library Liberation: Competitive Performance Matmul Through Compiler-composed Nanokernels](https://arxiv.org/abs/2511.13764)
*Arun Thangamani,Md Asghar Ahmad Shahid,Adam Siemieniuk,Rolf Morel,Renato Golin,Alexander Heinecke*

Main category: cs.LG

TL;DR: 该论文提出了一种自动生成高性能微内核的编译方案，通过MLIR方言桥接领域级操作和处理器能力，消除对底层库的依赖。


<details>
  <summary>Details</summary>
Motivation: AI和机器学习工作负载的快速发展扩大了高级领域操作与高效硬件利用之间的差距，当前实现接近峰值性能需要深度硬件专业知识，增加了复杂性并限制了可扩展性。

Method: 采用基于MLIR的编译方案，通过组合来自低级IR构造的纳米内核，实现接近最优的寄存器利用率，为每个目标生成高效的微内核。

Result: 实验表明生成的纳米内核具有生产质量，与最先进的微内核库具有竞争力。

Conclusion: 该编译方法能够自动生成可扩展的高性能微内核，为ML从业者提供了更简单高效的硬件利用方案。

Abstract: The rapidly evolving landscape of AI and machine learning workloads has widened the gap between high-level domain operations and efficient hardware utilization. Achieving near-peak performance still demands deep hardware expertise-experts either handcraft target-specific kernels (e.g., DeepSeek) or rely on specialized libraries (e.g., CUTLASS)-both of which add complexity and limit scalability for most ML practitioners.
  This paper introduces a compilation scheme that automatically generates scalable, high-performance microkernels by leveraging the MLIR dialects to bridge domain-level operations and processor capabilities. Our approach removes dependence on low-level libraries by enabling the compiler to auto-generate near-optimal code directly. At its core is a mechanism for composing nanokernels from low-level IR constructs with near-optimal register utilization, forming efficient microkernels tailored to each target. We implement this technique in an MLIR-based compiler supporting both vector and tile based CPU instructions. Experiments show that the generated nanokernels are of production-quality, and competitive with state-of-the-art microkernel libraries.

</details>


### [11] [PROF: An LLM-based Reward Code Preference Optimization Framework for Offline Imitation Learning](https://arxiv.org/abs/2511.13765)
*Shengjie Sun,Jiafei Lyu,Runze Liu,Mengbei Yan,Bo Liu,Deheng Ye,Xiu Li*

Main category: cs.LG

TL;DR: PROF是一个利用大语言模型从自然语言描述和单个专家轨迹生成可执行奖励函数代码的新框架，通过奖励偏好排序(RPR)自动评估和优化奖励函数，在离线模仿学习中超越现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的离线模仿学习方法通常假设轨迹与专家演示的相似性与奖励正相关，这过度简化了奖励结构。需要更准确的方法来从有限专家数据中估计奖励函数。

Method: 提出PROF框架：1) 使用LLM从自然语言描述和单个专家轨迹生成可执行奖励函数代码；2) 提出RPR策略，无需环境交互或RL训练即可评估奖励函数质量；3) 通过RPR和基于文本的梯度优化交替进行奖励函数的选择和优化。

Result: 在D4RL基准测试上的实证结果表明，PROF在多个数据集和领域上超越或匹配最近的强基线方法。

Conclusion: PROF框架通过自动化奖励函数生成和优化，有效提升了离线模仿学习的性能，证明了该方法在复杂奖励结构学习中的有效性。

Abstract: Offline imitation learning (offline IL) enables training effective policies without requiring explicit reward annotations. Recent approaches attempt to estimate rewards for unlabeled datasets using a small set of expert demonstrations. However, these methods often assume that the similarity between a trajectory and an expert demonstration is positively correlated with the reward, which oversimplifies the underlying reward structure. We propose PROF, a novel framework that leverages large language models (LLMs) to generate and improve executable reward function codes from natural language descriptions and a single expert trajectory. We propose Reward Preference Ranking (RPR), a novel reward function quality assessment and ranking strategy without requiring environment interactions or RL training. RPR calculates the dominance scores of the reward functions, where higher scores indicate better alignment with expert preferences. By alternating between RPR and text-based gradient optimization, PROF fully automates the selection and refinement of optimal reward functions for downstream policy learning. Empirical results on D4RL demonstrate that PROF surpasses or matches recent strong baselines across numerous datasets and domains, highlighting the effectiveness of our approach.

</details>


### [12] [Credal Ensemble Distillation for Uncertainty Quantification](https://arxiv.org/abs/2511.13766)
*Kaizheng Wang,Fabio Cuzzolin,David Moens,Hans Hallez*

Main category: cs.LG

TL;DR: 提出了一种名为credal ensemble distillation (CED)的新框架，将深度集成压缩为单一模型CREDIT，用于分类任务中的不确定性量化，显著降低推理开销。


<details>
  <summary>Details</summary>
Motivation: 深度集成在不确定性量化方面表现强大，但其高计算和内存成本限制了实际部署。需要一种方法在保持不确定性估计能力的同时显著降低推理开销。

Method: 提出credal ensemble distillation (CED)框架，将深度集成压缩为单一模型CREDIT。CREDIT预测类别概率区间而非单一softmax分布，这些区间定义了一个credal set（概率分布的凸集）用于不确定性量化。

Result: 在分布外检测基准测试中，CED在不确定性估计方面优于或与多个现有基线方法相当，同时相比深度集成显著降低了推理开销。

Conclusion: CED框架成功地将深度集成的优势压缩到单一模型中，在保持高质量不确定性估计的同时大幅减少了计算和内存需求，为不确定性量化的实际部署提供了可行方案。

Abstract: Deep ensembles (DE) have emerged as a powerful approach for quantifying predictive uncertainty and distinguishing its aleatoric and epistemic components, thereby enhancing model robustness and reliability. However, their high computational and memory costs during inference pose significant challenges for wide practical deployment. To overcome this issue, we propose credal ensemble distillation (CED), a novel framework that compresses a DE into a single model, CREDIT, for classification tasks. Instead of a single softmax probability distribution, CREDIT predicts class-wise probability intervals that define a credal set, a convex set of probability distributions, for uncertainty quantification. Empirical results on out-of-distribution detection benchmarks demonstrate that CED achieves superior or comparable uncertainty estimation compared to several existing baselines, while substantially reducing inference overhead compared to DE.

</details>


### [13] [Dynamic Temperature Scheduler for Knowledge Distillation](https://arxiv.org/abs/2511.13767)
*Sibgat Ul Islam,Jawad Ibn Ahad,Fuad Rahman,Mohammad Ruhul Amin,Nabeel Mohammed,Shafin Rahman*

Main category: cs.LG

TL;DR: 本文提出了动态温度调度器（DTS），通过基于师生模型交叉熵损失差距动态调整温度，改进了传统知识蒸馏中固定温度的方法，在视觉和NLP任务上均优于静态温度基线。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法使用固定温度参数，这在训练过程中是次优的。此外，师生模型架构差异导致logit幅度不匹配，学生模型在训练早期需要更软的概率分布，而在后期需要更尖锐的概率分布。

Method: 提出动态温度调度器（DTS），根据师生模型交叉熵损失差距动态调整温度参数。这是第一个基于师生分布差异自适应调整温度的调度方法，可无缝集成到现有KD框架中。

Result: 在多个知识蒸馏策略上验证了DTS的有效性，涵盖视觉任务（CIFAR-100、Tiny-ImageNet）和NLP任务（GLUE、Dolly、SelfIns、UnNI、S-NI），一致优于静态温度基线方法。

Conclusion: 动态温度调度器通过自适应调整温度参数，有效解决了传统固定温度方法的局限性，在知识蒸馏任务中取得了显著改进。

Abstract: Knowledge Distillation (KD) trains a smaller student model using a large, pre-trained teacher model, with temperature as a key hyperparameter controlling the softness of output probabilities. Traditional methods use a fixed temperature throughout training, which is suboptimal. Moreover, architectural differences between teacher and student often result in mismatched logit magnitudes. We demonstrate that students benefit from softer probabilities early in training but require sharper probabilities in later stages. We introduce Dynamic Temperature Scheduler (DTS), which adjusts temperature dynamically based on the cross-entropy loss gap between teacher and student. To our knowledge, this is the first temperature scheduling method that adapts based on the divergence between teacher and student distributions. Our method integrates seamlessly with existing KD frameworks. We validate DTS across multiple KD strategies on vision (CIFAR-100, Tiny-ImageNet) and NLP tasks (GLUE, Dolly, SelfIns, UnNI, S-NI), consistently outperforming static-temperature baselines. Code is available at https://github.com/Sibgat-Ul/DTS.

</details>


### [14] [Self-Attention as Distributional Projection: A Unified Interpretation of Transformer Architecture](https://arxiv.org/abs/2511.13780)
*Nihal Mehta*

Main category: cs.LG

TL;DR: 本文从分布语义学角度对自注意力机制进行数学解释，证明其源于将语料库级共现统计投影到序列上下文中，揭示了Transformer架构的代数形式是投影原理的自然结果而非任意设计选择。


<details>
  <summary>Details</summary>
Motivation: 为自注意力机制提供数学理论基础，证明Transformer架构的设计选择源于分布语义学原理，而非任意的工程决策。

Method: 从GloVe嵌入的共现矩阵出发，展示投影如何自然捕捉上下文影响，query-key-value机制作为建模方向关系的自然非对称扩展，位置编码和多头注意力作为同一投影原理的结构化改进。

Result: 证明了自注意力机制是从语料库级共现统计到序列上下文的投影结果，Transformer架构的特定代数形式遵循这些投影原理。

Conclusion: 自注意力和Transformer架构的设计可以从分布语义学的投影原理中自然推导出来，为其提供了坚实的数学基础。

Abstract: This paper presents a mathematical interpretation of self-attention by connecting it to distributional semantics principles. We show that self-attention emerges from projecting corpus-level co-occurrence statistics into sequence context. Starting from the co-occurrence matrix underlying GloVe embeddings, we demonstrate how the projection naturally captures contextual influence, with the query-key-value mechanism arising as the natural asymmetric extension for modeling directional relationships. Positional encodings and multi-head attention then follow as structured refinements of this same projection principle. Our analysis demonstrates that the Transformer architecture's particular algebraic form follows from these projection principles rather than being an arbitrary design choice.

</details>


### [15] [ScoresActivation: A New Activation Function for Model Agnostic Global Explainability by Design](https://arxiv.org/abs/2511.13809)
*Emanuel Covaci,Fabian Galis,Radu Balan,Daniela Zaharie,Darian Onchis*

Main category: cs.LG

TL;DR: 提出一种可微分的全局可解释性方法，通过将特征重要性估计直接集成到模型训练中，使用ScoresActivation函数实现特征排序，实现端到端训练的特征重要性评估。


<details>
  <summary>Details</summary>
Motivation: 当前的事后解释方法与模型训练过程脱节，限制了其忠实性和实用性，需要将可解释性直接融入模型训练过程。

Method: 使用ScoresActivation函数作为特征排序机制嵌入学习流程，使模型能够以可微分和端到端可训练的方式根据特征对预测性能的贡献进行优先级排序。

Result: 在基准数据集上的评估显示，该方法产生与SHAP值和真实特征重要性一致的全局忠实、稳定的特征排名，同时保持高预测性能。特征评分速度比SHAP快150倍，训练仅需2秒，而SHAP需要300秒。在包含相关和无关特征的设置中，分类准确率分别提高11.24%和29.33%。

Conclusion: 这项工作弥合了模型准确性和可解释性之间的差距，为固有的可解释机器学习提供了一个可扩展的框架。

Abstract: Understanding the decision of large deep learning models is a critical challenge for building transparent and trustworthy systems. Although the current post hoc explanation methods offer valuable insights into feature importance, they are inherently disconnected from the model training process, limiting their faithfulness and utility. In this work, we introduce a novel differentiable approach to global explainability by design, integrating feature importance estimation directly into model training. Central to our method is the ScoresActivation function, a feature-ranking mechanism embedded within the learning pipeline. This integration enables models to prioritize features according to their contribution to predictive performance in a differentiable and end-to-end trainable manner. Evaluations across benchmark datasets show that our approach yields globally faithful, stable feature rankings aligned with SHAP values and ground-truth feature importance, while maintaining high predictive performance. Moreover, feature scoring is 150 times faster than the classical SHAP method, requiring only 2 seconds during training compared to SHAP's 300 seconds for feature ranking in the same configuration. Our method also improves classification accuracy by 11.24% with 10 features (5 relevant) and 29.33% with 16 features (5 relevant, 11 irrelevant), demonstrating robustness to irrelevant inputs. This work bridges the gap between model accuracy and interpretability, offering a scalable framework for inherently explainable machine learning.

</details>


### [16] [Beat the long tail: Distribution-Aware Speculative Decoding for RL Training](https://arxiv.org/abs/2511.13841)
*Zelei Shao,Vikranth Srivatsa,Sanjana Srivastava,Qingyang Wu,Alpay Ariyak,Xiaoxia Wu,Ameen Patel,Jue Wang,Percy Liang,Tri Dao,Ce Zhang,Yiying Zhang,Ben Athiwaratkun,Chenfeng Xu,Junxiong Wang*

Main category: cs.LG

TL;DR: DAS是一个分布感知的推测解码框架，通过利用历史rollout数据和自适应草稿器来加速强化学习后训练中的rollout阶段，减少50%的生成时间而不改变模型输出。


<details>
  <summary>Details</summary>
Motivation: 强化学习后训练的效率受到rollout阶段的限制，特别是长尾分布中少数长生成序列占据了大部分时间成本，而历史rollout数据揭示了稳定的提示级别模式。

Method: DAS框架包含两个关键组件：基于最近rollout构建的自适应非参数草稿器（使用增量维护的后缀树），以及长度感知的推测策略，为支配总时长的长轨迹分配更激进的草稿预算。

Result: 在数学和代码推理任务上的实验表明，DAS将rollout时间减少了高达50%，同时保持了完全相同的训练曲线。

Conclusion: 分布感知的推测解码能够在不损害学习质量的前提下显著加速RL后训练过程。

Abstract: Reinforcement learning(RL) post-training has become essential for aligning large language models (LLMs), yet its efficiency is increasingly constrained by the rollout phase, where long trajectories are generated token by token. We identify a major bottleneck:the long-tail distribution of rollout lengths, where a small fraction of long generations dominates wall clock time and a complementary opportunity; the availability of historical rollouts that reveal stable prompt level patterns across training epochs. Motivated by these observations, we propose DAS, a Distribution Aware Speculative decoding framework that accelerates RL rollouts without altering model outputs. DAS integrates two key ideas: an adaptive, nonparametric drafter built from recent rollouts using an incrementally maintained suffix tree, and a length aware speculation policy that allocates more aggressive draft budgets to long trajectories that dominate makespan. This design exploits rollout history to sustain acceptance while balancing base and token level costs during decoding. Experiments on math and code reasoning tasks show that DAS reduces rollout time up to 50% while preserving identical training curves, demonstrating that distribution-aware speculative decoding can significantly accelerate RL post training without compromising learning quality.

</details>


### [17] [AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection](https://arxiv.org/abs/2511.13880)
*Saleh Momeni,Changnan Xiao,Bing Liu*

Main category: cs.LG

TL;DR: 本文提出AnaCP方法，解决基于预训练模型的类增量学习中的特征适应问题，在保持分析分类器效率的同时实现增量特征适应，无需梯度训练即可避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 传统类增量学习方法存在灾难性遗忘问题，而基于预训练模型的方法虽然高效但无法持续适应特征表示，导致性能次优。

Method: 提出AnaCP方法，通过分析对比投影在保持分析分类器效率的同时实现增量特征适应，无需基于梯度的训练。

Result: 实验表明AnaCP不仅优于现有基线方法，而且达到了联合训练的准确率水平，这是类增量学习的理论上界。

Conclusion: AnaCP方法成功解决了类增量学习中的特征适应问题，在避免灾难性遗忘的同时实现了接近理论上界的性能。

Abstract: This paper studies the problem of class-incremental learning (CIL), a core setting within continual learning where a model learns a sequence of tasks, each containing a distinct set of classes. Traditional CIL methods, which do not leverage pre-trained models (PTMs), suffer from catastrophic forgetting (CF) due to the need to incrementally learn both feature representations and the classifier. The integration of PTMs into CIL has recently led to efficient approaches that treat the PTM as a fixed feature extractor combined with analytic classifiers, achieving state-of-the-art performance. However, they still face a major limitation: the inability to continually adapt feature representations to best suit the CIL tasks, leading to suboptimal performance. To address this, we propose AnaCP (Analytic Contrastive Projection), a novel method that preserves the efficiency of analytic classifiers while enabling incremental feature adaptation without gradient-based training, thereby eliminating the CF caused by gradient updates. Our experiments show that AnaCP not only outperforms existing baselines but also achieves the accuracy level of joint training, which is regarded as the upper bound of CIL.

</details>


### [18] [The Impact of Bootstrap Sampling Rate on Random Forest Performance in Regression Tasks](https://arxiv.org/abs/2511.13952)
*Michał Iwaniuk,Mateusz Jarosz,Bartłomiej Borycki,Bartosz Jezierski,Jan Cwalina,Stanisław Kaźmierczak,Jacek Mańdziuk*

Main category: cs.LG

TL;DR: 本文系统研究了随机森林中自助采样率(BR)对回归性能的影响，发现调优BR可以显著提升模型性能，最佳BR值与数据集特征相关。


<details>
  <summary>Details</summary>
Motivation: 随机森林通常使用BR=1.0的默认设置，但缺乏对BR影响的系统性研究，本文旨在探索不同BR值对模型性能的影响规律。

Method: 在39个异质回归数据集和16种RF配置上，系统性地将BR从0.2变化到5.0，使用重复二折交叉验证和均方误差进行评估，并在合成数据集上验证发现。

Result: 调优BR可显著改善性能：24个数据集最佳BR≤1.0，15个数据集最佳BR>1.0，仅4个数据集BR=1.0最优。数据集特征与偏好BR相关：强全局特征-目标关系偏好高BR，高局部目标方差偏好低BR。

Conclusion: BR是一个有影响力的超参数，应根据数据集特征进行调优以优化随机森林回归模型，在低噪声场景中高BR减少偏差，高噪声场景中低BR减少方差。

Abstract: Random Forests (RFs) typically train each tree on a bootstrap sample of the same size as the training set, i.e., bootstrap rate (BR) equals 1.0. We systematically examine how varying BR from 0.2 to 5.0 affects RF performance across 39 heterogeneous regression datasets and 16 RF configurations, evaluating with repeated two-fold cross-validation and mean squared error. Our results demonstrate that tuning the BR can yield significant improvements over the default: the best setup relied on BR \leq 1.0 for 24 datasets, BR > 1.0 for 15, and BR = 1.0 was optimal in 4 cases only. We establish a link between dataset characteristics and the preferred BR: datasets with strong global feature-target relationships favor higher BRs, while those with higher local target variance benefit from lower BRs. To further investigate this relationship, we conducted experiments on synthetic datasets with controlled noise levels. These experiments reproduce the observed bias-variance trade-off: in low-noise scenarios, higher BRs effectively reduce model bias, whereas in high-noise settings, lower BRs help reduce model variance. Overall, BR is an influential hyperparameter that should be tuned to optimize RF regression models.

</details>


### [19] [Node-Level Uncertainty Estimation in LLM-Generated SQL](https://arxiv.org/abs/2511.13984)
*Hilaf Hasson,Ruocheng Guo*

Main category: cs.LG

TL;DR: 提出一个基于SQL抽象语法树(AST)节点级不确定性估计的LLM生成SQL错误检测框架，通过语义感知标签算法和模式感知特征训练分类器来预测节点错误概率。


<details>
  <summary>Details</summary>
Motivation: 传统基于token对数概率的聚合序列级置信度方法在检测LLM生成的SQL错误时效果有限，需要更细粒度和语义感知的错误检测方法。

Method: 两阶段方法：1) 语义感知标签算法为AST节点分配正确性标签；2) 使用模式感知和词汇特征训练监督分类器预测节点错误概率。

Result: 在多个数据库和数据集上，该方法显著优于token对数概率方法，平均AUC提升27.44%，在跨数据库评估中保持鲁棒性。

Conclusion: 节点中心、语义基础的不确定性估计是聚合序列级置信度测量的强大且可解释的替代方案，支持针对性修复、人机协同审查和下游选择性执行。

Abstract: We present a practical framework for detecting errors in LLM-generated SQL by estimating uncertainty at the level of individual nodes in the query's abstract syntax tree (AST). Our approach proceeds in two stages. First, we introduce a semantically aware labeling algorithm that, given a generated SQL and a gold reference, assigns node-level correctness without over-penalizing structural containers or alias variation. Second, we represent each node with a rich set of schema-aware and lexical features - capturing identifier validity, alias resolution, type compatibility, ambiguity in scope, and typo signals - and train a supervised classifier to predict per-node error probabilities. We interpret these probabilities as calibrated uncertainty, enabling fine-grained diagnostics that pinpoint exactly where a query is likely to be wrong. Across multiple databases and datasets, our method substantially outperforms token log-probabilities: average AUC improves by +27.44% while maintaining robustness under cross-database evaluation. Beyond serving as an accuracy signal, node-level uncertainty supports targeted repair, human-in-the-loop review, and downstream selective execution. Together, these results establish node-centric, semantically grounded uncertainty estimation as a strong and interpretable alternative to aggregate sequence level confidence measures.

</details>


### [20] [Certified but Fooled! Breaking Certified Defences with Ghost Certificates](https://arxiv.org/abs/2511.14003)
*Quoc Viet Vo,Tashreque M. Haq,Paul Montague,Tamas Abraham,Ehsan Abbasnejad,Damith C. Ranasinghe*

Main category: cs.LG

TL;DR: 本文研究了如何利用概率认证框架的漏洞，通过制作微小且难以察觉的扰动来欺骗认证防御系统，使其为对抗性输入生成虚假的鲁棒性保证。


<details>
  <summary>Details</summary>
Motivation: 研究认证防御系统的局限性，探索即使需要误导分类器并操纵认证过程生成对抗性输入的鲁棒性保证，所需的扰动是否仍可保持微小和难以察觉。

Method: 采用区域聚焦对抗样本的方法来制作难以察觉的扰动，欺骗认证系统并获得比源类幽灵认证更大的认证半径。

Result: 在ImageNet上的广泛评估表明，该方法能够有效绕过最先进的认证防御系统如Densepure。

Conclusion: 这项工作强调了需要更好地理解鲁棒性认证方法的局限性。

Abstract: Certified defenses promise provable robustness guarantees. We study the malicious exploitation of probabilistic certification frameworks to better understand the limits of guarantee provisions. Now, the objective is to not only mislead a classifier, but also manipulate the certification process to generate a robustness guarantee for an adversarial input certificate spoofing. A recent study in ICLR demonstrated that crafting large perturbations can shift inputs far into regions capable of generating a certificate for an incorrect class. Our study investigates if perturbations needed to cause a misclassification and yet coax a certified model into issuing a deceptive, large robustness radius for a target class can still be made small and imperceptible. We explore the idea of region-focused adversarial examples to craft imperceptible perturbations, spoof certificates and achieve certification radii larger than the source class ghost certificates. Extensive evaluations with the ImageNet demonstrate the ability to effectively bypass state-of-the-art certified defenses such as Densepure. Our work underscores the need to better understand the limits of robustness certification methods.

</details>


### [21] [Radial Compensation: Stable and Semantically Decoupled Generative Models on Riemannian Manifolds](https://arxiv.org/abs/2511.14056)
*Marios Papamichals,Regina Ruane*

Main category: cs.LG

TL;DR: 本文提出了径向补偿(RC)方法，用于解决流形上生成模型中曲率与模型参数纠缠的问题。RC通过选择切空间中的基础密度，使似然仅依赖于从极点出发的测地距离，从而将参数语义与曲率解耦。该方法扩展了具有已知测地极体积的流形，并推导了平衡指数(bExp)图族，平衡了体积失真和测地误差。


<details>
  <summary>Details</summary>
Motivation: 传统流形生成模型使用指数映射或体积保持图，但前者具有刚性、半径相关的雅可比矩阵，后者会扭曲测地距离。这两种方法都将曲率与模型参数纠缠在一起，增加了梯度方差。在高维潜在归一化流中，包裹指数先验可能将半径拉伸到远超过曲率尺度，导致测试似然性差和刚性求解器。

Method: 引入径向补偿(RC)方法，这是一种信息几何方法，选择切空间中的基础密度，使似然仅依赖于从极点出发的测地距离。推导了平衡指数(bExp)图族，平衡体积失真和测地误差。在RC下，所有bExp设置保持相同的流形密度和Fisher信息。

Result: RC在密度估计、VAE、图像和图上的流以及蛋白质模型中产生了稳定的生成模型。RC提高了似然性，恢复了干净的测地半径，并防止了高维流中的半径爆炸。RC-bExp成为流形上似然训练生成模型的稳健默认选择。

Conclusion: 径向补偿方法成功解决了流形生成模型中曲率与参数纠缠的问题，通过解耦参数语义与曲率，使径向参数在测地单位中保持其通常含义。RC-bExp在各种应用中表现出色，是流形上似然训练生成模型的稳健默认方法。

Abstract: Generative models on curved spaces rely on charts to map Euclidean spaces to manifolds. Exponential maps preserve geodesics but have stiff, radius-dependent Jacobians, while volume-preserving charts maintain densities but distort geodesic distances. Both approaches entangle curvature with model parameters, inflating gradient variance. In high-dimensional latent normalizing flows, the wrapped exponential prior can stretch radii far beyond the curvature scale, leading to poor test likelihoods and stiff solvers. We introduce Radial Compensation (RC), an information-geometric method that selects the base density in the tangent space so that the likelihood depends only on geodesic distance from a pole, decoupling parameter semantics from curvature. RC lets radial parameters retain their usual meaning in geodesic units, while the chart can be tuned as a numerical preconditioner. We extend RC to manifolds with known geodesic polar volume and show that RC is the only construction for geodesic-radial likelihoods with curvature-invariant Fisher information. We derive the Balanced-Exponential (bExp) chart family, balancing volume distortion and geodesic error. Under RC, all bExp settings preserve the same manifold density and Fisher information, with smaller dial values reducing gradient variance and flow cost. Empirically, RC yields stable generative models across densities, VAEs, flows on images and graphs, and protein models. RC improves likelihoods, restores clean geodesic radii, and prevents radius blow-ups in high-dimensional flows, making RC-bExp a robust default for likelihood-trained generative models on manifolds.

</details>


### [22] [A Machine Learning-Based Multimodal Framework for Wearable Sensor-Based Archery Action Recognition and Stress Estimation](https://arxiv.org/abs/2511.14057)
*Xianghe Liu,Jiajia Liu,Chuxian Xu,Minghan Wang,Hongbo Peng,Tao Sun,Jiaqi Xu*

Main category: cs.LG

TL;DR: 提出基于机器学习的多模态框架，集成可穿戴传感器数据同时进行动作识别和压力估计，在射箭运动中实现96.8%的动作识别准确率和80%的压力水平分类准确率。


<details>
  <summary>Details</summary>
Motivation: 传统运动分析系统昂贵且具有侵入性，限制了在自然训练环境中的应用。需要开发非侵入式、可负担的解决方案来同时监测运动员的技术动作和心理状态。

Method: 使用自研腕戴设备收集加速度和PPG数据，提出平滑差分加速度特征和LSTM模型进行动作识别，提取HRV特征并使用MLP分类器进行压力估计。

Result: 动作识别达到96.8%准确率和95.9% F1分数，压力估计达到80%准确率区分高低压力水平。

Conclusion: 集成运动和生理传感可为运动员的技术和心理状态提供有意义洞察，为开发实时反馈系统奠定基础。

Abstract: In precision sports such as archery, athletes' performance depends on both biomechanical stability and psychological resilience. Traditional motion analysis systems are often expensive and intrusive, limiting their use in natural training environments. To address this limitation, we propose a machine learning-based multimodal framework that integrates wearable sensor data for simultaneous action recognition and stress estimation. Using a self-developed wrist-worn device equipped with an accelerometer and photoplethysmography (PPG) sensor, we collected synchronized motion and physiological data during real archery sessions. For motion recognition, we introduce a novel feature--Smoothed Differential Acceleration (SmoothDiff)--and employ a Long Short-Term Memory (LSTM) model to identify motion phases, achieving 96.8% accuracy and 95.9% F1-score. For stress estimation, we extract heart rate variability (HRV) features from PPG signals and apply a Multi-Layer Perceptron (MLP) classifier, achieving 80% accuracy in distinguishing high- and low-stress levels. The proposed framework demonstrates that integrating motion and physiological sensing can provide meaningful insights into athletes' technical and mental states. This approach offers a foundation for developing intelligent, real-time feedback systems for training optimization in archery and other precision sports.

</details>


### [23] [CafeMed: Causal Attention Fusion Enhanced Medication Recommendation](https://arxiv.org/abs/2511.14064)
*Kelin Ren,Chan-Yang Ju,Dong-Ho Lee*

Main category: cs.LG

TL;DR: CafeMed是一个集成了动态因果推理和跨模态注意力的药物推荐框架，通过动态因果权重生成器和通道协调注意力细化模块，解决了现有方法中医疗实体独立处理和静态因果关系的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有药物推荐系统存在两个基本限制：(i)将医疗实体视为独立特征，未建模它们对药物选择的协同效应；(ii)使用静态因果关系，无法适应患者特定背景和健康状态。

Method: 提出CafeMed框架，包含两个关键组件：因果权重生成器(CWG)将静态因果效应转换为基于个体患者状态的动态调制权重；通道协调注意力细化模块(CHARM)捕获诊断和程序之间的复杂相互依赖关系。

Result: 在MIMIC-III和MIMIC-IV数据集上的广泛实验表明，CafeMed显著优于最先进的基线方法，在药物预测准确性方面表现优异，同时保持较低的药物-药物相互作用率。

Conclusion: 结合动态因果关系和跨模态协同效应能够产生更符合临床实践和个性化的药物推荐。

Abstract: Medication recommendation systems play a crucial role in assisting clinicians with personalized treatment decisions. While existing approaches have made significant progress in learning medication representations, they suffer from two fundamental limitations: (i) treating medical entities as independent features without modeling their synergistic effects on medication selection; (ii) employing static causal relationships that fail to adapt to patient-specific contexts and health states. To address these challenges, we propose CafeMed, a framework that integrates dynamic causal reasoning with cross-modal attention for safe and accurate medication recommendation. CafeMed introduces two key components: the Causal Weight Generator (CWG) that transforms static causal effects into dynamic modulation weights based on individual patient states, and the Channel Harmonized Attention Refinement Module (CHARM) that captures complex interdependencies between diagnoses and procedures. This design enables CafeMed to model how different medical conditions jointly influence treatment decisions while maintaining medication safety constraints. Extensive experiments on MIMIC-III and MIMIC-IV datasets demonstrate that CafeMed significantly outperforms state-of-the-art baselines, achieving superior accuracy in medication prediction while maintaining the lower drug--drug interaction rates. Our results indicate that incorporating dynamic causal relationships and cross-modal synergies leads to more clinically-aligned and personalized medication recommendations. Our code is released publicly at https://github.com/rkl71/CafeMed.

</details>


### [24] [CFG-EC: Error Correction Classifier-Free Guidance](https://arxiv.org/abs/2511.14075)
*Nakkyu Yang,Yechan Lee,SooJean Han*

Main category: cs.LG

TL;DR: 本文提出CFG-EC方法，通过修正无条件噪声预测来改进Classifier-Free Guidance（CFG）方法，解决训练和采样过程中噪声估计不一致的问题，提高生成图像的质量和提示对齐度。


<details>
  <summary>Details</summary>
Motivation: CFG方法在训练时交替使用条件提示和无条件提示，但在采样时同时输出两者，导致训练和采样过程中的噪声估计不一致，影响生成质量。

Method: 提出CFG-EC校正方案，通过重新对齐无条件噪声误差分量使其与条件误差分量正交，防止两个引导分量之间的干扰，约束采样误差的上界。

Result: 数值实验表明，CFG-EC比CFG和CFG++更有效地处理无条件分量，在低引导采样机制下性能显著提升，并在所有情况下都保持更高的提示对齐度。

Conclusion: CFG-EC是一种可增强任何基于CFG方法的通用校正方案，通过改进无条件噪声预测来建立更可靠的引导轨迹，实现高保真图像生成。

Abstract: Classifier-Free Guidance (CFG) has become a mainstream approach for simultaneously improving prompt fidelity and generation quality in conditional generative models. During training, CFG stochastically alternates between conditional and null prompts to enable both conditional and unconditional generation. However, during sampling, CFG outputs both null and conditional prompts simultaneously, leading to inconsistent noise estimates between the training and sampling processes. To reduce this error, we propose CFG-EC, a versatile correction scheme augmentable to any CFG-based method by refining the unconditional noise predictions. CFG-EC actively realigns the unconditional noise error component to be orthogonal to the conditional error component. This corrective maneuver prevents interference between the two guidance components, thereby constraining the sampling error's upper bound and establishing more reliable guidance trajectories for high-fidelity image generation. Our numerical experiments show that CFG-EC handles the unconditional component more effectively than CFG and CFG++, delivering a marked performance increase in the low guidance sampling regime and consistently higher prompt alignment across the board.

</details>


### [25] [Observational Auditing of Label Privacy](https://arxiv.org/abs/2511.14084)
*Iden Kalemaj,Luca Melis,Maxime Boucher,Ilya Mironov,Saeed Mahloujifar*

Main category: cs.LG

TL;DR: 提出了一种新颖的观察式差分隐私审计框架，无需修改原始训练数据集即可评估隐私保证，解决了现有方法在大规模系统中资源密集的问题。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私审计方法需要修改训练数据集（如注入异常样本或移除样本），在大规模系统中资源密集且工程开销大。

Method: 利用数据分布的固有随机性，开发观察式审计框架，无需修改原始数据集，将隐私审计扩展到保护属性和标签隐私。

Result: 在Criteo和CIFAR-10数据集上的实验证明了该方法在审计标签隐私保证方面的有效性。

Conclusion: 这项工作为大规模生产环境中的实用隐私审计开辟了新途径。

Abstract: Differential privacy (DP) auditing is essential for evaluating privacy guarantees in machine learning systems. Existing auditing methods, however, pose a significant challenge for large-scale systems since they require modifying the training dataset -- for instance, by injecting out-of-distribution canaries or removing samples from training. Such interventions on the training data pipeline are resource-intensive and involve considerable engineering overhead. We introduce a novel observational auditing framework that leverages the inherent randomness of data distributions, enabling privacy evaluation without altering the original dataset. Our approach extends privacy auditing beyond traditional membership inference to protected attributes, with labels as a special case, addressing a key gap in existing techniques. We provide theoretical foundations for our method and perform experiments on Criteo and CIFAR-10 datasets that demonstrate its effectiveness in auditing label privacy guarantees. This work opens new avenues for practical privacy auditing in large-scale production environments.

</details>


### [26] [MoE-SpeQ: Speculative Quantized Decoding with Proactive Expert Prefetching and Offloading for Mixture-of-Experts](https://arxiv.org/abs/2511.14102)
*Wenfeng Wang,Jiacheng Liu,Xiaofeng Hou,Xinfeng Xia,Peng Tang,Mingxuan Zhang,Chao Li,Minyi Guo*

Main category: cs.LG

TL;DR: MoE-SpeQ是一个新的推理系统，通过推测执行和专家卸载的协同设计来解决Mixture-of-Experts模型推理时的I/O瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 解决最先进MoE模型推理时由于内存需求过大而导致的I/O瓶颈问题，这些模型通常超过单个加速器的容量，专家卸载到主机内存会引入严重的PCIe总线I/O瓶颈。

Method: 使用小型设备端草稿模型预测未来token所需的专家序列，运行时编排器预取这些专家，将昂贵的I/O与有用计算重叠，通过自适应调节器动态调整推测策略。

Result: 在内存受限设备上，对Phi-MoE模型实现了最多2.34倍的速度提升，相比最先进的卸载框架。

Conclusion: 为资源受限环境中管理数据依赖内存访问建立了一种新的原则性方法，使MoE推理在商用硬件上更加可行。

Abstract: The immense memory requirements of state-of-the-art Mixture-of-Experts (MoE) models present a significant challenge for inference, often exceeding the capacity of a single accelerator. While offloading experts to host memory is a common solution, it introduces a severe I/O bottleneck over the PCIe bus, as the data-dependent nature of expert selection places these synchronous transfers directly on the critical path of execution, crippling performance.
  This paper argues that the I/O bottleneck can be overcome by trading a small amount of cheap, on-device computation to hide the immense cost of data movement. We present MoE-SpeQ, a new inference system built on a novel co-design of speculative execution and expert offloading. MoE-SpeQ employs a small, on-device draft model to predict the sequence of required experts for future tokens. This foresight enables a runtime orchestrator to prefetch these experts from host memory, effectively overlapping the expensive I/O with useful computation and hiding the latency from the critical path. To maximize performance, an adaptive governor, guided by an Amortization Roofline Model, dynamically tunes the speculation strategy to the underlying hardware. Our evaluation on memory-constrained devices shows that for the Phi-MoE model, MoE-SpeQ achieves at most 2.34x speedup over the state-of-the-art offloading framework. Our work establishes a new, principled approach for managing data-dependent memory access in resource-limited environments, making MoE inference more accessible on commodity hardware.

</details>


### [27] [Soft-Label Training Preserves Epistemic Uncertainty](https://arxiv.org/abs/2511.14117)
*Agamdeep Singh,Ashish Tiwari,Hosein Hasanbeig,Priyanshu Gupta*

Main category: cs.LG

TL;DR: 论文主张在主观性机器学习任务中，标注分布本身应被视为真实标签，而非将其压缩为单一标签。通过软标签训练，模型能更好地保留认知不确定性，在保持准确性的同时更贴近人类标注的多样性。


<details>
  <summary>Details</summary>
Motivation: 标准实践将多样的人类标注压缩为单一标签，这在模糊数据上存在认知偏差。模型被迫在本质上模糊的情况下表达虚假置信度，导致模型确定性与人类感知多样性之间的错位。

Method: 采用软标签训练方法，将标注分布视为真实标签进行训练，而不是将其压缩为单一硬标签。

Result: 在视觉和NLP任务中，软标签训练相比硬标签训练实现了32%更低的KL散度（与人类标注的差异）和61%更强的模型与标注熵相关性，同时保持相同的准确性。

Conclusion: 应将标注分布重新定位为模型应该学习复制的认知不确定性的忠实表示，而不是需要聚合消除的噪声信号。

Abstract: Many machine learning tasks involve inherent subjectivity, where annotators naturally provide varied labels. Standard practice collapses these label distributions into single labels, aggregating diverse human judgments into point estimates. We argue that this approach is epistemically misaligned for ambiguous data--the annotation distribution itself should be regarded as the ground truth. Training on collapsed single labels forces models to express false confidence on fundamentally ambiguous cases, creating a misalignment between model certainty and the diversity of human perception. We demonstrate empirically that soft-label training, which treats annotation distributions as ground truth, preserves epistemic uncertainty. Across both vision and NLP tasks, soft-label training achieves 32% lower KL divergence from human annotations and 61% stronger correlation between model and annotation entropy, while matching the accuracy of hard-label training. Our work repositions annotation distributions from noisy signals to be aggregated away, to faithful representations of epistemic uncertainty that models should learn to reproduce.

</details>


### [28] [Synthetic Survival Control: Extending Synthetic Controls for "When-If" Decision](https://arxiv.org/abs/2511.14133)
*Jessy Xinyi Han,Devavrat Shah*

Main category: cs.LG

TL;DR: 本文提出了合成生存控制（SSC）方法，用于在面板数据设置中估计反事实风险轨迹，解决观察性数据中时间到事件结果的因果效应估计问题。


<details>
  <summary>Details</summary>
Motivation: 在观察性数据中估计时间到事件结果的因果效应面临审查、样本量有限和非随机治疗分配的挑战，而现实世界中经常需要回答"何时-如果"问题，即在特定干预下事件时间如何变化。

Method: 提出SSC方法，将感兴趣单元的反事实风险轨迹估计为其他单元观察轨迹的加权组合，并引入具有低秩结构的面板框架来提供形式化证明。

Result: 在癌症治疗结果的多国临床数据集上验证了方法，发现新型治疗与改善生存相关，表现为干预后风险轨迹相对于合成对应物更低。

Conclusion: 该框架为使用观察性数据进行反事实生存推断提供了一个通用且可解释的工具，在医学、经济学和公共政策等领域具有广泛应用价值。

Abstract: Estimating causal effects on time-to-event outcomes from observational data is particularly challenging due to censoring, limited sample sizes, and non-random treatment assignment. The need for answering such "when-if" questions--how the timing of an event would change under a specified intervention--commonly arises in real-world settings with heterogeneous treatment adoption and confounding. To address these challenges, we propose Synthetic Survival Control (SSC) to estimate counterfactual hazard trajectories in a panel data setting where multiple units experience potentially different treatments over multiple periods. In such a setting, SSC estimates the counterfactual hazard trajectory for a unit of interest as a weighted combination of the observed trajectories from other units. To provide formal justification, we introduce a panel framework with a low-rank structure for causal survival analysis. Indeed, such a structure naturally arises under classical parametric survival models. Within this framework, for the causal estimand of interest, we establish identification and finite sample guarantees for SSC. We validate our approach using a multi-country clinical dataset of cancer treatment outcomes, where the staggered introduction of new therapies creates a quasi-experimental setting. Empirically, we find that access to novel treatments is associated with improved survival, as reflected by lower post-intervention hazard trajectories relative to their synthetic counterparts. Given the broad relevance of survival analysis across medicine, economics, and public policy, our framework offers a general and interpretable tool for counterfactual survival inference using observational data.

</details>


### [29] [Fair-GNE : Generalized Nash Equilibrium-Seeking Fairness in Multiagent Healthcare Automation](https://arxiv.org/abs/2511.14135)
*Promise Ekpo,Saesha Agarwal,Felix Grimm,Lekan Molu,Angelique Taylor*

Main category: cs.LG

TL;DR: 本文提出Fair-GNE方法，在医疗工作者多智能体系统中通过广义纳什均衡框架实现公平的工作负载分配，相比传统方法显著提升了公平性指标。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体强化学习方法通过事后协调来塑造奖励，无法在运行时提供可证明的自我强制执行公平性，这在医疗资源分配等关键场景中尤为重要。

Method: 将多智能体强化学习建模为约束广义纳什均衡寻求游戏，通过自适应约束执行确保群体策略达到安全且局部有效的均衡状态。

Result: 在定制的高保真复苏模拟器中，Fair-GNE相比固定惩罚基线显著改善了工作负载平衡（0.89 vs 0.33 JFI），同时保持86%的任务成功率。

Conclusion: Fair-GNE通过均衡寻求创新在大型多智能体医疗系统中实现了原则性的公平执行，为资源受限环境下的公平分配提供了有效解决方案。

Abstract: Enforcing a fair workload allocation among multiple agents tasked to achieve an objective in learning enabled demand side healthcare worker settings is crucial for consistent and reliable performance at runtime. Existing multi-agent reinforcement learning (MARL) approaches steer fairness by shaping reward through post hoc orchestrations, leaving no certifiable self-enforceable fairness that is immutable by individual agents at runtime. Contextualized within a setting where each agent shares resources with others, we address this shortcoming with a learning enabled optimization scheme among self-interested decision makers whose individual actions affect those of other agents. This extends the problem to a generalized Nash equilibrium (GNE) game-theoretic framework where we steer group policy to a safe and locally efficient equilibrium, so that no agent can improve its utility function by unilaterally changing its decisions. Fair-GNE models MARL as a constrained generalized Nash equilibrium-seeking (GNE) game, prescribing an ideal equitable collective equilibrium within the problem's natural fabric. Our hypothesis is rigorously evaluated in our custom-designed high-fidelity resuscitation simulator. Across all our numerical experiments, Fair-GNE achieves significant improvement in workload balance over fixed-penalty baselines (0.89 vs.\ 0.33 JFI, $p < 0.01$) while maintaining 86\% task success, demonstrating statistically significant fairness gains through adaptive constraint enforcement. Our results communicate our formulations, evaluation metrics, and equilibrium-seeking innovations in large multi-agent learning-based healthcare systems with clarity and principled fairness enforcement.

</details>


### [30] [A Comprehensive Study of Implicit and Explicit Biases in Large Language Models](https://arxiv.org/abs/2511.14153)
*Fatima Kazi,Alex Young,Yash Inani,Setareh Rafatirad*

Main category: cs.LG

TL;DR: 本研究提出自动化偏见识别框架来检测LLMs中的各种社会偏见，采用双重方法识别显性和隐性偏见，并通过微调和数据增强策略提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型从训练数据中继承显性和隐性偏见，可能传播有害刻板印象和错误信息，需要识别和缓解这些偏见以确保公平输出。

Method: 使用StereoSet和CrowSPairs等偏见基准评估BERT和GPT 3.5等生成模型，提出自动化偏见识别框架，采用双重方法检测显性和隐性偏见，应用词袋分析揭示隐性刻板印象，并通过微调、提示技术和数据增强来增强模型性能。

Result: 微调模型在处理性别偏见方面存在困难，但在识别和避免种族偏见方面表现优异。LLMs往往过度依赖关键词。通过增强策略，微调模型在跨数据集测试中表现出良好的适应性，在隐性偏见基准上的性能提升高达20%。

Conclusion: 尽管取得了一定成功，但LLMs在偏见检测方面仍有局限性，需要持续改进偏见缓解策略以确保AI系统的公平性。

Abstract: Large Language Models (LLMs) inherit explicit and implicit biases from their training datasets. Identifying and mitigating biases in LLMs is crucial to ensure fair outputs, as they can perpetuate harmful stereotypes and misinformation. This study highlights the need to address biases in LLMs amid growing generative AI. We studied bias-specific benchmarks such as StereoSet and CrowSPairs to evaluate the existence of various biases in multiple generative models such as BERT and GPT 3.5. We proposed an automated Bias-Identification Framework to recognize various social biases in LLMs such as gender, race, profession, and religion. We adopted a two-pronged approach to detect explicit and implicit biases in text data. Results indicated fine-tuned models struggle with gender biases but excelled at identifying and avoiding racial biases. Our findings illustrated that despite having some success, LLMs often over-relied on keywords. To illuminate the capability of the analyzed LLMs in detecting implicit biases, we employed Bag-of-Words analysis and unveiled indications of implicit stereotyping within the vocabulary. To bolster the model performance, we applied an enhancement strategy involving fine-tuning models using prompting techniques and data augmentation of the bias benchmarks. The fine-tuned models exhibited promising adaptability during cross-dataset testing and significantly enhanced performance on implicit bias benchmarks, with performance gains of up to 20%.

</details>


### [31] [Bridging the Gap Between Bayesian Deep Learning and Ensemble Weather Forecasts](https://arxiv.org/abs/2511.14218)
*Xinlei Xiong,Wenbo Hu,Shuxun Zhou,Kaifeng Bi,Lingxi Xie,Ying Liu,Richang Hong,Qi Tian*

Main category: cs.LG

TL;DR: 提出了一种统一的混合贝叶斯深度学习框架，用于集合天气预报，将预测不确定性分解为认知不确定性和偶然不确定性，通过变分推理和物理信息随机扰动方案分别学习。


<details>
  <summary>Details</summary>
Motivation: 天气预报面临大气混沌性质的挑战，需要概率方法来量化不确定性。传统集合预测方法计算密集，而贝叶斯深度学习提供了有前景但往往脱节的替代方案，需要桥接这两种范式。

Method: 通过混合贝叶斯深度学习框架，使用变分推理学习认知不确定性，通过物理信息随机扰动方案建模流依赖的大气动力学来学习偶然不确定性。建立了统一的理论框架，严格连接BDL和EPS。

Result: 在ERA5再分析数据集上的实验结果表明，该方法不仅提高了预报准确性，产生了更好校准的不确定性量化，而且相比最先进的概率扩散模型实现了更优的计算效率。

Conclusion: 提出的混合贝叶斯深度学习框架成功桥接了贝叶斯深度学习和传统集合预测方法，为天气预报提供了更准确、更高效的不确定性量化解决方案。

Abstract: Weather forecasting is fundamentally challenged by the chaotic nature of the atmosphere, necessitating probabilistic approaches to quantify uncertainty. While traditional ensemble prediction (EPS) addresses this through computationally intensive simulations, recent advances in Bayesian Deep Learning (BDL) offer a promising but often disconnected alternative. We bridge these paradigms through a unified hybrid Bayesian Deep Learning framework for ensemble weather forecasting that explicitly decomposes predictive uncertainty into epistemic and aleatoric components, learned via variational inference and a physics-informed stochastic perturbation scheme modeling flow-dependent atmospheric dynamics, respectively. We further establish a unified theoretical framework that rigorously connects BDL and EPS, providing formal theorems that decompose total predictive uncertainty into epistemic and aleatoric components under the hybrid BDL framework. We validate our framework on the large-scale 40-year ERA5 reanalysis dataset (1979-2019) with 0.25° spatial resolution. Experimental results show that our method not only improves forecast accuracy and yields better-calibrated uncertainty quantification but also achieves superior computational efficiency compared to state-of-the-art probabilistic diffusion models. We commit to making our code open-source upon acceptance of this paper.

</details>


### [32] [EBind: a practical approach to space binding](https://arxiv.org/abs/2511.14229)
*Jim Broadbent,Felix Cohen,Frederik Hvilshøj,Eric Landau,Eren Sasoglu*

Main category: cs.LG

TL;DR: EBind是一种简单、以数据为中心且参数高效的方法，用于绑定多个对比模型的嵌入空间。通过精心策划的数据集和单模态编码器，在单个GPU上几小时内训练出最先进模型，性能超越参数大4-17倍的模型。


<details>
  <summary>Details</summary>
Motivation: 简化空间绑定过程，专注于核心组件（单模态编码器和高质量数据），实现在单个GPU上快速训练高性能多模态模型，解决传统方法训练时间长、资源消耗大的问题。

Method: 使用三个互补数据源：670万全自动多模态五元组、100万半自动人工标注三元组、340万现有标注数据。采用参数高效的EBind方法绑定图像-文本-视频-音频-3D对比模型的嵌入空间。

Result: 仅1.8B参数的模型在13个不同评估中表现优异，超越参数大4-17倍的模型。同时创建了首个高质量、共识标注的音频与点云零样本分类基准。

Conclusion: EBind方法证明了通过精心策划的数据集和参数高效的设计，可以在有限计算资源下实现多模态模型的卓越性能，并将开源代码、模型权重和数据集。

Abstract: We simplify space binding by focusing on two core components, a single encoder per modality and high-quality data; enabling training state-of-the-art models on a single GPU in a few hours as opposed to multiple days. We present EBind, an Easy, data-centric, and parameter-efficient method to Bind the embedding spaces of multiple contrastive models. We demonstrate that a simple 1.8B-parameter image-text-video-audio-3D model can outperform models 4 to 17x the size. The key to achieving this is a carefully curated dataset of three complementary data sources: i) 6.7M fully-automated multimodal quintuples sourced via SOTA retrieval models, ii) 1M diverse, semi-automated triples annotated by humans as negative, partial, or positive matches, and iii) 3.4M pre-existing captioned data items. We use 13 different evaluations to demonstrate the value of each data source. Due to limitations with existing benchmarks, we further introduce the first high-quality, consensus-annotated zero-shot classification benchmark between audio and PCs. In contrast to related work, we will open-source our code, model weights, and datasets.

</details>


### [33] [Unified Multimodal Vessel Trajectory Prediction with Explainable Navigation Intention](https://arxiv.org/abs/2511.14265)
*Rui Zhang,Chao Li,Kezhong Liu,Chen Wang,Bolong Zheng,Hongbo Jiang*

Main category: cs.LG

TL;DR: 提出一种结合可解释导航意图的统一多模态轨迹预测框架，将意图分为持续性和瞬时性两类，通过CVAE建模动态意图，在真实AIS数据集上验证了方法的广泛适用性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有船舶多模态轨迹预测方法存在场景适用性有限和可解释性不足的问题，需要解决复杂海事环境中快速行为变化的短期预测挑战。

Method: 构建持续性意图树从历史轨迹中提取，使用条件变分自编码器建模动态瞬时意图，采用非局部注意力机制保持全局场景一致性。

Result: 在真实AIS数据集上的实验表明，该方法在多种场景下具有广泛适用性，在ADE和FDE指标上取得显著提升。

Conclusion: 所提出的框架不仅提高了预测性能，还通过显式揭示每条预测轨迹背后的导航意图来增强可解释性。

Abstract: Vessel trajectory prediction is fundamental to intelligent maritime systems. Within this domain, short-term prediction of rapid behavioral changes in complex maritime environments has established multimodal trajectory prediction (MTP) as a promising research area. However, existing vessel MTP methods suffer from limited scenario applicability and insufficient explainability. To address these challenges, we propose a unified MTP framework incorporating explainable navigation intentions, which we classify into sustained and transient categories. Our method constructs sustained intention trees from historical trajectories and models dynamic transient intentions using a Conditional Variational Autoencoder (CVAE), while using a non-local attention mechanism to maintain global scenario consistency. Experiments on real Automatic Identification System (AIS) datasets demonstrates our method's broad applicability across diverse scenarios, achieving significant improvements in both ADE and FDE. Furthermore, our method improves explainability by explicitly revealing the navigational intentions underlying each predicted trajectory.

</details>


### [34] [H-LDM: Hierarchical Latent Diffusion Models for Controllable and Interpretable PCG Synthesis from Clinical Metadata](https://arxiv.org/abs/2511.14312)
*Chenyang Xu,Siming Li,Hao Wang*

Main category: cs.LG

TL;DR: H-LDM是一个分层潜在扩散模型，用于从结构化元数据生成临床准确且可控的心音图信号，解决了病理数据稀缺问题，在PhysioNet CirCor数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 心音图分析对心血管疾病诊断至关重要，但标记病理数据的稀缺限制了AI系统的能力，需要解决数据稀缺问题。

Method: 采用多尺度变分自编码器学习生理解缠的潜在空间，分离节律、心音和杂音；构建分层文本到生物信号管道，利用丰富的临床元数据对17种不同条件进行细粒度控制；使用由新型医学注意力模块引导的可解释扩散过程。

Result: 在PhysioNet CirCor数据集上实现了9.7的Fréchet音频距离、92%的属性解缠分数和87.1%的临床有效性；使用合成数据增强诊断模型将罕见疾病分类准确率提高了11.3%。

Conclusion: H-LDM为心脏诊断中的数据增强开辟了新方向，通过可解释的临床洞察弥合了数据稀缺问题。

Abstract: Phonocardiogram (PCG) analysis is vital for cardiovascular disease diagnosis, yet the scarcity of labeled pathological data hinders the capability of AI systems. To bridge this, we introduce H-LDM, a Hierarchical Latent Diffusion Model for generating clinically accurate and controllable PCG signals from structured metadata. Our approach features: (1) a multi-scale VAE that learns a physiologically-disentangled latent space, separating rhythm, heart sounds, and murmurs; (2) a hierarchical text-to-biosignal pipeline that leverages rich clinical metadata for fine-grained control over 17 distinct conditions; and (3) an interpretable diffusion process guided by a novel Medical Attention module. Experiments on the PhysioNet CirCor dataset demonstrate state-of-the-art performance, achieving a Fréchet Audio Distance of 9.7, a 92% attribute disentanglement score, and 87.1% clinical validity confirmed by cardiologists. Augmenting diagnostic models with our synthetic data improves the accuracy of rare disease classification by 11.3\%. H-LDM establishes a new direction for data augmentation in cardiac diagnostics, bridging data scarcity with interpretable clinical insights.

</details>


### [35] [Intervention Efficiency and Perturbation Validation Framework: Capacity-Aware and Robust Clinical Model Selection under the Rashomon Effect](https://arxiv.org/abs/2511.14317)
*Yuwen Zhang,Viet Tran,Paul Weng*

Main category: cs.LG

TL;DR: 本文提出两种工具（干预效率和扰动验证框架）来解决临床机器学习中的Rashomon效应问题，通过考虑资源约束和模型稳定性来选择更可靠的模型。


<details>
  <summary>Details</summary>
Motivation: 临床机器学习中存在多个性能相当的模型（Rashomon效应），加上小样本、不平衡、噪声数据等问题，使传统验证方法不可靠，需要新的评估工具来确保模型部署的可信度。

Method: 提出干预效率（IE）指标量化模型在有限干预下的效率，以及扰动验证框架（PVF）评估模型在数据扰动下的稳定性。

Result: 在合成和真实医疗数据集上的实验表明，使用这些工具能够选择出泛化更稳健且符合容量约束的模型。

Conclusion: IE和PVF为解决临床环境中的Rashomon效应提供了新方向，能够选择出既稳健又符合临床实用性的模型。

Abstract: In clinical machine learning, the coexistence of multiple models with comparable performance -- a manifestation of the Rashomon Effect -- poses fundamental challenges for trustworthy deployment and evaluation. Small, imbalanced, and noisy datasets, coupled with high-dimensional and weakly identified clinical features, amplify this multiplicity and make conventional validation schemes unreliable. As a result, selecting among equally performing models becomes uncertain, particularly when resource constraints and operational priorities are not considered by conventional metrics like F1 score. To address these issues, we propose two complementary tools for robust model assessment and selection: Intervention Efficiency (IE) and the Perturbation Validation Framework (PVF). IE is a capacity-aware metric that quantifies how efficiently a model identifies actionable true positives when only limited interventions are feasible, thereby linking predictive performance with clinical utility. PVF introduces a structured approach to assess the stability of models under data perturbations, identifying models whose performance remains most invariant across noisy or shifted validation sets. Empirical results on synthetic and real-world healthcare datasets show that using these tools facilitates the selection of models that generalize more robustly and align with capacity constraints, offering a new direction for tackling the Rashomon Effect in clinical settings.

</details>


### [36] [Learning with Statistical Equality Constraints](https://arxiv.org/abs/2511.14320)
*Aneesh Barthakur,Luiz F. O. Chamon*

Main category: cs.LG

TL;DR: 该论文提出了针对包含等式约束的统计学习问题的泛化理论，并开发了一种实用的算法来处理机器学习中的复杂需求，如公平性和边界值问题。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习应用变得越来越普遍和复杂，除了准确性之外，它们面临着越来越多的需求。现有的加权惩罚方法需要仔细调整超参数，这在需求数量较多时变得无效，特别是当需求涉及等式约束时。

Method: 提出了一种基于求解一系列无约束经验学习问题的实用算法，并推导了等式约束统计学习问题的泛化理论。

Result: 展示了该算法在公平学习、插值分类器和边界值问题中的有效性，以及等式约束启用的新公式。

Conclusion: 该工作为包含等式约束的统计学习问题提供了泛化理论保证，并提出了一种有效的实用算法，能够处理机器学习中的复杂需求。

Abstract: As machine learning applications grow increasingly ubiquitous and complex, they face an increasing set of requirements beyond accuracy. The prevalent approach to handle this challenge is to aggregate a weighted combination of requirement violation penalties into the training objective. To be effective, this approach requires careful tuning of these hyperparameters (weights), involving trial-and-error and cross-validation, which becomes ineffective even for a moderate number of requirements. These issues are exacerbated when the requirements involve parities or equalities, as is the case in fairness and boundary value problems. An alternative technique uses constrained optimization to formulate these learning problems. Yet, existing approximation and generalization guarantees do not apply to problems involving equality constraints. In this work, we derive a generalization theory for equality-constrained statistical learning problems, showing that their solutions can be approximated using samples and rich parametrizations. Using these results, we propose a practical algorithm based on solving a sequence of unconstrained, empirical learning problems. We showcase its effectiveness and the new formulations enabled by equality constraints in fair learning, interpolating classifiers, and boundary value problems.

</details>


### [37] [Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation](https://arxiv.org/abs/2511.14406)
*Bastien Vuillod,Pierre-Alain Moellic,Jean-Max Dutertre*

Main category: cs.LG

TL;DR: 本文分析了联邦学习中LoRA参数高效微调技术对后门攻击的影响，发现低秩LoRA会使最优注入的后门在攻击后持续更长时间，并指出了FL中后门攻击评估的问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的大模型适配面临安全威胁，特别是后门攻击在本地训练步骤中注入恶意行为。需要分析LoRA技术如何影响后门攻击的效果和持久性。

Method: 通过实验分析LoRA在不同秩设置下对最先进后门攻击的影响，重点关注后门寿命这一关键特性，研究攻击场景和攻击者能力对后门注入效果的影响。

Result: 关键发现：对于最优注入的后门，当LoRA的秩较低时，攻击后的后门持久性更长。同时揭示了联邦学习中后门攻击评估存在的问题。

Conclusion: 本研究有助于开发更鲁棒和公平的后门攻击评估方法，提高关键联邦学习系统风险评估的可靠性。

Abstract: Large models adaptation through Federated Learning (FL) addresses a wide range of use cases and is enabled by Parameter-Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA). However, this distributed learning paradigm faces several security threats, particularly to its integrity, such as backdoor attacks that aim to inject malicious behavior during the local training steps of certain clients. We present the first analysis of the influence of LoRA on state-of-the-art backdoor attacks targeting model adaptation in FL. Specifically, we focus on backdoor lifespan, a critical characteristic in FL, that can vary depending on the attack scenario and the attacker's ability to effectively inject the backdoor. A key finding in our experiments is that for an optimally injected backdoor, the backdoor persistence after the attack is longer when the LoRA's rank is lower. Importantly, our work highlights evaluation issues of backdoor attacks against FL and contributes to the development of more robust and fair evaluations of backdoor attacks, enhancing the reliability of risk assessments for critical FL systems. Our code is publicly available.

</details>


### [38] [Toward Robust and Harmonious Adaptation for Cross-modal Retrieval](https://arxiv.org/abs/2511.14416)
*Haobin Li,Mouxing Yang,Xi Peng*

Main category: cs.LG

TL;DR: 本文提出REST方法解决跨模态检索中的查询偏移问题，包括在线偏移和多样偏移两个挑战，通过查询预测精化和梯度解耦模块实现鲁棒适应。


<details>
  <summary>Details</summary>
Motivation: 现有通用到定制化跨模态检索方法假设整个目标域数据可用，但现实场景中查询以在线方式到达且具有多样性，导致查询偏移问题，破坏通用空间结构并使模型遗忘必要知识。

Method: REST方法包含两个核心组件：1）通过精化检索结果构建查询预测，设计QS鲁棒目标函数在线保护通用空间；2）使用梯度解耦模块巧妙操纵适应过程中的梯度，防止模型遗忘通用知识。

Result: 在三个跨模态检索任务的20个基准测试上进行广泛实验，验证了该方法对抗查询偏移的有效性。

Conclusion: REST方法能够有效应对跨模态检索中的在线和多样查询偏移问题，保持模型性能的同时防止知识遗忘。

Abstract: Recently, the general-to-customized paradigm has emerged as the dominant approach for Cross-Modal Retrieval (CMR), which reconciles the distribution shift problem between the source domain and the target domain. However, existing general-to-customized CMR methods typically assume that the entire target-domain data is available, which is easily violated in real-world scenarios and thus inevitably suffer from the query shift (QS) problem. Specifically, query shift embraces the following two characteristics and thus poses new challenges to CMR. i) Online Shift: real-world queries always arrive in an online manner, rendering it impractical to access the entire query set beforehand for customization approaches; ii) Diverse Shift: even with domain customization, the CMR models struggle to satisfy queries from diverse users or scenarios, leaving an urgent need to accommodate diverse queries. In this paper, we observe that QS would not only undermine the well-structured common space inherited from the source model, but also steer the model toward forgetting the indispensable general knowledge for CMR. Inspired by the observations, we propose a novel method for achieving online and harmonious adaptation against QS, dubbed Robust adaptation with quEry ShifT (REST). To deal with online shift, REST first refines the retrieval results to formulate the query predictions and accordingly designs a QS-robust objective function on these predictions to preserve the well-established common space in an online manner. As for tackling the more challenging diverse shift, REST employs a gradient decoupling module to dexterously manipulate the gradients during the adaptation process, thus preventing the CMR model from forgetting the general knowledge. Extensive experiments on 20 benchmarks across three CMR tasks verify the effectiveness of our method against QS.

</details>


### [39] [FlowRoI A Fast Optical Flow Driven Region of Interest Extraction Framework for High-Throughput Image Compression in Immune Cell Migration Analysis](https://arxiv.org/abs/2511.14419)
*Xiaowei Xu,Justin Sonneck,Hongxiao Wang,Roman Burkard,Hendrik Wohrle,Anton Grabmasier,Matthias Gunzer,Jianxu Chen*

Main category: cs.LG

TL;DR: FlowRoI是一个基于光流的快速感兴趣区域提取框架，用于高通量免疫细胞迁移研究中的图像压缩，能够在保持高图像质量的同时实现2.0-2.2倍的压缩率提升。


<details>
  <summary>Details</summary>
Motivation: ComplexEye等高通量成像平台产生指数级增长的数据，给存储和传输带来巨大负担，需要高效的压缩方法来应对这一挑战。

Method: FlowRoI通过估计连续帧之间的光流来提取感兴趣区域掩码，然后使用JPEG2000对原始图像和掩码进行联合编码，实现ROI感知压缩。

Result: FlowRoI计算效率高，在现代笔记本电脑上达到约30帧/秒的处理速度，在细胞区域具有更高的PSNR，在相同PSNR下比标准JPEG2000实现2.0-2.2倍的压缩率提升。

Conclusion: FlowRoI为高通量免疫细胞迁移研究提供了一种高效的数据压缩解决方案，在保持图像质量的同时显著减少了存储和传输负担。

Abstract: Autonomous migration is essential for the function of immune cells such as neutrophils and plays a pivotal role in diverse diseases. Recently, we introduced ComplexEye, a multi-lens array microscope comprising 16 independent aberration-corrected glass lenses arranged at the pitch of a 96-well plate, capable of capturing high-resolution movies of migrating cells. This architecture enables high-throughput live-cell video microscopy for migration analysis, supporting routine quantification of autonomous motility with strong potential for clinical translation. However, ComplexEye and similar high-throughput imaging platforms generate data at an exponential rate, imposing substantial burdens on storage and transmission. To address this challenge, we present FlowRoI, a fast optical-flow-based region of interest (RoI) extraction framework designed for high-throughput image compression in immune cell migration studies. FlowRoI estimates optical flow between consecutive frames and derives RoI masks that reliably cover nearly all migrating cells. The raw image and its corresponding RoI mask are then jointly encoded using JPEG2000 to enable RoI-aware compression. FlowRoI operates with high computational efficiency, achieving runtimes comparable to standard JPEG2000 and reaching an average throughput of about 30 frames per second on a modern laptop equipped with an Intel i7-1255U CPU. In terms of image quality, FlowRoI yields higher peak signal-to-noise ratio (PSNR) in cellular regions and achieves 2.0-2.2x higher compression rates at matched PSNR compared to standard JPEG2000.

</details>


### [40] [MiAD: Mirage Atom Diffusion for De Novo Crystal Generation](https://arxiv.org/abs/2511.14426)
*Andrey Okhotin,Maksim Nakhodnov,Nikita Kazeev,Andrey E Ustyuzhanin,Dmitry Vetrov*

Main category: cs.LG

TL;DR: 本文提出了一种名为Mirage Atom Diffusion (MiAD)的新方法，通过mirage infusion技术使扩散模型能够在晶体生成过程中改变原子数量，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在生成晶体材料时无法改变原子数量，这限制了模型采样轨迹的多样性。

Method: 提出了mirage infusion技术，允许原子在存在和不存在状态之间转换，构建了MiAD模型——一个等变联合扩散模型。

Result: 该技术使模型质量提升高达2.5倍，在MP-20数据集上达到8.2%的S.U.N.率，大幅超越现有最先进方法。

Conclusion: MiAD模型通过允许改变原子数量，显著提升了晶体材料生成的性能，为扩散模型在材料科学中的应用开辟了新方向。

Abstract: In recent years, diffusion-based models have demonstrated exceptional performance in searching for simultaneously stable, unique, and novel (S.U.N.) crystalline materials. However, most of these models don't have the ability to change the number of atoms in the crystal during the generation process, which limits the variability of model sampling trajectories. In this paper, we demonstrate the severity of this restriction and introduce a simple yet powerful technique, mirage infusion, which enables diffusion models to change the state of the atoms that make up the crystal from existent to non-existent (mirage) and vice versa. We show that this technique improves model quality by up to $\times2.5$ compared to the same model without this modification. The resulting model, Mirage Atom Diffusion (MiAD), is an equivariant joint diffusion model for de novo crystal generation that is capable of altering the number of atoms during the generation process. MiAD achieves an $8.2\%$ S.U.N. rate on the MP-20 dataset, which substantially exceeds existing state-of-the-art approaches. The source code can be found at \href{https://github.com/andrey-okhotin/miad.git}{\texttt{github.com/andrey-okhotin/miad}}.

</details>


### [41] [Hybrid Modeling of Photoplethysmography for Non-invasive Monitoring of Cardiovascular Parameters](https://arxiv.org/abs/2511.14452)
*Emanuele Palumbo,Sorawit Saengkyongam,Maria R. Cervera,Jens Behrmann,Andrew C. Miller,Guillermo Sapiro,Christina Heinze-Deml,Antoine Wehenkel*

Main category: cs.LG

TL;DR: 提出了一种混合方法，通过血流动力学模拟和无标签临床数据，直接从PPG信号估计心血管生物标志物，解决了PPG测量中关键心脏生物标志物预测的挑战。


<details>
  <summary>Details</summary>
Motivation: 连续心血管监测在精准健康中起关键作用，但关键心脏生物标志物如每搏输出量和心输出量需要侵入性测量。PPG作为非侵入性替代方案，但预测这些生物标志物仍面临挑战且缺乏标注数据。

Method: 采用混合模型，结合在配对PPG-APW数据上训练的条件变分自编码器，以及在标记模拟APW段上训练的心脏生物标志物条件密度估计器。

Result: 实验表明，该方法能够检测心输出量和每搏输出量的波动，并在监测这些生物标志物时间变化方面优于监督基线。

Conclusion: 提出的混合方法能够直接从PPG信号有效估计心血管生物标志物，为连续心血管监测提供了可行的非侵入性解决方案。

Abstract: Continuous cardiovascular monitoring can play a key role in precision health. However, some fundamental cardiac biomarkers of interest, including stroke volume and cardiac output, require invasive measurements, e.g., arterial pressure waveforms (APW). As a non-invasive alternative, photoplethysmography (PPG) measurements are routinely collected in hospital settings. Unfortunately, the prediction of key cardiac biomarkers from PPG instead of APW remains an open challenge, further complicated by the scarcity of annotated PPG measurements. As a solution, we propose a hybrid approach that uses hemodynamic simulations and unlabeled clinical data to estimate cardiovascular biomarkers directly from PPG signals. Our hybrid model combines a conditional variational autoencoder trained on paired PPG-APW data with a conditional density estimator of cardiac biomarkers trained on labeled simulated APW segments. As a key result, our experiments demonstrate that the proposed approach can detect fluctuations of cardiac output and stroke volume and outperform a supervised baseline in monitoring temporal changes in these biomarkers.

</details>


### [42] [Nonparametric estimation of conditional probability distributions using a generative approach based on conditional push-forward neural networks](https://arxiv.org/abs/2511.14455)
*Nicola Rares Franco,Lorenzo Tedesco*

Main category: cs.LG

TL;DR: CPFN是一种条件分布估计的生成框架，通过学习随机映射来近似条件分布，支持高效的条件采样和统计量估计，无需可逆性或对抗训练。


<details>
  <summary>Details</summary>
Motivation: 开发一个轻量级且易于训练的条件分布估计方法，能够高效进行条件采样和统计量估计，避免传统方法中的可逆性或对抗训练要求。

Method: 学习随机映射φ(x,u)，使得φ(x,U)与Y|X=x的分布近似相同，使用基于Kullback-Leibler散度的目标函数进行训练。

Result: CPFN在性能上可与或优于最先进方法（包括核估计、树基算法和深度学习技术），同时保持轻量级和易训练特性。

Conclusion: CPFN提供了一个有效且实用的条件分布估计框架，在保持竞争力的同时简化了训练过程。

Abstract: We introduce conditional push-forward neural networks (CPFN), a generative framework for conditional distribution estimation. Instead of directly modeling the conditional density $f_{Y|X}$, CPFN learns a stochastic map $\varphi=\varphi(x,u)$ such that $\varphi(x,U)$ and $Y|X=x$ follow approximately the same law, with $U$ a suitable random vector of pre-defined latent variables. This enables efficient conditional sampling and straightforward estimation of conditional statistics through Monte Carlo methods. The model is trained via an objective function derived from a Kullback-Leibler formulation, without requiring invertibility or adversarial training. We establish a near-asymptotic consistency result and demonstrate experimentally that CPFN can achieve performance competitive with, or even superior to, state-of-the-art methods, including kernel estimators, tree-based algorithms, and popular deep learning techniques, all while remaining lightweight and easy to train.

</details>


### [43] [nnterp: A Standardized Interface for Mechanistic Interpretability of Transformers](https://arxiv.org/abs/2511.14465)
*Clément Dumas*

Main category: cs.LG

TL;DR: nnterp是一个轻量级包装器，为Transformer分析提供统一接口，同时保留原始HuggingFace实现，解决了现有工具在一致性和准确性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前Transformer可解释性研究工具面临基本权衡：自定义实现（如TransformerLens）确保接口一致但需要手动适配每个架构，而直接使用HuggingFace（通过NNsight）保留准确行为但缺乏跨模型标准化。

Method: 开发nnterp作为NNsight的轻量级包装器，通过自动模块重命名和全面验证测试，提供Transformer分析的统一接口。

Result: nnterp使研究人员能够编写一次干预代码并在50多个模型变体（涵盖16个架构系列）上部署，包含常见可解释性方法的内置实现，并提供对注意力概率的直接访问。

Conclusion: nnterp在机械可解释性工具中弥合了正确性和可用性之间的差距。

Abstract: Mechanistic interpretability research requires reliable tools for analyzing transformer internals across diverse architectures. Current approaches face a fundamental tradeoff: custom implementations like TransformerLens ensure consistent interfaces but require coding a manual adaptation for each architecture, introducing numerical mismatch with the original models, while direct HuggingFace access through NNsight preserves exact behavior but lacks standardization across models. To bridge this gap, we develop nnterp, a lightweight wrapper around NNsight that provides a unified interface for transformer analysis while preserving original HuggingFace implementations. Through automatic module renaming and comprehensive validation testing, nnterp enables researchers to write intervention code once and deploy it across 50+ model variants spanning 16 architecture families. The library includes built-in implementations of common interpretability methods (logit lens, patchscope, activation steering) and provides direct access to attention probabilities for models that support it. By packaging validation tests with the library, researchers can verify compatibility with custom models locally. nnterp bridges the gap between correctness and usability in mechanistic interpretability tooling.

</details>


### [44] [Notes on Kernel Methods in Machine Learning](https://arxiv.org/abs/2511.14485)
*Diego Armando Pérez-Rosero,Danna Valentina Salazar-Dubois,Juan Camilo Lugo-Rojas,Andrés Marino Álvarez-Meza,Germán Castellanos-Dominguez*

Main category: cs.LG

TL;DR: 本文提供了关于核方法及其在机器学习中几何基础的自包含介绍，涵盖希尔伯特空间构造、正定核理论、再生核希尔伯特空间和希尔伯特-施密特算子等内容。


<details>
  <summary>Details</summary>
Motivation: 为机器学习中的核方法提供几何基础理论，建立从希尔伯特空间到统计估计的完整框架，为高级主题如高斯过程和核贝叶斯推断奠定基础。

Method: 从希尔伯特空间构造出发，系统发展正定核理论、RKHS理论和希尔伯特-施密特算子理论，重新审视协方差、回归和信息度量等经典概念。

Result: 建立了核方法在统计估计和概率测度表示中的理论基础，引入了核密度估计、分布核嵌入和最大均值差异等核心概念。

Conclusion: 该阐述为高斯过程、核贝叶斯推断和现代机器学习的功能分析方法等高级主题提供了理论基础，强调了希尔伯特空间几何在机器学习中的核心作用。

Abstract: These notes provide a self-contained introduction to kernel methods and their geometric foundations in machine learning. Starting from the construction of Hilbert spaces, we develop the theory of positive definite kernels, reproducing kernel Hilbert spaces (RKHS), and Hilbert-Schmidt operators, emphasizing their role in statistical estimation and representation of probability measures. Classical concepts such as covariance, regression, and information measures are revisited through the lens of Hilbert space geometry. We also introduce kernel density estimation, kernel embeddings of distributions, and the Maximum Mean Discrepancy (MMD). The exposition is designed to serve as a foundation for more advanced topics, including Gaussian processes, kernel Bayesian inference, and functional analytic approaches to modern machine learning.

</details>


### [45] [Towards Stable and Structured Time Series Generation with Perturbation-Aware Flow Matching](https://arxiv.org/abs/2511.14488)
*Jintao Zhang,Mingyue Cheng,Zirui Liu,Xianquan Wang,Yitong Zhou,Qi Liu*

Main category: cs.LG

TL;DR: PAFM是一个扰动感知的流匹配框架，用于生成结构一致的时间序列，通过模拟局部扰动和双路径速度场来捕捉轨迹偏差，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 时间序列生成在分析和决策任务中很重要，但局部扰动引起的时间异质性对生成结构一致的时间序列提出了挑战。现有流匹配方法使用全局共享参数，无法充分捕捉扰动时间序列中的突变转换。

Method: 提出PAFM框架，包含扰动引导训练模拟局部干扰，使用双路径速度场捕捉扰动下的轨迹偏差，并采用带流路由的专家混合解码器动态分配建模能力。

Result: 在无条件和条件生成任务上的大量实验表明，PAFM始终优于强基线方法。

Conclusion: PAFM通过扰动感知的流匹配方法，能够生成稳定且结构一致的时间序列，有效解决了局部扰动带来的挑战。

Abstract: Time series generation is critical for a wide range of applications, which greatly supports downstream analytical and decision-making tasks. However, the inherent temporal heterogeneous induced by localized perturbations present significant challenges for generating structurally consistent time series. While flow matching provides a promising paradigm by modeling temporal dynamics through trajectory-level supervision, it fails to adequately capture abrupt transitions in perturbed time series, as the use of globally shared parameters constrains the velocity field to a unified representation. To address these limitations, we introduce \textbf{PAFM}, a \textbf{P}erturbation-\textbf{A}ware \textbf{F}low \textbf{M}atching framework that models perturbed trajectories to ensure stable and structurally consistent time series generation. The framework incorporates perturbation-guided training to simulate localized disturbances and leverages a dual-path velocity field to capture trajectory deviations under perturbation, enabling refined modeling of perturbed behavior to enhance the structural coherence. In order to further improve sensitivity to trajectory perturbations while enhancing expressiveness, a mixture-of-experts decoder with flow routing dynamically allocates modeling capacity in response to different trajectory dynamics. Extensive experiments on both unconditional and conditional generation tasks demonstrate that PAFM consistently outperforms strong baselines. Code is available at https://anonymous.4open.science/r/PAFM-03B2.

</details>


### [46] [CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design](https://arxiv.org/abs/2511.14510)
*Jiawei Yi,Ping Gong,Youhui Bai,Jiaqi Ruan,Shengnan Wang,Pengcheng Wang,Haibo Wang,Weiguang Wang,Xia Zhu,Feng Wu,Cheng Li*

Main category: cs.LG

TL;DR: CLO是一个通过算法-系统协同设计实现的CPU轻量级KVCache卸载系统，解决了现有系统中CPU瓶颈问题，显著提高了解码吞吐量。


<details>
  <summary>Details</summary>
Motivation: 随着百万token LLM的发展，推理系统面临可扩展性限制，其中KVCache主导内存使用和数据传输开销。现有卸载系统虽然将KVCache迁移到CPU内存并采用top-k注意力，但忽视了CPU瓶颈的三个关键方面：细粒度动态缓存管理开销、PCIe带宽利用率差导致的传输开销，以及CPU中心同步引入的GPU运行时气泡。

Method: CLO采用算法-系统协同设计，包括：粗粒度的头级近似GPU缓存策略、数据预取与GPU持久缓存的无缝结合、充分利用PCIe带宽的零拷贝传输引擎，以及消除GPU停滞的GPU中心同步方法。

Result: 在两个广泛使用的LLM上的评估表明，CLO在保持与最先进系统相当精度的同时，显著最小化CPU开销，充分利用PCIe带宽，将解码吞吐量提高了9.3%-66.6%。

Conclusion: 算法-系统协同设计对于现代GPU平台上内存受限的LLM推理至关重要。CLO已开源在GitHub上。

Abstract: The growth of million-token LLMs exposes the scalability limits of inference systems, where the KVCache dominates memory usage and data transfer overhead. Recent offloading systems migrate the KVCache to CPU memory and incorporate top-k attention to reduce the volume of data transferred from the CPU, while further applying system-level optimizations such as on-GPU caching and prefetching to lower transfer overhead. However, they overlook the CPU bottleneck in three aspects: (1) substantial overhead of fine-grained dynamic cache management performed on the CPU side, (2) significant transfer overhead from poor PCIe bandwidth utilization caused by heavy gathering operations at the CPU side, and (3) GPU runtime bubbles introduced by coarse-grained CPU-centric synchronization. To address these challenges, we propose CLO, a CPU-light KVCache offloading system via algorithm-system co-design. CLO features: (1) a coarse-grained head-wise approximate on-GPU caching strategy with negligible cache management cost, (2) seamless combination of data prefetching and on-GPU persistent caching for lower transfer overhead, (3) a zero-copy transfer engine to fully exploit PCIe bandwidth, and a GPU-centric synchronization method to eliminate GPU stalls. Evaluation on two widely-used LLMs demonstrates that CLO achieves comparable accuracy to state-of-the-art systems, while substantially minimizing CPU overhead, fully utilizing PCIe bandwidth, thus improving decoding throughput by 9.3%-66.6%. Our results highlight that algorithm-system co-design is essential for memory-constrained LLM inference on modern GPU platforms. We open source CLO at https://github.com/CommediaJW/CLO.

</details>


### [47] [MissHDD: Hybrid Deterministic Diffusion for Hetrogeneous Incomplete Data Imputation](https://arxiv.org/abs/2511.14543)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.LG

TL;DR: 提出了一种混合确定性扩散框架，用于处理混合类型表格数据中的缺失值问题，将数值型和分类型特征分离到两个互补的生成通道中处理。


<details>
  <summary>Details</summary>
Motivation: 现实世界表格数据中数值型、分类型和离散型属性共存，现有基于扩散的插补模型假设同质特征空间，难以保持条件一致性，导致分类变量信息崩溃或数值变量不稳定。

Method: 采用混合确定性扩散框架：连续DDIM通道处理数值变量，离散潜在路径扩散通道处理分类和离散特征，两个通道在统一条件插补目标下训练。

Result: 在多个真实数据集上实验表明，该方法相比现有扩散方法和经典方法，在MCAR、MAR和MNAR设置下实现了更高的插补精度、更稳定的采样轨迹和更好的鲁棒性。

Conclusion: 结构感知的扩散过程对于推进深度学习处理不完整表格数据方法具有重要意义。

Abstract: Incomplete data are common in real-world tabular applications, where numerical, categorical, and discrete attributes coexist within a single dataset. This heterogeneous structure presents significant challenges for existing diffusion-based imputation models, which typically assume a homogeneous feature space and rely on stochastic denoising trajectories. Such assumptions make it difficult to maintain conditional consistency, and they often lead to information collapse for categorical variables or instability when numerical variables require deterministic updates. These limitations indicate that a single diffusion process is insufficient for mixed-type tabular imputation.
  We propose a hybrid deterministic diffusion framework that separates heterogeneous features into two complementary generative channels. A continuous DDIM-based channel provides efficient and stable deterministic denoising for numerical variables, while a discrete latent-path diffusion channel, inspired by loopholing-based discrete diffusion, models categorical and discrete features without leaving their valid sample manifolds. The two channels are trained under a unified conditional imputation objective, enabling coherent reconstruction of mixed-type incomplete data.
  Extensive experiments on multiple real-world datasets show that the proposed framework achieves higher imputation accuracy, more stable sampling trajectories, and improved robustness across MCAR, MAR, and MNAR settings compared with existing diffusion-based and classical methods. These results demonstrate the importance of structure-aware diffusion processes for advancing deep learning approaches to incomplete tabular data.

</details>


### [48] [Mind the Gaps: Measuring Visual Artifacts in Dimensionality Reduction](https://arxiv.org/abs/2511.14544)
*Jaume Ros,Alessio Arleo,Fernando Paulovich*

Main category: cs.LG

TL;DR: 本文提出了一种新的维度降维投影质量度量指标——扭曲指数(WI)，该指标基于正确保持点之间空白区域对于数据忠实视觉表示至关重要的假设。


<details>
  <summary>Details</summary>
Motivation: 现有的投影质量度量指标主要关注投影捕捉数据全局或局部结构的能力，但忽略了视觉扭曲、异常值或伪影的存在，这些因素可能导致用户对投影的视觉分析产生误导性结论。

Method: 引入扭曲指数(WI)作为新的度量指标，特别关注点之间空白区域的正确保持，认为这对于数据的忠实视觉表示至关重要。

Result: 提出了一个新的投影质量度量框架，能够更好地评估维度降维投影在视觉表示方面的质量。

Conclusion: 扭曲指数(WI)为维度降维投影的质量评估提供了一个新的视角，特别关注视觉表示的忠实性，有助于避免用户因视觉扭曲而产生误导性分析结论。

Abstract: Dimensionality Reduction (DR) techniques are commonly used for the visual exploration and analysis of high-dimensional data due to their ability to project datasets of high-dimensional points onto the 2D plane. However, projecting datasets in lower dimensions often entails some distortion, which is not necessarily easy to recognize but can lead users to misleading conclusions. Several Projection Quality Metrics (PQMs) have been developed as tools to quantify the goodness-of-fit of a DR projection; however, they mostly focus on measuring how well the projection captures the global or local structure of the data, without taking into account the visual distortion of the resulting plots, thus often ignoring the presence of outliers or artifacts that can mislead a visual analysis of the projection. In this work, we introduce the Warping Index (WI), a new metric for measuring the quality of DR projections onto the 2D plane, based on the assumption that the correct preservation of empty regions between points is of crucial importance towards a faithful visual representation of the data.

</details>


### [49] [ReflexGrad: Three-Way Synergistic Architecture for Zero-Shot Generalization in LLM Agents](https://arxiv.org/abs/2511.14584)
*Ankush Kadu,Ashwanth Krishnan*

Main category: cs.LG

TL;DR: ReflexGrad是一个结合分层任务分解、历史感知因果反思和梯度优化的新架构，在ALFWorld基准测试中实现了67%的零样本成功率，无需任务特定训练或演示。


<details>
  <summary>Details</summary>
Motivation: 解决智能体从经验中学习并在无需任务特定训练的情况下跨多样化任务泛化的基本挑战，探索互补学习机制的协同整合潜力。

Method: 结合三种互补机制：基于LLM的分层TODO分解用于战略规划、历史感知因果反思分析行动模式以识别失败根源、基于梯度的优化进行系统改进。

Result: 在ALFWorld基准测试中，Trial 0实现了67%的零样本成功率，无需任何先前的任务经验或演示，有效性能在首次接触时即建立。

Conclusion: 互补学习机制的协同整合能够实现稳健的零样本泛化，接近先前工作中的少样本基线性能。

Abstract: Enabling agents to learn from experience and generalize across diverse tasks without task-specific training remains a fundamental challenge in reinforcement learning and decision-making. While recent approaches have explored episodic memory (Reflexion), gradient-based prompt optimization (TextGrad),and hierarchical task decomposition independently, their potential for synergistic integration remains unexplored. We introduce ReflexGrad, a novel architecture that tightly couples three complementary mechanisms: (1) LLM-based hierarchical TODO decomposition for strategic planning, (2) history-aware causal reflection that analyzes recent action patterns to identify failure root causes and enable within-trial learning, and (3) gradient-based optimization for systematic improvement. Unlike prior work relying on few-shot demonstrations, our system achieves true zero-shot generalization through pure LLM semantic reasoning,requiring no task-specific examples, fine-tuning, or hardcoded similarity metrics. Evaluated on ALFWorld benchmark tasks, ReflexGrad demonstrates 67% zero-shot success rate on Trial 0 without any prior task experience or demonstrations, establishing effective performance on first exposure. Through empirical analysis, we identify the architectural mechanisms underlying stable convergence (zero action loops) and effective cross-task transfer (67% to 78% improvement).Our work demonstrates that synergistic integration of complementary learning mechanisms enables robust zero-shot generalization that approaches few-shot baselines from prior work.

</details>


### [50] [Task Addition and Weight Disentanglement in Closed-Vocabulary Models](https://arxiv.org/abs/2511.14569)
*Adam Hazimeh,Alessandro Favero,Pascal Frossard*

Main category: cs.LG

TL;DR: 本文研究了任务算术在闭词汇图像分类模型中的应用，发现权重解缠是预训练的一般特性，闭词汇视觉变换器也能通过任务算术进行编辑，实现高效的多任务部署，且线性探测是任务加法的竞争性基线。


<details>
  <summary>Details</summary>
Motivation: 任务算术在开放词汇模型中已被证明是有效的模型编辑方法，但在未使用语言监督预训练的闭词汇模型中的应用尚未探索。本文旨在填补这一空白，研究任务算术在闭词汇图像分类模型中的适用性。

Method: 在闭词汇图像分类模型中部署和研究任务加法，考虑不同的预训练方案，分析权重解缠特性，并比较任务算术与线性探测的性能。

Result: 发现权重解缠是预训练的一般特性，存在于不同的预训练闭词汇模型中。闭词汇视觉变换器可以通过任务算术进行编辑，实现高任务加法性能。线性探测是任务加法的竞争性基线方法。

Conclusion: 研究结果扩展了任务算术在预训练模型中的适用性，为在不同设置中更高效地使用预训练模型开辟了新途径。

Abstract: Task arithmetic has recently emerged as a promising method for editing pre-trained \textit{open-vocabulary} models, offering a cost-effective alternative to standard multi-task fine-tuning. However, despite the abundance of \textit{closed-vocabulary} models that are not pre-trained with language supervision, applying task arithmetic to these models remains unexplored. In this paper, we deploy and study task addition in closed-vocabulary image classification models. We consider different pre-training schemes and find that \textit{weight disentanglement} -- the property enabling task arithmetic -- is a general consequence of pre-training, as it appears in different pre-trained closed-vocabulary models. In fact, we find that pre-trained closed-vocabulary vision transformers can also be edited with task arithmetic, achieving high task addition performance and enabling the efficient deployment of multi-task models. Finally, we demonstrate that simple linear probing is a competitive baseline to task addition. Overall, our findings expand the applicability of task arithmetic to a broader class of pre-trained models and open the way for more efficient use of pre-trained models in diverse settings.

</details>


### [51] [Expert-Guided POMDP Learning for Data-Efficient Modeling in Healthcare](https://arxiv.org/abs/2511.14619)
*Marco Locatelli,Arjen Hommersom,Roberto Clemens Cerioli,Daniela Besozzi,Fabio Stella*

Main category: cs.LG

TL;DR: 提出Fuzzy MAP EM算法，将专家知识通过模糊伪计数融入POMDP参数估计，在数据有限和噪声高的医疗模拟中优于标准EM算法。


<details>
  <summary>Details</summary>
Motivation: 解决从有限数据中学习部分可观测马尔可夫决策过程参数的挑战，特别是在医疗领域数据稀缺的情况下。

Method: 将专家定义的模糊模型生成的模糊伪计数融入期望最大化框架，自然地将其重新表述为最大后验估计问题。

Result: 在合成医疗模拟中，该方法在低数据和高噪声条件下始终优于标准EM算法；肌无力案例研究显示能恢复临床一致的POMDP模型。

Conclusion: Fuzzy MAP EM算法是医疗保健中数据高效建模的实用工具，能有效利用专家知识指导学习过程。

Abstract: Learning the parameters of Partially Observable Markov Decision Processes (POMDPs) from limited data is a significant challenge. We introduce the Fuzzy MAP EM algorithm, a novel approach that incorporates expert knowledge into the parameter estimation process by enriching the Expectation Maximization (EM) framework with fuzzy pseudo-counts derived from an expert-defined fuzzy model. This integration naturally reformulates the problem as a Maximum A Posteriori (MAP) estimation, effectively guiding learning in environments with limited data. In synthetic medical simulations, our method consistently outperforms the standard EM algorithm under both low-data and high-noise conditions. Furthermore, a case study on Myasthenia Gravis illustrates the ability of the Fuzzy MAP EM algorithm to recover a clinically coherent POMDP, demonstrating its potential as a practical tool for data-efficient modeling in healthcare.

</details>


### [52] [Failure to Mix: Large language models struggle to answer according to desired probability distributions](https://arxiv.org/abs/2511.14630)
*Ivy Yuqian Yang,David Yu Zhang*

Main category: cs.LG

TL;DR: 现代大型语言模型在遵循简单概率分布方面存在严重失败，即使要求以49%概率输出"1"，模型也几乎100%输出"0"，表现出类似阶跃函数的行为。


<details>
  <summary>Details</summary>
Motivation: 科学思想生成和选择需要遵循目标概率分布进行探索，而当前AI基准测试有客观正确答案，通过强化学习训练LLM会抑制概率探索行为。

Method: 进行系统性实验，要求LLM按照简单概率分布生成输出，测试模型遵循分布的能力。

Result: 所有测试的现代LLM都严重无法遵循指定分布，即使要求以49%概率输出"1"，模型也几乎100%输出"0"，这种阶跃函数行为甚至压倒了模型内置的强偏见。

Conclusion: 当前LLM在概率探索方面存在根本性缺陷，无法按照指定概率分布生成输出，这对科学思想生成等需要概率探索的应用构成严重限制。

Abstract: Scientific idea generation and selection requires exploration following a target probability distribution. In contrast, current AI benchmarks have objectively correct answers, and training large language models (LLMs) via reinforcement learning against these benchmarks discourages probabilistic exploration. Here, we conducted systematic experiments requesting LLMs to produce outputs following simple probabilistic distributions, and found that all modern LLMs tested grossly fail to follow the distributions. For example, requesting a binary output of "1" 49% of the time produces an answer of "0" nearly 100% of the time. This step function-like behavior of near-exclusively generating the output with marginally highest probability even overrules even strong in-built LLM biases.

</details>


### [53] [Adapformer: Adaptive Channel Management for Multivariate Time Series Forecasting](https://arxiv.org/abs/2511.14632)
*Yuchen Luo,Xinyu Li,Liuhua Peng,Mingming Gong*

Main category: cs.LG

TL;DR: Adapformer是一个基于Transformer的多变量时间序列预测框架，通过自适应通道管理结合了通道独立和通道依赖方法的优点，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统多变量时间序列预测方法存在通道独立方法无法利用通道间交互信息，以及通道依赖方法容易引入过多无关信息导致过拟合的问题。

Method: 采用双阶段编码器-解码器架构，包含自适应通道增强器(ACE)用于丰富嵌入过程，以及自适应通道预测器(ACF)用于优化预测结果。ACE选择性整合关键依赖关系，ACF专注于最相关的协变量以减少噪声和冗余。

Result: 在多个数据集上的严格测试表明，Adapformer在预测准确性和计算效率方面均优于现有模型，达到了最先进的性能水平。

Conclusion: Adapformer通过有效的通道管理策略，成功解决了多变量时间序列预测中的关键挑战，成为该领域的先进解决方案。

Abstract: In multivariate time series forecasting (MTSF), accurately modeling the intricate dependencies among multiple variables remains a significant challenge due to the inherent limitations of traditional approaches. Most existing models adopt either \textbf{channel-independent} (CI) or \textbf{channel-dependent} (CD) strategies, each presenting distinct drawbacks. CI methods fail to leverage the potential insights from inter-channel interactions, resulting in models that may not fully exploit the underlying statistical dependencies present in the data. Conversely, CD approaches often incorporate too much extraneous information, risking model overfitting and predictive inefficiency. To address these issues, we introduce the Adaptive Forecasting Transformer (\textbf{Adapformer}), an advanced Transformer-based framework that merges the benefits of CI and CD methodologies through effective channel management. The core of Adapformer lies in its dual-stage encoder-decoder architecture, which includes the \textbf{A}daptive \textbf{C}hannel \textbf{E}nhancer (\textbf{ACE}) for enriching embedding processes and the \textbf{A}daptive \textbf{C}hannel \textbf{F}orecaster (\textbf{ACF}) for refining the predictions. ACE enhances token representations by selectively incorporating essential dependencies, while ACF streamlines the decoding process by focusing on the most relevant covariates, substantially reducing noise and redundancy. Our rigorous testing on diverse datasets shows that Adapformer achieves superior performance over existing models, enhancing both predictive accuracy and computational efficiency, thus making it state-of-the-art in MTSF.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [54] [Enhancing Decision Support in Construction through Industrial AI](https://arxiv.org/abs/2511.13910)
*Parul Khanna,Sameer Prabhu,Ramin Karim,Phillip Tretten*

Main category: cs.HC

TL;DR: 本研究探索建筑行业中AI解决方案开发的关键因素及其相关性，通过开发演示器并收集终端用户的量化反馈，为提升人机交互、决策支持和AI解决方案采用提供见解。


<details>
  <summary>Details</summary>
Motivation: 建筑行业正在经历数字化转型，AI解决方案在生产阶段具有独特潜力。为了通过以人为本的AI解决方案促进建筑生产阶段的决策过程，需要理解终端用户的需求和挑战，否则这些AI解决方案的潜在使用可能受限。

Method: 开发演示器并通过问卷调查收集终端用户（如现场经理和建筑专业人员）的量化反馈，探索、识别和描述建筑行业AI解决方案开发的关键因素及其相关性。

Result: 识别了建筑行业AI解决方案开发的关键因素及其相互关系，为改进这些工业AI解决方案提供了量化依据。

Conclusion: 本研究为开发和改进工业AI解决方案提供了重要见解，特别关注人机交互方面，以增强决策支持、可用性和整体AI解决方案的采用率。

Abstract: The construction industry is presently going through a transformation led by adopting digital technologies that leverage Artificial Intelligence (AI). These industrial AI solutions assist in various phases of the construction process, including planning, design, production and management. In particular, the production phase offers unique potential for the integration of such AI-based solutions. These AI-based solutions assist site managers, project engineers, coordinators and other key roles in making final decisions. To facilitate the decision-making process in the production phase of construction through a human-centric AI-based solution, it is important to understand the needs and challenges faced by the end users who interact with these AI-based solutions to enhance the effectiveness and usability of these systems. Without this understanding, the potential usage of these AI-based solutions may be limited. Hence, the purpose of this research study is to explore, identify and describe the key factors crucial for developing AI solutions in the construction industry. This study further identifies the correlation between these key factors. This was done by developing a demonstrator and collecting quantifiable feedback through a questionnaire targeting the end users, such as site managers and construction professionals. This research study will offer insights into developing and improving these industrial AI solutions, focusing on Human-System Interaction aspects to enhance decision support, usability, and overall AI solution adoption.

</details>


### [55] [Human-centric Maintenance Process Through Integration of AI, Speech, and AR](https://arxiv.org/abs/2511.13918)
*Parul Khanna,Ravdeep Kour,Ramin Karim*

Main category: cs.HC

TL;DR: 本研究开发了一个基于微软HoloLens 2的增强现实维护支持系统，整合AI、AR和语音处理技术，实现免手持实时任务记录和交互，旨在降低维护人员的认知负荷并提高工作效率。


<details>
  <summary>Details</summary>
Motivation: 传统工业维护使用物理文档和设备交互，会中断任务、影响效率并增加维护人员的认知负荷。AR技术有潜力在这些方面支持并增强工业维护流程。

Method: 使用Unity、C#、Azure认知服务和Azure函数开发微软HoloLens 2演示器，实现语音转文本转录功能，为免手持维护提供支持。

Result: 利用Azure语音识别，演示器在AR环境中实现了高精度的转录，促进了用户与增强环境之间的自然交互。

Conclusion: 研究表明AR技术有潜力通过增强人机交互来降低认知负荷、简化工作流程，并提高高风险环境中维护人员的安全性。

Abstract: The adoption of Augmented Reality (AR) is increasing to enhance Human-System Interaction (HSI) by creating immersive experiences that improve efficiency and safety in various industries. In industrial maintenance, traditional practices involve physical documentation and device interactions, which might disrupt the task, affect efficiency, and increase the cognitive load for the maintenance personnel. AR has the potential to support and enhance industrial maintenance processes in these aspects. Therefore, the purpose of this research is to study and explore how advanced technologies like Artificial Intelligence (AI), AR and speech processing can be integrated to support hands-free, real-time task logging and interaction in maintenance environments. This is done by developing a demonstrator for Microsoft HoloLens 2 using Unity, C#, Azure Cognitive Services, and Azure Functions, which enables speech-to-text transcription for hands-free maintenance support. Using Azures' speech recognition, the demonstrator can achieve high transcription accuracy in an AR environment, facilitating natural interactions between users and the augmented environment. The study aims to explore the potential of AR to reduce cognitive load, streamline workflows, and improve safety by enhancing HSI for maintenance personnel in high-stakes environments.

</details>


### [56] [Affective Color Scales for Colormap Data Visualizations](https://arxiv.org/abs/2511.14009)
*Halle C. Braun,Kushin Mukherjee,Seth R. Gorelik,Karen B. Schloss*

Main category: cs.HC

TL;DR: 研究发现可以设计同时具有强亮度对比度以支持空间视觉和明确情感内涵的色图，情感内涵不仅取决于色标，还取决于数据分布。


<details>
  <summary>Details</summary>
Motivation: 现有情感可视化设计中，使用全亮或全暗颜色来传达情感的方法不适用于用颜色表示空间数据模式的色图可视化，因为需要亮度对比来显示细节。

Method: 研究设计具有强亮度对比度的色图，同时测试情感内涵与色标构造和数据分布频率的关系。

Result: 成功设计出既能支持空间视觉又能传达清晰情感内涵的色图，情感内涵具有数据依赖性。

Conclusion: 强调数据感知设计的重要性，需要考虑设计特征在数据属性下的具体实现方式。

Abstract: Research on affective visualization design has shown that color is an especially powerful feature for influencing the emotional connotation of visualizations. Associations between colors and emotions are largely driven by lightness (e.g., lighter colors are associated with positive emotions, whereas darker colors are associated with negative emotions). Designing visualizations to have all light or all dark colors to convey particular emotions may work well for visualizations in which colors represent categories and spatial channels encode data values. However, this approach poses a problem for visualizations that use color to represent spatial patterns in data (e.g., colormap data visualizations) because lightness contrast is needed to reveal fine details in spatial structure. In this study, we found it is possible to design colormaps that have strong lightness contrast to support spatial vision while communicating clear affective connotation. We also found that affective connotation depended not only on the color scales used to construct the colormaps, but also the frequency with which colors appeared in the map, as determined by the underlying dataset (data-dependence hypothesis). These results emphasize the importance of data-aware design, which accounts for not only the design features that encode data (e.g., colors, shapes, textures), but also how those design features are instantiated in a visualization, given the properties of the data.

</details>


### [57] [Developing a Grounded View of AI](https://arxiv.org/abs/2511.14013)
*Bifei Mao,Lanqing Hong*

Main category: cs.HC

TL;DR: 本文从工程角度分析AI与基于规则软件的根本区别，提出识别AI行为边界的方法论，强调人类责任和AI系统稳健性的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨AI作为计算能力与基于规则软件能力的本质差异，澄清AI的性质和限制，维护人类追求和遵循规则的理性价值。

Method: 提出一种方法论，通过三种决策类型来区分AI模型的行为，使AI行为的隐藏规则变得可识别和可实践。

Result: 建立了识别AI行为差异的实用框架，为理解AI与规则软件的根本区别提供了可行方法。

Conclusion: 识别基于规则的实践理性边界是确保人类责任的前提，这是保障AI系统对人类、社会和环境福祉稳健性的坚实基础。

Abstract: As a capability coming from computation, how does AI differ fundamentally from the capabilities delivered by rule-based software program? The paper examines the behavior of artificial intelligence (AI) from engineering points of view to clarify its nature and limits. The paper argues that the rationality underlying humanity's impulse to pursue, articulate, and adhere to rules deserves to be valued and preserved. Identifying where rule-based practical rationality ends is the beginning of making it aware until action. Although the rules of AI behaviors are still hidden or only weakly observable, the paper has proposed a methodology to make a sense of discrimination possible and practical to identify the distinctions of the behavior of AI models with three types of decisions. It is a prerequisite for human responsibilities with alternative possibilities, considering how and when to use AI. It would be a solid start for people to ensure AI system soundness for the well-being of humans, society, and the environment.

</details>


### [58] [Gamified Virtual Reality Exposure Therapy for Mysophobia: Evaluating the Efficacy of a Simulated Sneeze Intervention](https://arxiv.org/abs/2511.14118)
*Md Mosharaf Hossan,Rifat Ara Tasnim,Farjana Z Eishita*

Main category: cs.HC

TL;DR: 本研究开发了一款基于虚拟现实的打喷嚏模拟游戏，用于评估其对参与者情绪状态的影响，发现打喷嚏模拟会轻微增加负面情绪和焦虑水平，但差异不显著。


<details>
  <summary>Details</summary>
Motivation: 研究洁癖（对细菌的恐惧）这一普遍焦虑障碍，探索游戏化虚拟现实干预在模拟污染相关场景方面的潜力，以了解其情绪和心理影响。

Method: 开发了基于打喷嚏模拟的VR游戏，7名参与者完成基线版本和实验版本（含打喷嚏模拟），使用PANAS和STAI-S问卷测量情绪反应。

Result: 打喷嚏模拟期间负面情绪和焦虑水平略有增加，积极情绪减少，但这些差异在统计学上不显著（p > 0.05）。

Conclusion: 这项探索性研究突显了基于VR的干预措施在理解和解决污染相关焦虑方面的潜力，为未来更大规模、更多样化的研究奠定了基础。

Abstract: Mysophobia, or the fear of germs, is a prevalent anxiety disorder that significantly impacts daily life. This study investigates the potential of a gamified virtual reality (VR) intervention to simulate contamination-related scenarios and assess their emotional and psychological effects. A VR game based sneeze simulation was developed to evaluate its influence on participants' emotional states. Seven participants completed two versions of the game: a baseline version and an experimental version featuring the sneeze simulation. Emotional responses were measured using the Positive and Negative Affect Schedule (PANAS) and State-Trait Anxiety Inventory - State (STAI-S) questionnaires. The results revealed slight increases in negative affect and anxiety levels during the sneeze simulation. Also, a reduction in positive affect was revealed. However, these differences were not statistically significant (p > 0.05). This is likely due to small sample sizes, a lack of grossness in the simulation, or participants not being clinically mysophobes. This exploratory study highlights the potential of VR-based interventions for understanding and addressing contamination-related anxieties. It provides a foundation for future research with larger and more diverse participant pools.

</details>


### [59] [Final Happiness: What Intelligent User Interfaces Can Do for the lonely Dying](https://arxiv.org/abs/2511.14164)
*Yibo Meng,Xiaolan Ding,Lyumanshan Ye,Zhiming Liu,Yan Guan*

Main category: cs.HC

TL;DR: 本研究探讨了为临终孤独患者设计智能用户界面，提出了基于实证的'三支柱十二原则'框架，强调技术应追求超越而非模拟人类连接。


<details>
  <summary>Details</summary>
Motivation: 当前人机交互在'死亡技术'领域主要关注数字遗产管理等实际问题，忽视了临终患者的主观存在需求，特别是那些在孤独中面对死亡的人群。

Method: 对14名孤独的临终患者进行深度定性访谈，分析他们的心理、实践、社交和精神需求。

Result: 建立了临终患者需求模型，提出了'存在伴侣'设计框架，发现技术应创造超越人类能力的体验而非模拟基础人际连接。

Conclusion: 智能用户界面应作为'充分活到最后的伙伴'而非'死亡工具'，通过超越性体验来缓解存在性孤独。

Abstract: This study explores the design of Intelligent User Interfaces (IUIs) to address the profound existential loneliness of terminally ill individuals. While Human-Computer Interaction (HCI) has made inroads in "Thanatechnology," current research often focuses on practical aspects like digital legacy management, overlooking the subjective, existential needs of those facing death in isolation. To address this gap, we conducted in-depth qualitative interviews with 14 lonely, terminally ill individuals. Our core contributions are: (1) An empirically-grounded model articulating the complex psychological, practical, social, and spiritual needs of this group; (2) The "Three Pillars, Twelve Principles" framework for designing IUIs as "Existential Companions"; and (3) A critical design directive derived from user evaluations: technology in this context should aim for transcendence over simulation. The findings suggest that IUIs should create experiences that augment or surpass human capabilities, rather than attempting to simulate basic human connections, which can paradoxically deepen loneliness. This research provides a clear, user-centered path for designing technology that serves not as a "tool for dying," but as a "partner for living fully until the end".

</details>


### [60] [Algorithmic Management and the Future of Human Work: Implications for Autonomy, Collaboration, and Innovation](https://arxiv.org/abs/2511.14231)
*Huram Konjen*

Main category: cs.HC

TL;DR: 本文探讨算法管理对人力资源管理的影响，重点关注员工自主权、程序透明度和绩效评估的社会技术动态，提出基于社会技术视角的算法问责框架。


<details>
  <summary>Details</summary>
Motivation: 随着算法管理系统在人力资源管理中的广泛应用，需要理解其对员工自主权、程序透明度和组织正义的影响，避免算法系统强化偏见并忽视工作的关系和情境维度。

Method: 采用概念整合方法，综合人力资源管理、人机交互和科学技术研究领域的见解，构建理论分析框架。

Result: 分析发现算法系统虽能提升运营效率，但可能强化偏见并忽视创造力、同理心和协作问题解决等无形贡献，在数据驱动的绩效衡量中存在明显差距。

Conclusion: 提出基于社会技术视角的算法问责方法，强调程序透明度、组织正义和员工能动性，为设计支持而非限制人类自主权的管理技术提供理论指导。

Abstract: This study examines the evolving impact of algorithmic management on human resource management (HRM) practices, with a focus on employee autonomy, procedural transparency, and the sociotechnical dynamics of performance evaluation. Rather than adopting a qualitative or empirical approach, the paper develops a conceptual integration of insights from HRM, human-computer interaction (HCI), and Science and Technology Studies. The analysis highlights that although algorithmic systems can enhance operational efficiency, they risk reinforcing biases and narrowing the relational and contextual dimensions of work. These systems often overlook intangible contributions such as creativity, empathy, and collaborative problem solving, revealing gaps in data-driven performance measurement. In response, the study proposes a sociotechnical perspective on algorithmic accountability that emphasizes procedural transparency, organizational justice, and employee agency. By revisiting foundational questions within the rapidly evolving landscape of algorithmic management, the paper contributes to ongoing debates about the future of work and the design of managerial technologies that support, rather than constrain, human autonomy and organizational life.

</details>


### [61] [Visionary Co-Driver: Enhancing Driver Perception of Potential Risks with LLM and HUD](https://arxiv.org/abs/2511.14233)
*Wei Xiang,Ziyue Lei,Jie Wang,Yingying Huang,Qi Zheng,Tianyi Zhang,An Zhao,Lingyun Sun*

Main category: cs.HC

TL;DR: Visionary Co-Driver系统利用大语言模型识别非碰撞路边风险，通过结合视频处理算法和LLMs识别潜在危险道路使用者，并在自适应平视显示器上动态提示，提升驾驶员风险感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有风险检测方法擅长识别碰撞情况，但在评估非碰撞情况下道路使用者行为方面面临挑战，需要提升驾驶员对非碰撞路边风险的感知能力。

Method: 结合视频处理算法和大语言模型识别潜在危险道路使用者，通过自适应平视显示器动态提示风险，基于驾驶员眼动进行预警。

Result: 41名驾驶员参与的用户研究证实，Visionary Co-Driver能改善驾驶员的风险感知能力，支持他们对路边风险的识别。

Conclusion: 该系统有效提升了驾驶员对非碰撞路边风险的感知和识别能力，验证了基于大语言模型的风险检测方法的可行性。

Abstract: Drivers' perception of risky situations has always been a challenge in driving. Existing risk-detection methods excel at identifying collisions but face challenges in assessing the behavior of road users in non-collision situations. This paper introduces Visionary Co-Driver, a system that leverages large language models to identify non-collision roadside risks and alert drivers based on their eye movements. Specifically, the system combines video processing algorithms and LLMs to identify potentially risky road users. These risks are dynamically indicated on an adaptive heads-up display interface to enhance drivers' attention. A user study with 41 drivers confirms that Visionary Co-Driver improves drivers' risk perception and supports their recognition of roadside risks.

</details>


### [62] [TailCue: Exploring Animal-inspired Robotic Tail for Automated Vehicles Interaction](https://arxiv.org/abs/2511.14242)
*Yuan Li,Xinyue Gui,Ding Xia,Mark Colley,Takeo Igarashi*

Main category: cs.HC

TL;DR: 本文提出TailCue，研究基于尾巴的外部人机界面如何影响用户与自动驾驶车辆的互动。通过从机器人和动物学中研究尾巴运动与情感表达的映射关系，开发了运动-情感映射方案，并进行了在线用户研究。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆与道路使用者之间的有效沟通存在挑战，现有的外部人机界面在信任和情感信号传递方面仍有不足，需要探索新的交互方式来增强用户信心。

Method: 首先从机器人和动物学中研究尾巴运动与情感表达的映射关系，开发运动-情感映射方案，实现物理机器人尾巴并设计特定尾巴运动，然后进行基于视频的在线用户研究（21名参与者）。

Result: 虽然尾巴传达的预期情感并未被一致识别，但开放式反馈表明尾巴运动需要与场景和提示保持一致。结果强调了场景特定优化的必要性。

Conclusion: 基于尾巴的外部人机界面需要根据具体场景进行优化，未来工作将改进尾巴运动策略以在不同交互情境中最大化其有效性。

Abstract: Automated vehicles (AVs) are gradually becoming part of our daily lives. However, effective communication between road users and AVs remains a significant challenge. Although various external human-machine interfaces (eHMIs) have been developed to facilitate interactions, psychological factors, such as a lack of trust and inadequate emotional signaling, may still deter users from confidently engaging with AVs in certain contexts. To address this gap, we propose TailCue, an exploration of how tail-based eHMIs affect user interaction with AVs. We first investigated mappings between tail movements and emotional expressions from robotics and zoology, and accordingly developed a motion-emotion mapping scheme. A physical robotic tail was implemented, and specific tail motions were designed based on our scheme. An online, video-based user study with 21 participants was conducted. Our findings suggest that, although the intended emotions conveyed by the tail were not consistently recognized, open-ended feedback indicated that the tail motion needs to align with the scenarios and cues. Our result highlights the necessity of scenario-specific optimization to enhance tail-based eHMIs. Future work will refine tail movement strategies to maximize their effectiveness across diverse interaction contexts.

</details>


### [63] [Towards LLM-Based Usability Analysis for Recommender User Interfaces](https://arxiv.org/abs/2511.14359)
*Sebastian Lubos,Alexander Felfernig,Damian Garber,Viet-Man Le,Thi Ngoc Trang Tran*

Main category: cs.HC

TL;DR: 探索多模态大语言模型在评估推荐系统界面可用性方面的潜力，通过分析多个公开推荐平台的界面截图，自动化进行启发式可用性评估。


<details>
  <summary>Details</summary>
Motivation: 推荐系统的可用性是影响其有效性的关键因素，但用户界面分析需要专业知识且耗时。多模态大语言模型的发展为自动化此类评估提供了机会。

Method: 收集多个公开推荐平台的界面截图，涵盖偏好获取和推荐展示场景，使用大语言模型根据不同的可用性标准分析这些界面并提供解释性反馈。

Result: 评估表明大语言模型能够支持大规模的启发式可用性评估，帮助改进用户体验。

Conclusion: 多模态大语言模型在自动化推荐系统界面可用性评估方面具有潜力，能够支持用户体验的改进。

Abstract: Usability is a key factor in the effectiveness of recommender systems. However, the analysis of user interfaces is a time-consuming process that requires expertise. Recent advances in multimodal large language models (LLMs) offer promising opportunities to automate such evaluations. In this work, we explore the potential of multimodal LLMs to assess the usability of recommender system interfaces by considering a variety of publicly available systems as examples. We take user interface screenshots from multiple of these recommender platforms to cover both preference elicitation and recommendation presentation scenarios. An LLM is instructed to analyze these interfaces with regard to different usability criteria and provide explanatory feedback. Our evaluation demonstrates how LLMs can support heuristic-style usability assessments at scale to support the improvement of user experience.

</details>


### [64] [PACEE: Supporting Children's Personal Emotion Education through Parent-AI Collaboration](https://arxiv.org/abs/2511.14414)
*Yu Mei,Xutong Wang,Ziyao Zhang,Yiming Fu,Shiyi Wang,Qingyang Wan,Qinghuan Lan,Chang Liu,Jie Cai,Chun Yu,Yuanchun Shi*

Main category: cs.HC

TL;DR: 本文开发了PACEE系统，支持家长与AI协作进行幼儿情绪教育，通过生成式AI提供多形式支持，促进亲子情感对话和个性化指导。


<details>
  <summary>Details</summary>
Motivation: 现有技术主要从儿童角度促进情绪教育，忽视了家长在幼儿情绪发展中的核心作用，需要开发支持家长参与的家庭情绪教育系统。

Method: 与幼儿园教师和家长进行协同设计，识别家长挑战和AI角色，开发PACEE系统，结合家长洞察和AI建模儿童情绪状态，提供个性化、家长介导的指导。

Result: 在16个家庭的用户研究中，PACEE显著增强了亲子互动，鼓励更深层次的情感交流，改善了家长体验。

Conclusion: 研究推进了家庭环境和LLM辅助情境下的情绪辅导理论，为设计AI支持、以家长为中心的家庭教育系统提供了宝贵见解。

Abstract: Emotion education is a crucial lesson for children aged 3 to 6. However, existing technologies primarily focus on promoting emotion education from the child's perspective, often neglecting the central role of parents in guiding early childhood emotion development. In this work, we conducted co-design sessions with five experienced kindergarten teachers and five parents to identify parental challenges and the roles that AI can play in family emotion education. Guided by these insights, we developed PACEE, an assistant for supporting parent-AI collaborative emotion education. PACEE enables parents to engage in emotional dialogues about common scenarios, with multiple forms of support provided by generative AI. It combines insights from parents and AI to model children's emotional states and collaboratively delivers personalized, parent-mediated guidance. In a user study involving 16 families, we found that PACEE significantly enhances parent-child engagement, encourages more in-depth emotional communication, and improves the parental experience. Our findings advance emotion coaching theory in both family settings and LLM-assisted contexts, offering valuable insights for designing AI-supported, parent-centered family education systems.

</details>


### [65] [SweeperBot: Making 3D Browsing Accessible through View Analysis and Visual Question Answering](https://arxiv.org/abs/2511.14567)
*Chen Chen,Cuong Nguyen,Alexa Siu,Dingzeyu Li,Nadir Weibel*

Main category: cs.HC

TL;DR: SweeperBot系统通过视觉问答帮助屏幕阅读器用户探索和比较3D模型，结合最优视图选择技术和基础模型，为盲人和低视力用户提供详细描述。


<details>
  <summary>Details</summary>
Motivation: 现有3D查看器为屏幕阅读器用户提供的替代文本通常缺乏足够细节，难以满足他们对3D模型的探索需求。

Method: 结合最优视图选择技术与生成式和识别式基础模型，通过视觉问答方式回答用户关于3D模型的问题。

Result: 10名盲人和低视力用户的专家评审验证了系统的可行性，30名视力正常参与者的调查验证了生成描述的质量。

Conclusion: SweeperBot系统能够有效帮助屏幕阅读器用户探索和比较3D模型，为这一用户群体提供了更好的3D模型访问体验。

Abstract: Accessing 3D models remains challenging for Screen Reader (SR) users. While some existing 3D viewers allow creators to provide alternative text, they often lack sufficient detail about the 3D models. Grounded on a formative study, this paper introduces SweeperBot, a system that enables SR users to leverage visual question answering to explore and compare 3D models. SweeperBot answers SR users' visual questions by combining an optimal view selection technique with the strength of generative- and recognition-based foundation models. An expert review with 10 Blind and Low-Vision (BLV) users with SR experience demonstrated the feasibility of using SweeperBot to assist BLV users in exploring and comparing 3D models. The quality of the descriptions generated by SweeperBot was validated by a second survey study with 30 sighted participants.

</details>


### [66] [Biased Minds Meet Biased AI: How Class Imbalance Shapes Appropriate Reliance and Interacts with Human Base Rate Neglect](https://arxiv.org/abs/2511.14591)
*Nick von Felten,Johannes Schöning,Klaus Opwis,Nicolas Scharowksi*

Main category: cs.HC

TL;DR: 本文研究了AI偏见（类别不平衡）与人类偏见（基础率忽视）在决策支持系统中的复杂交互作用，发现两者会相互强化形成复合偏见。


<details>
  <summary>Details</summary>
Motivation: 虽然AI和人类偏见已被单独研究，但它们在交互中的复杂影响尚未充分探索。本文旨在填补这一空白，特别关注类别不平衡AI偏见如何影响人们对AI决策支持系统的依赖程度，以及与人类基础率忽视偏见的相互作用。

Method: 采用被试内在线实验设计（N=46），参与者使用基于AI的决策支持系统对三种疾病进行分类，该系统分别在平衡或不平衡数据集上训练。

Result: 研究发现类别不平衡扰乱了参与者对AI依赖的校准，并且观察到类别不平衡与基础率忽视之间存在相互强化效应，提供了复合人机偏见的证据。

Conclusion: 基于研究结果，作者倡导采用交互主义视角，并呼吁进一步研究人机交互中偏见的相互强化效应。

Abstract: Humans increasingly interact with artificial intelligence (AI) in decision-making. However, both AI and humans are prone to biases. While AI and human biases have been studied extensively in isolation, this paper examines their complex interaction. Specifically, we examined how class imbalance as an AI bias affects people's ability to appropriately rely on an AI-based decision-support system, and how it interacts with base rate neglect as a human bias. In a within-subject online study (N= 46), participants classified three diseases using an AI-based decision-support system trained on either a balanced or unbalanced dataset. We found that class imbalance disrupted participants' calibration of AI reliance. Moreover, we observed mutually reinforcing effects between class imbalance and base rate neglect, offering evidence of a compound human-AI bias. Based on these findings, we advocate for an interactionist perspective and further research into the mutually reinforcing effects of biases in human-AI interaction.

</details>


### [67] [Theoretical basis for code presentation: A case for cognitive load](https://arxiv.org/abs/2511.14636)
*Nyah Speicher,Prashant Chandrasekar*

Main category: cs.HC

TL;DR: 本文探讨了认知负荷对盲人和低视力开发者的影响，分析了现有解决方案在减轻认知负荷方面的不足，并提出了初步的设计建议来降低BLV开发者的认知负荷。


<details>
  <summary>Details</summary>
Motivation: 认知负荷管理对任务表现至关重要，但盲人和低视力个体无法依赖基于视觉的常用方法。现有解决方案很少考虑认知负荷，且缺乏评估认知负荷是否被减轻的方法。

Method: 基于心理学科学基础，识别影响编程表现和学习的认知负荷方面，评估现有BLV编程子任务解决方案，并提出初步代码呈现设计建议。

Result: 确定了影响编程的认知负荷关键方面，发现现有解决方案在减轻认知负荷方面存在不足，提出了能够降低BLV开发者认知负荷的设计建议。

Conclusion: 通过遵循提出的设计建议，可以有效降低盲人和低视力开发者的认知负荷，从而改善他们的编程表现和学习效果。

Abstract: Evidence supports that reducing cognitive load (CL) improves task performance for people of all abilities. This effect is specifically important for blind-and-low-vision (BLV) individuals because they cannot rely on many common methods of managing CL, which are frequently vision-based techniques. Current accessible "solutions" for BLV developers only sporadically consider CL in their design. There isn't a way to know whether CL is being alleviated by them. Neither do we know if alleviating CL is part of the mechanism behind why these solutions help BLV people. Using a strong foundation in psychological sciences, we identify aspects of CL that impact performance and learning in programming. These aspects are then examined when evaluating existing solutions for programming sub-tasks for BLV users. We propose an initial design "recommendations" for presentation of code which, when followed, will reduce cognitive load for BLV developers.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [68] [Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models](https://arxiv.org/abs/2511.13782)
*Xiaoxing Lian,Aidong Yang,Jun Zhu,Peng Wang,Yue Zhang*

Main category: cs.AI

TL;DR: SpatiaLite基准测试揭示先进视觉语言模型在空间推理方面存在显著缺陷，主要依赖语言表征而非视觉想象，导致在需要3D几何变换的任务上表现不佳且效率低下。


<details>
  <summary>Details</summary>
Motivation: 当前先进视觉语言模型在逻辑推理、问题解决等方面表现出色，但空间推理这一人类认知的基本能力仍是重大挑战。研究旨在探索空间推理机制，特别是想象力在空间世界模型中的作用。

Method: 引入SpatiaLite合成基准测试，联合测量空间推理准确性和效率；提出图像驱动框架(IDF)用于数据合成和训练，隐式构建内部世界模型。

Result: 发现三个关键结果：1)先进VLMs主要依赖语言表征，在视觉中心任务上表现不足；2)空间推理机制效率严重低下，token使用随复杂度快速增加；3)IDF框架能有效构建内部世界模型。

Conclusion: 本研究划定了先进VLMs的空间推理界限和模式，识别了关键缺陷，为未来发展提供了指导。图像驱动的内部世界模型构建是提升空间推理能力的关键方向。

Abstract: Large language models (LLMs) and vision language models (VLMs), such as DeepSeek R1,OpenAI o3, and Gemini 2.5 Pro, have demonstrated remarkable reasoning capabilities across logical inference, problem solving, and decision making. However, spatial reasoning:a fundamental component of human cognition that includes mental rotation, navigation, and spatial relationship comprehension remains a significant challenge for current advanced VLMs. We hypothesize that imagination, the internal simulation of spatial states, is the dominant reasoning mechanism within a spatial world model. To test this hypothesis and systematically probe current VLM spatial reasoning mechanisms, we introduce SpatiaLite, a fully synthetic benchmark that jointly measures spatial reasoning accuracy and reasoning efficiency. Comprehensive experiments reveal three key findings. First, advanced VLMs predominantly rely on linguistic representations for reasoning and imagination, resulting in significant deficiencies on visual centric tasks that demand perceptual spatial relations and 3D geometry transformations such as mental rotation or projection prediction. Second, advanced VLMs exhibit severe inefficiency in their current spatial reasoning mechanisms, with token usage growing rapidly as transformation complexity increases. Third, we propose an Imagery Driven Framework (IDF) for data synthesis and training, which can implicitly construct an internal world model that is critical for spatial reasoning in VLMs. Building on SpatiaLite, this work delineates the spatial reasoning limits and patterns of advanced VLMs, identifies key shortcomings, and informs future advances

</details>


### [69] [KANGURA: Kolmogorov-Arnold Network-Based Geometry-Aware Learning with Unified Representation Attention for 3D Modeling of Complex Structures](https://arxiv.org/abs/2511.13798)
*Mohammad Reza Shafie,Morteza Hajiabadi,Hamed Khosravi,Mobina Noori,Imtiaz Ahmed*

Main category: cs.AI

TL;DR: KANGURA是一种基于Kolmogorov-Arnold Network的几何感知学习框架，通过函数分解方法解决3D机器学习建模问题，在MFC阳极结构优化和ModelNet40基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 微生物燃料电池(MFCs)的性能受阳极结构影响，现有预测模型难以捕捉复杂的几何依赖关系来优化这些结构。

Method: 提出KANGURA框架：使用KAN-based表示学习重构几何关系，几何解耦表示学习分离结构变化为可解释组件，统一注意力机制动态增强关键几何区域。

Result: 在ModelNet40基准数据集上超越15个SOTA模型，达到92.7%准确率；在真实MFC阳极结构问题上达到97%准确率。

Conclusion: KANGURA为3D几何建模提供了稳健框架，为先进制造和质量驱动工程应用中复杂结构的优化开辟了新可能性。

Abstract: Microbial Fuel Cells (MFCs) offer a promising pathway for sustainable energy generation by converting organic matter into electricity through microbial processes. A key factor influencing MFC performance is the anode structure, where design and material properties play a crucial role. Existing predictive models struggle to capture the complex geometric dependencies necessary to optimize these structures. To solve this problem, we propose KANGURA: Kolmogorov-Arnold Network-Based Geometry-Aware Learning with Unified Representation Attention. KANGURA introduces a new approach to three-dimensional (3D) machine learning modeling. It formulates prediction as a function decomposition problem, where Kolmogorov-Arnold Network (KAN)- based representation learning reconstructs geometric relationships without a conventional multi- layer perceptron (MLP). To refine spatial understanding, geometry-disentangled representation learning separates structural variations into interpretable components, while unified attention mechanisms dynamically enhance critical geometric regions. Experimental results demonstrate that KANGURA outperforms over 15 state-of-the-art (SOTA) models on the ModelNet40 benchmark dataset, achieving 92.7% accuracy, and excels in a real-world MFC anode structure problem with 97% accuracy. This establishes KANGURA as a robust framework for 3D geometric modeling, unlocking new possibilities for optimizing complex structures in advanced manufacturing and quality-driven engineering applications.

</details>


### [70] [Causal computations in Semi Markovian Structural Causal Models using divide and conquer](https://arxiv.org/abs/2511.13852)
*Anna Rodum Bjøru,Rafael Cabañas,Helge Langseth,Antonio Salmerón*

Main category: cs.AI

TL;DR: 本文研究了将Bjøru等人提出的反事实概率边界计算算法从马尔可夫模型扩展到半马尔可夫结构因果模型的方法，解决了外生变量可能影响多个内生变量的情况。


<details>
  <summary>Details</summary>
Motivation: Bjøru等人的方法仅适用于马尔可夫模型，而半马尔可夫模型能够表示马尔可夫模型无法表示的混杂关系，因此需要扩展该方法以处理更一般的因果模型。

Method: 通过最小示例说明扩展的挑战，并提出替代解决方案策略，包括理论分析和计算研究评估。

Result: 提出了针对半马尔可夫结构因果模型的反事实概率边界计算方法，并通过理论和计算研究验证了所提策略的有效性。

Conclusion: 成功将反事实概率边界计算算法扩展到半马尔可夫结构因果模型，为处理更复杂的混杂关系提供了有效方法。

Abstract: Recently, Bjøru et al. proposed a novel divide-and-conquer algorithm for bounding counterfactual probabilities in structural causal models (SCMs). They assumed that the SCMs were learned from purely observational data, leading to an imprecise characterization of the marginal distributions of exogenous variables. Their method leveraged the canonical representation of structural equations to decompose a general SCM with high-cardinality exogenous variables into a set of sub-models with low-cardinality exogenous variables. These sub-models had precise marginals over the exogenous variables and therefore admitted efficient exact inference. The aggregated results were used to bound counterfactual probabilities in the original model. The approach was developed for Markovian models, where each exogenous variable affects only a single endogenous variable. In this paper, we investigate extending the methodology to \textit{semi-Markovian} SCMs, where exogenous variables may influence multiple endogenous variables. Such models are capable of representing confounding relationships that Markovian models cannot. We illustrate the challenges of this extension using a minimal example, which motivates a set of alternative solution strategies. These strategies are evaluated both theoretically and through a computational study.

</details>


### [71] [Jailbreaking Large Vision Language Models in Intelligent Transportation Systems](https://arxiv.org/abs/2511.13892)
*Badhan Chandra Das,Md Tasnim Jawad,Md Jueal Mia,M. Hadi Amini,Yanzhao Wu*

Main category: cs.AI

TL;DR: 本文系统分析了智能交通系统中大型视觉语言模型的安全漏洞，提出了一种利用图像排版操纵和多轮提示的新型越狱攻击方法，并设计了多层响应过滤防御技术来保护模型安全。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在智能交通系统中具有广泛应用，但存在严重的安全漏洞，容易受到越狱攻击。本文旨在揭示这些安全风险并开发相应的防御机制。

Method: 首先构建了与交通相关的有害查询数据集，然后提出了结合图像排版操纵和多轮提示的新型越狱攻击方法，最后设计了多层响应过滤防御技术。

Result: 实验表明提出的攻击方法对开源和闭源LVLMs都有效，而防御技术能有效阻止模型生成不当响应。通过GPT-4毒性评分和人工验证评估了攻击和防御效果。

Conclusion: 研究揭示了LVLMs在智能交通系统中的严重安全风险，提出的攻击和防御方法为模型安全提供了重要参考，强调了图像排版操纵和多轮提示组合攻击的威胁性。

Abstract: Large Vision Language Models (LVLMs) demonstrate strong capabilities in multimodal reasoning and many real-world applications, such as visual question answering. However, LVLMs are highly vulnerable to jailbreaking attacks. This paper systematically analyzes the vulnerabilities of LVLMs integrated in Intelligent Transportation Systems (ITS) under carefully crafted jailbreaking attacks. First, we carefully construct a dataset with harmful queries relevant to transportation, following OpenAI's prohibited categories to which the LVLMs should not respond. Second, we introduce a novel jailbreaking attack that exploits the vulnerabilities of LVLMs through image typography manipulation and multi-turn prompting. Third, we propose a multi-layered response filtering defense technique to prevent the model from generating inappropriate responses. We perform extensive experiments with the proposed attack and defense on the state-of-the-art LVLMs (both open-source and closed-source). To evaluate the attack method and defense technique, we use GPT-4's judgment to determine the toxicity score of the generated responses, as well as manual verification. Further, we compare our proposed jailbreaking method with existing jailbreaking techniques and highlight severe security risks involved with jailbreaking attacks with image typography manipulation and multi-turn prompting in the LVLMs integrated in ITS.

</details>


### [72] [CORGI: Efficient Pattern Matching With Quadratic Guarantees](https://arxiv.org/abs/2511.13942)
*Daniel Weitekamp*

Main category: cs.AI

TL;DR: CORGI是一种新的匹配算法，针对规则系统中指数级时间和空间复杂度问题，提供二次时间空间保证，通过两步法避免传统RETE算法的内存溢出问题。


<details>
  <summary>Details</summary>
Motivation: 解决实时应用中规则匹配的指数级复杂度问题，特别是在AI系统自动生成规则时容易产生最坏情况匹配模式，导致程序执行缓慢或内存耗尽。

Method: 采用两步法：前向传递构建/维护接地关系图，后向迭代器按需生成匹配，避免传统RETE算法中β内存收集部分匹配的问题。

Result: 在性能评估中，CORGI在简单组合匹配任务上显著优于SOAR和OPS5的RETE实现。

Conclusion: CORGI算法通过消除高延迟延迟和内存溢出，使基于示例学习的认知系统在实际应用中更加可行，无需手动工程约束。

Abstract: Rule-based systems must solve complex matching problems within tight time constraints to be effective in real-time applications, such as planning and reactive control for AI agents, as well as low-latency relational database querying. Pattern-matching systems can encounter issues where exponential time and space are required to find matches for rules with many underconstrained variables, or which produce combinatorial intermediate partial matches (but are otherwise well-constrained). When online AI systems automatically generate rules from example-driven induction or code synthesis, they can easily produce worst-case matching patterns that slow or halt program execution by exceeding available memory. In our own work with cognitive systems that learn from example, we've found that aggressive forms of anti-unification-based generalization can easily produce these circumstances. To make these systems practical without hand-engineering constraints or succumbing to unpredictable failure modes, we introduce a new matching algorithm called CORGI (Collection-Oriented Relational Graph Iteration). Unlike RETE-based approaches, CORGI offers quadratic time and space guarantees for finding single satisficing matches, and the ability to iteratively stream subsequent matches without committing entire conflict sets to memory. CORGI differs from RETE in that it does not have a traditional $β$-memory for collecting partial matches. Instead, CORGI takes a two-step approach: a graph of grounded relations is built/maintained in a forward pass, and an iterator generates matches as needed by working backward through the graph. This approach eliminates the high-latency delays and memory overflows that can result from populating full conflict sets. In a performance evaluation, we demonstrate that CORGI significantly outperforms RETE implementations from SOAR and OPS5 on a simple combinatorial matching task.

</details>


### [73] [Scene Graph-Guided Generative AI Framework for Synthesizing and Evaluating Industrial Hazard Scenarios](https://arxiv.org/abs/2511.13970)
*Sanjay Acharjee,Abir Khan Ratul,Diego Patino,Md Nazmus Sakib*

Main category: cs.AI

TL;DR: 提出了一种基于场景图引导的生成AI框架，利用历史OSHA事故报告生成逼真的工作场所危险场景图像，并通过VQA框架评估生成数据的真实性和语义保真度。


<details>
  <summary>Details</summary>
Motivation: 训练视觉模型准确检测工作场所危险需要真实的危险条件图像，但获取此类数据集很困难，因为捕捉实际发生的危险场景几乎不可能。

Method: 使用GPT-4o分析OSHA叙述提取结构化危险推理，转换为对象级场景图捕获空间和上下文关系，然后用文本到图像扩散模型生成构图准确的危险场景，并通过VQA框架评估生成质量。

Result: 提出的VQA图分数在四个最先进的生成模型上优于CLIP和BLIP指标，基于熵验证确认其具有更高的区分敏感性。

Conclusion: 该框架能够有效生成逼真的工作场所危险场景图像，为训练安全检测模型提供了可行的数据生成解决方案。

Abstract: Training vision models to detect workplace hazards accurately requires realistic images of unsafe conditions that could lead to accidents. However, acquiring such datasets is difficult because capturing accident-triggering scenarios as they occur is nearly impossible. To overcome this limitation, this study presents a novel scene graph-guided generative AI framework that synthesizes photorealistic images of hazardous scenarios grounded in historical Occupational Safety and Health Administration (OSHA) accident reports. OSHA narratives are analyzed using GPT-4o to extract structured hazard reasoning, which is converted into object-level scene graphs capturing spatial and contextual relationships essential for understanding risk. These graphs guide a text-to-image diffusion model to generate compositionally accurate hazard scenes. To evaluate the realism and semantic fidelity of the generated data, a visual question answering (VQA) framework is introduced. Across four state-of-the-art generative models, the proposed VQA Graph Score outperforms CLIP and BLIP metrics based on entropy-based validation, confirming its higher discriminative sensitivity.

</details>


### [74] [ALEX:A Light Editing-knowledge Extractor](https://arxiv.org/abs/2511.14018)
*Minghu Wang,Shuliang Zhao,Yuanyuan Zhao,Hongxia Xu*

Main category: cs.AI

TL;DR: ALEX是一个轻量级知识编辑框架，通过分层内存架构将知识更新组织成语义簇，将检索复杂度从O(N)降低到O(K+N/C)，显著提高了多跳问题回答的准确性和推理路径的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中的知识是静态的，难以适应不断变化的信息，现有方法在处理需要多步推理的复杂多跳问题时面临可扩展性和检索效率的挑战。

Method: ALEX采用分层内存架构组织知识更新，包含推理查询合成模块来弥合查询与事实之间的语义差距，以及动态证据裁决引擎执行高效的两阶段检索过程。

Result: 在MQUAKE基准测试中，ALEX显著提高了多跳答案准确率和推理路径可靠性，同时将所需搜索空间减少了80%以上。

Conclusion: ALEX为构建可扩展、高效且准确的知识编辑系统提供了一条有前景的路径。

Abstract: The static nature of knowledge within Large Language Models (LLMs) makes it difficult for them to adapt to evolving information, rendering knowledge editing a critical task. However, existing methods struggle with challenges of scalability and retrieval efficiency, particularly when handling complex, multi-hop questions that require multi-step reasoning. To address these challenges, this paper introduces ALEX (A Light Editing-knowledge Extractor), a lightweight knowledge editing framework. The core innovation of ALEX is its hierarchical memory architecture, which organizes knowledge updates (edits) into semantic clusters. This design fundamentally reduces retrieval complexity from a linear O(N) to a highly scalable O(K+N/C). Furthermore, the framework integrates an Inferential Query Synthesis (IQS) module to bridge the semantic gap between queries and facts , and a Dynamic Evidence Adjudication (DEA) engine that executes an efficient two-stage retrieval process. Experiments on the MQUAKE benchmark demonstrate that ALEX significantly improves both the accuracy of multi-hop answers (MultiHop-ACC) and the reliability of reasoning paths (HopWise-ACC). It also reduces the required search space by over 80% , presenting a promising path toward building scalable, efficient, and accurate knowledge editing systems.

</details>


### [75] [Syn-STARTS: Synthesized START Triage Scenario Generation Framework for Scalable LLM Evaluation](https://arxiv.org/abs/2511.14023)
*Chiharu Hagiwara,Naoki Nonaka,Yuhta Hashimoto,Ryu Uchimido,Jun Seita*

Main category: cs.AI

TL;DR: Syn-STARTS是一个使用LLM生成大规模分类案例的框架，用于解决大规模伤亡事件中AI训练数据不足的问题。该框架生成的分类案例在质量上与人工整理的数据集难以区分，且在不同分类类别中表现出高度稳定性。


<details>
  <summary>Details</summary>
Motivation: 大规模伤亡事件中的分类决策对提高受害者生存率至关重要。AI在此类场景中的应用需要大量高质量的基准数据集，但由于此类事件发生频率低且现场记录难以积累，获取真实世界数据具有挑战性。

Method: 开发了Syn-STARTS框架，利用大型语言模型生成分类案例。通过比较生成的案例与人工整理的TRIAGE开放数据集，验证了生成数据的质量。

Result: Syn-STARTS生成的分类案例在质量上与人工整理的数据集难以区分。在使用标准分类方法START定义的绿色、黄色、红色和黑色类别中，LLM的准确性评估结果表现出高度稳定性。

Conclusion: 合成数据在开发用于严重和危急医疗情况的高性能AI模型方面具有巨大潜力，为解决数据稀缺问题提供了可行方案。

Abstract: Triage is a critically important decision-making process in mass casualty incidents (MCIs) to maximize victim survival rates. While the role of AI in such situations is gaining attention for making optimal decisions within limited resources and time, its development and performance evaluation require benchmark datasets of sufficient quantity and quality. However, MCIs occur infrequently, and sufficient records are difficult to accumulate at the scene, making it challenging to collect large-scale realworld data for research use. Therefore, we developed Syn-STARTS, a framework that uses LLMs to generate triage cases, and verified its effectiveness. The results showed that the triage cases generated by Syn-STARTS were qualitatively indistinguishable from the TRIAGE open dataset generated by manual curation from training materials. Furthermore, when evaluating the LLM accuracy using hundreds of cases each from the green, yellow, red, and black categories defined by the standard triage method START, the results were found to be highly stable. This strongly indicates the possibility of synthetic data in developing high-performance AI models for severe and critical medical situations.

</details>


### [76] [Making Evidence Actionable in Adaptive Learning](https://arxiv.org/abs/2511.14052)
*Amirreza Mehrabi,Jason W. Morphew,Breejha Quezada,N. Sanjay Rebello*

Main category: cs.AI

TL;DR: 本文提出了一种教师主导的反馈循环系统，将概念级评估证据转化为经过验证的微干预措施，通过三种保障机制（充分性、注意力预算、多样性）实现可审计的自适应学习控制。


<details>
  <summary>Details</summary>
Motivation: 传统自适应学习系统诊断精准但干预薄弱，导致帮助时机不当或内容不匹配。需要建立诊断与教学之间的闭环，实现公平、负载感知的个性化教学。

Method: 将干预分配形式化为带约束的二元整数规划，包含覆盖度、时间、难度窗口、概念矩阵先决条件和反冗余多样性约束。采用贪心选择、基于梯度的松弛和混合方法三种求解器。

Result: 在1204名学生的物理课程部署中，两种求解器都能在有限观看时间内为几乎所有学习者实现完整的技能覆盖。基于梯度的方法比贪心方法减少约12%的冗余覆盖，并在难度分布上更均衡。

Conclusion: 该系统构建了一个可处理、可审计的控制器，闭合了诊断-教学循环，在课堂规模上实现了公平、负载感知的个性化教学。

Abstract: Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows informed by ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy enforced through diversity. Greedy selection serves low-richness and tight-latency regimes, gradient-based relaxation serves rich repositories, and a hybrid method transitions along a richness-latency frontier. In simulation and in an introductory physics deployment with one thousand two hundred four students, both solvers achieved full skill coverage for essentially all learners within bounded watch time. The gradient-based method reduced redundant coverage by approximately twelve percentage points relative to greedy and harmonized difficulty across slates, while greedy delivered comparable adequacy with lower computational cost in scarce settings. Slack variables localized missing content and supported targeted curation, sustaining sufficiency across subgroups. The result is a tractable and auditable controller that closes the diagnostic-pedagogical loop and delivers equitable, load-aware personalization at classroom scale.

</details>


### [77] [APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design](https://arxiv.org/abs/2511.14101)
*Xinpeng Chen,Xiaofeng Han,Kaihao Zhang,Guochao Ren,Yujie Wang,Wenhao Cao,Yang Zhou,Jianfeng Lu,Zhenbo Song*

Main category: cs.AI

TL;DR: APD-agents是一个基于大语言模型的多智能体框架，用于自动化移动应用页面设计，通过多个专业智能体的协作将用户描述转换为完整页面布局。


<details>
  <summary>Details</summary>
Motivation: 移动应用页面设计耗时且需要专业技能，现有设计软件学习成本高，跨页面协作设计需要额外时间保证一致性。

Method: 提出多智能体框架，包含编排智能体、语义解析智能体、主布局智能体、模板检索智能体和递归组件智能体，通过智能体协作将用户描述转换为结构化数据并生成页面布局。

Result: 在RICO数据集上的实验结果表明，APD-agents达到了最先进的性能水平。

Conclusion: 该工作充分利用了大模型驱动的多智能体系统的自动协作能力，能够有效自动化移动应用页面设计过程。

Abstract: Layout design is a crucial step in developing mobile app pages. However, crafting satisfactory designs is time-intensive for designers: they need to consider which controls and content to present on the page, and then repeatedly adjust their size, position, and style for better aesthetics and structure. Although many design software can now help to perform these repetitive tasks, extensive training is needed to use them effectively. Moreover, collaborative design across app pages demands extra time to align standards and ensure consistent styling. In this work, we propose APD-agents, a large language model (LLM) driven multi-agent framework for automated page design in mobile applications. Our framework contains OrchestratorAgent, SemanticParserAgent, PrimaryLayoutAgent, TemplateRetrievalAgent, and RecursiveComponentAgent. Upon receiving the user's description of the page, the OrchestratorAgent can dynamically can direct other agents to accomplish users' design task. To be specific, the SemanticParserAgent is responsible for converting users' descriptions of page content into structured data. The PrimaryLayoutAgent can generate an initial coarse-grained layout of this page. The TemplateRetrievalAgent can fetch semantically relevant few-shot examples and enhance the quality of layout generation. Besides, a RecursiveComponentAgent can be used to decide how to recursively generate all the fine-grained sub-elements it contains for each element in the layout. Our work fully leverages the automatic collaboration capabilities of large-model-driven multi-agent systems. Experimental results on the RICO dataset show that our APD-agents achieve state-of-the-art performance.

</details>


### [78] [Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation](https://arxiv.org/abs/2511.14131)
*Yu Zhong,Zihao Zhang,Rui Zhang,Lingdong Huang,Haihan Gao,Shuo Wang,Da Li,Ruijian Han,Jiaming Guo,Shaohui Peng,Di Huang,Yunji Chen*

Main category: cs.AI

TL;DR: 提出了R3双过程思维框架，将大型语言模型的泛化能力与视觉语言导航专家知识相结合，在零样本设置下显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的视觉语言导航方法存在空间理解不精确、计算成本高和推理延迟大的问题，与领域专家相比仍有较大性能差距。

Method: 设计了Runner、Ruminator和Regulator三个核心模块：Runner是轻量级专家模型负责常规导航，Ruminator使用多模态LLM进行结构化推理，Regulator根据三个标准监控进度并控制思维模式。

Result: 在REVERIE基准测试中，SPL和RGSPL分别超过最先进方法3.28%和3.30%，显著提升了挑战性VLN任务的处理效果。

Conclusion: R3框架有效整合了LLM的泛化能力和VLN专业知识，在保持高效性的同时显著提升了导航性能，证明了双过程思维框架的有效性。

Abstract: Vision-and-Language Navigation (VLN) requires an agent to dynamically explore complex 3D environments following human instructions. Recent research underscores the potential of harnessing large language models (LLMs) for VLN, given their commonsense knowledge and general reasoning capabilities. Despite their strengths, a substantial gap in task completion performance persists between LLM-based approaches and domain experts, as LLMs inherently struggle to comprehend real-world spatial correlations precisely. Additionally, introducing LLMs is accompanied with substantial computational cost and inference latency. To address these issues, we propose a novel dual-process thinking framework dubbed R3, integrating LLMs' generalization capabilities with VLN-specific expertise in a zero-shot manner. The framework comprises three core modules: Runner, Ruminator, and Regulator. The Runner is a lightweight transformer-based expert model that ensures efficient and accurate navigation under regular circumstances. The Ruminator employs a powerful multimodal LLM as the backbone and adopts chain-of-thought (CoT) prompting to elicit structured reasoning. The Regulator monitors the navigation progress and controls the appropriate thinking mode according to three criteria, integrating Runner and Ruminator harmoniously. Experimental results illustrate that R3 significantly outperforms other state-of-the-art methods, exceeding 3.28% and 3.30% in SPL and RGSPL respectively on the REVERIE benchmark. This pronounced enhancement highlights the effectiveness of our method in handling challenging VLN tasks.

</details>


### [79] [Do Large Language Models (LLMs) Understand Chronology?](https://arxiv.org/abs/2511.14214)
*Pattaraphon Kenny Wongchamcharoen,Paul Glasserman*

Main category: cs.AI

TL;DR: 论文测试了大型语言模型在金融经济学应用中理解时间顺序的能力，发现模型在处理长序列时难以保持全局一致的时间线，但通过增加推理预算可以显著改善性能。


<details>
  <summary>Details</summary>
Motivation: 测试大型语言模型是否真正理解时间顺序这一基本问题，因为金融经济学应用中基于提示的方法隐含假设模型理解时间顺序，但可能存在前瞻性偏差。

Method: 设计了一系列时间顺序任务，包括时间排序、条件排序（先筛选后排序）和时代错误检测，评估GPT-4.1、Claude-3.7 Sonnet（有/无扩展思维）和GPT-5在不同推理努力设置下的表现。

Result: 随着序列长度增加，精确匹配率急剧下降，但排名相关性保持较高；条件排序中大多数失败来自筛选步骤；时代错误检测是最简单的任务但性能仍会下降；GPT-5和带扩展思维的Claude-3.7 Sonnet表现显著优于普通模型。

Conclusion: 分配明确的推理预算有助于时间排序，GPT-5在中等/高推理努力下在所有长度上实现完美排序和完美条件排序；当前LLM在时间任务上存在局限性，推理有助于改善性能，这对金融实时应用具有重要意义。

Abstract: Large language models (LLMs) are increasingly used in finance and economics, where prompt-based attempts against look-ahead bias implicitly assume that models understand chronology. We test this fundamental question with a series of chronological ordering tasks with increasing complexities over facts the model already knows from pre-training. Our tasks cover (1) chronological ordering, (2) conditional sorting (filter, then order), and (3) anachronism detection. We evaluate GPT-4.1, Claude-3.7 Sonnet, with and without Extended Thinking (ET), and GPT-5 across multiple reasoning-effort settings. Across models, Exact match rate drops sharply as sequences lengthen even while rank correlations stay high as LLMs largely preserve local order but struggle to maintain a single globally consistent timeline. In conditional sorting, most failures stem from the filtering step rather than the ordering step, but GPT-5 and Claude-3.7 Sonnet with Extended Thinking outshine normal models significantly. Lastly, anachronism detection is found to be the easiest task for the LLMs but performance still declines with increasingly overlapping timelines or entities. Overall, our main contribution is showing that allocating explicit reasoning budget helps with chronological ordering with GPT-5 at medium/high reasoning effort achieving flawless ordering at all lengths and perfect conditional sorting (both self-filtered and given-subset), whereas low/minimal effort degrades with longer lists, mirroring earlier models. Our findings delineate limits of current LLMs on chronological tasks, providing insights into task complexity, and demonstrate scenarios in which reasoning helps. These patterns are important for the real-time application of LLMs in finance. We release all code and evaluation templates to support full reproducibility.

</details>


### [80] [Listen Like a Teacher: Mitigating Whisper Hallucinations using Adaptive Layer Attention and Knowledge Distillation](https://arxiv.org/abs/2511.14219)
*Kumud Tripathi,Aditya Srinivas Menon,Aman Gaurav,Raj Prakash Gohil,Pankaj Wasnik*

Main category: cs.AI

TL;DR: 本文提出了一种两阶段架构来减少Whisper模型在噪声环境下的幻觉错误，包括自适应层注意力机制和多目标知识蒸馏框架。


<details>
  <summary>Details</summary>
Motivation: Whisper模型在噪声环境下经常出现幻觉错误，而之前的工作主要关注音频预处理或转录后处理，对模型本身的修改研究较少。

Method: 第一阶段使用自适应层注意力将编码器层分组为语义连贯的块，通过多头注意力融合块表示；第二阶段使用多目标知识蒸馏框架，在噪声音频上训练学生模型，使其语义和注意力分布与处理干净输入的教师模型对齐。

Result: 在噪声语音基准测试中显著减少了幻觉错误和词错误率，同时在干净语音上保持了性能。

Conclusion: 自适应层注意力和知识蒸馏为在真实世界噪声条件下提高Whisper的可靠性提供了一种原则性策略。

Abstract: The Whisper model, an open-source automatic speech recognition system, is widely adopted for its strong performance across multilingual and zero-shot settings. However, it frequently suffers from hallucination errors, especially under noisy acoustic conditions. Previous works to reduce hallucinations in Whisper-style ASR systems have primarily focused on audio preprocessing or post-processing of transcriptions to filter out erroneous content. However, modifications to the Whisper model itself remain largely unexplored to mitigate hallucinations directly. To address this challenge, we present a two-stage architecture that first enhances encoder robustness through Adaptive Layer Attention (ALA) and further suppresses hallucinations using a multi-objective knowledge distillation (KD) framework. In the first stage, ALA groups encoder layers into semantically coherent blocks via inter-layer correlation analysis. A learnable multi-head attention module then fuses these block representations, enabling the model to jointly exploit low- and high-level features for more robust encoding. In the second stage, our KD framework trains the student model on noisy audio to align its semantic and attention distributions with a teacher model processing clean inputs. Our experiments on noisy speech benchmarks show notable reductions in hallucinations and word error rates, while preserving performance on clean speech. Together, ALA and KD offer a principled strategy to improve Whisper's reliability under real-world noisy conditions.

</details>


### [81] [DevPiolt: Operation Recommendation for IoT Devices at Xiaomi Home](https://arxiv.org/abs/2511.14227)
*Yuxiang Wang,Siwen Wang,Haowei Han,Ao Wang,Boya Liu,Yong Zhao,Chengbo Wu,Bin Zhu,Bin Qin,Xiaokai Zhou,Xiao Yan,Jiawei Jiang,Bo Du*

Main category: cs.AI

TL;DR: DevPiolt是一个基于大语言模型的物联网设备操作推荐系统，通过持续预训练、多任务微调、直接偏好优化和置信度控制机制，显著提升了推荐性能，已在小米家庭应用中实际部署。


<details>
  <summary>Details</summary>
Motivation: 现有推荐模型难以处理物联网设备操作的复杂逻辑、多样化用户偏好以及对次优建议的敏感性，限制了其在物联网设备操作推荐中的应用。

Method: 1. 通过持续预训练和多任务微调为LLM配备物联网操作领域知识；2. 使用直接偏好优化使微调后的LLM与特定用户偏好对齐；3. 设计基于置信度的曝光控制机制避免低质量推荐带来的负面用户体验。

Result: 在所有数据集上显著超越基线模型，所有指标平均提升69.5%；实际部署在小米家庭应用中一个季度，为25.5万用户提供日常操作推荐，在线实验显示独立访客设备覆盖率增加21.6%，页面浏览接受率增加29.1%。

Conclusion: DevPiolt成功解决了物联网设备操作推荐中的关键挑战，通过LLM技术和精心设计的优化策略实现了显著的性能提升和实际应用价值。

Abstract: Operation recommendation for IoT devices refers to generating personalized device operations for users based on their context, such as historical operations, environment information, and device status. This task is crucial for enhancing user satisfaction and corporate profits. Existing recommendation models struggle with complex operation logic, diverse user preferences, and sensitive to suboptimal suggestions, limiting their applicability to IoT device operations. To address these issues, we propose DevPiolt, a LLM-based recommendation model for IoT device operations. Specifically, we first equip the LLM with fundamental domain knowledge of IoT operations via continual pre-training and multi-task fine-tuning. Then, we employ direct preference optimization to align the fine-tuned LLM with specific user preferences. Finally, we design a confidence-based exposure control mechanism to avoid negative user experiences from low-quality recommendations. Extensive experiments show that DevPiolt significantly outperforms baselines on all datasets, with an average improvement of 69.5% across all metrics. DevPiolt has been practically deployed in Xiaomi Home app for one quarter, providing daily operation recommendations to 255,000 users. Online experiment results indicate a 21.6% increase in unique visitor device coverage and a 29.1% increase in page view acceptance rates.

</details>


### [82] [Enhancing Regional Airbnb Trend Forecasting Using LLM-Based Embeddings of Accessibility and Human Mobility](https://arxiv.org/abs/2511.14248)
*Hongju Lee,Youngjun Park,Jisun An,Dongman Lee*

Main category: cs.AI

TL;DR: 提出了一种新颖的时间序列预测框架，用于预测区域层面的Airbnb关键指标（收入、预订天数、预订数量），通过结合房源特征和外部环境因素构建区域表示，使用LLM生成区域嵌入，再输入时间序列模型进行预测。


<details>
  <summary>Details</summary>
Motivation: 短期租赁平台（如Airbnb）的扩张扰乱了当地住房市场，导致租金上涨和住房负担能力问题。准确预测区域Airbnb市场趋势可为政策制定者和城市规划者提供关键见解。

Method: 采用滑动窗口方法预测1-3个月趋势，将结构化表格数据转换为基于提示的LLM输入以生成全面的区域嵌入，然后将这些嵌入输入到先进的时间序列模型（RNN、LSTM、Transformer）中。

Result: 在首尔Airbnb数据集上的实验表明，与传统基线相比，该方法将平均RMSE和MAE降低了约48%。

Conclusion: 该框架不仅提高了预测准确性，还为检测供应过剩区域和支持数据驱动的城市政策决策提供了实用见解。

Abstract: The expansion of short-term rental platforms, such as Airbnb, has significantly disrupted local housing markets, often leading to increased rental prices and housing affordability issues. Accurately forecasting regional Airbnb market trends can thus offer critical insights for policymakers and urban planners aiming to mitigate these impacts. This study proposes a novel time-series forecasting framework to predict three key Airbnb indicators -- Revenue, Reservation Days, and Number of Reservations -- at the regional level. Using a sliding-window approach, the model forecasts trends 1 to 3 months ahead. Unlike prior studies that focus on individual listings at fixed time points, our approach constructs regional representations by integrating listing features with external contextual factors such as urban accessibility and human mobility. We convert structured tabular data into prompt-based inputs for a Large Language Model (LLM), producing comprehensive regional embeddings. These embeddings are then fed into advanced time-series models (RNN, LSTM, Transformer) to better capture complex spatio-temporal dynamics. Experiments on Seoul's Airbnb dataset show that our method reduces both average RMSE and MAE by approximately 48% compared to conventional baselines, including traditional statistical and machine learning models. Our framework not only improves forecasting accuracy but also offers practical insights for detecting oversupplied regions and supporting data-driven urban policy decisions.

</details>


### [83] [PathMind: A Retrieve-Prioritize-Reason Framework for Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2511.14256)
*Yu Liu,Xixun Lin,Yanmin Shang,Yangxi Li,Shi Wang,Yanan Cao*

Main category: cs.AI

TL;DR: PathMind是一个新颖的知识图谱推理框架，通过选择性引导LLM使用重要推理路径来增强忠实和可解释的推理。它采用"检索-优先排序-推理"范式，包含路径优先排序机制和双阶段训练策略，在复杂推理任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的知识图谱推理方法存在两个关键限制：1）不加区分地提取推理路径，可能引入无关噪声误导LLM；2）动态探索推理路径需要高检索需求和频繁的LLM调用。

Method: PathMind采用"检索-优先排序-推理"范式：1）通过检索模块从KG中检索查询子图；2）引入路径优先排序机制，使用语义感知路径优先级函数识别重要推理路径；3）通过双阶段训练策略（任务特定指令调优和路径偏好对齐）生成准确且逻辑一致的响应。

Result: 在基准数据集上的广泛实验表明，PathMind始终优于竞争基线方法，特别是在复杂推理任务上，通过识别基本推理路径，使用更少的输入token实现了更好的性能。

Conclusion: PathMind通过选择性引导LLM使用重要推理路径，有效解决了现有方法中的噪声问题和效率问题，在知识图谱推理任务中实现了更忠实、可解释且高效的推理性能。

Abstract: Knowledge graph reasoning (KGR) is the task of inferring new knowledge by performing logical deductions on knowledge graphs. Recently, large language models (LLMs) have demonstrated remarkable performance in complex reasoning tasks. Despite promising success, current LLM-based KGR methods still face two critical limitations. First, existing methods often extract reasoning paths indiscriminately, without assessing their different importance, which may introduce irrelevant noise that misleads LLMs. Second, while many methods leverage LLMs to dynamically explore potential reasoning paths, they require high retrieval demands and frequent LLM calls. To address these limitations, we propose PathMind, a novel framework designed to enhance faithful and interpretable reasoning by selectively guiding LLMs with important reasoning paths. Specifically, PathMind follows a "Retrieve-Prioritize-Reason" paradigm. First, it retrieves a query subgraph from KG through the retrieval module. Next, it introduces a path prioritization mechanism that identifies important reasoning paths using a semantic-aware path priority function, which simultaneously considers the accumulative cost and the estimated future cost for reaching the target. Finally, PathMind generates accurate and logically consistent responses via a dual-phase training strategy, including task-specific instruction tuning and path-wise preference alignment. Extensive experiments on benchmark datasets demonstrate that PathMind consistently outperforms competitive baselines, particularly on complex reasoning tasks with fewer input tokens, by identifying essential reasoning paths.

</details>


### [84] [DataSage: Multi-agent Collaboration for Insight Discovery with External Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning](https://arxiv.org/abs/2511.14299)
*Xiaochuan Liu,Yuanfeng Song,Xiaoming Yin,Xing Chen*

Main category: cs.AI

TL;DR: DataSage是一个新颖的多智能体框架，通过外部知识检索、多角色辩论机制和多路径推理来解决现有数据洞察智能体在领域知识利用不足、分析深度浅和代码生成易出错的问题，在InsightBench上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在数据驱动时代，全自动端到端数据分析特别是洞察发现对于组织决策至关重要。现有数据洞察智能体存在领域知识利用不足、分析深度浅、代码生成易出错等限制，无法提供满意结果。

Method: 提出DataSage多智能体框架，包含三个创新特征：外部知识检索丰富分析上下文、多角色辩论机制模拟多样化分析视角加深分析深度、多路径推理提高生成代码和洞察的准确性。

Result: 在InsightBench上的广泛实验表明，DataSage在所有难度级别上都持续优于现有数据洞察智能体。

Conclusion: DataSage为自动化数据洞察发现提供了一个有效的解决方案。

Abstract: In today's data-driven era, fully automated end-to-end data analytics, particularly insight discovery, is critical for discovering actionable insights that assist organizations in making effective decisions. With the rapid advancement of large language models (LLMs), LLM-driven agents have emerged as a promising paradigm for automating data analysis and insight discovery. However, existing data insight agents remain limited in several key aspects, often failing to deliver satisfactory results due to: (1) insufficient utilization of domain knowledge, (2) shallow analytical depth, and (3) error-prone code generation during insight generation. To address these issues, we propose DataSage, a novel multi-agent framework that incorporates three innovative features including external knowledge retrieval to enrich the analytical context, a multi-role debating mechanism to simulate diverse analytical perspectives and deepen analytical depth, and multi-path reasoning to improve the accuracy of the generated code and insights. Extensive experiments on InsightBench demonstrate that DataSage consistently outperforms existing data insight agents across all difficulty levels, offering an effective solution for automated data insight discovery.

</details>


### [85] [When Words Change the Model: Sensitivity of LLMs for Constraint Programming Modelling](https://arxiv.org/abs/2511.14334)
*Alessio Pellegrino,Jacopo Mauro*

Main category: cs.AI

TL;DR: 本文通过重新表述和扰动经典的CSPLib问题来测试LLMs在优化和约束编程中的模型生成能力，发现LLMs的表现受数据污染影响较大，对上下文和语言变化敏感。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在自动生成优化和约束编程模型方面的真实能力，检验其表现是否源于数据污染而非真正的推理能力。

Method: 系统性地重新表述和扰动一组著名的CSPLib问题，保持结构不变但修改上下文并引入误导元素，比较三个代表性LLM在原始和修改描述下生成的模型。

Result: LLMs能生成语法有效且语义合理的模型，但在上下文和语言变化下性能急剧下降，显示出浅层理解和对措辞的敏感性。

Conclusion: LLMs在优化和约束编程中的模型生成能力很大程度上依赖于训练数据中的问题，缺乏真正的推理能力，对语言变化敏感。

Abstract: One of the long-standing goals in optimisation and constraint programming is to describe a problem in natural language and automatically obtain an executable, efficient model. Large language models appear to bring this vision closer, showing impressive results in automatically generating models for classical benchmarks. However, much of this apparent success may derive from data contamination rather than genuine reasoning: many standard CP problems are likely included in the training data of these models. To examine this hypothesis, we systematically rephrased and perturbed a set of well-known CSPLib problems to preserve their structure while modifying their context and introducing misleading elements. We then compared the models produced by three representative LLMs across original and modified descriptions. Our qualitative analysis shows that while LLMs can produce syntactically valid and semantically plausible models, their performance drops sharply under contextual and linguistic variation, revealing shallow understanding and sensitivity to wording.

</details>


### [86] [Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior](https://arxiv.org/abs/2511.14476)
*Dalia Ali,Dora Zhao,Allison Koenecke,Orestis Papakyriakopoulos*

Main category: cs.AI

TL;DR: 本研究探讨了在LLM对齐过程中纳入多元人类价值观的影响，发现人口统计学因素和技术设计选择都会显著影响模型行为。


<details>
  <summary>Details</summary>
Motivation: 当前LLM对齐决策往往忽视人类社会的多样性，需要研究如何将多元价值观纳入对齐流程以确保公平代表性。

Method: 收集美国德国1095名参与者的27,375个评分，从毒性、情感意识等五个维度评估LLM回复，并对不同社会群体的偏好进行模型微调，同时比较评分尺度、分歧处理方法和优化技术。

Result: 发现系统性人口统计学效应：男性评分毒性低18%，保守派和黑人评分情感意识高27.9%和44%；技术选择影响显著：保留分歧比多数投票毒性减少53%，5点量表比二元格式减少22%，DPO优于GRPO。

Conclusion: 这是回答对齐如何平衡专家驱动和用户驱动信号以确保安全性和公平代表性的初步步骤，强调了多元价值观纳入的重要性。

Abstract: Although large language models (LLMs) are increasingly trained using human feedback for safety and alignment with human values, alignment decisions often overlook human social diversity. This study examines how incorporating pluralistic values affects LLM behavior by systematically evaluating demographic variation and design parameters in the alignment pipeline. We collected alignment data from US and German participants (N = 1,095, 27,375 ratings) who rated LLM responses across five dimensions: Toxicity, Emotional Awareness (EA), Sensitivity, Stereotypical Bias, and Helpfulness. We fine-tuned multiple Large Language Models and Large Reasoning Models using preferences from different social groups while varying rating scales, disagreement handling methods, and optimization techniques. The results revealed systematic demographic effects: male participants rated responses 18% less toxic than female participants; conservative and Black participants rated responses 27.9% and 44% more emotionally aware than liberal and White participants, respectively. Models fine-tuned on group-specific preferences exhibited distinct behaviors. Technical design choices showed strong effects: the preservation of rater disagreement achieved roughly 53% greater toxicity reduction than majority voting, and 5-point scales yielded about 22% more reduction than binary formats; and Direct Preference Optimization (DPO) consistently outperformed Group Relative Policy Optimization (GRPO) in multi-value optimization. These findings represent a preliminary step in answering a critical question: How should alignment balance expert-driven and user-driven signals to ensure both safety and fair representation?

</details>


### [87] [Rate-Distortion Guided Knowledge Graph Construction from Lecture Notes Using Gromov-Wasserstein Optimal Transport](https://arxiv.org/abs/2511.14595)
*Yuan An,Ruhma Hashmi,Michelle Rogers,Jane Greenberg,Brian K. Smith*

Main category: cs.AI

TL;DR: 提出基于率失真理论和最优传输几何的知识图谱构建与优化框架，用于从非结构化教学材料生成高质量选择题。


<details>
  <summary>Details</summary>
Motivation: 解决将非结构化教学材料（如讲义和幻灯片）转换为能够捕捉关键教学内容的知识图谱的困难，以支持AI驱动的学习助手系统自动生成高质量选择题。

Method: 将教学内容建模为度量-测度空间，使用融合Gromov-Wasserstein耦合量化语义失真，通过精炼操作（添加、合并、拆分、移除、重连）最小化率失真拉格朗日量，生成紧凑且信息保留的知识图谱。

Result: 在数据科学课程上的原型应用显示，从优化后知识图谱生成的选择题在15个质量标准上持续优于从原始笔记生成的选择题，并产生可解释的率失真曲线。

Conclusion: 本研究为个性化教育和AI辅助教育中的信息论知识图谱优化建立了理论基础。

Abstract: Task-oriented knowledge graphs (KGs) enable AI-powered learning assistant systems to automatically generate high-quality multiple-choice questions (MCQs). Yet converting unstructured educational materials, such as lecture notes and slides, into KGs that capture key pedagogical content remains difficult. We propose a framework for knowledge graph construction and refinement grounded in rate-distortion (RD) theory and optimal transport geometry. In the framework, lecture content is modeled as a metric-measure space, capturing semantic and relational structure, while candidate KGs are aligned using Fused Gromov-Wasserstein (FGW) couplings to quantify semantic distortion. The rate term, expressed via the size of KG, reflects complexity and compactness. Refinement operators (add, merge, split, remove, rewire) minimize the rate-distortion Lagrangian, yielding compact, information-preserving KGs. Our prototype applied to data science lectures yields interpretable RD curves and shows that MCQs generated from refined KGs consistently surpass those from raw notes on fifteen quality criteria. This study establishes a principled foundation for information-theoretic KG optimization in personalized and AI-assisted education.

</details>
