{"id": "2512.14965", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2512.14965", "abs": "https://arxiv.org/abs/2512.14965", "authors": ["Renkai Ma", "Dominique Geissler", "Stefan Feuerriegel", "Tobias Lauinger", "Damon McCoy", "Pamela Wisniewski"], "title": "Analyzing Social Media Claims regarding Youth Online Safety Features to Identify Problem Areas and Communication Gaps", "comment": "Accepted to ACM CSCW 2026. 31 pages", "summary": "Social media platforms have faced increasing scrutiny over whether and how they protect youth online. While online risks to children have been well-documented by prior research, how social media platforms communicate about these risks and their efforts to improve youth safety have not been holistically examined. To fill this gap, we analyzed N=352 press releases and safety-related blogs published between 2019 and 2024 by four platforms popular among youth: YouTube, TikTok, Meta (Facebook and Instagram), and Snapchat. Leveraging both inductive and deductive qualitative approaches, we developed a comprehensive framework of seven problem areas where risks arise, and a taxonomy of safety features that social media platforms claim address these risks. Our analysis revealed uneven emphasis across problem areas, with most communications focused on Content Exposure and Interpersonal Communication, whereas less emphasis was placed on Content Creation, Data Access, and Platform Access. Additionally, we identified three problematic communication practices related to their described safety features, including discrepancies between feature implementation and availability, unclear or inconsistent explanations of safety feature operation, and a lack of evidence regarding the effectiveness of safety features in mitigating risks once implemented. Based on these findings, we discuss the communication gaps between risks and the described safety features, as well as the tensions in achieving transparency in platform communication. Our analysis of platform communication informs guidelines for responsibly communicating about youth safety features.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86YouTube\u3001TikTok\u3001Meta\u548cSnapchat\u57282019-2024\u5e74\u95f4\u53d1\u5e03\u7684352\u4efd\u65b0\u95fb\u7a3f\u548c\u5b89\u5168\u76f8\u5173\u535a\u5ba2\uff0c\u5f00\u53d1\u4e86\u9752\u5c11\u5e74\u5728\u7ebf\u98ce\u9669\u7684\u4e03\u4e2a\u95ee\u9898\u9886\u57df\u6846\u67b6\u548c\u5b89\u5168\u529f\u80fd\u5206\u7c7b\uff0c\u53d1\u73b0\u5e73\u53f0\u6c9f\u901a\u5b58\u5728\u4e0d\u5747\u8861\u91cd\u70b9\u548c\u4e09\u4e2a\u6709\u95ee\u9898\u7684\u6c9f\u901a\u5b9e\u8df5\u3002", "motivation": "\u867d\u7136\u9752\u5c11\u5e74\u5728\u7ebf\u98ce\u9669\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u5982\u4f55\u6c9f\u901a\u8fd9\u4e9b\u98ce\u9669\u53ca\u5176\u5b89\u5168\u6539\u8fdb\u63aa\u65bd\u5c1a\u672a\u5f97\u5230\u5168\u9762\u8003\u5bdf\u3002\u968f\u7740\u5e73\u53f0\u9762\u4e34\u8d8a\u6765\u8d8a\u4e25\u683c\u7684\u5ba1\u67e5\uff0c\u9700\u8981\u4e86\u89e3\u5b83\u4eec\u5982\u4f55\u5411\u516c\u4f17\u4f20\u8fbe\u9752\u5c11\u5e74\u5b89\u5168\u4fdd\u62a4\u63aa\u65bd\u3002", "method": "\u91c7\u7528\u5f52\u7eb3\u548c\u6f14\u7ece\u76f8\u7ed3\u5408\u7684\u5b9a\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u56db\u4e2a\u9752\u5c11\u5e74\u5e38\u7528\u5e73\u53f0\uff08YouTube\u3001TikTok\u3001Meta\u3001Snapchat\uff09\u57282019-2024\u5e74\u95f4\u53d1\u5e03\u7684352\u4efd\u65b0\u95fb\u7a3f\u548c\u5b89\u5168\u76f8\u5173\u535a\u5ba2\uff0c\u5f00\u53d1\u4e86\u98ce\u9669\u95ee\u9898\u9886\u57df\u6846\u67b6\u548c\u5b89\u5168\u529f\u80fd\u5206\u7c7b\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u5e73\u53f0\u6c9f\u901a\u91cd\u70b9\u4e0d\u5747\u8861\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728\u5185\u5bb9\u66b4\u9732\u548c\u4eba\u9645\u6c9f\u901a\u98ce\u9669\uff0c\u800c\u5bf9\u5185\u5bb9\u521b\u4f5c\u3001\u6570\u636e\u8bbf\u95ee\u548c\u5e73\u53f0\u8bbf\u95ee\u5173\u6ce8\u8f83\u5c11\uff1b2\uff09\u8bc6\u522b\u51fa\u4e09\u4e2a\u6709\u95ee\u9898\u7684\u6c9f\u901a\u5b9e\u8df5\uff1a\u529f\u80fd\u5b9e\u65bd\u4e0e\u53ef\u7528\u6027\u4e0d\u4e00\u81f4\u3001\u5b89\u5168\u529f\u80fd\u64cd\u4f5c\u89e3\u91ca\u4e0d\u6e05\u6670\u6216\u4e0d\u4e00\u81f4\u3001\u7f3a\u4e4f\u529f\u80fd\u6709\u6548\u6027\u7684\u8bc1\u636e\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5e73\u53f0\u6c9f\u901a\u4e2d\u98ce\u9669\u4e0e\u5b89\u5168\u529f\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4ee5\u53ca\u5b9e\u73b0\u900f\u660e\u5ea6\u6c9f\u901a\u7684\u5f20\u529b\u3002\u5206\u6790\u7ed3\u679c\u4e3a\u8d1f\u8d23\u4efb\u5730\u6c9f\u901a\u9752\u5c11\u5e74\u5b89\u5168\u529f\u80fd\u63d0\u4f9b\u4e86\u6307\u5bfc\u65b9\u9488\uff0c\u6709\u52a9\u4e8e\u6539\u5584\u5e73\u53f0\u5728\u9752\u5c11\u5e74\u5b89\u5168\u4fdd\u62a4\u65b9\u9762\u7684\u900f\u660e\u5ea6\u3002"}}
{"id": "2512.14977", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2512.14977", "abs": "https://arxiv.org/abs/2512.14977", "authors": ["Stuart Winby", "Wei Xu"], "title": "Human-Centered AI Maturity Model (HCAI-MM): An Organizational Design Perspective", "comment": null, "summary": "Human-centered artificial intelligence (HCAI) is an approach to AI design, development, and deployment that prioritizes human needs, values, and experiences, ensuring that technology enhances human capabilities, well-being, and workforce empowerment. While HCAI has gained prominence in academic discourse and organizational practice, its implementation remains constrained by the absence of methodological guidance and structured frameworks. In particular, HCAI and organizational design practices are often treated separately, despite their interdependence in shaping effective socio-technical systems. This chapter addresses this gap by introducing the Human-Centered AI Maturity Model (HCAI-MM), a structured framework that enables organizations to evaluate, monitor, and advance their capacity to design and implement HCAI solutions. The model specifies stages of maturity, metrics, tools, governance mechanisms, and best practices, supported by case studies, while also incorporating an organizational design methodology that operationalizes maturity progression. Encompassing dimensions such as human-AI collaboration, explainability, fairness, and user experience, the HCAI-MM provides a roadmap for organizations to move from novice to advanced levels of maturity, aligning AI technologies with human values and organizational design principles.", "AI": {"tldr": "\u63d0\u51fa\u4e86HCAI-MM\u6210\u719f\u5ea6\u6a21\u578b\uff0c\u5e2e\u52a9\u7ec4\u7ec7\u8bc4\u4f30\u548c\u63d0\u5347\u4ee5\u4eba\u4e3a\u672cAI\u7684\u8bbe\u8ba1\u4e0e\u5b9e\u65bd\u80fd\u529b\uff0c\u5c06AI\u6280\u672f\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u548c\u7ec4\u7ec7\u8bbe\u8ba1\u539f\u5219\u76f8\u7ed3\u5408\u3002", "motivation": "\u867d\u7136\u4ee5\u4eba\u4e3a\u672c\u7684\u4eba\u5de5\u667a\u80fd\uff08HCAI\uff09\u5728\u5b66\u672f\u8ba8\u8bba\u548c\u7ec4\u7ec7\u5b9e\u8df5\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u5176\u5b9e\u65bd\u53d7\u5230\u65b9\u6cd5\u8bba\u6307\u5bfc\u548c\u7ed3\u6784\u5316\u6846\u67b6\u7f3a\u4e4f\u7684\u9650\u5236\u3002\u7279\u522b\u662fHCAI\u548c\u7ec4\u7ec7\u8bbe\u8ba1\u5b9e\u8df5\u5f80\u5f80\u88ab\u5206\u5f00\u5904\u7406\uff0c\u5c3d\u7ba1\u5b83\u4eec\u5728\u5851\u9020\u6709\u6548\u7684\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u4e2d\u76f8\u4e92\u4f9d\u5b58\u3002", "method": "\u63d0\u51fa\u4e86HCAI-MM\u6210\u719f\u5ea6\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5b9a\u4e49\u4e86\u6210\u719f\u5ea6\u9636\u6bb5\u3001\u6307\u6807\u3001\u5de5\u5177\u3001\u6cbb\u7406\u673a\u5236\u548c\u6700\u4f73\u5b9e\u8df5\uff0c\u5e76\u6574\u5408\u4e86\u7ec4\u7ec7\u8bbe\u8ba1\u65b9\u6cd5\u8bba\u6765\u64cd\u4f5c\u5316\u6210\u719f\u5ea6\u63d0\u5347\u8fc7\u7a0b\u3002", "result": "HCAI-MM\u6a21\u578b\u6db5\u76d6\u4e86\u4eba\u673a\u534f\u4f5c\u3001\u53ef\u89e3\u91ca\u6027\u3001\u516c\u5e73\u6027\u548c\u7528\u6237\u4f53\u9a8c\u7b49\u7ef4\u5ea6\uff0c\u4e3a\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u4ece\u65b0\u624b\u5230\u9ad8\u7ea7\u6210\u719f\u5ea6\u6c34\u5e73\u7684\u8def\u7ebf\u56fe\u3002", "conclusion": "HCAI-MM\u6846\u67b6\u4f7f\u7ec4\u7ec7\u80fd\u591f\u8bc4\u4f30\u3001\u76d1\u63a7\u548c\u63d0\u5347\u5176\u8bbe\u8ba1\u548c\u5b9e\u65bd\u4ee5\u4eba\u4e3a\u672cAI\u89e3\u51b3\u65b9\u6848\u7684\u80fd\u529b\uff0c\u5c06AI\u6280\u672f\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u548c\u7ec4\u7ec7\u8bbe\u8ba1\u539f\u5219\u5bf9\u9f50\u3002"}}
{"id": "2512.15117", "categories": ["cs.HC", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.15117", "abs": "https://arxiv.org/abs/2512.15117", "authors": ["Pilyoung Kim", "Yun Xie", "Sujin Yang"], "title": "I am here for you\": How relational conversational AI appeals to adolescents, especially those who are socially and emotionally vulnerable", "comment": null, "summary": "General-purpose conversational AI chatbots and AI companions increasingly provide young adolescents with emotionally supportive conversations, raising questions about how conversational style shapes anthropomorphism and emotional reliance. In a preregistered online experiment with 284 adolescent-parent dyads, youth aged 11-15 and their parents read two matched transcripts in which a chatbot responded to an everyday social problem using either a relational style (first-person, affiliative, commitment language) or a transparent style (explicit nonhumanness, informational tone). Adolescents more often preferred the relational than the transparent style, whereas parents were more likely to prefer transparent style than adolescents. Adolescents rated the relational chatbot as more human-like, likable, trustworthy and emotionally close, while perceiving both styles as similarly helpful. Adolescents who preferred relational style had lower family and peer relationship quality and higher stress and anxiety than those preferring transparent style or both chatbots. These findings identify conversational style as a key design lever for youth AI safety, showing that relational framing heightens anthropomorphism, trust and emotional closeness and can be especially appealing to socially and emotionally vulnerable adolescents, who may be at increased risk for emotional reliance on conversational AI.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u804a\u5929\u673a\u5668\u4eba\u7684\u5bf9\u8bdd\u98ce\u683c\uff08\u5173\u7cfb\u578bvs\u900f\u660e\u578b\uff09\u663e\u8457\u5f71\u54cd\u9752\u5c11\u5e74\u5bf9\u5176\u62df\u4eba\u5316\u611f\u77e5\u548c\u60c5\u611f\u4f9d\u8d56\uff0c\u5173\u7cfb\u578b\u98ce\u683c\u66f4\u53d7\u9752\u5c11\u5e74\u559c\u7231\u4f46\u53ef\u80fd\u589e\u52a0\u60c5\u611f\u4f9d\u8d56\u98ce\u9669", "motivation": "\u968f\u7740\u901a\u7528\u5bf9\u8bddAI\u548cAI\u4f34\u4fa3\u8d8a\u6765\u8d8a\u591a\u5730\u4e3a\u9752\u5c11\u5e74\u63d0\u4f9b\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\uff0c\u9700\u8981\u7814\u7a76\u5bf9\u8bdd\u98ce\u683c\u5982\u4f55\u5f71\u54cd\u62df\u4eba\u5316\u611f\u77e5\u548c\u60c5\u611f\u4f9d\u8d56\uff0c\u7279\u522b\u662f\u5bf9\u9752\u5c11\u5e74AI\u5b89\u5168\u7684\u8bbe\u8ba1\u8003\u91cf", "method": "\u901a\u8fc7\u9884\u6ce8\u518c\u7684\u5728\u7ebf\u5b9e\u9a8c\uff0c\u62db\u52df284\u5bf9\u9752\u5c11\u5e74-\u7236\u6bcd\u7ec4\u5408\uff0c\u8ba911-15\u5c81\u9752\u5c11\u5e74\u53ca\u5176\u7236\u6bcd\u9605\u8bfb\u4e24\u79cd\u4e0d\u540c\u5bf9\u8bdd\u98ce\u683c\u7684\u804a\u5929\u673a\u5668\u4eba\u56de\u5e94\u65e5\u5e38\u793e\u4ea4\u95ee\u9898\u7684\u5bf9\u8bdd\u8bb0\u5f55\uff1a\u5173\u7cfb\u578b\u98ce\u683c\uff08\u7b2c\u4e00\u4eba\u79f0\u3001\u4eb2\u548c\u6027\u3001\u627f\u8bfa\u6027\u8bed\u8a00\uff09\u548c\u900f\u660e\u578b\u98ce\u683c\uff08\u660e\u786e\u975e\u4eba\u7c7b\u6027\u3001\u4fe1\u606f\u6027\u8bed\u8c03\uff09", "result": "\u9752\u5c11\u5e74\u66f4\u504f\u597d\u5173\u7cfb\u578b\u98ce\u683c\uff0c\u800c\u7236\u6bcd\u66f4\u53ef\u80fd\u504f\u597d\u900f\u660e\u578b\u98ce\u683c\uff1b\u9752\u5c11\u5e74\u8ba4\u4e3a\u5173\u7cfb\u578b\u804a\u5929\u673a\u5668\u4eba\u66f4\u50cf\u4eba\u7c7b\u3001\u66f4\u8ba8\u4eba\u559c\u6b22\u3001\u66f4\u503c\u5f97\u4fe1\u4efb\u4e14\u60c5\u611f\u4e0a\u66f4\u4eb2\u8fd1\uff0c\u4f46\u8ba4\u4e3a\u4e24\u79cd\u98ce\u683c\u540c\u6837\u6709\u5e2e\u52a9\uff1b\u504f\u597d\u5173\u7cfb\u578b\u98ce\u683c\u7684\u9752\u5c11\u5e74\u5bb6\u5ead\u548c\u540c\u4f34\u5173\u7cfb\u8d28\u91cf\u8f83\u4f4e\uff0c\u538b\u529b\u548c\u7126\u8651\u6c34\u5e73\u8f83\u9ad8", "conclusion": "\u5bf9\u8bdd\u98ce\u683c\u662f\u9752\u5c11\u5e74AI\u5b89\u5168\u7684\u5173\u952e\u8bbe\u8ba1\u6760\u6746\uff0c\u5173\u7cfb\u578b\u6846\u67b6\u589e\u5f3a\u4e86\u62df\u4eba\u5316\u3001\u4fe1\u4efb\u548c\u60c5\u611f\u4eb2\u8fd1\uff0c\u5c24\u5176\u5438\u5f15\u793e\u4ea4\u548c\u60c5\u611f\u8106\u5f31\u7684\u9752\u5c11\u5e74\uff0c\u8fd9\u4e9b\u9752\u5c11\u5e74\u53ef\u80fd\u9762\u4e34\u5bf9\u5bf9\u8bddAI\u60c5\u611f\u4f9d\u8d56\u7684\u66f4\u9ad8\u98ce\u9669"}}
{"id": "2512.14709", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14709", "abs": "https://arxiv.org/abs/2512.14709", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Attention as Binding: A Vector-Symbolic Perspective on Transformer Reasoning", "comment": "12 pages with references. Submitted to 'Logical and Symbolic Reasoning in Language Models @ AAAI 2026' conference and is under review", "summary": "Transformer-based language models display impressive reasoning-like behavior, yet remain brittle on tasks that require stable symbolic manipulation. This paper develops a unified perspective on these phenomena by interpreting self-attention and residual streams as implementing an approximate Vector Symbolic Architecture (VSA). In this view, queries and keys define role spaces, values encode fillers, attention weights perform soft unbinding, and residual connections realize superposition of many bound structures. We use this algebraic lens to relate transformer internals to chain-of-thought traces, program-based reasoning, and memory-augmented tool use, and to explain characteristic failure modes such as variable confusion and inconsistency across logically related prompts. Building on this perspective, we propose VSA-inspired architectural biases, including explicit binding/unbinding heads and hyperdimensional memory layers, and training objectives that promote role-filler separation and robust superposition. Finally, we outline metrics for measuring \"VSA-likeness\" and logical compositionality, and pose theoretical and architectural open problems. Overall, the paper argues that viewing attention as soft vector-symbolic computation offers a principled route toward more interpretable and logically reliable reasoning systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06Transformer\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u6b8b\u5dee\u6d41\u89e3\u91ca\u4e3a\u8fd1\u4f3c\u7684\u5411\u91cf\u7b26\u53f7\u67b6\u6784\uff0c\u4ee5\u6b64\u7edf\u4e00\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u884c\u4e3a\u53ca\u5176\u5728\u7b26\u53f7\u64cd\u4f5c\u4e0a\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u51fa\u7c7b\u4f3c\u63a8\u7406\u7684\u884c\u4e3a\uff0c\u4f46\u5728\u9700\u8981\u7a33\u5b9a\u7b26\u53f7\u64cd\u4f5c\u7684\u4efb\u52a1\u4e0a\u4ecd\u7136\u8106\u5f31\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5411\u91cf\u7b26\u53f7\u67b6\u6784\u7684\u7edf\u4e00\u89c6\u89d2\u6765\u89e3\u91ca\u8fd9\u4e9b\u73b0\u8c61\uff0c\u4e3a\u6784\u5efa\u66f4\u5177\u89e3\u91ca\u6027\u548c\u903b\u8f91\u53ef\u9760\u6027\u7684\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5c06\u81ea\u6ce8\u610f\u529b\u673a\u5236\u89e3\u91ca\u4e3a\u8fd1\u4f3c\u7684\u5411\u91cf\u7b26\u53f7\u67b6\u6784\uff1a\u67e5\u8be2\u548c\u952e\u5b9a\u4e49\u89d2\u8272\u7a7a\u95f4\uff0c\u503c\u7f16\u7801\u586b\u5145\u7269\uff0c\u6ce8\u610f\u529b\u6743\u91cd\u6267\u884c\u8f6f\u89e3\u7ed1\uff0c\u6b8b\u5dee\u8fde\u63a5\u5b9e\u73b0\u591a\u4e2a\u7ed1\u5b9a\u7ed3\u6784\u7684\u53e0\u52a0\u3002\u57fa\u4e8e\u6b64\u89c6\u89d2\uff0c\u63d0\u51fa\u4e86VSA\u542f\u53d1\u7684\u67b6\u6784\u504f\u7f6e\uff0c\u5305\u62ec\u663e\u5f0f\u7684\u7ed1\u5b9a/\u89e3\u7ed1\u5934\u548c\u8d85\u7ef4\u5185\u5b58\u5c42\uff0c\u4ee5\u53ca\u4fc3\u8fdb\u89d2\u8272-\u586b\u5145\u5206\u79bb\u548c\u9c81\u68d2\u53e0\u52a0\u7684\u8bad\u7ec3\u76ee\u6807\u3002", "result": "\u5efa\u7acb\u4e86Transformer\u5185\u90e8\u673a\u5236\u4e0e\u601d\u7ef4\u94fe\u8ffd\u8e2a\u3001\u57fa\u4e8e\u7a0b\u5e8f\u7684\u63a8\u7406\u548c\u5185\u5b58\u589e\u5f3a\u5de5\u5177\u4f7f\u7528\u4e4b\u95f4\u7684\u4ee3\u6570\u8054\u7cfb\uff0c\u89e3\u91ca\u4e86\u53d8\u91cf\u6df7\u6dc6\u548c\u903b\u8f91\u76f8\u5173\u63d0\u793a\u95f4\u4e0d\u4e00\u81f4\u7b49\u7279\u5f81\u6027\u5931\u8d25\u6a21\u5f0f\u3002\u63d0\u51fa\u4e86\u6d4b\u91cf\"VSA\u76f8\u4f3c\u5ea6\"\u548c\u903b\u8f91\u7ec4\u5408\u6027\u7684\u6307\u6807\u3002", "conclusion": "\u5c06\u6ce8\u610f\u529b\u89c6\u4e3a\u8f6f\u5411\u91cf\u7b26\u53f7\u8ba1\u7b97\u4e3a\u6784\u5efa\u66f4\u5177\u89e3\u91ca\u6027\u548c\u903b\u8f91\u53ef\u9760\u6027\u7684\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8def\u5f84\uff0c\u5e76\u63d0\u51fa\u4e86\u7406\u8bba\u548c\u67b6\u6784\u4e0a\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002"}}
{"id": "2512.15220", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2512.15220", "abs": "https://arxiv.org/abs/2512.15220", "authors": ["Vahid Pooryousef", "Tim Dwyer", "Richard Bassed", "Maxime Cordeil", "Lonni Besan\u00e7on"], "title": "Lessons Learnt from Expert-Centred Studies Exploring Opportunities and Challenges for Immersive Forensic Investigation", "comment": null, "summary": "Research studies involving human participants present challenges, including strict ethical considerations, participant recruitment, costs, and many human factors. While human-computer interaction researchers are familiar with these challenges and current solutions, expert-centred studies can be even more challenging in ways that researchers may not anticipate. This issue is particularly important as research grants are increasingly based on practical and real-world problems, which necessitate close collaboration with experts. In this paper, we reflect on and discuss the challenges, solutions, and specific requirements that arose during our expert-centred studies conducted over three years of a PhD study exploring immersive forensic investigation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53cd\u601d\u4e86\u4e13\u5bb6\u4e2d\u5fc3\u7814\u7a76\u4e2d\u7684\u6311\u6218\uff0c\u5305\u62ec\u4f26\u7406\u8003\u91cf\u3001\u62db\u52df\u56f0\u96be\u3001\u6210\u672c\u95ee\u9898\u7b49\uff0c\u5e76\u57fa\u4e8e\u4e09\u5e74\u535a\u58eb\u7814\u7a76\u7ecf\u9a8c\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u7814\u7a76\u8d44\u52a9\u8d8a\u6765\u8d8a\u57fa\u4e8e\u5b9e\u9645\u548c\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\uff0c\u9700\u8981\u4e0e\u4e13\u5bb6\u5bc6\u5207\u5408\u4f5c\uff0c\u4f46\u4e13\u5bb6\u4e2d\u5fc3\u7814\u7a76\u5b58\u5728\u8bb8\u591a\u7814\u7a76\u4eba\u5458\u53ef\u80fd\u672a\u9884\u6599\u5230\u7684\u6311\u6218\uff0c\u5305\u62ec\u4e25\u683c\u7684\u4f26\u7406\u8003\u91cf\u3001\u53c2\u4e0e\u8005\u62db\u52df\u3001\u6210\u672c\u4ee5\u53ca\u8bb8\u591a\u4eba\u56e0\u56e0\u7d20\u3002", "method": "\u57fa\u4e8e\u4e09\u5e74\u535a\u58eb\u7814\u7a76\u7ecf\u9a8c\uff0c\u5bf9\u6c89\u6d78\u5f0f\u6cd5\u533b\u8c03\u67e5\u9886\u57df\u7684\u4e13\u5bb6\u4e2d\u5fc3\u7814\u7a76\u8fdb\u884c\u53cd\u601d\u548c\u8ba8\u8bba\uff0c\u5206\u6790\u9047\u5230\u7684\u6311\u6218\u3001\u89e3\u51b3\u65b9\u6848\u548c\u7279\u5b9a\u8981\u6c42\u3002", "result": "\u8bc6\u522b\u4e86\u4e13\u5bb6\u4e2d\u5fc3\u7814\u7a76\u4e2d\u7684\u5177\u4f53\u6311\u6218\uff0c\u5305\u62ec\u4f26\u7406\u5ba1\u67e5\u7684\u590d\u6742\u6027\u3001\u4e13\u5bb6\u53c2\u4e0e\u8005\u7684\u62db\u52df\u56f0\u96be\u3001\u7814\u7a76\u6210\u672c\u63a7\u5236\u3001\u4ee5\u53ca\u4e13\u5bb6\u7279\u6709\u7684\u5de5\u4f5c\u6d41\u7a0b\u548c\u9700\u6c42\u3002", "conclusion": "\u4e13\u5bb6\u4e2d\u5fc3\u7814\u7a76\u9700\u8981\u7279\u522b\u5173\u6ce8\u4f26\u7406\u3001\u62db\u52df\u548c\u6210\u672c\u7b49\u6311\u6218\uff0c\u7814\u7a76\u4eba\u5458\u5e94\u63d0\u524d\u89c4\u5212\u5e76\u5236\u5b9a\u9488\u5bf9\u6027\u7b56\u7565\uff0c\u4ee5\u4fc3\u8fdb\u4e0e\u4e13\u5bb6\u7684\u6709\u6548\u5408\u4f5c\u5e76\u786e\u4fdd\u7814\u7a76\u8d28\u91cf\u3002"}}
{"id": "2512.14766", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14766", "abs": "https://arxiv.org/abs/2512.14766", "authors": ["Dongzhuoran Zhou", "Yuqicheng Zhu", "Xiaxia Wang", "Hongkuan Zhou", "Jiaoyan Chen", "Steffen Staab", "Yuan He", "Evgeny Kharlamov"], "title": "GR-Agent: Adaptive Graph Reasoning Agent under Incomplete Knowledge", "comment": null, "summary": "Large language models (LLMs) achieve strong results on knowledge graph question answering (KGQA), but most benchmarks assume complete knowledge graphs (KGs) where direct supporting triples exist. This reduces evaluation to shallow retrieval and overlooks the reality of incomplete KGs, where many facts are missing and answers must be inferred from existing facts. We bridge this gap by proposing a methodology for constructing benchmarks under KG incompleteness, which removes direct supporting triples while ensuring that alternative reasoning paths required to infer the answer remain. Experiments on benchmarks constructed using our methodology show that existing methods suffer consistent performance degradation under incompleteness, highlighting their limited reasoning ability. To overcome this limitation, we present the Adaptive Graph Reasoning Agent (GR-Agent). It first constructs an interactive environment from the KG, and then formalizes KGQA as agent environment interaction within this environment. GR-Agent operates over an action space comprising graph reasoning tools and maintains a memory of potential supporting reasoning evidence, including relevant relations and reasoning paths. Extensive experiments demonstrate that GR-Agent outperforms non-training baselines and performs comparably to training-based methods under both complete and incomplete settings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u77e5\u8bc6\u56fe\u8c31\u4e0d\u5b8c\u6574\u60c5\u51b5\u4e0b\u6784\u5efaKGQA\u57fa\u51c6\u7684\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u81ea\u9002\u5e94\u56fe\u63a8\u7406\u667a\u80fd\u4f53\uff08GR-Agent\uff09\u6765\u89e3\u51b3\u4e0d\u5b8c\u6574\u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u63a8\u7406\u95ee\u9898\u3002", "motivation": "\u73b0\u6709KGQA\u57fa\u51c6\u5927\u591a\u5047\u8bbe\u77e5\u8bc6\u56fe\u8c31\u662f\u5b8c\u6574\u7684\uff0c\u5305\u542b\u76f4\u63a5\u652f\u6301\u7b54\u6848\u7684\u4e09\u5143\u7ec4\uff0c\u8fd9\u4e0e\u73b0\u5b9e\u4e16\u754c\u4e2d\u77e5\u8bc6\u56fe\u8c31\u901a\u5e38\u4e0d\u5b8c\u6574\u7684\u5b9e\u9645\u60c5\u51b5\u4e0d\u7b26\u3002\u8fd9\u79cd\u5047\u8bbe\u5c06\u8bc4\u4f30\u7b80\u5316\u4e3a\u6d45\u5c42\u68c0\u7d22\uff0c\u5ffd\u89c6\u4e86\u9700\u8981\u4ece\u73b0\u6709\u4e8b\u5b9e\u8fdb\u884c\u63a8\u7406\u7684\u80fd\u529b\u3002", "method": "1\uff09\u63d0\u51fa\u6784\u5efa\u4e0d\u5b8c\u6574\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\u7684\u65b9\u6cd5\u8bba\uff0c\u79fb\u9664\u76f4\u63a5\u652f\u6301\u4e09\u5143\u7ec4\u4f46\u4fdd\u7559\u66ff\u4ee3\u63a8\u7406\u8def\u5f84\uff1b2\uff09\u5f00\u53d1\u81ea\u9002\u5e94\u56fe\u63a8\u7406\u667a\u80fd\u4f53\uff08GR-Agent\uff09\uff0c\u5c06KGQA\u5f62\u5f0f\u5316\u4e3a\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4ea4\u4e92\uff0c\u667a\u80fd\u4f53\u5728\u5305\u542b\u56fe\u63a8\u7406\u5de5\u5177\u7684\u52a8\u4f5c\u7a7a\u95f4\u4e0a\u64cd\u4f5c\uff0c\u5e76\u7ef4\u62a4\u6f5c\u5728\u652f\u6301\u63a8\u7406\u8bc1\u636e\u7684\u8bb0\u5fc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09\u73b0\u6709\u65b9\u6cd5\u5728\u4e0d\u5b8c\u6574\u77e5\u8bc6\u56fe\u8c31\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff1b2\uff09GR-Agent\u5728\u5b8c\u6574\u548c\u4e0d\u5b8c\u6574\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u975e\u8bad\u7ec3\u57fa\u7ebf\uff0c\u4e0e\u57fa\u4e8e\u8bad\u7ec3\u7684\u65b9\u6cd5\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "\u8bba\u6587\u586b\u8865\u4e86KGQA\u8bc4\u4f30\u5728\u4e0d\u5b8c\u6574\u77e5\u8bc6\u56fe\u8c31\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684GR-Agent\u80fd\u591f\u6709\u6548\u5904\u7406\u77e5\u8bc6\u56fe\u8c31\u4e0d\u5b8c\u6574\u60c5\u51b5\u4e0b\u7684\u63a8\u7406\u4efb\u52a1\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2512.14706", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.14706", "abs": "https://arxiv.org/abs/2512.14706", "authors": ["Krunal Jesani", "Dmitry Ignatov", "Radu Timofte"], "title": "LLM as a Neural Architect: Controlled Generation of Image Captioning Models Under Strict API Contracts", "comment": null, "summary": "Neural architecture search (NAS) traditionally requires significant human expertise or automated trial-and-error to design deep learning models. We present NN-Caption, an LLM-guided neural architecture search pipeline that generates runnable image-captioning models by composing CNN encoders from LEMUR's classification backbones with sequence decoders (LSTM/GRU/Transformer) under a strict Net API. Using DeepSeek-R1-0528-Qwen3-8B as the primary generator, we present the prompt template and examples of generated architectures. We evaluate on MS COCO with BLEU-4. The LLM generated dozens of captioning models, with over half successfully trained and producing meaningful captions. We analyse the outcomes of using different numbers of input model snippets (5 vs. 10) in the prompt, finding a slight drop in success rate when providing more candidate components. We also report training dynamics (caption accuracy vs. epochs) and the highest BLEU-4 attained. Our results highlight the promise of LLM-guided NAS: the LLM not only proposes architectures but also suggests hyperparameters and training practices. We identify the challenges encountered (e.g., code hallucinations or API compliance issues) and detail how prompt rules and iterative code fixes addressed them. This work presents a pipeline that integrates prompt-based code generation with automatic evaluation, and adds dozens of novel captioning models to the open LEMUR dataset to facilitate reproducible benchmarking and downstream AutoML research.", "AI": {"tldr": "NN-Caption\uff1a\u57fa\u4e8eLLM\u5f15\u5bfc\u7684\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u7ec4\u5408CNN\u7f16\u7801\u5668\u548c\u5e8f\u5217\u89e3\u7801\u5668\u81ea\u52a8\u751f\u6210\u53ef\u8fd0\u884c\u7684\u56fe\u50cf\u63cf\u8ff0\u6a21\u578b\uff0c\u5728MS COCO\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u9700\u8981\u5927\u91cf\u4eba\u5de5\u4e13\u4e1a\u77e5\u8bc6\u6216\u81ea\u52a8\u5316\u8bd5\u9519\u6765\u8bbe\u8ba1\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u4f5c\u8005\u5e0c\u671b\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6765\u5f15\u5bfcNAS\u8fc7\u7a0b\uff0c\u81ea\u52a8\u751f\u6210\u56fe\u50cf\u63cf\u8ff0\u6a21\u578b\u67b6\u6784\u3002", "method": "\u4f7f\u7528DeepSeek-R1-0528-Qwen3-8B\u4f5c\u4e3a\u4e3b\u8981\u751f\u6210\u5668\uff0c\u57fa\u4e8e\u4e25\u683c\u7684Net API\uff0c\u5c06LEMUR\u5206\u7c7b\u4e3b\u5e72\u4e2d\u7684CNN\u7f16\u7801\u5668\u4e0e\u5e8f\u5217\u89e3\u7801\u5668\uff08LSTM/GRU/Transformer\uff09\u7ec4\u5408\uff0c\u6784\u5efa\u53ef\u8fd0\u884c\u7684\u56fe\u50cf\u63cf\u8ff0\u6a21\u578b\u3002\u8bbe\u8ba1\u4e86\u63d0\u793a\u6a21\u677f\u548c\u793a\u4f8b\u67b6\u6784\uff0c\u5e76\u5728MS COCO\u6570\u636e\u96c6\u4e0a\u7528BLEU-4\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "LLM\u751f\u6210\u4e86\u6570\u5341\u4e2a\u63cf\u8ff0\u6a21\u578b\uff0c\u5176\u4e2d\u8d85\u8fc7\u4e00\u534a\u6210\u529f\u8bad\u7ec3\u5e76\u4ea7\u751f\u6709\u610f\u4e49\u7684\u63cf\u8ff0\u3002\u6bd4\u8f83\u4e86\u4f7f\u7528\u4e0d\u540c\u6570\u91cf\u8f93\u5165\u6a21\u578b\u7247\u6bb5\uff085\u4e2avs 10\u4e2a\uff09\u7684\u6548\u679c\uff0c\u53d1\u73b0\u63d0\u4f9b\u66f4\u591a\u5019\u9009\u7ec4\u4ef6\u65f6\u6210\u529f\u7387\u7565\u6709\u4e0b\u964d\u3002\u62a5\u544a\u4e86\u8bad\u7ec3\u52a8\u6001\uff08\u63cf\u8ff0\u51c6\u786e\u7387vs\u8bad\u7ec3\u8f6e\u6570\uff09\u548c\u8fbe\u5230\u7684\u6700\u9ad8BLEU-4\u5206\u6570\u3002", "conclusion": "LLM\u5f15\u5bfc\u7684NAS\u5c55\u73b0\u51fa\u826f\u597d\u524d\u666f\uff1aLLM\u4e0d\u4ec5\u80fd\u63d0\u51fa\u67b6\u6784\uff0c\u8fd8\u80fd\u5efa\u8bae\u8d85\u53c2\u6570\u548c\u8bad\u7ec3\u5b9e\u8df5\u3002\u7814\u7a76\u8bc6\u522b\u4e86\u9047\u5230\u7684\u6311\u6218\uff08\u5982\u4ee3\u7801\u5e7b\u89c9\u6216API\u5408\u89c4\u95ee\u9898\uff09\uff0c\u5e76\u8be6\u7ec6\u8bf4\u660e\u4e86\u5982\u4f55\u901a\u8fc7\u63d0\u793a\u89c4\u5219\u548c\u8fed\u4ee3\u4ee3\u7801\u4fee\u590d\u6765\u89e3\u51b3\u3002\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06\u57fa\u4e8e\u63d0\u793a\u7684\u4ee3\u7801\u751f\u6210\u4e0e\u81ea\u52a8\u8bc4\u4f30\u76f8\u7ed3\u5408\u7684\u6d41\u6c34\u7ebf\uff0c\u5e76\u4e3a\u5f00\u653e\u7684LEMUR\u6570\u636e\u96c6\u6dfb\u52a0\u4e86\u6570\u5341\u4e2a\u65b0\u9896\u7684\u63cf\u8ff0\u6a21\u578b\uff0c\u4ee5\u4fc3\u8fdb\u53ef\u91cd\u590d\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e0b\u6e38AutoML\u7814\u7a76\u3002"}}
{"id": "2512.15263", "categories": ["cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.15263", "abs": "https://arxiv.org/abs/2512.15263", "authors": ["Ashirbad Samantaray", "Taranjit Kaur", "Sapna S Mishra", "Kritika Lohia", "Chayan Majumder", "Sheffali Gulati", "Tapan Kumar Gandhi"], "title": "Development of Immersive Virtual and Augmented Reality-Based Joint Attention Training Platform for Children with Autism", "comment": null, "summary": "Joint Attention (JA), a crucial social skill for developing shared focus, is often impaired in children with Autism Spectrum Disorder (ASD), affecting social communication and highlighting the need for early intervention. Addressing gaps in prior research, such as limited use of immersive technology and reliance on distracting peripherals, we developed a novel JA training platform using Augmented Reality (AR) and Virtual Reality (VR) devices. The platform integrates eye gaze-based interactions to ensure participants undivided attention. To validate the platform, we conducted experiments on ASD (N=19) and Neurotypical (NT) (N=13) participants under a trained pediatric neurologist's supervision. For quantitative analysis, we employed key measures such as the number of correct responses, the duration of establishing eye contact (s), and the duration of registering a response (s), along with correlations to CARS scores and age. Results from AR-based experiments showed NT participants registered responses significantly faster (<0.00001) than ASD participants. A correlation (Spearman coefficient=0.57, p=0.03) was found between ASD participants response time and CARS scores. A similar trend was observed in VR-based experiments. When comparing response accuracy in ASD participants across platforms, AR yielded a higher correctness rate (92.30%) than VR (69.49%), indicating AR's greater effectiveness. These findings suggest that immersive technology can aid JA training in ASD. Future studies should explore long-term benefits and real-world applicability.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408AR/VR\u548c\u773c\u52a8\u8ffd\u8e2a\u7684\u8054\u5408\u6ce8\u610f\u529b\u8bad\u7ec3\u5e73\u53f0\uff0c\u7528\u4e8e\u81ea\u95ed\u75c7\u513f\u7ae5\u5e72\u9884\uff0c\u5b9e\u9a8c\u663e\u793aAR\u6bd4VR\u66f4\u6709\u6548\uff0cNT\u53c2\u4e0e\u8005\u53cd\u5e94\u66f4\u5feb\uff0c\u53cd\u5e94\u65f6\u95f4\u4e0eCARS\u8bc4\u5206\u76f8\u5173\u3002", "motivation": "\u8054\u5408\u6ce8\u610f\u529b\u662f\u81ea\u95ed\u75c7\u8c31\u7cfb\u969c\u788d\u513f\u7ae5\u793e\u4ea4\u6280\u80fd\u7684\u91cd\u8981\u7f3a\u9677\uff0c\u5f71\u54cd\u793e\u4ea4\u6c9f\u901a\uff0c\u9700\u8981\u65e9\u671f\u5e72\u9884\u3002\u5148\u524d\u7814\u7a76\u5b58\u5728\u6c89\u6d78\u6280\u672f\u5e94\u7528\u6709\u9650\u3001\u4f9d\u8d56\u5206\u6563\u6ce8\u610f\u529b\u7684\u5916\u8bbe\u7b49\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8eAR\u548cVR\u8bbe\u5907\u7684\u8054\u5408\u6ce8\u610f\u529b\u8bad\u7ec3\u5e73\u53f0\uff0c\u6574\u5408\u773c\u52a8\u8ffd\u8e2a\u4ea4\u4e92\u786e\u4fdd\u4e13\u6ce8\u3002\u5bf919\u540dASD\u548c13\u540dNT\u53c2\u4e0e\u8005\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7531\u513f\u79d1\u795e\u7ecf\u5b66\u5bb6\u76d1\u7763\uff0c\u6d4b\u91cf\u6b63\u786e\u53cd\u5e94\u6570\u3001\u773c\u795e\u63a5\u89e6\u65f6\u957f\u3001\u53cd\u5e94\u65f6\u957f\u7b49\u6307\u6807\uff0c\u5e76\u4e0eCARS\u8bc4\u5206\u548c\u5e74\u9f84\u76f8\u5173\u5206\u6790\u3002", "result": "AR\u5b9e\u9a8c\u4e2dNT\u53c2\u4e0e\u8005\u53cd\u5e94\u663e\u8457\u5feb\u4e8eASD\u53c2\u4e0e\u8005(p<0.00001)\u3002ASD\u53c2\u4e0e\u8005\u53cd\u5e94\u65f6\u95f4\u4e0eCARS\u8bc4\u5206\u76f8\u5173(Spearman\u7cfb\u6570=0.57, p=0.03)\u3002AR\u5e73\u53f0\u6b63\u786e\u7387(92.30%)\u9ad8\u4e8eVR\u5e73\u53f0(69.49%)\uff0c\u8868\u660eAR\u66f4\u6709\u6548\u3002", "conclusion": "\u6c89\u6d78\u5f0f\u6280\u672f\u53ef\u8f85\u52a9ASD\u7684\u8054\u5408\u6ce8\u610f\u529b\u8bad\u7ec3\uff0cAR\u6bd4VR\u66f4\u6709\u6548\u3002\u672a\u6765\u7814\u7a76\u5e94\u63a2\u7d22\u957f\u671f\u6548\u76ca\u548c\u73b0\u5b9e\u4e16\u754c\u9002\u7528\u6027\u3002"}}
{"id": "2512.14792", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.14792", "abs": "https://arxiv.org/abs/2512.14792", "authors": ["Roman Nekrasov", "Stefano Fossati", "Indika Kumara", "Damian Andrew Tamburri", "Willem-Jan van den Heuvel"], "title": "IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection", "comment": "Submitted to ACM", "summary": "Large Language Models (LLMs) currently exhibit low success rates in generating correct and intent-aligned Infrastructure as Code (IaC). This research investigated methods to improve LLM-based IaC generation, specifically for Terraform, by systematically injecting structured configuration knowledge. To facilitate this, an existing IaC-Eval benchmark was significantly enhanced with cloud emulation and automated error analysis. Additionally, a novel error taxonomy for LLM-assisted IaC code generation was developed. A series of knowledge injection techniques was implemented and evaluated, progressing from Naive Retrieval-Augmented Generation (RAG) to more sophisticated Graph RAG approaches. These included semantic enrichment of graph components and modeling inter-resource dependencies. Experimental results demonstrated that while baseline LLM performance was poor (27.1% overall success), injecting structured configuration knowledge increased technical validation success to 75.3% and overall success to 62.6%. Despite these gains in technical correctness, intent alignment plateaued, revealing a \"Correctness-Congruence Gap\" where LLMs can become proficient \"coders\" but remain limited \"architects\" in fulfilling nuanced user intent.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u7ed3\u6784\u5316\u914d\u7f6e\u77e5\u8bc6\u6ce8\u5165\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210Terraform\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801(IaC)\u7684\u6210\u529f\u7387\uff0c\u4ece27.1%\u63d0\u9ad8\u523062.6%\uff0c\u4f46\u53d1\u73b0LLM\u5728\u6280\u672f\u6b63\u786e\u6027\u548c\u610f\u56fe\u5bf9\u9f50\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u6b63\u786e\u4e14\u7b26\u5408\u610f\u56fe\u7684\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\u65b9\u9762\u6210\u529f\u7387\u8f83\u4f4e\uff0c\u9700\u8981\u7cfb\u7edf\u65b9\u6cd5\u6765\u6539\u8fdbLLM\u5728IaC\u751f\u6210\u4e2d\u7684\u8868\u73b0\u3002", "method": "1. \u589e\u5f3aIaC-Eval\u57fa\u51c6\u6d4b\u8bd5\uff0c\u589e\u52a0\u4e91\u4eff\u771f\u548c\u81ea\u52a8\u5316\u9519\u8bef\u5206\u6790\uff1b2. \u5f00\u53d1LLM\u8f85\u52a9IaC\u4ee3\u7801\u751f\u6210\u7684\u9519\u8bef\u5206\u7c7b\u6cd5\uff1b3. \u5b9e\u65bd\u4ece\u6734\u7d20\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5230\u66f4\u590d\u6742\u7684\u56feRAG\u65b9\u6cd5\u7684\u77e5\u8bc6\u6ce8\u5165\u6280\u672f\uff0c\u5305\u62ec\u56fe\u7ec4\u4ef6\u7684\u8bed\u4e49\u4e30\u5bcc\u5316\u548c\u8d44\u6e90\u95f4\u4f9d\u8d56\u5173\u7cfb\u5efa\u6a21\u3002", "result": "\u57fa\u7ebfLLM\u6027\u80fd\u8f83\u5dee\uff08\u603b\u4f53\u6210\u529f\u738727.1%\uff09\uff0c\u6ce8\u5165\u7ed3\u6784\u5316\u914d\u7f6e\u77e5\u8bc6\u540e\uff0c\u6280\u672f\u9a8c\u8bc1\u6210\u529f\u7387\u63d0\u9ad8\u523075.3%\uff0c\u603b\u4f53\u6210\u529f\u7387\u63d0\u9ad8\u523062.6%\u3002\u7136\u800c\u610f\u56fe\u5bf9\u9f50\u65b9\u9762\u51fa\u73b0\u5e73\u53f0\u671f\uff0c\u63ed\u793a\u4e86\"\u6b63\u786e\u6027-\u4e00\u81f4\u6027\u5dee\u8ddd\"\u3002", "conclusion": "\u867d\u7136\u7ed3\u6784\u5316\u77e5\u8bc6\u6ce8\u5165\u663e\u8457\u63d0\u9ad8\u4e86LLM\u751f\u6210IaC\u7684\u6280\u672f\u6b63\u786e\u6027\uff0c\u4f46LLM\u5728\u6ee1\u8db3\u7ec6\u5fae\u7528\u6237\u610f\u56fe\u65b9\u9762\u4ecd\u7136\u53d7\u9650\uff0c\u8868\u660e\u5b83\u4eec\u53ef\u4ee5\u6210\u4e3a\u719f\u7ec3\u7684\"\u7f16\u7801\u8005\"\u4f46\u4ecd\u7136\u662f\u6709\u9650\u7684\"\u67b6\u6784\u5e08\"\u3002"}}
{"id": "2512.14710", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14710", "abs": "https://arxiv.org/abs/2512.14710", "authors": ["Keqiuyin Li", "Jie Lu", "Hua Zuo", "Guangquan Zhang"], "title": "Autonomous Source Knowledge Selection in Multi-Domain Adaptation", "comment": null, "summary": "Unsupervised multi-domain adaptation plays a key role in transfer learning by leveraging acquired rich source information from multiple source domains to solve target task from an unlabeled target domain. However, multiple source domains often contain much redundant or unrelated information which can harm transfer performance, especially when in massive-source domain settings. It is urgent to develop effective strategies for identifying and selecting the most transferable knowledge from massive source domains to address the target task. In this paper, we propose a multi-domain adaptation method named \\underline{\\textit{Auto}}nomous Source Knowledge \\underline{\\textit{S}}election (AutoS) to autonomosly select source training samples and models, enabling the prediction of target task using more relevant and transferable source information. The proposed method employs a density-driven selection strategy to choose source samples during training and to determine which source models should contribute to target prediction. Simulteneously, a pseudo-label enhancement module built on a pre-trained multimodal modal is employed to mitigate target label noise and improve self-supervision. Experiments on real-world datasets indicate the superiority of the proposed method.", "AI": {"tldr": "\u63d0\u51faAutoS\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u4e3b\u9009\u62e9\u6e90\u57df\u6837\u672c\u548c\u6a21\u578b\uff0c\u5728\u591a\u57df\u81ea\u9002\u5e94\u4e2d\u7b5b\u9009\u6700\u53ef\u8fc1\u79fb\u7684\u77e5\u8bc6\uff0c\u63d0\u9ad8\u76ee\u6807\u4efb\u52a1\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u591a\u6e90\u57df\u81ea\u9002\u5e94\u4e2d\uff0c\u591a\u4e2a\u6e90\u57df\u901a\u5e38\u5305\u542b\u5927\u91cf\u5197\u4f59\u6216\u4e0d\u76f8\u5173\u4fe1\u606f\uff0c\u8fd9\u4e9b\u4fe1\u606f\u4f1a\u635f\u5bb3\u8fc1\u79fb\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u6e90\u57df\u8bbe\u7f6e\u4e0b\u3002\u9700\u8981\u5f00\u53d1\u6709\u6548\u7b56\u7565\u6765\u8bc6\u522b\u548c\u9009\u62e9\u6700\u53ef\u8fc1\u79fb\u7684\u77e5\u8bc6\u3002", "method": "\u63d0\u51faAutoS\u65b9\u6cd5\uff1a1) \u91c7\u7528\u5bc6\u5ea6\u9a71\u52a8\u9009\u62e9\u7b56\u7565\u9009\u62e9\u6e90\u57df\u8bad\u7ec3\u6837\u672c\u548c\u786e\u5b9a\u54ea\u4e9b\u6e90\u6a21\u578b\u5e94\u8d21\u732e\u4e8e\u76ee\u6807\u9884\u6d4b\uff1b2) \u57fa\u4e8e\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u6a21\u578b\u6784\u5efa\u4f2a\u6807\u7b7e\u589e\u5f3a\u6a21\u5757\uff0c\u51cf\u8f7b\u76ee\u6807\u6807\u7b7e\u566a\u58f0\u5e76\u6539\u8fdb\u81ea\u76d1\u7763\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "AutoS\u65b9\u6cd5\u80fd\u591f\u81ea\u4e3b\u9009\u62e9\u6e90\u57df\u6837\u672c\u548c\u6a21\u578b\uff0c\u4f7f\u7528\u66f4\u76f8\u5173\u548c\u53ef\u8fc1\u79fb\u7684\u6e90\u4fe1\u606f\u6765\u9884\u6d4b\u76ee\u6807\u4efb\u52a1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6e90\u57df\u81ea\u9002\u5e94\u4e2d\u7684\u77e5\u8bc6\u9009\u62e9\u95ee\u9898\u3002"}}
{"id": "2512.15325", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15325", "abs": "https://arxiv.org/abs/2512.15325", "authors": ["Agnieszka Bienkowska", "Jacek Malecki", "Alexander Mathiesen-Ohman", "Katarzyna Tworek"], "title": "Managing Ambiguity: A Proof of Concept of Human-AI Symbiotic Sense-making based on Quantum-Inspired Cognitive Mechanism of Rogue Variable Detection", "comment": "19 pages, 6 figures", "summary": "Organizations increasingly operate in environments characterized by volatility, uncertainty, complexity, and ambiguity (VUCA), where early indicators of change often emerge as weak, fragmented signals. Although artificial intelligence (AI) is widely used to support managerial decision-making, most AI-based systems remain optimized for prediction and resolution, leading to premature interpretive closure under conditions of high ambiguity. This creates a gap in management science regarding how human-AI systems can responsibly manage ambiguity before it crystallizes into error or crisis. This study addresses this gap by presenting a proof of concept (PoC) of the LAIZA human-AI augmented symbiotic intelligence system and its patented process: Systems and Methods for Quantum-Inspired Rogue Variable Modeling (QRVM), Human-in-the-Loop Decoherence, and Collective Cognitive Inference. The mechanism operationalizes ambiguity as a non-collapsed cognitive state, detects persistent interpretive breakdowns (rogue variables), and activates structured human-in-the-loop clarification when autonomous inference becomes unreliable. Empirically, the article draws on a three-month case study conducted in 2025 within the AI development, involving prolonged ambiguity surrounding employee intentions and intellectual property boundaries. The findings show that preserving interpretive plurality enabled early scenario-based preparation, including proactive patent protection, allowing decisive and disruption-free action once ambiguity collapsed. The study contributes to management theory by reframing ambiguity as a first-class construct and demonstrates the practical value of human-AI symbiosis for organizational resilience in VUCA environments.", "AI": {"tldr": "LAIZA\u7cfb\u7edf\u901a\u8fc7\u91cf\u5b50\u542f\u53d1\u7684QRVM\u6d41\u7a0b\uff0c\u5728VUCA\u73af\u5883\u4e2d\u5c06\u6a21\u7cca\u6027\u89c6\u4e3a\u975e\u574d\u7f29\u8ba4\u77e5\u72b6\u6001\uff0c\u5229\u7528\u4eba\u673a\u534f\u540c\u4fdd\u6301\u89e3\u91ca\u591a\u6837\u6027\uff0c\u5b9e\u73b0\u65e9\u671f\u573a\u666f\u51c6\u5907\u548c\u7ec4\u7ec7\u97e7\u6027\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u4e3b\u8981\u4f18\u5316\u9884\u6d4b\u548c\u89e3\u51b3\uff0c\u5728\u9ad8\u5ea6\u6a21\u7cca\u6027\u6761\u4ef6\u4e0b\u5bb9\u6613\u8fc7\u65e9\u5f62\u6210\u89e3\u91ca\u95ed\u5408\uff0c\u7f3a\u4e4f\u5728\u6a21\u7cca\u6027\u6f14\u53d8\u4e3a\u9519\u8bef\u6216\u5371\u673a\u524d\u8d1f\u8d23\u4efb\u7ba1\u7406\u6a21\u7cca\u6027\u7684\u4eba\u673a\u7cfb\u7edf\u65b9\u6cd5\u3002", "method": "\u63d0\u51faLAIZA\u4eba\u673a\u589e\u5f3a\u5171\u751f\u667a\u80fd\u7cfb\u7edf\u53ca\u5176\u4e13\u5229\u6d41\u7a0b\uff1a\u91cf\u5b50\u542f\u53d1\u7684\u5f02\u5e38\u53d8\u91cf\u5efa\u6a21\u3001\u4eba\u5728\u56de\u8def\u9000\u76f8\u5e72\u548c\u96c6\u4f53\u8ba4\u77e5\u63a8\u7406\u3002\u901a\u8fc72025\u5e74\u4e3a\u671f\u4e09\u4e2a\u6708\u7684AI\u5f00\u53d1\u6848\u4f8b\u7814\u7a76\uff0c\u5206\u6790\u5458\u5de5\u610f\u56fe\u548c\u77e5\u8bc6\u4ea7\u6743\u8fb9\u754c\u6a21\u7cca\u6027\u95ee\u9898\u3002", "result": "\u4fdd\u6301\u89e3\u91ca\u591a\u6837\u6027\u5b9e\u73b0\u4e86\u65e9\u671f\u57fa\u4e8e\u573a\u666f\u7684\u51c6\u5907\uff0c\u5305\u62ec\u4e3b\u52a8\u4e13\u5229\u4fdd\u62a4\uff0c\u4f7f\u7ec4\u7ec7\u5728\u6a21\u7cca\u6027\u574d\u7f29\u65f6\u80fd\u591f\u679c\u65ad\u4e14\u65e0\u5e72\u6270\u5730\u884c\u52a8\u3002", "conclusion": "\u5c06\u6a21\u7cca\u6027\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e00\u7ea7\u6784\u9020\uff0c\u8bc1\u660e\u4e86\u4eba\u673a\u5171\u751f\u5728VUCA\u73af\u5883\u4e2d\u5bf9\u7ec4\u7ec7\u97e7\u6027\u7684\u5b9e\u9645\u4ef7\u503c\uff0c\u4e3a\u7ba1\u7406\u7406\u8bba\u505a\u51fa\u8d21\u732e\u3002"}}
{"id": "2512.14910", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.14910", "abs": "https://arxiv.org/abs/2512.14910", "authors": ["Nadine Angela Cantonjos", "Arpita Biswas"], "title": "AgroAskAI: A Multi-Agentic AI Framework for Supporting Smallholder Farmers' Enquiries Globally", "comment": null, "summary": "Agricultural regions in rural areas face damage from climate-related risks, including droughts, heavy rainfall, and shifting weather patterns. Prior research calls for adaptive risk-management solutions and decision-making strategies. To this end, artificial intelligence (AI), particularly agentic AI, offers a promising path forward. Agentic AI systems consist of autonomous, specialized agents capable of solving complex, dynamic tasks. While past systems have relied on single-agent models or have used multi-agent frameworks only for static functions, there is a growing need for architectures that support dynamic collaborative reasoning and context-aware outputs. To bridge this gap, we present AgroAskAI, a multi-agent reasoning system for climate adaptation decision support in agriculture, with a focus on vulnerable rural communities. AgroAskAI features a modular, role-specialized architecture that uses a chain-of-responsibility approach to coordinate autonomous agents, integrating real-time tools and datasets. The system has built-in governance mechanisms that mitigate hallucination and enable internal feedback for coherent, locally relevant strategies. The system also supports multilingual interactions, making it accessible to non-English-speaking farmers. Experiments on common agricultural queries related to climate adaptation show that, with additional tools and prompt refinement, AgroAskAI delivers more actionable, grounded, and inclusive outputs. Our experimental results highlight the potential of agentic AI for sustainable and accountable decision support in climate adaptation for agriculture.", "AI": {"tldr": "AgroAskAI\u662f\u4e00\u4e2a\u7528\u4e8e\u519c\u4e1a\u6c14\u5019\u9002\u5e94\u51b3\u7b56\u652f\u6301\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7cfb\u7edf\uff0c\u4e13\u6ce8\u4e8e\u519c\u6751\u8106\u5f31\u793e\u533a\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u89d2\u8272\u67b6\u6784\u548c\u94fe\u5f0f\u8d23\u4efb\u65b9\u6cd5\u534f\u8c03\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u63d0\u4f9b\u53ef\u64cd\u4f5c\u3001\u672c\u5730\u5316\u4e14\u5305\u5bb9\u6027\u7684\u8f93\u51fa\u3002", "motivation": "\u519c\u6751\u519c\u4e1a\u5730\u533a\u9762\u4e34\u5e72\u65f1\u3001\u5f3a\u964d\u96e8\u548c\u5929\u6c14\u6a21\u5f0f\u53d8\u5316\u7b49\u6c14\u5019\u76f8\u5173\u98ce\u9669\u7684\u635f\u5bb3\u3002\u73b0\u6709\u7814\u7a76\u547c\u5401\u9002\u5e94\u6027\u98ce\u9669\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u548c\u51b3\u7b56\u7b56\u7565\uff0c\u800c\u73b0\u6709\u7cfb\u7edf\u591a\u4e3a\u5355\u667a\u80fd\u4f53\u6a21\u578b\u6216\u4ec5\u7528\u4e8e\u9759\u6001\u529f\u80fd\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7f3a\u4e4f\u652f\u6301\u52a8\u6001\u534f\u4f5c\u63a8\u7406\u548c\u60c5\u5883\u611f\u77e5\u8f93\u51fa\u7684\u67b6\u6784\u3002", "method": "\u63d0\u51faAgroAskAI\u7cfb\u7edf\uff0c\u91c7\u7528\u6a21\u5757\u5316\u3001\u89d2\u8272\u4e13\u4e1a\u5316\u7684\u67b6\u6784\uff0c\u4f7f\u7528\u94fe\u5f0f\u8d23\u4efb\u65b9\u6cd5\u534f\u8c03\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u96c6\u6210\u5b9e\u65f6\u5de5\u5177\u548c\u6570\u636e\u96c6\u3002\u7cfb\u7edf\u5185\u7f6e\u6cbb\u7406\u673a\u5236\u4ee5\u51cf\u5c11\u5e7b\u89c9\u5e76\u5b9e\u73b0\u5185\u90e8\u53cd\u9988\uff0c\u652f\u6301\u591a\u8bed\u8a00\u4ea4\u4e92\u3002", "result": "\u5728\u5e38\u89c1\u519c\u4e1a\u6c14\u5019\u9002\u5e94\u76f8\u5173\u67e5\u8be2\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u989d\u5916\u5de5\u5177\u548c\u63d0\u793a\u4f18\u5316\uff0cAgroAskAI\u80fd\u591f\u63d0\u4f9b\u66f4\u53ef\u64cd\u4f5c\u3001\u66f4\u63a5\u5730\u6c14\u3001\u66f4\u5177\u5305\u5bb9\u6027\u7684\u8f93\u51fa\u3002\u5b9e\u9a8c\u7ed3\u679c\u7a81\u663e\u4e86\u667a\u80fd\u4f53AI\u5728\u519c\u4e1a\u6c14\u5019\u9002\u5e94\u4e2d\u53ef\u6301\u7eed\u548c\u8d1f\u8d23\u4efb\u7684\u51b3\u7b56\u652f\u6301\u6f5c\u529b\u3002", "conclusion": "AgroAskAI\u5c55\u793a\u4e86\u667a\u80fd\u4f53AI\u5728\u519c\u4e1a\u6c14\u5019\u9002\u5e94\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63a8\u7406\u67b6\u6784\u4e3a\u519c\u6751\u8106\u5f31\u793e\u533a\u63d0\u4f9b\u672c\u5730\u5316\u3001\u53ef\u64cd\u4f5c\u7684\u7b56\u7565\uff0c\u652f\u6301\u53ef\u6301\u7eed\u548c\u8d1f\u8d23\u4efb\u7684\u51b3\u7b56\u3002"}}
{"id": "2512.14713", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.14713", "abs": "https://arxiv.org/abs/2512.14713", "authors": ["Georges Sfeir", "Stephane Hess", "Thomas O. Hancock", "Filipe Rodrigues", "Jamal Amani Rad", "Michiel Bliemer", "Matthew Beck", "Fayyaz Khan"], "title": "A Bayesian latent class reinforcement learning framework to capture adaptive, feedback-driven travel behaviour", "comment": "32 pages, 8 figures, 6 tables", "summary": "Many travel decisions involve a degree of experience formation, where individuals learn their preferences over time. At the same time, there is extensive scope for heterogeneity across individual travellers, both in their underlying preferences and in how these evolve. The present paper puts forward a Latent Class Reinforcement Learning (LCRL) model that allows analysts to capture both of these phenomena. We apply the model to a driving simulator dataset and estimate the parameters through Variational Bayes. We identify three distinct classes of individuals that differ markedly in how they adapt their preferences: the first displays context-dependent preferences with context-specific exploitative tendencies; the second follows a persistent exploitative strategy regardless of context; and the third engages in an exploratory strategy combined with context-specific preferences.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6f5c\u5728\u7c7b\u522b\u5f3a\u5316\u5b66\u4e60\uff08LCRL\uff09\u6a21\u578b\uff0c\u7528\u4e8e\u6355\u6349\u65c5\u884c\u51b3\u7b56\u4e2d\u4e2a\u4f53\u504f\u597d\u5f02\u8d28\u6027\u548c\u968f\u65f6\u95f4\u6f14\u5316\u7684\u73b0\u8c61\uff0c\u901a\u8fc7\u9a7e\u9a76\u6a21\u62df\u5668\u6570\u636e\u96c6\u9a8c\u8bc1\u5e76\u8bc6\u522b\u51fa\u4e09\u7c7b\u4e0d\u540c\u7684\u504f\u597d\u9002\u5e94\u6a21\u5f0f\u3002", "motivation": "\u65c5\u884c\u51b3\u7b56\u901a\u5e38\u6d89\u53ca\u7ecf\u9a8c\u5f62\u6210\u8fc7\u7a0b\uff0c\u4e2a\u4f53\u968f\u65f6\u95f4\u5b66\u4e60\u5176\u504f\u597d\uff0c\u540c\u65f6\u65c5\u884c\u8005\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u5f02\u8d28\u6027\uff0c\u5305\u62ec\u57fa\u7840\u504f\u597d\u548c\u504f\u597d\u6f14\u5316\u65b9\u5f0f\u3002\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u6355\u6349\u8fd9\u4e24\u79cd\u73b0\u8c61\u3002", "method": "\u63d0\u51fa\u6f5c\u5728\u7c7b\u522b\u5f3a\u5316\u5b66\u4e60\uff08LCRL\uff09\u6a21\u578b\uff0c\u7ed3\u5408\u6f5c\u5728\u7c7b\u522b\u5206\u6790\u548c\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53d8\u5206\u8d1d\u53f6\u65af\u65b9\u6cd5\u4f30\u8ba1\u6a21\u578b\u53c2\u6570\uff0c\u5e94\u7528\u4e8e\u9a7e\u9a76\u6a21\u62df\u5668\u6570\u636e\u96c6\u8fdb\u884c\u5206\u6790\u3002", "result": "\u8bc6\u522b\u51fa\u4e09\u7c7b\u663e\u8457\u4e0d\u540c\u7684\u4e2a\u4f53\uff1a\u7b2c\u4e00\u7c7b\u663e\u793a\u60c5\u5883\u4f9d\u8d56\u7684\u504f\u597d\u548c\u60c5\u5883\u7279\u5b9a\u7684\u5229\u7528\u503e\u5411\uff1b\u7b2c\u4e8c\u7c7b\u9075\u5faa\u6301\u7eed\u5229\u7528\u7b56\u7565\uff0c\u4e0d\u53d7\u60c5\u5883\u5f71\u54cd\uff1b\u7b2c\u4e09\u7c7b\u91c7\u7528\u63a2\u7d22\u6027\u7b56\u7565\u5e76\u7ed3\u5408\u60c5\u5883\u7279\u5b9a\u504f\u597d\u3002", "conclusion": "LCRL\u6a21\u578b\u80fd\u591f\u6709\u6548\u6355\u6349\u65c5\u884c\u51b3\u7b56\u4e2d\u7684\u5f02\u8d28\u6027\u548c\u504f\u597d\u6f14\u5316\uff0c\u4e3a\u7406\u89e3\u4e2a\u4f53\u5982\u4f55\u5728\u4e0d\u540c\u60c5\u5883\u4e0b\u9002\u5e94\u548c\u8c03\u6574\u504f\u597d\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2512.15491", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2512.15491", "abs": "https://arxiv.org/abs/2512.15491", "authors": ["Omar Namnakani", "Yasmeen Abdrabou", "Jonathan Grizou", "Mohamed Khamis"], "title": "GazeBlend: Exploring Paired Gaze-Based Input Techniques for Navigation and Selection Tasks on Mobile Devices", "comment": "26 pages, 10 figures", "summary": "The potential of gaze for hands-free mobile interaction is increasingly evident. While each gaze input technique presents distinct advantages and limitations, a combination can amplify strengths and mitigate challenges. We report on the results of a user study (N=24), in which we compared the usability and performance of pairing three popular gaze input techniques: Dwell Time, Pursuits, and Gaze Gestures, for navigation and selection tasks while sitting and walking. Results show that pairing gestures for navigation with either Dwell time or Pursuits for selection improves task completion time and rate compared to using either individually. We discuss the implications of pairing gaze input techniques, such as how Pursuits may negatively impact other techniques, likely due to the visual clutter it adds, how integrating gestures for navigation reduces the chances of unintentional selections, and the impact of motor activity on performance. Our findings provide insights for effective gaze-enabled interfaces.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e09\u79cd\u89c6\u7ebf\u8f93\u5165\u6280\u672f\uff08\u6ce8\u89c6\u65f6\u95f4\u3001\u8ffd\u8e2a\u3001\u89c6\u7ebf\u624b\u52bf\uff09\u5728\u79fb\u52a8\u4ea4\u4e92\u4e2d\u7684\u7ec4\u5408\u4f7f\u7528\u6548\u679c\uff0c\u53d1\u73b0\u624b\u52bf\u5bfc\u822a\u4e0e\u6ce8\u89c6\u65f6\u95f4/\u8ffd\u8e2a\u9009\u62e9\u7ec4\u5408\u80fd\u63d0\u9ad8\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u548c\u6210\u529f\u7387\u3002", "motivation": "\u89c6\u7ebf\u8f93\u5165\u5728\u514d\u624b\u6301\u79fb\u52a8\u4ea4\u4e92\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u6bcf\u79cd\u6280\u672f\u90fd\u6709\u4f18\u7f3a\u70b9\u3002\u901a\u8fc7\u7ec4\u5408\u4e0d\u540c\u7684\u89c6\u7ebf\u8f93\u5165\u6280\u672f\uff0c\u53ef\u4ee5\u53d1\u6325\u5404\u81ea\u4f18\u52bf\u5e76\u5f25\u8865\u4e0d\u8db3\uff0c\u63d0\u5347\u6574\u4f53\u4ea4\u4e92\u4f53\u9a8c\u3002", "method": "\u8fdb\u884c\u7528\u6237\u7814\u7a76\uff08N=24\uff09\uff0c\u6bd4\u8f83\u4e09\u79cd\u6d41\u884c\u89c6\u7ebf\u8f93\u5165\u6280\u672f\uff08\u6ce8\u89c6\u65f6\u95f4\u3001\u8ffd\u8e2a\u3001\u89c6\u7ebf\u624b\u52bf\uff09\u5728\u5750\u59ff\u548c\u884c\u8d70\u72b6\u6001\u4e0b\uff0c\u7528\u4e8e\u5bfc\u822a\u548c\u9009\u62e9\u4efb\u52a1\u7684\u7ec4\u5408\u4f7f\u7528\u6548\u679c\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a\u624b\u52bf\u7528\u4e8e\u5bfc\u822a\uff0c\u914d\u5408\u6ce8\u89c6\u65f6\u95f4\u6216\u8ffd\u8e2a\u7528\u4e8e\u9009\u62e9\uff0c\u76f8\u6bd4\u5355\u72ec\u4f7f\u7528\u4efb\u4f55\u4e00\u79cd\u6280\u672f\uff0c\u80fd\u63d0\u9ad8\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u548c\u6210\u529f\u7387\u3002\u8ffd\u8e2a\u6280\u672f\u53ef\u80fd\u56e0\u589e\u52a0\u89c6\u89c9\u6df7\u4e71\u800c\u8d1f\u9762\u5f71\u54cd\u5176\u4ed6\u6280\u672f\uff0c\u624b\u52bf\u5bfc\u822a\u80fd\u51cf\u5c11\u610f\u5916\u9009\u62e9\uff0c\u8fd0\u52a8\u6d3b\u52a8\u4f1a\u5f71\u54cd\u6027\u80fd\u3002", "conclusion": "\u7ec4\u5408\u4f7f\u7528\u89c6\u7ebf\u8f93\u5165\u6280\u672f\u80fd\u6709\u6548\u63d0\u5347\u79fb\u52a8\u4ea4\u4e92\u6027\u80fd\uff0c\u7279\u522b\u662f\u624b\u52bf\u5bfc\u822a\u4e0e\u6ce8\u89c6\u65f6\u95f4/\u8ffd\u8e2a\u9009\u62e9\u7684\u7ec4\u5408\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u6709\u6548\u7684\u89c6\u7ebf\u4ea4\u4e92\u754c\u9762\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2512.15514", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2512.15514", "abs": "https://arxiv.org/abs/2512.15514", "authors": ["Lu Ying", "Junxiu Tang", "Tingying He", "Jean-Daniel Fekete"], "title": "A Constructive Scientific Methodology to Improve Climate Figures from IPCC", "comment": null, "summary": "We propose a methodology to improve figures from the Intergovernmental Panel on Climate Change (IPCC), ensuring that all modifications remain scientifically rigorous. IPCC figures are notoriously difficult to understand, and although designers have proposed alternatives, these lack formal IPCC validation and can be dismissed by skeptics. To address this gap, our approach starts from official IPCC figures. We gather their associated learning objectives and devise tests to score a pool of figure readers to assess how well they learn the objectives.We define improvement as higher scores obtained by a comparable reader pool after viewing a revised figure, where all modifications undergo review to ensure scientific validity. This assessment gives freedom to designers, who can deviate from the original design while making sure the objectives are still met and improved. We demonstrate the methodology through a case study and describe unexpected challenges encountered during the process.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6539\u8fdbIPCC\u56fe\u8868\u7684\u65b9\u6cd5\u8bba\uff0c\u786e\u4fdd\u4fee\u6539\u79d1\u5b66\u4e25\u8c28\uff0c\u901a\u8fc7\u6d4b\u8bd5\u8bfb\u8005\u5bf9\u5b66\u4e60\u76ee\u6807\u7684\u638c\u63e1\u7a0b\u5ea6\u6765\u8bc4\u4f30\u6539\u8fdb\u6548\u679c", "motivation": "IPCC\u56fe\u8868\u96be\u4ee5\u7406\u89e3\uff0c\u73b0\u6709\u66ff\u4ee3\u8bbe\u8ba1\u7f3a\u4e4f\u6b63\u5f0f\u9a8c\u8bc1\uff0c\u5bb9\u6613\u88ab\u6000\u7591\u8005\u5426\u5b9a\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u6539\u8fdb\u56fe\u8868\u8bbe\u8ba1\u53c8\u4fdd\u6301\u79d1\u5b66\u4e25\u8c28\u6027\u7684\u65b9\u6cd5", "method": "\u4ece\u5b98\u65b9IPCC\u56fe\u8868\u51fa\u53d1\uff0c\u6536\u96c6\u5176\u5b66\u4e60\u76ee\u6807\uff0c\u8bbe\u8ba1\u6d4b\u8bd5\u8bc4\u4f30\u8bfb\u8005\u5bf9\u76ee\u6807\u7684\u638c\u63e1\u7a0b\u5ea6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u539f\u59cb\u56fe\u8868\u548c\u6539\u8fdb\u540e\u56fe\u8868\u7684\u6d4b\u8bd5\u5206\u6570\u6765\u5b9a\u4e49\u6539\u8fdb\uff0c\u6240\u6709\u4fee\u6539\u90fd\u7ecf\u8fc7\u79d1\u5b66\u6709\u6548\u6027\u5ba1\u67e5", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u8bba\u7684\u5e94\u7528\uff0c\u5e76\u63cf\u8ff0\u4e86\u5b9e\u65bd\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u610f\u5916\u6311\u6218", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8bbe\u8ba1\u5e08\u63d0\u4f9b\u4e86\u6539\u8fdbIPCC\u56fe\u8868\u7684\u81ea\u7531\uff0c\u540c\u65f6\u786e\u4fdd\u79d1\u5b66\u4e25\u8c28\u6027\uff0c\u901a\u8fc7\u91cf\u5316\u8bc4\u4f30\u8bc1\u660e\u6539\u8fdb\u6548\u679c"}}
{"id": "2512.15044", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.15044", "abs": "https://arxiv.org/abs/2512.15044", "authors": ["Wenwen Xie", "Geng Sun", "Ruichen Zhang", "Xuejie Liu", "Yinqiu Liu", "Jiacheng Wang", "Dusit Niyato", "Ping Zhang"], "title": "Agentic AI for Integrated Sensing and Communication: Analysis, Framework, and Case Study", "comment": null, "summary": "Integrated sensing and communication (ISAC) has emerged as a key development direction in the sixth-generation (6G) era, which provides essential support for the collaborative sensing and communication of future intelligent networks. However, as wireless environments become increasingly dynamic and complex, ISAC systems require more intelligent processing and more autonomous operation to maintain efficiency and adaptability. Meanwhile, agentic artificial intelligence (AI) offers a feasible solution to address these challenges by enabling continuous perception-reasoning-action loops in dynamic environments to support intelligent, autonomous, and efficient operation for ISAC systems. As such, we delve into the application value and prospects of agentic AI in ISAC systems in this work. Firstly, we provide a comprehensive review of agentic AI and ISAC systems to demonstrate their key characteristics. Secondly, we show several common optimization approaches for ISAC systems and highlight the significant advantages of generative artificial intelligence (GenAI)-based agentic AI. Thirdly, we propose a novel agentic ISAC framework and prensent a case study to verify its superiority in optimizing ISAC performance. Finally, we clarify future research directions for agentic AI-based ISAC systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\u5728\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u4ef7\u503c\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53AI\u7684ISAC\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u65e0\u7ebf\u73af\u5883\u65e5\u76ca\u52a8\u6001\u590d\u6742\uff0cISAC\u7cfb\u7edf\u9700\u8981\u66f4\u667a\u80fd\u7684\u5904\u7406\u548c\u66f4\u81ea\u4e3b\u7684\u64cd\u4f5c\u6765\u4fdd\u6301\u6548\u7387\u548c\u9002\u5e94\u6027\u3002\u667a\u80fd\u4f53AI\u901a\u8fc7\u5b9e\u73b0\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6301\u7eed\u611f\u77e5-\u63a8\u7406-\u884c\u52a8\u5faa\u73af\uff0c\u4e3aISAC\u7cfb\u7edf\u63d0\u4f9b\u667a\u80fd\u3001\u81ea\u4e3b\u3001\u9ad8\u6548\u8fd0\u884c\u7684\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u9996\u5148\u5168\u9762\u56de\u987e\u667a\u80fd\u4f53AI\u548cISAC\u7cfb\u7edf\u7684\u5173\u952e\u7279\u6027\uff1b\u5176\u6b21\u5c55\u793aISAC\u7cfb\u7edf\u7684\u51e0\u79cd\u5e38\u89c1\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u7a81\u51fa\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u667a\u80fd\u4f53AI\u7684\u663e\u8457\u4f18\u52bf\uff1b\u7136\u540e\u63d0\u51fa\u4e00\u4e2a\u65b0\u9896\u7684\u667a\u80fd\u4f53ISAC\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u4f18\u5316ISAC\u6027\u80fd\u7684\u4f18\u8d8a\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u7684\u667a\u80fd\u4f53ISAC\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u4f18\u5316ISAC\u6027\u80fd\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u667a\u80fd\u4f53AI\u4e3aISAC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u6280\u672f\u652f\u6491\uff0c\u672a\u6765\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u667a\u80fd\u4f53AI\u5728ISAC\u7cfb\u7edf\u4e2d\u7684\u5177\u4f53\u5e94\u7528\u65b9\u5411\u548c\u53d1\u5c55\u8def\u5f84\u3002"}}
{"id": "2512.14715", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14715", "abs": "https://arxiv.org/abs/2512.14715", "authors": ["Zafaryab Haider", "Md Hafizur Rahman", "Shane Moeykens", "Vijay Devabhaktuni", "Prabuddha Chakraborty"], "title": "How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection", "comment": null, "summary": "Hard-to-detect hardware bit flips, from either malicious circuitry or bugs, have already been shown to make transformers vulnerable in non-generative tasks. This work, for the first time, investigates how low-level, bitwise perturbations (fault injection) to the weights of a large language model (LLM) used for image captioning can influence the semantic meaning of its generated descriptions while preserving grammatical structure. While prior fault analysis methods have shown that flipping a few bits can crash classifiers or degrade accuracy, these approaches overlook the semantic and linguistic dimensions of generative systems. In image captioning models, a single flipped bit might subtly alter how visual features map to words, shifting the entire narrative an AI tells about the world. We hypothesize that such semantic drifts are not random but differentiably estimable. That is, the model's own gradients can predict which bits, if perturbed, will most strongly influence meaning while leaving syntax and fluency intact. We design a differentiable fault analysis framework, BLADE (Bit-level Fault Analysis via Differentiable Estimation), that uses gradient-based sensitivity estimation to locate semantically critical bits and then refines their selection through a caption-level semantic-fluency objective. Our goal is not merely to corrupt captions, but to understand how meaning itself is encoded, distributed, and alterable at the bit level, revealing that even imperceptible low-level changes can steer the high-level semantics of generative vision-language models. It also opens pathways for robustness testing, adversarial defense, and explainable AI, by exposing how structured bit-level faults can reshape a model's semantic output.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7814\u7a76\u4e86\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6743\u91cd\u8fdb\u884c\u6bd4\u7279\u7ea7\u6270\u52a8\u5982\u4f55\u5f71\u54cd\u56fe\u50cf\u63cf\u8ff0\u751f\u6210\u7684\u8bed\u4e49\u542b\u4e49\uff0c\u540c\u65f6\u4fdd\u6301\u8bed\u6cd5\u7ed3\u6784\u5b8c\u6574\u3002\u63d0\u51fa\u4e86BLADE\u6846\u67b6\uff0c\u901a\u8fc7\u68af\u5ea6\u654f\u611f\u6027\u4f30\u8ba1\u5b9a\u4f4d\u8bed\u4e49\u5173\u952e\u6bd4\u7279\uff0c\u63ed\u793a\u6bd4\u7279\u7ea7\u53d8\u5316\u5982\u4f55\u91cd\u5851\u751f\u6210\u5f0f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u5c42\u8bed\u4e49\u3002", "motivation": "\u5148\u524d\u7684\u7814\u7a76\u8868\u660e\uff0c\u786c\u4ef6\u6bd4\u7279\u7ffb\u8f6c\uff08\u65e0\u8bba\u662f\u6076\u610f\u7535\u8def\u8fd8\u662fbug\uff09\u5df2\u7ecf\u4f7ftransformer\u5728\u975e\u751f\u6210\u4efb\u52a1\u4e2d\u53d8\u5f97\u8106\u5f31\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5ffd\u7565\u4e86\u751f\u6210\u7cfb\u7edf\u7684\u8bed\u4e49\u548c\u8bed\u8a00\u7ef4\u5ea6\u3002\u5728\u56fe\u50cf\u63cf\u8ff0\u6a21\u578b\u4e2d\uff0c\u5355\u4e2a\u7ffb\u8f6c\u7684\u6bd4\u7279\u53ef\u80fd\u4f1a\u5fae\u5999\u5730\u6539\u53d8\u89c6\u89c9\u7279\u5f81\u5230\u8bcd\u8bed\u7684\u6620\u5c04\uff0c\u4ece\u800c\u6539\u53d8AI\u5bf9\u4e16\u754c\u7684\u53d9\u8ff0\u65b9\u5f0f\u3002", "method": "\u8bbe\u8ba1\u4e86BLADE\uff08Bit-level Fault Analysis via Differentiable Estimation\uff09\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u654f\u611f\u6027\u4f30\u8ba1\u6765\u5b9a\u4f4d\u8bed\u4e49\u5173\u952e\u6bd4\u7279\uff0c\u7136\u540e\u901a\u8fc7\u63cf\u8ff0\u7ea7\u522b\u7684\u8bed\u4e49\u6d41\u7545\u6027\u76ee\u6807\u6765\u4f18\u5316\u6bd4\u7279\u9009\u62e9\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u7834\u574f\u63cf\u8ff0\uff0c\u8fd8\u7406\u89e3\u610f\u4e49\u5982\u4f55\u5728\u6bd4\u7279\u7ea7\u522b\u7f16\u7801\u3001\u5206\u5e03\u548c\u6539\u53d8\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u96be\u4ee5\u5bdf\u89c9\u7684\u4f4e\u5c42\u6bd4\u7279\u53d8\u5316\u4e5f\u80fd\u5f15\u5bfc\u751f\u6210\u5f0f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u5c42\u8bed\u4e49\u3002\u8bed\u4e49\u6f02\u79fb\u4e0d\u662f\u968f\u673a\u7684\uff0c\u800c\u662f\u53ef\u4ee5\u901a\u8fc7\u6a21\u578b\u81ea\u8eab\u7684\u68af\u5ea6\u8fdb\u884c\u53ef\u5fae\u5206\u4f30\u8ba1\u7684\u3002\u7279\u5b9a\u7684\u6bd4\u7279\u6270\u52a8\u53ef\u4ee5\u5f3a\u70c8\u5f71\u54cd\u542b\u4e49\uff0c\u540c\u65f6\u4fdd\u6301\u8bed\u6cd5\u548c\u6d41\u7545\u6027\u5b8c\u6574\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63ed\u793a\u4e86\u6bd4\u7279\u7ea7\u6545\u969c\u5982\u4f55\u91cd\u5851\u6a21\u578b\u7684\u8bed\u4e49\u8f93\u51fa\uff0c\u4e3a\u9c81\u68d2\u6027\u6d4b\u8bd5\u3001\u5bf9\u6297\u9632\u5fa1\u548c\u53ef\u89e3\u91caAI\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002\u5b83\u5c55\u793a\u4e86\u7ed3\u6784\u5316\u6bd4\u7279\u7ea7\u6545\u969c\u5982\u4f55\u80fd\u591f\u6539\u53d8\u751f\u6210\u5f0f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u5c42\u8bed\u4e49\uff0c\u5373\u4f7f\u662f\u6700\u5fae\u5c0f\u7684\u5e95\u5c42\u53d8\u5316\u4e5f\u80fd\u4ea7\u751f\u663e\u8457\u5f71\u54cd\u3002"}}
{"id": "2512.15462", "categories": ["cs.AI", "cs.HC", "cs.SC"], "pdf": "https://arxiv.org/pdf/2512.15462", "abs": "https://arxiv.org/abs/2512.15462", "authors": ["Jeongseok Kim", "Kangjin Kim"], "title": "Intent-Driven UAM Rescheduling", "comment": "18 pages, 2 figures, AAIML submitted", "summary": "Due to the restricted resources, efficient scheduling in vertiports has received much more attention in the field of Urban Air Mobility (UAM). For the scheduling problem, we utilize a Mixed Integer Linear Programming (MILP), which is often formulated in a resource-restricted project scheduling problem (RCPSP). In this paper, we show our approach to handle both dynamic operation requirements and vague rescheduling requests from humans. Particularly, we utilize a three-valued logic for interpreting ambiguous user intents and a decision tree, proposing a newly integrated system that combines Answer Set Programming (ASP) and MILP. This integrated framework optimizes schedules and supports human inputs transparently. With this system, we provide a robust structure for explainable, adaptive UAM scheduling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408ASP\u548cMILP\u7684\u96c6\u6210\u7cfb\u7edf\uff0c\u7528\u4e8e\u5904\u7406UAM\u5782\u76f4\u8d77\u964d\u673a\u573a\u7684\u52a8\u6001\u8c03\u5ea6\u9700\u6c42\u548c\u6a21\u7cca\u7684\u4eba\u7c7b\u91cd\u8c03\u5ea6\u8bf7\u6c42\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u81ea\u9002\u5e94\u8c03\u5ea6\u6846\u67b6\u3002", "motivation": "\u7531\u4e8e\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a\uff08UAM\uff09\u9886\u57df\u8d44\u6e90\u53d7\u9650\uff0c\u5782\u76f4\u8d77\u964d\u673a\u573a\u7684\u9ad8\u6548\u8c03\u5ea6\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\u3002\u73b0\u6709\u8c03\u5ea6\u65b9\u6cd5\u9700\u8981\u540c\u65f6\u5904\u7406\u52a8\u6001\u64cd\u4f5c\u9700\u6c42\u548c\u4eba\u7c7b\u6a21\u7cca\u7684\u91cd\u8c03\u5ea6\u8bf7\u6c42\uff0c\u8fd9\u9700\u8981\u66f4\u7075\u6d3b\u548c\u900f\u660e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u4f5c\u4e3a\u8c03\u5ea6\u95ee\u9898\u7684\u57fa\u7840\uff0c\u5c06\u5176\u5efa\u6a21\u4e3a\u8d44\u6e90\u53d7\u9650\u9879\u76ee\u8c03\u5ea6\u95ee\u9898\uff08RCPSP\uff09\u3002\u521b\u65b0\u6027\u5730\u7ed3\u5408\u4e86\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u548cMILP\uff0c\u4f7f\u7528\u4e09\u503c\u903b\u8f91\u89e3\u91ca\u6a21\u7cca\u7684\u7528\u6237\u610f\u56fe\uff0c\u5e76\u5229\u7528\u51b3\u7b56\u6811\u6784\u5efa\u96c6\u6210\u7cfb\u7edf\uff0c\u4ee5\u900f\u660e\u5730\u652f\u6301\u4eba\u7c7b\u8f93\u5165\u3002", "result": "\u63d0\u51fa\u7684\u96c6\u6210\u6846\u67b6\u80fd\u591f\u4f18\u5316\u8c03\u5ea6\u65b9\u6848\uff0c\u540c\u65f6\u900f\u660e\u5730\u652f\u6301\u4eba\u7c7b\u8f93\u5165\uff0c\u4e3aUAM\u8c03\u5ea6\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u7ed3\u6784\u3002\u7cfb\u7edf\u80fd\u591f\u5904\u7406\u52a8\u6001\u64cd\u4f5c\u9700\u6c42\u548c\u6a21\u7cca\u7684\u91cd\u8c03\u5ea6\u8bf7\u6c42\uff0c\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u7684\u81ea\u9002\u5e94\u8c03\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408ASP\u548cMILP\u7684\u96c6\u6210\u7cfb\u7edf\uff0c\u4e3aUAM\u5782\u76f4\u8d77\u964d\u673a\u573a\u8c03\u5ea6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u3001\u53ef\u89e3\u91ca\u7684\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u52a8\u6001\u9700\u6c42\u548c\u4eba\u7c7b\u6a21\u7cca\u8bf7\u6c42\uff0c\u63d0\u9ad8\u4e86\u8c03\u5ea6\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2512.15089", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15089", "abs": "https://arxiv.org/abs/2512.15089", "authors": ["Jinwu Hu", "Dongjin Yang", "Langyu Bian", "Zhiquan Wen", "Yufeng Wang", "Yaofo Chen", "Bin Xiao", "Yuanqing Li", "Mingkui Tan"], "title": "Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models", "comment": "under review", "summary": "Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of varying difficulties. In this paper, we propose Cognitive-Inspired Elastic Reasoning (CogER), a framework inspired by human hierarchical reasoning that dynamically selects the most suitable reasoning strategy for each query. Specifically, CogER first assesses the complexity of incoming queries and assigns them to one of several predefined levels, each corresponding to a tailored processing strategy, thereby addressing the challenge of unobservable query difficulty. To achieve automatic strategy selection, we model the process as a Markov Decision Process and train a CogER-Agent using reinforcement learning. The agent is guided by a reward function that balances solution quality and computational cost, ensuring resource-efficient reasoning. Moreover, for queries requiring external tools, we introduce Cognitive Tool-Assisted Reasoning, which enables the LLM to autonomously invoke external tools within its chain-of-thought. Extensive experiments demonstrate that CogER outperforms state-of-the-art Test-Time scaling methods, achieving at least a 13% relative improvement in average exact match on In-Domain tasks and an 8% relative gain on Out-of-Domain tasks.", "AI": {"tldr": "CogER\u662f\u4e00\u4e2a\u53d7\u4eba\u7c7b\u5206\u5c42\u63a8\u7406\u542f\u53d1\u7684\u5f39\u6027\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u6700\u9002\u5408\u6bcf\u4e2a\u67e5\u8be2\u7684\u63a8\u7406\u7b56\u7565\u6765\u5e73\u8861LLM\u7684\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709LLM\u63a8\u7406\u7b56\u7565\u4e3b\u8981\u4f9d\u8d56LLM\u81ea\u8eab\u7684\u5feb\u6162\u6a21\u5f0f\uff08\u5982o1\u601d\u8003\uff09\uff0c\u96be\u4ee5\u5728\u67e5\u8be2\u96be\u5ea6\u53d8\u5316\u65f6\u5e73\u8861\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "1) \u8bc4\u4f30\u67e5\u8be2\u590d\u6742\u5ea6\u5e76\u5206\u914d\u5230\u9884\u5b9a\u4e49\u7ea7\u522b\uff1b2) \u5c06\u7b56\u7565\u9009\u62e9\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3CogER-Agent\uff1b3) \u5f15\u5165\u8ba4\u77e5\u5de5\u5177\u8f85\u52a9\u63a8\u7406\uff0c\u8ba9LLM\u5728\u601d\u7ef4\u94fe\u4e2d\u81ea\u4e3b\u8c03\u7528\u5916\u90e8\u5de5\u5177\u3002", "result": "CogER\u5728\u9886\u57df\u5185\u4efb\u52a1\u4e0a\u5b9e\u73b0\u81f3\u5c1113%\u7684\u76f8\u5bf9\u5e73\u5747\u7cbe\u786e\u5339\u914d\u63d0\u5347\uff0c\u5728\u9886\u57df\u5916\u4efb\u52a1\u4e0a\u5b9e\u73b08%\u7684\u76f8\u5bf9\u589e\u76ca\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\u3002", "conclusion": "CogER\u901a\u8fc7\u52a8\u6001\u7b56\u7565\u9009\u62e9\u548c\u5de5\u5177\u8f85\u52a9\u63a8\u7406\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u63a8\u7406\u4e2d\u6548\u7387\u4e0e\u51c6\u786e\u6027\u7684\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2512.14717", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14717", "abs": "https://arxiv.org/abs/2512.14717", "authors": ["Ziqian Bi", "Danyang Zhang", "Junhao Song", "Chiung-Yi Tseng"], "title": "Is GPT-OSS All You Need? Benchmarking Large Language Models for Financial Intelligence and the Surprising Efficiency Paradox", "comment": null, "summary": "The rapid adoption of large language models in financial services necessitates rigorous evaluation frameworks to assess their performance, efficiency, and practical applicability. This paper conducts a comprehensive evaluation of the GPT-OSS model family alongside contemporary LLMs across ten diverse financial NLP tasks. Through extensive experimentation on 120B and 20B parameter variants of GPT-OSS, we reveal a counterintuitive finding: the smaller GPT-OSS-20B model achieves comparable accuracy (65.1% vs 66.5%) while demonstrating superior computational efficiency with 198.4 Token Efficiency Score and 159.80 tokens per second processing speed [1]. Our evaluation encompasses sentiment analysis, question answering, and entity recognition tasks using real-world financial datasets including Financial PhraseBank, FiQA-SA, and FLARE FINERORD. We introduce novel efficiency metrics that capture the trade-off between model performance and resource utilization, providing critical insights for deployment decisions in production environments. The benchmark reveals that GPT-OSS models consistently outperform larger competitors including Qwen3-235B, challenging the prevailing assumption that model scale directly correlates with task performance [2]. Our findings demonstrate that architectural innovations and training strategies in GPT-OSS enable smaller models to achieve competitive performance with significantly reduced computational overhead, offering a pathway toward sustainable and cost-effective deployment of LLMs in financial applications.", "AI": {"tldr": "GPT-OSS-20B\u5728\u91d1\u878dNLP\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0e\u66f4\u5927\u6a21\u578b\u76f8\u5f53\uff0c\u4f46\u8ba1\u7b97\u6548\u7387\u663e\u8457\u66f4\u9ad8\uff0c\u6311\u6218\u4e86\u6a21\u578b\u89c4\u6a21\u4e0e\u6027\u80fd\u76f4\u63a5\u76f8\u5173\u7684\u5047\u8bbe\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u670d\u52a1\u4e2d\u7684\u5feb\u901f\u5e94\u7528\uff0c\u9700\u8981\u5efa\u7acb\u4e25\u683c\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u8861\u91cf\u5176\u6027\u80fd\u3001\u6548\u7387\u548c\u5b9e\u9645\u9002\u7528\u6027\uff0c\u4ee5\u6307\u5bfc\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u51b3\u7b56\u3002", "method": "\u5bf9GPT-OSS\u6a21\u578b\u5bb6\u65cf\u53ca\u5f53\u4ee3LLMs\u572810\u4e2a\u4e0d\u540c\u91d1\u878dNLP\u4efb\u52a1\u4e0a\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff0c\u5305\u62ec120B\u548c20B\u53c2\u6570\u53d8\u4f53\u3002\u4f7f\u7528\u771f\u5b9e\u91d1\u878d\u6570\u636e\u96c6\uff08Financial PhraseBank\u3001FiQA-SA\u3001FLARE FINERORD\uff09\u8fdb\u884c\u60c5\u611f\u5206\u6790\u3001\u95ee\u7b54\u548c\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u6548\u7387\u6307\u6807\u6765\u6355\u6349\u6027\u80fd\u4e0e\u8d44\u6e90\u5229\u7528\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "GPT-OSS-20B\u6a21\u578b\u5728\u51c6\u786e\u7387\u4e0a\u4e0e\u66f4\u5927\u6a21\u578b\u76f8\u5f53\uff0865.1% vs 66.5%\uff09\uff0c\u4f46\u8ba1\u7b97\u6548\u7387\u663e\u8457\u66f4\u9ad8\uff0c\u83b7\u5f97198.4 Token Efficiency Score\u548c159.80 tokens/\u79d2\u7684\u5904\u7406\u901f\u5ea6\u3002GPT-OSS\u6a21\u578b\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5305\u62ecQwen3-235B\u5728\u5185\u7684\u66f4\u5927\u7ade\u4e89\u5bf9\u624b\u3002", "conclusion": "GPT-OSS\u7684\u67b6\u6784\u521b\u65b0\u548c\u8bad\u7ec3\u7b56\u7565\u4f7f\u8f83\u5c0f\u6a21\u578b\u80fd\u591f\u4ee5\u663e\u8457\u964d\u4f4e\u7684\u8ba1\u7b97\u5f00\u9500\u5b9e\u73b0\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u4e3a\u91d1\u878d\u5e94\u7528\u4e2d\u53ef\u6301\u7eed\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
{"id": "2512.15198", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.15198", "abs": "https://arxiv.org/abs/2512.15198", "authors": ["Mohsen Nafar", "Michael R\u00f6mer", "Lin Xie"], "title": "A Clustering-Based Variable Ordering Framework for Relaxed Decision Diagrams for Maximum Weighted Independent Set Problem", "comment": null, "summary": "Efficient exact algorithms for Discrete Optimization (DO) rely heavily on strong primal and dual bounds. Relaxed Decision Diagrams (DDs) provide a versatile mechanism for deriving such dual bounds by compactly over-approximating the solution space through node merging. However, the quality of these relaxed diagrams, i.e. the tightness of the resulting dual bounds, depends critically on the variable ordering and the merging decisions executed during compilation. While dynamic variable ordering heuristics effectively tighten bounds, they often incur computational overhead when evaluated globally across the entire variable set. To mitigate this trade-off, this work introduces a novel clustering-based framework for variable ordering. Instead of applying dynamic ordering heuristics to the full set of unfixed variables, we first partition variables into clusters. We then leverage this structural decomposition to guide the ordering process, significantly reducing the heuristic's search space. Within this framework, we investigate two distinct strategies: Cluster-to-Cluster, which processes clusters sequentially using problem-specific aggregate criteria (such as cumulative vertex weights in the Maximum Weighted Independent Set Problem (MWISP)), and Pick-and-Sort, which iteratively selects and sorts representative variables from each cluster to balance local diversity with heuristic guidance. Later on, developing some theoretical results on the growth of the size of DDs for MWISP we propose two different policies for setting the number of clusters within the proposed framework. We embed these strategies into a DD-based branch-and-bound algorithm and evaluate them on the MWISP. Across benchmark instances, the proposed methodology consistently reduces computational costs compared to standard dynamic variable ordering baseline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u53d8\u91cf\u6392\u5e8f\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u79bb\u6563\u4f18\u5316\u4e2d\u51b3\u7b56\u56fe\u7684\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u5728\u6700\u5927\u52a0\u6743\u72ec\u7acb\u96c6\u95ee\u9898\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u79bb\u6563\u4f18\u5316\u4e2d\u7684\u9ad8\u6548\u7cbe\u786e\u7b97\u6cd5\u4f9d\u8d56\u4e8e\u5f3a\u539f\u59cb\u548c\u5bf9\u5076\u8fb9\u754c\u3002\u677e\u5f1b\u51b3\u7b56\u56fe\u901a\u8fc7\u8282\u70b9\u5408\u5e76\u63d0\u4f9b\u5bf9\u5076\u8fb9\u754c\uff0c\u4f46\u5176\u8d28\u91cf\u4e25\u91cd\u4f9d\u8d56\u4e8e\u53d8\u91cf\u6392\u5e8f\u548c\u5408\u5e76\u51b3\u7b56\u3002\u867d\u7136\u52a8\u6001\u53d8\u91cf\u6392\u5e8f\u542f\u53d1\u5f0f\u65b9\u6cd5\u80fd\u6536\u7d27\u8fb9\u754c\uff0c\u4f46\u5728\u6574\u4e2a\u53d8\u91cf\u96c6\u4e0a\u5168\u5c40\u8bc4\u4f30\u4f1a\u4ea7\u751f\u8ba1\u7b97\u5f00\u9500\u3002\u9700\u8981\u5e73\u8861\u8fb9\u754c\u8d28\u91cf\u548c\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u805a\u7c7b\u7684\u53d8\u91cf\u6392\u5e8f\u6846\u67b6\uff1a\u9996\u5148\u5c06\u53d8\u91cf\u5212\u5206\u4e3a\u805a\u7c7b\uff0c\u7136\u540e\u5229\u7528\u8fd9\u79cd\u7ed3\u6784\u5206\u89e3\u6307\u5bfc\u6392\u5e8f\u8fc7\u7a0b\uff0c\u663e\u8457\u51cf\u5c11\u542f\u53d1\u5f0f\u641c\u7d22\u7a7a\u95f4\u3002\u7814\u7a76\u4e86\u4e24\u79cd\u7b56\u7565\uff1a1) \u805a\u7c7b\u5230\u805a\u7c7b\u7b56\u7565\uff0c\u4f7f\u7528\u95ee\u9898\u7279\u5b9a\u7684\u805a\u5408\u6807\u51c6\uff08\u5982MWISP\u4e2d\u7684\u7d2f\u79ef\u9876\u70b9\u6743\u91cd\uff09\u987a\u5e8f\u5904\u7406\u805a\u7c7b\uff1b2) \u9009\u53d6\u6392\u5e8f\u7b56\u7565\uff0c\u4ece\u6bcf\u4e2a\u805a\u7c7b\u8fed\u4ee3\u9009\u62e9\u548c\u6392\u5e8f\u4ee3\u8868\u6027\u53d8\u91cf\u4ee5\u5e73\u8861\u5c40\u90e8\u591a\u6837\u6027\u548c\u542f\u53d1\u5f0f\u6307\u5bfc\u3002\u9488\u5bf9MWISP\u63d0\u51fa\u4e86\u4e24\u79cd\u8bbe\u7f6e\u805a\u7c7b\u6570\u91cf\u7684\u7b56\u7565\uff0c\u5e76\u5c06\u8fd9\u4e9b\u7b56\u7565\u5d4c\u5165\u5230\u57fa\u4e8e\u51b3\u7b56\u56fe\u7684\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\u4e2d\u3002", "result": "\u5728\u6700\u5927\u52a0\u6743\u72ec\u7acb\u96c6\u95ee\u9898\u7684\u57fa\u51c6\u5b9e\u4f8b\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u76f8\u6bd4\u6807\u51c6\u52a8\u6001\u53d8\u91cf\u6392\u5e8f\u57fa\u7ebf\uff0c\u80fd\u591f\u4e00\u81f4\u5730\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u57fa\u4e8e\u805a\u7c7b\u7684\u53d8\u91cf\u6392\u5e8f\u6846\u67b6\u6709\u6548\u5e73\u8861\u4e86\u51b3\u7b56\u56fe\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u901a\u8fc7\u7ed3\u6784\u5206\u89e3\u51cf\u5c11\u542f\u53d1\u5f0f\u641c\u7d22\u7a7a\u95f4\uff0c\u5728MWISP\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8e\u4f20\u7edf\u52a8\u6001\u6392\u5e8f\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2512.14719", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14719", "abs": "https://arxiv.org/abs/2512.14719", "authors": ["Zhuoran Zhang", "Feng Zhang", "Shangyuan Li", "Yang Shi", "Yuanxing Zhang", "Wei Chen", "Tengjiao Wang", "Kam-Fai Wong"], "title": "Hybrid Attribution Priors for Explainable and Robust Model Training", "comment": "15 pages", "summary": "Small language models (SLMs) are widely used in tasks that require low latency and lightweight deployment, particularly classification. As interpretability and robustness gain increasing importance, explanation-guided learning has emerged as an effective framework by introducing attribution-based supervision during training; however, deriving general and reliable attribution priors remains a significant challenge. Through an analysis of representative attribution methods in classification settings, we find that although these methods can reliably highlight class-relevant tokens, they often focus on common keywords shared by semantically similar classes. Because such classes are already difficult to distinguish under standard training, these attributions provide insufficient discriminative cues, limiting their ability to improve model differentiation. To overcome this limitation, we propose Class-Aware Attribution Prior (CAP), a novel attribution prior extraction framework that guides language models toward capturing fine-grained class distinctions and producing more salient, discriminative attribution priors. Building on this idea, we further introduce CAP Hybrid, which combines priors from CAP with those from existing attribution techniques to form a more comprehensive and balanced supervisory signal. By aligning a model's self-attribution with these enriched priors, our approach encourages the learning of diverse, decision-relevant features. Extensive experiments in full-data, few-shot, and adversarial scenarios demonstrate that our method consistently enhances both interpretability and robustness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCAP\uff08Class-Aware Attribution Prior\uff09\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u73b0\u6709\u5f52\u56e0\u65b9\u6cd5\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u96be\u4ee5\u533a\u5206\u8bed\u4e49\u76f8\u4f3c\u7c7b\u522b\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u63d0\u53d6\u7ec6\u7c92\u5ea6\u7c7b\u522b\u533a\u5206\u7279\u5f81\u6765\u63d0\u5347\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u65e5\u76ca\u91cd\u8981\uff0c\u57fa\u4e8e\u5f52\u56e0\u7684\u76d1\u7763\u5b66\u4e60\u6210\u4e3a\u6709\u6548\u6846\u67b6\uff0c\u4f46\u83b7\u53d6\u901a\u7528\u53ef\u9760\u7684\u5f52\u56e0\u5148\u9a8c\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u5f52\u56e0\u65b9\u6cd5\u867d\u7136\u80fd\u53ef\u9760\u5730\u7a81\u51fa\u7c7b\u522b\u76f8\u5173\u6807\u8bb0\uff0c\u4f46\u5f80\u5f80\u805a\u7126\u4e8e\u8bed\u4e49\u76f8\u4f3c\u7c7b\u522b\u5171\u4eab\u7684\u5e38\u89c1\u5173\u952e\u8bcd\uff0c\u8fd9\u4e9b\u7c7b\u522b\u5728\u6807\u51c6\u8bad\u7ec3\u4e2d\u672c\u5c31\u96be\u4ee5\u533a\u5206\uff0c\u5bfc\u81f4\u5f52\u56e0\u63d0\u4f9b\u4e0d\u8db3\u7684\u5224\u522b\u6027\u7ebf\u7d22\uff0c\u9650\u5236\u4e86\u6a21\u578b\u533a\u5206\u80fd\u529b\u7684\u63d0\u5347\u3002", "method": "\u63d0\u51faClass-Aware Attribution Prior\uff08CAP\uff09\u6846\u67b6\uff0c\u5f15\u5bfc\u8bed\u8a00\u6a21\u578b\u6355\u6349\u7ec6\u7c92\u5ea6\u7c7b\u522b\u5dee\u5f02\uff0c\u751f\u6210\u66f4\u663e\u8457\u3001\u66f4\u5177\u5224\u522b\u6027\u7684\u5f52\u56e0\u5148\u9a8c\u3002\u8fdb\u4e00\u6b65\u63d0\u51faCAP Hybrid\u65b9\u6cd5\uff0c\u5c06CAP\u7684\u5148\u9a8c\u4e0e\u73b0\u6709\u5f52\u56e0\u6280\u672f\u7684\u5148\u9a8c\u76f8\u7ed3\u5408\uff0c\u5f62\u6210\u66f4\u5168\u9762\u5e73\u8861\u7684\u76d1\u7763\u4fe1\u53f7\u3002\u901a\u8fc7\u5c06\u6a21\u578b\u7684\u81ea\u5f52\u56e0\u4e0e\u8fd9\u4e9b\u4e30\u5bcc\u7684\u5148\u9a8c\u5bf9\u9f50\uff0c\u9f13\u52b1\u5b66\u4e60\u591a\u6837\u5316\u7684\u51b3\u7b56\u76f8\u5173\u7279\u5f81\u3002", "result": "\u5728\u5b8c\u6574\u6570\u636e\u3001\u5c11\u6837\u672c\u548c\u5bf9\u6297\u573a\u666f\u4e0b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u4e00\u81f4\u5730\u63d0\u5347\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "CAP\u6846\u67b6\u901a\u8fc7\u63d0\u53d6\u7ec6\u7c92\u5ea6\u7c7b\u522b\u533a\u5206\u7279\u5f81\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5f52\u56e0\u65b9\u6cd5\u5728\u533a\u5206\u8bed\u4e49\u76f8\u4f3c\u7c7b\u522b\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5c0f\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u91ca\u6027\u76d1\u7763\u4fe1\u53f7\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u591a\u79cd\u573a\u666f\u4e0b\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2512.14721", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14721", "abs": "https://arxiv.org/abs/2512.14721", "authors": ["Arno Appenzeller", "Nick Terzer", "Andr\u00e9 Hohmeyer", "Jan-Philipp Redlich", "Sabine Luttmann", "Friedrich Feuerhake", "Nadine S. Schaadt", "Timm Intemann", "Sarah Teuber-Hanselmann", "Stefan Nikolin", "Joachim Weis", "Klaus Kraywinkel", "Pascal Birnstill"], "title": "Automatic Extraction of Rules for Generating Synthetic Patient Data From Real-World Population Data Using Glioblastoma as an Example", "comment": "16 pages, 8 figures", "summary": "The generation of synthetic data is a promising technology to make medical data available for secondary use in a privacy-compliant manner. A popular method for creating realistic patient data is the rule-based Synthea data generator. Synthea generates data based on rules describing the lifetime of a synthetic patient. These rules typically express the probability of a condition occurring, such as a disease, depending on factors like age. Since they only contain statistical information, rules usually have no specific data protection requirements. However, creating meaningful rules can be a very complex process that requires expert knowledge and realistic sample data. In this paper, we introduce and evaluate an approach to automatically generate Synthea rules based on statistics from tabular data, which we extracted from cancer reports. As an example use case, we created a Synthea module for glioblastoma from a real-world dataset and used it to generate a synthetic dataset. Compared to the original dataset, the synthetic data reproduced known disease courses and mostly retained the statistical properties. Overall, synthetic patient data holds great potential for privacy-preserving research. The data can be used to formulate hypotheses and to develop prototypes, but medical interpretation should consider the specific limitations as with any currently available approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u764c\u75c7\u62a5\u544a\u7edf\u8ba1\u4fe1\u606f\u81ea\u52a8\u751f\u6210Synthea\u89c4\u5219\u7684\u65b9\u6cd5\uff0c\u5e76\u4ee5\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u4e3a\u4f8b\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u80fd\u591f\u590d\u73b0\u75be\u75c5\u8fdb\u7a0b\u5e76\u4fdd\u7559\u7edf\u8ba1\u7279\u6027\u3002", "motivation": "\u5408\u6210\u6570\u636e\u751f\u6210\u662f\u533b\u7597\u6570\u636e\u9690\u79c1\u5408\u89c4\u4e8c\u6b21\u5229\u7528\u7684\u6709\u524d\u666f\u6280\u672f\u3002Synthea\u662f\u57fa\u4e8e\u89c4\u5219\u7684\u6d41\u884c\u65b9\u6cd5\uff0c\u4f46\u624b\u52a8\u521b\u5efa\u6709\u610f\u4e49\u7684\u89c4\u5219\u9700\u8981\u4e13\u5bb6\u77e5\u8bc6\u548c\u771f\u5b9e\u6837\u672c\u6570\u636e\uff0c\u8fc7\u7a0b\u590d\u6742\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8868\u683c\u6570\u636e\u7edf\u8ba1\u4fe1\u606f\u81ea\u52a8\u751f\u6210Synthea\u89c4\u5219\u7684\u65b9\u6cd5\u3002\u4ece\u764c\u75c7\u62a5\u544a\u4e2d\u63d0\u53d6\u7edf\u8ba1\u4fe1\u606f\uff0c\u4ee5\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u4e3a\u7528\u4f8b\uff0c\u521b\u5efaSynthea\u6a21\u5757\u5e76\u751f\u6210\u5408\u6210\u6570\u636e\u96c6\u3002", "result": "\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u80fd\u591f\u590d\u73b0\u5df2\u77e5\u75be\u75c5\u8fdb\u7a0b\uff0c\u5927\u90e8\u5206\u4fdd\u7559\u4e86\u539f\u59cb\u6570\u636e\u96c6\u7684\u7edf\u8ba1\u7279\u6027\u3002\u5408\u6210\u6570\u636e\u4e0e\u539f\u59cb\u6570\u636e\u96c6\u76f8\u6bd4\u5177\u6709\u826f\u597d\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u5408\u6210\u60a3\u8005\u6570\u636e\u5728\u9690\u79c1\u4fdd\u62a4\u7814\u7a76\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u53ef\u7528\u4e8e\u5047\u8bbe\u63d0\u51fa\u548c\u539f\u578b\u5f00\u53d1\uff0c\u4f46\u533b\u7597\u89e3\u91ca\u5e94\u8003\u8651\u5f53\u524d\u53ef\u7528\u65b9\u6cd5\u7684\u7279\u5b9a\u5c40\u9650\u6027\u3002"}}
{"id": "2512.15298", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.15298", "abs": "https://arxiv.org/abs/2512.15298", "authors": ["Seok-Hyun Ga", "Chun-Yen Chang"], "title": "ChatGPT and Gemini participated in the Korean College Scholastic Ability Test -- Earth Science I", "comment": "23 pages, 9 tables, 1 figure", "summary": "The rapid development of Generative AI is bringing innovative changes to education and assessment. As the prevalence of students utilizing AI for assignments increases, concerns regarding academic integrity and the validity of assessments are growing. This study utilizes the Earth Science I section of the 2025 Korean College Scholastic Ability Test (CSAT) to deeply analyze the multimodal scientific reasoning capabilities and cognitive limitations of state-of-the-art Large Language Models (LLMs), including GPT-4o, Gemini 2.5 Flash, and Gemini 2.5 Pro. Three experimental conditions (full-page input, individual item input, and optimized multimodal input) were designed to evaluate model performance across different data structures. Quantitative results indicated that unstructured inputs led to significant performance degradation due to segmentation and Optical Character Recognition (OCR) failures. Even under optimized conditions, models exhibited fundamental reasoning flaws. Qualitative analysis revealed that \"Perception Errors\" were dominant, highlighting a \"Perception-Cognition Gap\" where models failed to interpret symbolic meanings in schematic diagrams despite recognizing visual data. Furthermore, models demonstrated a \"Calculation-Conceptualization Discrepancy,\" successfully performing calculations while failing to apply the underlying scientific concepts, and \"Process Hallucination,\" where models skipped visual verification in favor of plausible but unfounded background knowledge. Addressing the challenge of unauthorized AI use in coursework, this study provides actionable cues for designing \"AI-resistant questions\" that target these specific cognitive vulnerabilities. By exploiting AI's weaknesses, such as the gap between perception and cognition, educators can distinguish genuine student competency from AI-generated responses, thereby ensuring assessment fairness.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86GPT-4o\u3001Gemini 2.5\u7b49\u5927\u8bed\u8a00\u6a21\u578b\u5728\u97e9\u56fd\u9ad8\u8003\u5730\u7403\u79d1\u5b66I\u8bd5\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u611f\u77e5-\u8ba4\u77e5\u9e3f\u6c9f\u3001\u8ba1\u7b97-\u6982\u5ff5\u5316\u5dee\u5f02\u548c\u8fc7\u7a0b\u5e7b\u89c9\u7b49\u8ba4\u77e5\u7f3a\u9677\uff0c\u4e3a\u8bbe\u8ba1\"AI\u6297\u6027\u9898\u76ee\"\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002", "motivation": "\u968f\u7740\u5b66\u751f\u4f7f\u7528AI\u5b8c\u6210\u4f5c\u4e1a\u7684\u73b0\u8c61\u65e5\u76ca\u666e\u904d\uff0c\u5b66\u672f\u8bda\u4fe1\u548c\u8bc4\u4f30\u6709\u6548\u6027\u53d7\u5230\u5a01\u80c1\u3002\u672c\u7814\u7a76\u65e8\u5728\u6df1\u5165\u5206\u6790\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6a21\u6001\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u548c\u8ba4\u77e5\u5c40\u9650\u6027\uff0c\u4e3a\u5e94\u5bf9AI\u5728\u8bfe\u7a0b\u4f5c\u4e1a\u4e2d\u7684\u672a\u7ecf\u6388\u6743\u4f7f\u7528\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u75282025\u5e74\u97e9\u56fd\u9ad8\u8003\u5730\u7403\u79d1\u5b66I\u8bd5\u9898\uff0c\u6d4b\u8bd5GPT-4o\u3001Gemini 2.5 Flash\u548cGemini 2.5 Pro\u4e09\u79cd\u6a21\u578b\u3002\u8bbe\u8ba1\u4e86\u4e09\u79cd\u5b9e\u9a8c\u6761\u4ef6\uff1a\u6574\u9875\u8f93\u5165\u3001\u5355\u9879\u8f93\u5165\u548c\u4f18\u5316\u7684\u591a\u6a21\u6001\u8f93\u5165\uff0c\u4ee5\u8bc4\u4f30\u4e0d\u540c\u6570\u636e\u7ed3\u6784\u4e0b\u7684\u6a21\u578b\u8868\u73b0\u3002\u91c7\u7528\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u8bc6\u522b\u6a21\u578b\u7684\u8ba4\u77e5\u7f3a\u9677\u3002", "result": "\u5b9a\u91cf\u7ed3\u679c\u663e\u793a\uff0c\u975e\u7ed3\u6784\u5316\u8f93\u5165\u56e0\u5206\u5272\u548cOCR\u5931\u8d25\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u5373\u4f7f\u5728\u4f18\u5316\u6761\u4ef6\u4e0b\uff0c\u6a21\u578b\u4ecd\u8868\u73b0\u51fa\u57fa\u672c\u63a8\u7406\u7f3a\u9677\u3002\u5b9a\u6027\u5206\u6790\u53d1\u73b0\"\u611f\u77e5\u9519\u8bef\"\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u5b58\u5728\"\u611f\u77e5-\u8ba4\u77e5\u9e3f\u6c9f\"\uff08\u6a21\u578b\u80fd\u8bc6\u522b\u89c6\u89c9\u6570\u636e\u4f46\u65e0\u6cd5\u89e3\u91ca\u793a\u610f\u56fe\u4e2d\u7684\u7b26\u53f7\u610f\u4e49\uff09\u3001\"\u8ba1\u7b97-\u6982\u5ff5\u5316\u5dee\u5f02\"\uff08\u80fd\u6267\u884c\u8ba1\u7b97\u4f46\u65e0\u6cd5\u5e94\u7528\u57fa\u7840\u79d1\u5b66\u6982\u5ff5\uff09\u548c\"\u8fc7\u7a0b\u5e7b\u89c9\"\uff08\u8df3\u8fc7\u89c6\u89c9\u9a8c\u8bc1\u800c\u4f9d\u8d56\u65e0\u6839\u636e\u7684\u80cc\u666f\u77e5\u8bc6\uff09\u3002", "conclusion": "\u901a\u8fc7\u9488\u5bf9AI\u7684\u7279\u5b9a\u8ba4\u77e5\u5f31\u70b9\uff08\u5982\u611f\u77e5\u4e0e\u8ba4\u77e5\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff09\uff0c\u6559\u80b2\u8005\u53ef\u4ee5\u8bbe\u8ba1\"AI\u6297\u6027\u9898\u76ee\"\uff0c\u533a\u5206\u771f\u5b9e\u5b66\u751f\u80fd\u529b\u4e0eAI\u751f\u6210\u56de\u7b54\uff0c\u4ece\u800c\u786e\u4fdd\u8bc4\u4f30\u7684\u516c\u5e73\u6027\u3002\u8fd9\u4e3a\u89e3\u51b3\u8bfe\u7a0b\u4f5c\u4e1a\u4e2d\u672a\u7ecf\u6388\u6743\u4f7f\u7528AI\u7684\u6311\u6218\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u7ebf\u7d22\u3002"}}
{"id": "2512.14722", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14722", "abs": "https://arxiv.org/abs/2512.14722", "authors": ["Mohamed Malhou", "Ludovic Perret", "Kristin Lauter"], "title": "HATSolver: Learning Groebner Bases with Hierarchical Attention Transformers", "comment": null, "summary": "At NeurIPS 2024, Kera et al. introduced the use of transformers for computing Groebner bases, a central object in computer algebra with numerous practical applications. In this paper, we improve this approach by applying Hierarchical Attention Transformers (HATs) to solve systems of multivariate polynomial equations via Groebner bases computation. The HAT architecture incorporates a tree-structured inductive bias that enables the modeling of hierarchical relationships present in the data and thus achieves significant computational savings compared to conventional flat attention models. We generalize to arbitrary depths and include a detailed computational cost analysis. Combined with curriculum learning, our method solves instances that are much larger than those in Kera et al. (2024 Learning to compute Groebner bases)", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb\u4e86\u4f7f\u7528Transformer\u8ba1\u7b97Gr\u00f6bner\u57fa\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5c42\u6b21\u6ce8\u610f\u529bTransformer\uff08HATs\uff09\u6765\u6c42\u89e3\u591a\u5143\u591a\u9879\u5f0f\u65b9\u7a0b\u7ec4\uff0c\u76f8\u6bd4\u4f20\u7edf\u5e73\u9762\u6ce8\u610f\u529b\u6a21\u578b\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u8ba1\u7b97\u8282\u7701\u3002", "motivation": "Kera\u7b49\u4eba\u5728NeurIPS 2024\u4e2d\u9996\u6b21\u4f7f\u7528Transformer\u8ba1\u7b97Gr\u00f6bner\u57fa\uff0c\u8fd9\u662f\u8ba1\u7b97\u673a\u4ee3\u6570\u4e2d\u7684\u6838\u5fc3\u5bf9\u8c61\uff0c\u5177\u6709\u4f17\u591a\u5b9e\u9645\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u6539\u8fdb\u8fd9\u4e00\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u66f4\u9002\u5408\u5904\u7406\u5c42\u6b21\u7ed3\u6784\u6570\u636e\u7684\u67b6\u6784\u6765\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u91c7\u7528\u5c42\u6b21\u6ce8\u610f\u529bTransformer\uff08HATs\uff09\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u5305\u542b\u6811\u72b6\u7ed3\u6784\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u80fd\u591f\u5efa\u6a21\u6570\u636e\u4e2d\u7684\u5c42\u6b21\u5173\u7cfb\u3002\u65b9\u6cd5\u63a8\u5e7f\u5230\u4efb\u610f\u6df1\u5ea6\uff0c\u5e76\u5305\u542b\u8be6\u7ec6\u7684\u8ba1\u7b97\u6210\u672c\u5206\u6790\u3002\u7ed3\u5408\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u80fd\u591f\u5904\u7406\u6bd4\u5148\u524d\u5de5\u4f5c\u66f4\u5927\u89c4\u6a21\u7684\u95ee\u9898\u5b9e\u4f8b\u3002", "result": "\u76f8\u6bd4\u4f20\u7edf\u7684\u5e73\u9762\u6ce8\u610f\u529b\u6a21\u578b\uff0cHATs\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u8ba1\u7b97\u8282\u7701\u3002\u7ed3\u5408\u8bfe\u7a0b\u5b66\u4e60\u540e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u89e3\u51b3\u6bd4Kera\u7b49\u4eba\uff082024\uff09\u5de5\u4f5c\u4e2d\u66f4\u5927\u89c4\u6a21\u7684\u95ee\u9898\u5b9e\u4f8b\u3002", "conclusion": "\u5c42\u6b21\u6ce8\u610f\u529bTransformer\u4e3a\u8ba1\u7b97Gr\u00f6bner\u57fa\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u6570\u636e\u4e2d\u7684\u5c42\u6b21\u7ed3\u6784\u5173\u7cfb\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u80fd\u591f\u5904\u7406\u66f4\u5927\u89c4\u6a21\u7684\u591a\u9879\u5f0f\u65b9\u7a0b\u7ec4\u6c42\u89e3\u95ee\u9898\u3002"}}
{"id": "2512.15388", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15388", "abs": "https://arxiv.org/abs/2512.15388", "authors": ["Reinhard Moratz", "Niklas Daute", "James Ondieki", "Markus Kattenbeck", "Mario Krajina", "Ioannis Giannopoulos"], "title": "Bilateral Spatial Reasoning about Street Networks: Graph-based RAG with Qualitative Spatial Representations", "comment": null, "summary": "This paper deals with improving the capabilities of Large Language Models (LLM) to provide route instructions for pedestrian wayfinders by means of qualitative spatial relations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5b9a\u6027\u7a7a\u95f4\u5173\u7cfb\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u884c\u4eba\u63d0\u4f9b\u8def\u7ebf\u6307\u5f15\u7684\u80fd\u529b", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63d0\u4f9b\u884c\u4eba\u8def\u7ebf\u6307\u5f15\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u7a7a\u95f4\u5173\u7cfb\u7684\u51c6\u786e\u63cf\u8ff0\u4e0a\uff0c\u9700\u8981\u6539\u8fdb\u5176\u57fa\u4e8e\u5b9a\u6027\u7a7a\u95f4\u5173\u7cfb\u63d0\u4f9b\u5bfc\u822a\u6307\u4ee4\u7684\u80fd\u529b", "method": "\u4f7f\u7528\u5b9a\u6027\u7a7a\u95f4\u5173\u7cfb\u6765\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53ef\u80fd\u5305\u62ec\u7a7a\u95f4\u5173\u7cfb\u8868\u793a\u3001\u8def\u7ebf\u6307\u4ee4\u751f\u6210\u6846\u67b6\u3001\u4ee5\u53ca\u7ed3\u5408\u5730\u7406\u7a7a\u95f4\u77e5\u8bc6\u7684\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5", "result": "\u6539\u8fdb\u540e\u7684\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u751f\u6210\u66f4\u51c6\u786e\u3001\u66f4\u7b26\u5408\u4eba\u7c7b\u8ba4\u77e5\u7684\u884c\u4eba\u5bfc\u822a\u6307\u4ee4\uff0c\u63d0\u9ad8\u4e86\u8def\u7ebf\u6307\u5f15\u7684\u8d28\u91cf\u548c\u5b9e\u7528\u6027", "conclusion": "\u901a\u8fc7\u6574\u5408\u5b9a\u6027\u7a7a\u95f4\u5173\u7cfb\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u884c\u4eba\u5bfc\u822a\u9886\u57df\u7684\u5e94\u7528\u80fd\u529b\uff0c\u4e3a\u667a\u80fd\u5bfc\u822a\u7cfb\u7edf\u63d0\u4f9b\u66f4\u81ea\u7136\u3001\u66f4\u51c6\u786e\u7684\u8def\u7ebf\u6307\u5f15"}}
{"id": "2512.15435", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15435", "abs": "https://arxiv.org/abs/2512.15435", "authors": ["Stefan Edelkamp"], "title": "Outer-Learning Framework for Playing Multi-Player Trick-Taking Card Games: A Case Study in Skat", "comment": null, "summary": "In multi-player card games such as Skat or Bridge, the early stages of the game, such as bidding, game selection, and initial card selection, are often more critical to the success of the play than refined middle- and end-game play. At the current limits of computation, such early decision-making resorts to using statistical information derived from a large corpus of human expert games. In this paper, we derive and evaluate a general bootstrapping outer-learning framework that improves prediction accuracy by expanding the database of human games with millions of self-playing AI games to generate and merge statistics. We implement perfect feature hash functions to address compacted tables, producing a self-improving card game engine, where newly inferred knowledge is continuously improved during self-learning. The case study in Skat shows that the automated approach can be used to support various decisions in the game.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u901a\u8fc7\u81ea\u6211\u5bf9\u5f08AI\u6e38\u620f\u6269\u5c55\u4eba\u7c7b\u4e13\u5bb6\u6e38\u620f\u6570\u636e\u5e93\u7684\u5916\u5b66\u4e60\u6846\u67b6\uff0c\u63d0\u9ad8\u591a\u73a9\u5bb6\u7eb8\u724c\u6e38\u620f\u65e9\u671f\u51b3\u7b56\u7684\u9884\u6d4b\u51c6\u786e\u6027", "motivation": "\u5728\u591a\u73a9\u5bb6\u7eb8\u724c\u6e38\u620f\u4e2d\uff0c\u5982\u53eb\u724c\u3001\u6e38\u620f\u9009\u62e9\u548c\u521d\u59cb\u51fa\u724c\u7b49\u65e9\u671f\u51b3\u7b56\u901a\u5e38\u6bd4\u4e2d\u540e\u671f\u6e38\u620f\u73a9\u6cd5\u66f4\u4e3a\u5173\u952e\u3002\u5f53\u524d\u8ba1\u7b97\u9650\u5236\u4e0b\uff0c\u8fd9\u4e9b\u65e9\u671f\u51b3\u7b56\u4f9d\u8d56\u4e8e\u4ece\u5927\u91cf\u4eba\u7c7b\u4e13\u5bb6\u6e38\u620f\u4e2d\u63d0\u53d6\u7684\u7edf\u8ba1\u4fe1\u606f\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u5916\u5b66\u4e60\u5f15\u5bfc\u6846\u67b6\uff0c\u901a\u8fc7\u7528\u6570\u767e\u4e07\u81ea\u6211\u5bf9\u5f08\u7684AI\u6e38\u620f\u6269\u5c55\u4eba\u7c7b\u6e38\u620f\u6570\u636e\u5e93\u6765\u751f\u6210\u548c\u5408\u5e76\u7edf\u8ba1\u6570\u636e\u3002\u4f7f\u7528\u5b8c\u7f8e\u7279\u5f81\u54c8\u5e0c\u51fd\u6570\u5904\u7406\u538b\u7f29\u8868\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u81ea\u6211\u6539\u8fdb\u7684\u7eb8\u724c\u6e38\u620f\u5f15\u64ce\uff0c\u5728\u81ea\u6211\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u6301\u7eed\u6539\u8fdb\u65b0\u63a8\u65ad\u7684\u77e5\u8bc6\u3002", "result": "\u5728Skat\u6e38\u620f\u4e2d\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u81ea\u52a8\u5316\u65b9\u6cd5\u53ef\u4ee5\u652f\u6301\u6e38\u620f\u4e2d\u7684\u5404\u79cd\u51b3\u7b56\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u4eba\u7c7b\u4e13\u5bb6\u6570\u636e\u548cAI\u81ea\u6211\u5bf9\u5f08\u751f\u6210\u7684\u6570\u636e\uff0c\u53ef\u4ee5\u663e\u8457\u6539\u8fdb\u591a\u73a9\u5bb6\u7eb8\u724c\u6e38\u620f\u7684\u65e9\u671f\u51b3\u7b56\u7cfb\u7edf\uff0c\u521b\u5efa\u4e00\u4e2a\u6301\u7eed\u81ea\u6211\u6539\u8fdb\u7684\u6e38\u620f\u5f15\u64ce\u3002"}}
{"id": "2512.14727", "categories": ["cs.LG", "cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.14727", "abs": "https://arxiv.org/abs/2512.14727", "authors": ["Klaus-Rudolf Kladny", "Bernhard Sch\u00f6lkopf", "Lisa Koch", "Christian F. Baumgartner", "Michael Muehlebach"], "title": "A Critical Perspective on Finite Sample Conformal Prediction Theory in Medical Applications", "comment": null, "summary": "Machine learning (ML) is transforming healthcare, but safe clinical decisions demand reliable uncertainty estimates that standard ML models fail to provide. Conformal prediction (CP) is a popular tool that allows users to turn heuristic uncertainty estimates into uncertainty estimates with statistical guarantees. CP works by converting predictions of a ML model, together with a calibration sample, into prediction sets that are guaranteed to contain the true label with any desired probability. An often cited advantage is that CP theory holds for calibration samples of arbitrary size, suggesting that uncertainty estimates with practically meaningful statistical guarantees can be achieved even if only small calibration sets are available. We question this promise by showing that, although the statistical guarantees hold for calibration sets of arbitrary size, the practical utility of these guarantees does highly depend on the size of the calibration set. This observation is relevant in medical domains because data is often scarce and obtaining large calibration sets is therefore infeasible. We corroborate our critique in an empirical demonstration on a medical image classification task.", "AI": {"tldr": "\u672c\u6587\u8d28\u7591\u4e86\u4fdd\u5f62\u9884\u6d4b\u5728\u5c0f\u6821\u51c6\u96c6\u4e0a\u7684\u5b9e\u7528\u6027\uff0c\u6307\u51fa\u867d\u7136\u7edf\u8ba1\u4fdd\u8bc1\u5728\u4efb\u610f\u5927\u5c0f\u7684\u6821\u51c6\u96c6\u4e0a\u90fd\u6210\u7acb\uff0c\u4f46\u8fd9\u4e9b\u4fdd\u8bc1\u7684\u5b9e\u9645\u6548\u7528\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u6821\u51c6\u96c6\u7684\u5927\u5c0f\uff0c\u8fd9\u5728\u533b\u7597\u6570\u636e\u7a00\u7f3a\u7684\u9886\u57df\u5c24\u4e3a\u91cd\u8981\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u9700\u8981\u53ef\u9760\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\uff0c\u4f46\u6807\u51c6ML\u6a21\u578b\u65e0\u6cd5\u63d0\u4f9b\u3002\u4fdd\u5f62\u9884\u6d4b\u867d\u7136\u80fd\u5c06\u542f\u53d1\u5f0f\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u8f6c\u5316\u4e3a\u5177\u6709\u7edf\u8ba1\u4fdd\u8bc1\u7684\u4f30\u8ba1\uff0c\u4f46\u73b0\u6709\u7406\u8bba\u58f0\u79f0\u53ef\u4ee5\u5728\u4efb\u610f\u5927\u5c0f\u7684\u6821\u51c6\u96c6\u4e0a\u83b7\u5f97\u6709\u610f\u4e49\u7684\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u8fd9\u4e0e\u533b\u7597\u6570\u636e\u7a00\u7f3a\u7684\u73b0\u5b9e\u5b58\u5728\u77db\u76fe\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u4fdd\u5f62\u9884\u6d4b\u7684\u7edf\u8ba1\u4fdd\u8bc1\u867d\u7136\u5728\u5c0f\u6821\u51c6\u96c6\u4e0a\u6210\u7acb\uff0c\u4f46\u5b9e\u9645\u6548\u7528\u4f1a\u663e\u8457\u4e0b\u964d\u3002\u5728\u533b\u7597\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u6f14\u793a\u6765\u652f\u6301\u8fd9\u4e00\u89c2\u70b9\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4fdd\u5f62\u9884\u6d4b\u7684\u7edf\u8ba1\u4fdd\u8bc1\u786e\u5b9e\u5728\u4efb\u610f\u5927\u5c0f\u7684\u6821\u51c6\u96c6\u4e0a\u90fd\u6210\u7acb\uff0c\u4f46\u8fd9\u4e9b\u4fdd\u8bc1\u7684\u5b9e\u9645\u6548\u7528\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u6821\u51c6\u96c6\u7684\u5927\u5c0f\u3002\u5c0f\u6821\u51c6\u96c6\u867d\u7136\u80fd\u63d0\u4f9b\u7406\u8bba\u4e0a\u7684\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u4f46\u5728\u5b9e\u8df5\u4e2d\u53ef\u80fd\u65e0\u6cd5\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002", "conclusion": "\u5728\u533b\u7597\u7b49\u6570\u636e\u7a00\u7f3a\u9886\u57df\u5e94\u7528\u4fdd\u5f62\u9884\u6d4b\u65f6\u9700\u8981\u8c28\u614e\uff0c\u4e0d\u80fd\u4ec5\u4f9d\u8d56\u7406\u8bba\u4e0a\u7684\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u5fc5\u987b\u8003\u8651\u6821\u51c6\u96c6\u5927\u5c0f\u5bf9\u5b9e\u9645\u6548\u7528\u7684\u5f71\u54cd\u3002\u8fd9\u4e3a\u533b\u7597ML\u5e94\u7528\u4e2d\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u8b66\u793a\u3002"}}
{"id": "2512.14728", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14728", "abs": "https://arxiv.org/abs/2512.14728", "authors": ["Jie He", "Yong Qin", "Jianyuan Guo", "Xuan Sun", "Xuanchuan Zheng"], "title": "A data-driven approach to inferring travel trajectory during peak hours in urban rail transit systems", "comment": null, "summary": "Refined trajectory inference of urban rail transit is of great significance to the operation organization. In this paper, we develop a fully data-driven approach to inferring individual travel trajectories in urban rail transit systems. It utilizes data from the Automatic Fare Collection (AFC) and Automatic Vehicle Location (AVL) systems to infer key trajectory elements, such as selected train, access/egress time, and transfer time. The approach includes establishing train alternative sets based on spatio-temporal constraints, data-driven adaptive trajectory inference, and trave l trajectory construction. To realize data-driven adaptive trajectory inference, a data-driven parameter estimation method based on KL divergence combined with EM algorithm (KLEM) was proposed. This method eliminates the reliance on external or survey data for parameter fitting, enhancing the robustness and applicability of the model. Furthermore, to overcome the limitations of using synthetic data to validate the result, this paper employs real individual travel trajectory data for verification. The results show that the approach developed in this paper can achieve high-precision passenger trajectory inference, with an accuracy rate of over 90% in urban rail transit travel trajectory inference during peak hours.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAFC\u548cAVL\u6570\u636e\u7684\u57ce\u5e02\u8f68\u9053\u4ea4\u901a\u4e2a\u4f53\u51fa\u884c\u8f68\u8ff9\u63a8\u65ad\u65b9\u6cd5\uff0c\u91c7\u7528\u6570\u636e\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u8f68\u8ff9\u63a8\u65ad\u548cKLEM\u53c2\u6570\u4f30\u8ba1\uff0c\u65e0\u9700\u5916\u90e8\u8c03\u67e5\u6570\u636e\uff0c\u5728\u9ad8\u5cf0\u65f6\u6bb5\u8fbe\u523090%\u4ee5\u4e0a\u7684\u63a8\u65ad\u51c6\u786e\u7387\u3002", "motivation": "\u57ce\u5e02\u8f68\u9053\u4ea4\u901a\u7cbe\u7ec6\u5316\u8f68\u8ff9\u63a8\u65ad\u5bf9\u8fd0\u8425\u7ec4\u7ec7\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u8c03\u67e5\u6570\u636e\u6216\u5408\u6210\u6570\u636e\u9a8c\u8bc1\uff0c\u53c2\u6570\u62df\u5408\u7f3a\u4e4f\u9c81\u68d2\u6027\uff0c\u9700\u8981\u5f00\u53d1\u5b8c\u5168\u6570\u636e\u9a71\u52a8\u7684\u8f68\u8ff9\u63a8\u65ad\u65b9\u6cd5\u3002", "method": "1) \u57fa\u4e8e\u65f6\u7a7a\u7ea6\u675f\u5efa\u7acb\u5217\u8f66\u5907\u9009\u96c6\uff1b2) \u6570\u636e\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u8f68\u8ff9\u63a8\u65ad\uff0c\u63d0\u51fa\u57fa\u4e8eKL\u6563\u5ea6\u7ed3\u5408EM\u7b97\u6cd5\u7684KLEM\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff1b3) \u6784\u5efa\u51fa\u884c\u8f68\u8ff9\u3002\u5229\u7528AFC\u548cAVL\u7cfb\u7edf\u6570\u636e\u63a8\u65ad\u5173\u952e\u8f68\u8ff9\u8981\u7d20\uff08\u6240\u9009\u5217\u8f66\u3001\u8fdb\u51fa\u7ad9\u65f6\u95f4\u3001\u6362\u4e58\u65f6\u95f4\uff09\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u4e58\u5ba2\u8f68\u8ff9\u63a8\u65ad\uff0c\u5728\u57ce\u5e02\u8f68\u9053\u4ea4\u901a\u9ad8\u5cf0\u65f6\u6bb5\u7684\u51fa\u884c\u8f68\u8ff9\u63a8\u65ad\u51c6\u786e\u7387\u8d85\u8fc790%\u3002\u4f7f\u7528\u771f\u5b9e\u4e2a\u4f53\u51fa\u884c\u8f68\u8ff9\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\uff0c\u514b\u670d\u4e86\u5408\u6210\u6570\u636e\u9a8c\u8bc1\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b8c\u5168\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63a8\u65ad\u57ce\u5e02\u8f68\u9053\u4ea4\u901a\u4e2a\u4f53\u51fa\u884c\u8f68\u8ff9\uff0c\u6d88\u9664\u4e86\u5bf9\u5916\u90e8\u6216\u8c03\u67e5\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u9002\u7528\u6027\uff0c\u4e3a\u8fd0\u8425\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2512.15489", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15489", "abs": "https://arxiv.org/abs/2512.15489", "authors": ["Wei Du", "Shubham Toshniwal", "Branislav Kisacanin", "Sadegh Mahdavi", "Ivan Moshkov", "George Armstrong", "Stephen Ge", "Edgar Minasyan", "Feng Chen", "Igor Gitman"], "title": "Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision", "comment": null, "summary": "High-quality mathematical reasoning supervision requires diverse reasoning styles, long-form traces, and effective tool integration, capabilities that existing datasets provide only in limited form. Leveraging the multi-mode generation ability of gpt-oss-120b, we introduce Nemotron-Math, a large-scale mathematical reasoning dataset containing 7.5M solution traces across high, medium, and low reasoning modes, each available both with and without Python tool-integrated reasoning (TIR).\n  The dataset integrates 85K curated AoPS problems with 262K community-sourced StackExchange-Math problems, combining structured competition tasks with diverse real-world mathematical queries. We conduct controlled evaluations to assess the dataset quality.\n  Nemotron-Math consistently outperforms the original OpenMathReasoning on matched AoPS problems. Incorporating StackExchange-Math substantially improves robustness and generalization, especially on HLE-Math, while preserving accuracy on math competition benchmarks.\n  To support efficient long-context training, we develop a sequential bucketed strategy that accelerates 128K context-length fine-tuning by 2--3$\\times$ without significant accuracy loss. Overall, Nemotron-Math enables state-of-the-art performance, including 100\\% maj@16 accuracy on AIME 2024 and 2025 with Python TIR.", "AI": {"tldr": "Nemotron-Math\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\uff0c\u5305\u542b750\u4e07\u6761\u89e3\u9898\u8f68\u8ff9\uff0c\u6db5\u76d6\u9ad8\u3001\u4e2d\u3001\u4f4e\u4e09\u79cd\u63a8\u7406\u6a21\u5f0f\uff0c\u652f\u6301Python\u5de5\u5177\u96c6\u6210\u63a8\u7406\uff0c\u7ed3\u5408\u4e86AoPS\u7ade\u8d5b\u9898\u548cStackExchange-Math\u793e\u533a\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u5728\u63a8\u7406\u98ce\u683c\u591a\u6837\u6027\u3001\u957f\u5f62\u5f0f\u8f68\u8ff9\u548c\u5de5\u5177\u96c6\u6210\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u6ee1\u8db3\u9ad8\u8d28\u91cf\u6570\u5b66\u63a8\u7406\u76d1\u7763\u7684\u9700\u6c42\u3002", "method": "\u5229\u7528GPT-OSS-120B\u7684\u591a\u6a21\u5f0f\u751f\u6210\u80fd\u529b\uff0c\u6784\u5efa\u5305\u542b7.5M\u89e3\u9898\u8f68\u8ff9\u7684\u6570\u636e\u96c6\uff0c\u6574\u540885K AoPS\u95ee\u9898\u548c262K StackExchange-Math\u95ee\u9898\uff0c\u5f00\u53d1\u5e8f\u5217\u5206\u6876\u7b56\u7565\u52a0\u901f\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\u3002", "result": "Nemotron-Math\u5728\u5339\u914d\u7684AoPS\u95ee\u9898\u4e0a\u6301\u7eed\u4f18\u4e8eOpenMathReasoning\uff0cStackExchange-Math\u7684\u52a0\u5165\u663e\u8457\u63d0\u5347\u4e86\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5728AIME 2024\u548c2025\u4e0a\u5b9e\u73b0\u4e86100% maj@16\u51c6\u786e\u7387\u3002", "conclusion": "Nemotron-Math\u6570\u636e\u96c6\u901a\u8fc7\u63d0\u4f9b\u591a\u6837\u5316\u7684\u63a8\u7406\u98ce\u683c\u3001\u957f\u5f62\u5f0f\u8f68\u8ff9\u548c\u5de5\u5177\u96c6\u6210\u652f\u6301\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6570\u5b66\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u9ad8\u6548\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.14731", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14731", "abs": "https://arxiv.org/abs/2512.14731", "authors": ["Nikit Phadke"], "title": "Semantic Geometry for policy-constrained interpretation", "comment": null, "summary": "We present a geometric framework for policy-constrained semantic interpretation that provably prevents hallucinated commitments in high-stakes domains. Semantic meaning is represented as direction on a unit sphere, evidence is modeled as sets of witness vectors, and admissible interpretations correspond to spherical convex regions. Policy constraints are introduced as explicit priors defined over the same manifold, separated from evidence geometry. Interpretation reduces to constrained optimization over admissible regions, with refusal emerging as a topologically necessary outcome under contradiction or policy exclusion. We connect this framework to information theory, Bayesian inference, and sheaf-theoretic semantics, proving that our complexity bounds are information-theoretically optimal. Empirical validation on large scale regulated financial data demonstrates zero hallucinated approvals across multiple policy regimes-the first such result at scale.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u51e0\u4f55\u6846\u67b6\uff0c\u901a\u8fc7\u7403\u9762\u51f8\u533a\u57df\u8868\u793a\u8bed\u4e49\uff0c\u5c06\u8bc1\u636e\u4e0e\u7b56\u7565\u7ea6\u675f\u5206\u79bb\uff0c\u786e\u4fdd\u9ad8\u98ce\u9669\u9886\u57df\u96f6\u5e7b\u89c9\u627f\u8bfa", "motivation": "\u89e3\u51b3\u9ad8\u98ce\u9669\u9886\u57df\u4e2d\u8bed\u4e49\u89e3\u91ca\u53ef\u80fd\u4ea7\u751f\u5e7b\u89c9\u627f\u8bfa\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u53d7\u76d1\u7ba1\u7684\u91d1\u878d\u7b49\u5173\u952e\u9886\u57df\uff0c\u9700\u8981\u786e\u4fdd\u89e3\u91ca\u7684\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027", "method": "\u4f7f\u7528\u5355\u4f4d\u7403\u9762\u4e0a\u7684\u65b9\u5411\u8868\u793a\u8bed\u4e49\u610f\u4e49\uff0c\u8bc1\u636e\u5efa\u6a21\u4e3a\u89c1\u8bc1\u5411\u91cf\u96c6\uff0c\u53ef\u63a5\u53d7\u89e3\u91ca\u5bf9\u5e94\u7403\u9762\u51f8\u533a\u57df\uff1b\u7b56\u7565\u7ea6\u675f\u4f5c\u4e3a\u663e\u5f0f\u5148\u9a8c\u5b9a\u4e49\u5728\u540c\u4e00\u6d41\u5f62\u4e0a\uff0c\u4e0e\u8bc1\u636e\u51e0\u4f55\u5206\u79bb\uff1b\u89e3\u91ca\u7b80\u5316\u4e3a\u5bf9\u53ef\u63a5\u53d7\u533a\u57df\u7684\u7ea6\u675f\u4f18\u5316", "result": "\u5728\u5927\u578b\u53d7\u76d1\u7ba1\u91d1\u878d\u6570\u636e\u4e0a\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u663e\u793a\uff0c\u5728\u591a\u79cd\u7b56\u7565\u5236\u5ea6\u4e0b\u5b9e\u73b0\u4e86\u96f6\u5e7b\u89c9\u6279\u51c6\uff0c\u8fd9\u662f\u9996\u6b21\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u53d6\u5f97\u8fd9\u6837\u7684\u7ed3\u679c\uff1b\u590d\u6742\u5ea6\u754c\u9650\u88ab\u8bc1\u660e\u662f\u4fe1\u606f\u8bba\u6700\u4f18\u7684", "conclusion": "\u8be5\u51e0\u4f55\u6846\u67b6\u4e3a\u7b56\u7565\u7ea6\u675f\u7684\u8bed\u4e49\u89e3\u91ca\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u80fd\u6709\u6548\u9632\u6b62\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5e7b\u89c9\u627f\u8bfa\uff0c\u5c06\u62d2\u7edd\u4f5c\u4e3a\u62d3\u6251\u5fc5\u7136\u7ed3\u679c\uff0c\u5e76\u4e0e\u4fe1\u606f\u8bba\u3001\u8d1d\u53f6\u65af\u63a8\u65ad\u548c\u5c42\u8bba\u8bed\u4e49\u5b66\u5efa\u7acb\u4e86\u7406\u8bba\u8054\u7cfb"}}
{"id": "2512.15567", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2512.15567", "abs": "https://arxiv.org/abs/2512.15567", "authors": ["Zhangde Song", "Jieyu Lu", "Yuanqi Du", "Botao Yu", "Thomas M. Pruyn", "Yue Huang", "Kehan Guo", "Xiuzhe Luo", "Yuanhao Qu", "Yi Qu", "Yinkai Wang", "Haorui Wang", "Jeff Guo", "Jingru Gan", "Parshin Shojaee", "Di Luo", "Andres M Bran", "Gen Li", "Qiyuan Zhao", "Shao-Xiong Lennon Luo", "Yuxuan Zhang", "Xiang Zou", "Wanru Zhao", "Yifan F. Zhang", "Wucheng Zhang", "Shunan Zheng", "Saiyang Zhang", "Sartaaj Takrim Khan", "Mahyar Rajabi-Kochi", "Samantha Paradi-Maropakis", "Tony Baltoiu", "Fengyu Xie", "Tianyang Chen", "Kexin Huang", "Weiliang Luo", "Meijing Fang", "Xin Yang", "Lixue Cheng", "Jiajun He", "Soha Hassoun", "Xiangliang Zhang", "Wei Wang", "Chandan K. Reddy", "Chao Zhang", "Zhiling Zheng", "Mengdi Wang", "Le Cong", "Carla P. Gomes", "Chang-Yu Hsieh", "Aditya Nandy", "Philippe Schwaller", "Heather J. Kulik", "Haojun Jia", "Huan Sun", "Seyed Mohamad Moosavi", "Chenru Duan"], "title": "Evaluating Large Language Models in Scientific Discovery", "comment": null, "summary": "Large language models (LLMs) are increasingly applied to scientific research, yet prevailing science benchmarks probe decontextualized knowledge and overlook the iterative reasoning, hypothesis generation, and observation interpretation that drive scientific discovery. We introduce a scenario-grounded benchmark that evaluates LLMs across biology, chemistry, materials, and physics, where domain experts define research projects of genuine interest and decompose them into modular research scenarios from which vetted questions are sampled. The framework assesses models at two levels: (i) question-level accuracy on scenario-tied items and (ii) project-level performance, where models must propose testable hypotheses, design simulations or experiments, and interpret results. Applying this two-phase scientific discovery evaluation (SDE) framework to state-of-the-art LLMs reveals a consistent performance gap relative to general science benchmarks, diminishing return of scaling up model sizes and reasoning, and systematic weaknesses shared across top-tier models from different providers. Large performance variation in research scenarios leads to changing choices of the best performing model on scientific discovery projects evaluated, suggesting all current LLMs are distant to general scientific \"superintelligence\". Nevertheless, LLMs already demonstrate promise in a great variety of scientific discovery projects, including cases where constituent scenario scores are low, highlighting the role of guided exploration and serendipity in discovery. This SDE framework offers a reproducible benchmark for discovery-relevant evaluation of LLMs and charts practical paths to advance their development toward scientific discovery.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u573a\u666f\u7684\u79d1\u5b66\u53d1\u73b0\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u79d1\u5b66\u7814\u7a76\u9879\u76ee\u4e2d\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u79d1\u5b66\u53d1\u73b0\u4efb\u52a1\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u5f31\u70b9\uff0c\u8ddd\u79bb\u901a\u7528\u79d1\u5b66\"\u8d85\u7ea7\u667a\u80fd\"\u8fd8\u5f88\u9065\u8fdc\u3002", "motivation": "\u73b0\u6709\u79d1\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u8bc4\u4f30\u53bb\u8bed\u5883\u5316\u7684\u77e5\u8bc6\uff0c\u5ffd\u89c6\u4e86\u9a71\u52a8\u79d1\u5b66\u53d1\u73b0\u7684\u8fed\u4ee3\u63a8\u7406\u3001\u5047\u8bbe\u751f\u6210\u548c\u89c2\u5bdf\u89e3\u91ca\u7b49\u5173\u952e\u80fd\u529b\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u66f4\u8d34\u8fd1\u771f\u5b9e\u79d1\u5b66\u7814\u7a76\u8fc7\u7a0b\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f15\u5165\u573a\u666f\u5316\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7531\u9886\u57df\u4e13\u5bb6\u5b9a\u4e49\u771f\u5b9e\u7814\u7a76\u9879\u76ee\uff0c\u5e76\u5c06\u5176\u5206\u89e3\u4e3a\u6a21\u5757\u5316\u7814\u7a76\u573a\u666f\uff0c\u4ece\u4e2d\u91c7\u6837\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u95ee\u9898\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bc4\u4f30\u6846\u67b6\uff1a\u95ee\u9898\u7ea7\u51c6\u786e\u6027\u8bc4\u4f30\u548c\u9879\u76ee\u7ea7\u6027\u80fd\u8bc4\u4f30\uff08\u5305\u62ec\u63d0\u51fa\u53ef\u6d4b\u8bd5\u5047\u8bbe\u3001\u8bbe\u8ba1\u5b9e\u9a8c/\u6a21\u62df\u3001\u89e3\u91ca\u7ed3\u679c\u7b49\uff09\u3002", "result": "\u5e94\u7528\u8be5\u6846\u67b6\u8bc4\u4f30\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u73b0\uff1a1\uff09\u76f8\u5bf9\u4e8e\u901a\u7528\u79d1\u5b66\u57fa\u51c6\u5b58\u5728\u4e00\u81f4\u6027\u80fd\u5dee\u8ddd\uff1b2\uff09\u6a21\u578b\u89c4\u6a21\u548c\u63a8\u7406\u80fd\u529b\u7684\u6269\u5c55\u6536\u76ca\u9012\u51cf\uff1b3\uff09\u4e0d\u540c\u63d0\u4f9b\u5546\u9876\u7ea7\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u5f31\u70b9\uff1b4\uff09\u7814\u7a76\u573a\u666f\u95f4\u6027\u80fd\u5dee\u5f02\u5927\u5bfc\u81f4\u6700\u4f73\u6a21\u578b\u9009\u62e9\u4e0d\u7a33\u5b9a\uff1b5\uff09\u5c3d\u7ba1\u573a\u666f\u5f97\u5206\u4f4e\uff0c\u4f46\u6a21\u578b\u5728\u67d0\u4e9b\u79d1\u5b66\u53d1\u73b0\u9879\u76ee\u4e2d\u4ecd\u663e\u793a\u51fa\u6f5c\u529b\u3002", "conclusion": "\u5f53\u524d\u6240\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8ddd\u79bb\u901a\u7528\u79d1\u5b66\"\u8d85\u7ea7\u667a\u80fd\"\u8fd8\u5f88\u9065\u8fdc\uff0c\u4f46\u5df2\u5c55\u73b0\u51fa\u5728\u591a\u79cd\u79d1\u5b66\u53d1\u73b0\u9879\u76ee\u4e2d\u7684\u6f5c\u529b\u3002\u8be5SDE\u6846\u67b6\u4e3a\u53d1\u73b0\u76f8\u5173\u7684LLM\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u57fa\u51c6\uff0c\u5e76\u4e3a\u63a8\u52a8\u5176\u9762\u5411\u79d1\u5b66\u53d1\u73b0\u7684\u53d1\u5c55\u6307\u660e\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2512.15584", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.15584", "abs": "https://arxiv.org/abs/2512.15584", "authors": ["Daniel A. Herrmann", "Abinav Chari", "Isabelle Qian", "Sree Sharvesh", "B. A. Levinstein"], "title": "A Decision-Theoretic Approach for Managing Misalignment", "comment": "Second Conference of the International Association for Safe and Ethical Artificial Intelligence (IASEAI '26)", "summary": "When should we delegate decisions to AI systems? While the value alignment literature has developed techniques for shaping AI values, less attention has been paid to how to determine, under uncertainty, when imperfect alignment is good enough to justify delegation. We argue that rational delegation requires balancing an agent's value (mis)alignment with its epistemic accuracy and its reach (the acts it has available). This paper introduces a formal, decision-theoretic framework to analyze this tradeoff precisely accounting for a principal's uncertainty about these factors. Our analysis reveals a sharp distinction between two delegation scenarios. First, universal delegation (trusting an agent with any problem) demands near-perfect value alignment and total epistemic trust, conditions rarely met in practice. Second, we show that context-specific delegation can be optimal even with significant misalignment. An agent's superior accuracy or expanded reach may grant access to better overall decision problems, making delegation rational in expectation. We develop a novel scoring framework to quantify this ex ante decision. Ultimately, our work provides a principled method for determining when an AI is aligned enough for a given context, shifting the focus from achieving perfect alignment to managing the risks and rewards of delegation under uncertainty.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u51b3\u7b56\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u786e\u5b9a\u4f55\u65f6\u5c06\u51b3\u7b56\u59d4\u6258\u7ed9AI\u7cfb\u7edf\uff0c\u5f3a\u8c03\u9700\u8981\u5e73\u8861\u4ef7\u503c\u5bf9\u9f50\u3001\u8ba4\u77e5\u51c6\u786e\u6027\u548c\u884c\u52a8\u8303\u56f4\uff0c\u5e76\u533a\u5206\u4e86\u901a\u7528\u59d4\u6258\u548c\u60c5\u5883\u7279\u5b9a\u59d4\u6258\u7684\u4e0d\u540c\u8981\u6c42\u3002", "motivation": "\u73b0\u6709\u4ef7\u503c\u5bf9\u9f50\u6587\u732e\u4e3b\u8981\u5173\u6ce8\u5982\u4f55\u5851\u9020AI\u4ef7\u503c\u89c2\uff0c\u4f46\u8f83\u5c11\u7814\u7a76\u5728\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u5982\u4f55\u5224\u65ad\u4e0d\u5b8c\u7f8e\u7684\u5bf9\u9f50\u662f\u5426\u8db3\u591f\u597d\u4ee5\u8bc1\u660e\u59d4\u6258\u51b3\u7b56\u7684\u5408\u7406\u6027\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u51b3\u5b9aAI\u5728\u4f55\u79cd\u60c5\u5883\u4e0b\u8db3\u591f\u5bf9\u9f50\u4ee5\u8fdb\u884c\u59d4\u6258\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u6b63\u5f0f\u7684\u51b3\u7b56\u7406\u8bba\u6846\u67b6\uff0c\u7cbe\u786e\u5206\u6790\u59d4\u6258\u51b3\u7b56\u4e2d\u7684\u6743\u8861\uff0c\u8003\u8651\u59d4\u6258\u4eba\u5bf9AI\u4ef7\u503c\u5bf9\u9f50\u3001\u8ba4\u77e5\u51c6\u786e\u6027\u548c\u884c\u52a8\u8303\u56f4\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u8bc4\u5206\u6846\u67b6\u6765\u91cf\u5316\u8fd9\u79cd\u4e8b\u524d\u51b3\u7b56\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u4e24\u79cd\u59d4\u6258\u60c5\u5883\u7684\u663e\u8457\u533a\u522b\uff1a\u901a\u7528\u59d4\u6258\u9700\u8981\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u4ef7\u503c\u5bf9\u9f50\u548c\u5b8c\u5168\u7684\u8ba4\u77e5\u4fe1\u4efb\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u5f88\u5c11\u6ee1\u8db3\uff1b\u800c\u60c5\u5883\u7279\u5b9a\u59d4\u6258\u5373\u4f7f\u5728\u663e\u8457\u4ef7\u503c\u4e0d\u5bf9\u9f50\u7684\u60c5\u51b5\u4e0b\u4e5f\u53ef\u80fd\u662f\u6700\u4f18\u7684\uff0c\u56e0\u4e3aAI\u7684\u66f4\u9ad8\u51c6\u786e\u6027\u6216\u66f4\u5e7f\u884c\u52a8\u8303\u56f4\u53ef\u80fd\u63d0\u4f9b\u66f4\u597d\u7684\u6574\u4f53\u51b3\u7b56\u95ee\u9898\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u65b9\u6cd5\u6765\u786e\u5b9aAI\u5728\u7279\u5b9a\u60c5\u5883\u4e0b\u662f\u5426\u8db3\u591f\u5bf9\u9f50\u4ee5\u8fdb\u884c\u59d4\u6258\uff0c\u5c06\u91cd\u70b9\u4ece\u5b9e\u73b0\u5b8c\u7f8e\u5bf9\u9f50\u8f6c\u5411\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7ba1\u7406\u59d4\u6258\u7684\u98ce\u9669\u548c\u56de\u62a5\u3002"}}
{"id": "2512.14734", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14734", "abs": "https://arxiv.org/abs/2512.14734", "authors": ["Qiang Chen", "Venkatesh Ganapati Hegde", "Hongfei Li"], "title": "Inference Time Feature Injection: A Lightweight Approach for Real-Time Recommendation Freshness", "comment": "3rd IEEE International Conference on Artificial Intelligence, Blockchain, and Internet of Things, September 06-07, 2025, Central Michigan University, USA", "summary": "Many recommender systems in long-form video streaming reply on batch-trained models and batch-updated features, where user features are updated daily and served statically throughout the day. While efficient, this approach fails to incorporate a user's most recent actions, often resulting in stale recommendations. In this work, we present a lightweight, model-agnostic approach for intra-day personalization that selectively injects recent watch history at inference time without requiring model retraining. Our approach selectively overrides stale user features at inference time using the recent watch history, allowing the system to adapt instantly to evolving preferences. By reducing the personalization feedback loop from daily to intra-day, we observed a statistically significant 0.47% increase in key user engagement metrics which ranked among the most substantial engagement gains observed in recent experimentation cycles. To our knowledge, this is the first published evidence that intra-day personalization can drive meaningful impact in long-form video streaming service, providing a compelling alternative to full real-time architectures where model retraining is required.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u6a21\u578b\u65e0\u5173\u7684\u65e5\u5185\u4e2a\u6027\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u9009\u62e9\u6027\u6ce8\u5165\u8fd1\u671f\u89c2\u770b\u5386\u53f2\u6765\u66f4\u65b0\u7528\u6237\u7279\u5f81\uff0c\u65e0\u9700\u6a21\u578b\u91cd\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u957f\u89c6\u9891\u6d41\u5a92\u4f53\u63a8\u8350\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u957f\u89c6\u9891\u6d41\u5a92\u4f53\u63a8\u8350\u7cfb\u7edf\u4f9d\u8d56\u6279\u91cf\u8bad\u7ec3\u7684\u6a21\u578b\u548c\u6bcf\u65e5\u66f4\u65b0\u7684\u7279\u5f81\uff0c\u7528\u6237\u7279\u5f81\u6bcf\u5929\u66f4\u65b0\u4e00\u6b21\u5e76\u5728\u5168\u5929\u9759\u6001\u670d\u52a1\u3002\u8fd9\u79cd\u65b9\u6cd5\u6548\u7387\u9ad8\u4f46\u65e0\u6cd5\u7eb3\u5165\u7528\u6237\u6700\u65b0\u884c\u4e3a\uff0c\u5bfc\u81f4\u63a8\u8350\u5185\u5bb9\u8fc7\u65f6\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u3001\u6a21\u578b\u65e0\u5173\u7684\u65e5\u5185\u4e2a\u6027\u5316\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u65f6\u9009\u62e9\u6027\u8986\u76d6\u8fc7\u65f6\u7684\u7528\u6237\u7279\u5f81\uff0c\u4f7f\u7528\u8fd1\u671f\u89c2\u770b\u5386\u53f2\u6765\u5373\u65f6\u9002\u5e94\u7528\u6237\u504f\u597d\u53d8\u5316\uff0c\u65e0\u9700\u6a21\u578b\u91cd\u8bad\u7ec3\u3002", "result": "\u901a\u8fc7\u5c06\u4e2a\u6027\u5316\u53cd\u9988\u5faa\u73af\u4ece\u6bcf\u65e5\u7f29\u77ed\u5230\u65e5\u5185\uff0c\u89c2\u5bdf\u5230\u5173\u952e\u7528\u6237\u53c2\u4e0e\u5ea6\u6307\u6807\u7edf\u8ba1\u663e\u8457\u63d0\u53470.47%\uff0c\u8fd9\u662f\u8fd1\u671f\u5b9e\u9a8c\u5468\u671f\u4e2d\u89c2\u5bdf\u5230\u7684\u6700\u663e\u8457\u53c2\u4e0e\u5ea6\u63d0\u5347\u4e4b\u4e00\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u8bc1\u660e\u65e5\u5185\u4e2a\u6027\u5316\u80fd\u5728\u957f\u89c6\u9891\u6d41\u5a92\u4f53\u670d\u52a1\u4e2d\u4ea7\u751f\u6709\u610f\u4e49\u5f71\u54cd\u7684\u516c\u5f00\u8bc1\u636e\uff0c\u4e3a\u9700\u8981\u6a21\u578b\u91cd\u8bad\u7ec3\u7684\u5b8c\u6574\u5b9e\u65f6\u67b6\u6784\u63d0\u4f9b\u4e86\u6709\u5438\u5f15\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2512.15662", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15662", "abs": "https://arxiv.org/abs/2512.15662", "authors": ["Jiaqi Xu", "Cuiling Lan", "Xuejin Chen", "Yan LU"], "title": "Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning", "comment": "Under Review", "summary": "Human beings solve complex problems through critical thinking, where reasoning and evaluation are intertwined to converge toward correct solutions. However, most existing large language models (LLMs) decouple reasoning from verification: they either generate reasoning without explicit self-checking or rely on external verifiers to detect errors post hoc. The former lacks immediate feedback, while the latter increases system complexity and hinders synchronized learning. Motivated by human critical thinking, we propose Stepwise Think-Critique (STC), a unified framework that interleaves reasoning and self-critique at each step within a single model. STC is trained with a hybrid reinforcement learning objective combining reasoning rewards and critique-consistency rewards to jointly optimize reasoning quality and self-evaluation. Experiments on mathematical reasoning benchmarks show that STC demonstrates strong critic-thinking capabilities and produces more interpretable reasoning traces, representing a step toward LLMs with built-in critical thinking.", "AI": {"tldr": "STC\u6846\u67b6\u5728LLM\u4e2d\u96c6\u6210\u63a8\u7406\u4e0e\u81ea\u6211\u6279\u5224\uff0c\u901a\u8fc7\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u63a8\u7406\u8d28\u91cf\u548c\u81ea\u6211\u8bc4\u4f30\uff0c\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709LLM\u5c06\u63a8\u7406\u4e0e\u9a8c\u8bc1\u5206\u79bb\uff1a\u8981\u4e48\u751f\u6210\u63a8\u7406\u800c\u4e0d\u8fdb\u884c\u81ea\u6211\u68c0\u67e5\uff0c\u8981\u4e48\u4f9d\u8d56\u5916\u90e8\u9a8c\u8bc1\u5668\u4e8b\u540e\u68c0\u6d4b\u9519\u8bef\u3002\u524d\u8005\u7f3a\u4e4f\u5373\u65f6\u53cd\u9988\uff0c\u540e\u8005\u589e\u52a0\u7cfb\u7edf\u590d\u6742\u6027\u5e76\u963b\u788d\u540c\u6b65\u5b66\u4e60\u3002\u53d7\u4eba\u7c7b\u6279\u5224\u6027\u601d\u7ef4\u542f\u53d1\uff0c\u9700\u8981\u7edf\u4e00\u6846\u67b6\u5728\u5355\u6a21\u578b\u4e2d\u4ea4\u7ec7\u63a8\u7406\u4e0e\u81ea\u6211\u6279\u5224\u3002", "method": "\u63d0\u51faStepwise Think-Critique (STC)\u6846\u67b6\uff0c\u5728\u6bcf\u4e00\u6b65\u63a8\u7406\u4e2d\u4ea4\u7ec7\u63a8\u7406\u548c\u81ea\u6211\u6279\u5224\u3002\u4f7f\u7528\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\uff0c\u7ed3\u5408\u63a8\u7406\u5956\u52b1\u548c\u6279\u5224\u4e00\u81f4\u6027\u5956\u52b1\uff0c\u5171\u540c\u4f18\u5316\u63a8\u7406\u8d28\u91cf\u548c\u81ea\u6211\u8bc4\u4f30\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSTC\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6279\u5224\u6027\u601d\u7ef4\u80fd\u529b\uff0c\u5e76\u4ea7\u751f\u66f4\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u4ee3\u8868\u4e86LLM\u5185\u7f6e\u6279\u5224\u6027\u601d\u7ef4\u7684\u91cd\u8981\u8fdb\u5c55\u3002", "conclusion": "STC\u6846\u67b6\u901a\u8fc7\u5c06\u63a8\u7406\u548c\u81ea\u6211\u6279\u5224\u4ea4\u7ec7\u5728\u5355\u6a21\u578b\u4e2d\uff0c\u5b9e\u73b0\u4e86\u66f4\u63a5\u8fd1\u4eba\u7c7b\u6279\u5224\u6027\u601d\u7ef4\u7684\u80fd\u529b\uff0c\u4e3aLLM\u5185\u7f6e\u6279\u5224\u6027\u601d\u7ef4\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2512.14738", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.14738", "abs": "https://arxiv.org/abs/2512.14738", "authors": ["Zhengxu Yan", "Han Li", "Yuming Feng"], "title": "NoveltyRank: Estimating Conceptual Novelty of AI Papers", "comment": null, "summary": "With the growing ease of academic publishing, the volume of research papers, especially in AI-related fields, has surged dramatically. This flood of publications makes it difficult for truly novel and impactful work to stand out, and manual novelty assessment is often unstable and time-consuming. Our project aims to develop a model that estimates and ranks the conceptual novelty of AI papers, enabling a data-driven and scalable assessment of research originality. Such a system can help researchers efficiently identify submissions that introduce genuinely innovative ideas rather than minor variants, and provide conference reviewers with a quantitative and consistent signal of novelty. Our approach evaluates novelty primarily through a paper's title, abstract, and semantic similarity to prior literature. Given the motivation of novelty estimation, we explore two task formulations with different modeling objectives, each offering a different perspective: (1) binary classification, which predicts the paper's absolute novelty from learned patterns of prior novel works, and (2) pairwise novelty comparison, which learns to distinguish papers by relative novelty over others. We fine-tune Qwen3-4B-Instruct-2507 and SciBERT on both tasks, benchmarking against GPT-5.1 to analyze how task formulation and modeling choices affect performance. The implementation is publicly available at https://github.com/ZhengxuYan/NoveltyRank.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8bc4\u4f30AI\u8bba\u6587\u6982\u5ff5\u65b0\u9896\u6027\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u6807\u9898\u3001\u6458\u8981\u548c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u6765\u91cf\u5316\u7814\u7a76\u539f\u521b\u6027\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u5ba1\u7a3f\u4eba\u8bc6\u522b\u771f\u6b63\u521b\u65b0\u7684\u5de5\u4f5c\u3002", "motivation": "\u968f\u7740\u5b66\u672f\u51fa\u7248\u95e8\u69db\u964d\u4f4e\uff0cAI\u9886\u57df\u8bba\u6587\u6570\u91cf\u6fc0\u589e\uff0c\u771f\u6b63\u65b0\u9896\u548c\u6709\u5f71\u54cd\u529b\u7684\u5de5\u4f5c\u96be\u4ee5\u8131\u9896\u800c\u51fa\uff0c\u624b\u52a8\u8bc4\u4f30\u65b0\u9896\u6027\u4e0d\u7a33\u5b9a\u4e14\u8017\u65f6\uff0c\u9700\u8981\u6570\u636e\u9a71\u52a8\u7684\u53ef\u6269\u5c55\u8bc4\u4f30\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u4efb\u52a1\u6846\u67b6\uff1a1\uff09\u4e8c\u5143\u5206\u7c7b\uff0c\u4ece\u5148\u524d\u65b0\u9896\u5de5\u4f5c\u4e2d\u5b66\u4e60\u6a21\u5f0f\u9884\u6d4b\u8bba\u6587\u7edd\u5bf9\u65b0\u9896\u6027\uff1b2\uff09\u6210\u5bf9\u65b0\u9896\u6027\u6bd4\u8f83\uff0c\u5b66\u4e60\u533a\u5206\u8bba\u6587\u7684\u76f8\u5bf9\u65b0\u9896\u6027\u3002\u4f7f\u7528Qwen3-4B-Instruct-2507\u548cSciBERT\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u4e0eGPT-5.1\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5f00\u53d1\u4e86\u516c\u5f00\u53ef\u7528\u7684\u5b9e\u73b0\uff08GitHub\uff09\uff0c\u901a\u8fc7\u5206\u6790\u4efb\u52a1\u6846\u67b6\u548c\u5efa\u6a21\u9009\u62e9\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4e3aAI\u8bba\u6587\u65b0\u9896\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cf\u5316\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u9879\u76ee\u4e3aAI\u7814\u7a76\u65b0\u9896\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6570\u636e\u9a71\u52a8\u7684\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u8bc6\u522b\u771f\u6b63\u521b\u65b0\u7684\u5de5\u4f5c\uff0c\u4e3a\u4f1a\u8bae\u5ba1\u7a3f\u4eba\u63d0\u4f9b\u4e00\u81f4\u7684\u65b0\u9896\u6027\u91cf\u5316\u4fe1\u53f7\u3002"}}
{"id": "2512.15663", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.15663", "abs": "https://arxiv.org/abs/2512.15663", "authors": ["Chase Walker", "Rickard Ewetz"], "title": "Explaining the Reasoning of Large Language Models Using Attribution Graphs", "comment": null, "summary": "Large language models (LLMs) exhibit remarkable capabilities, yet their reasoning remains opaque, raising safety and trust concerns. Attribution methods, which assign credit to input features, have proven effective for explaining the decision making of computer vision models. From these, context attributions have emerged as a promising approach for explaining the behavior of autoregressive LLMs. However, current context attributions produce incomplete explanations by directly relating generated tokens to the prompt, discarding inter-generational influence in the process. To overcome these shortcomings, we introduce the Context Attribution via Graph Explanations (CAGE) framework. CAGE introduces an attribution graph: a directed graph that quantifies how each generation is influenced by both the prompt and all prior generations. The graph is constructed to preserve two properties-causality and row stochasticity. The attribution graph allows context attributions to be computed by marginalizing intermediate contributions along paths in the graph. Across multiple models, datasets, metrics, and methods, CAGE improves context attribution faithfulness, achieving average gains of up to 40%.", "AI": {"tldr": "CAGE\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u5f52\u56e0\u56fe\u6765\u6539\u8fdbLLM\u7684\u4e0a\u4e0b\u6587\u5f52\u56e0\uff0c\u91cf\u5316\u6bcf\u4e2a\u751f\u6210\u5185\u5bb9\u5982\u4f55\u53d7\u5230\u63d0\u793a\u548c\u5148\u524d\u751f\u6210\u5185\u5bb9\u7684\u5f71\u54cd\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u534740%\u7684\u5fe0\u5b9e\u5ea6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u63a8\u7406\u8fc7\u7a0b\u4e0d\u900f\u660e\uff0c\u5b58\u5728\u5b89\u5168\u548c\u4fe1\u4efb\u95ee\u9898\u3002\u73b0\u6709\u7684\u4e0a\u4e0b\u6587\u5f52\u56e0\u65b9\u6cd5\u76f4\u63a5\u5173\u8054\u751f\u6210\u6807\u8bb0\u4e0e\u63d0\u793a\uff0c\u5ffd\u7565\u4e86\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u4ee3\u9645\u5f71\u54cd\uff0c\u5bfc\u81f4\u89e3\u91ca\u4e0d\u5b8c\u6574\u3002", "method": "\u63d0\u51faCAGE\uff08Context Attribution via Graph Explanations\uff09\u6846\u67b6\uff0c\u6784\u5efa\u4e00\u4e2a\u5f52\u56e0\u56fe\uff1a\u6709\u5411\u56fe\u91cf\u5316\u6bcf\u4e2a\u751f\u6210\u5185\u5bb9\u5982\u4f55\u53d7\u5230\u63d0\u793a\u548c\u6240\u6709\u5148\u524d\u751f\u6210\u5185\u5bb9\u7684\u5f71\u54cd\u3002\u8be5\u56fe\u4fdd\u6301\u56e0\u679c\u5173\u7cfb\u548c\u884c\u968f\u673a\u6027\uff0c\u901a\u8fc7\u6cbf\u56fe\u4e2d\u8def\u5f84\u8fb9\u7f18\u5316\u4e2d\u95f4\u8d21\u732e\u6765\u8ba1\u7b97\u4e0a\u4e0b\u6587\u5f52\u56e0\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u3001\u6570\u636e\u96c6\u3001\u6307\u6807\u548c\u65b9\u6cd5\u4e0a\uff0cCAGE\u663e\u8457\u63d0\u9ad8\u4e86\u4e0a\u4e0b\u6587\u5f52\u56e0\u7684\u5fe0\u5b9e\u5ea6\uff0c\u5e73\u5747\u63d0\u5347\u9ad8\u8fbe40%\u3002", "conclusion": "CAGE\u6846\u67b6\u901a\u8fc7\u8003\u8651\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u4ee3\u9645\u5f71\u54cd\uff0c\u63d0\u4f9b\u4e86\u66f4\u5b8c\u6574\u548c\u5fe0\u5b9e\u7684LLM\u884c\u4e3a\u89e3\u91ca\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4e0a\u4e0b\u6587\u5f52\u56e0\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2512.14765", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14765", "abs": "https://arxiv.org/abs/2512.14765", "authors": ["Justin Jung"], "title": "Guided Discrete Diffusion for Constraint Satisfaction Problems", "comment": "Originally published in Jan 2025 on the SpringtailAI Blog", "summary": "We propose discrete diffusion guidance for constraint satisfaction problems (CSPs) and demonstrate its ability to solve Sudoku puzzles without supervision.", "AI": {"tldr": "\u63d0\u51fa\u79bb\u6563\u6269\u6563\u5f15\u5bfc\u65b9\u6cd5\u89e3\u51b3\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff0c\u4ee5\u65e0\u76d1\u7763\u65b9\u5f0f\u89e3\u51b3\u6570\u72ec\u8c1c\u9898", "motivation": "\u4f20\u7edf\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u6c42\u89e3\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u76d1\u7763\u5b66\u4e60\u6216\u542f\u53d1\u5f0f\u641c\u7d22\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u76d1\u7763\u7684\u901a\u7528\u6c42\u89e3\u65b9\u6cd5", "method": "\u91c7\u7528\u79bb\u6563\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u6269\u6563\u8fc7\u7a0b\u5f15\u5bfc\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u7684\u6c42\u89e3\uff0c\u7279\u522b\u9488\u5bf9\u6570\u72ec\u95ee\u9898\u8bbe\u8ba1", "result": "\u6210\u529f\u5b9e\u73b0\u65e0\u76d1\u7763\u89e3\u51b3\u6570\u72ec\u8c1c\u9898\uff0c\u9a8c\u8bc1\u4e86\u79bb\u6563\u6269\u6563\u5f15\u5bfc\u5728\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u4e0a\u7684\u6709\u6548\u6027", "conclusion": "\u79bb\u6563\u6269\u6563\u5f15\u5bfc\u4e3a\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u76d1\u7763\u6c42\u89e3\u8303\u5f0f\uff0c\u5177\u6709\u6269\u5c55\u5230\u5176\u4ed6\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u6f5c\u529b"}}
{"id": "2512.14779", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.14779", "abs": "https://arxiv.org/abs/2512.14779", "authors": ["Kornelius Raeth", "Nicole Ludwig"], "title": "Evaluating Weather Forecasts from a Decision Maker's Perspective", "comment": null, "summary": "Standard weather forecast evaluations focus on the forecaster's perspective and on a statistical assessment comparing forecasts and observations. In practice, however, forecasts are used to make decisions, so it seems natural to take the decision-maker's perspective and quantify the value of a forecast by its ability to improve decision-making. Decision calibration provides a novel framework for evaluating forecast performance at the decision level rather than the forecast level. We evaluate decision calibration to compare Machine Learning and classical numerical weather prediction models on various weather-dependent decision tasks. We find that model performance at the forecast level does not reliably translate to performance in downstream decision-making: some performance differences only become apparent at the decision level, and model rankings can change among different decision tasks. Our results confirm that typical forecast evaluations are insufficient for selecting the optimal forecast model for a specific decision task.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u51b3\u7b56\u6821\u51c6\u6846\u67b6\uff0c\u4ece\u51b3\u7b56\u8005\u800c\u975e\u9884\u62a5\u8005\u89d2\u5ea6\u8bc4\u4f30\u5929\u6c14\u9884\u62a5\u4ef7\u503c\uff0c\u53d1\u73b0\u9884\u62a5\u5c42\u9762\u7684\u6027\u80fd\u5dee\u5f02\u4e0d\u4e00\u5b9a\u8f6c\u5316\u4e3a\u51b3\u7b56\u5c42\u9762\u7684\u4f18\u52bf", "motivation": "\u4f20\u7edf\u5929\u6c14\u9884\u62a5\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u9884\u62a5\u8005\u89c6\u89d2\u548c\u7edf\u8ba1\u6307\u6807\u5bf9\u6bd4\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u9884\u62a5\u7528\u4e8e\u51b3\u7b56\u5236\u5b9a\uff0c\u56e0\u6b64\u9700\u8981\u4ece\u51b3\u7b56\u8005\u89d2\u5ea6\u91cf\u5316\u9884\u62a5\u5728\u6539\u8fdb\u51b3\u7b56\u65b9\u9762\u7684\u4ef7\u503c", "method": "\u63d0\u51fa\u51b3\u7b56\u6821\u51c6\u6846\u67b6\uff0c\u5728\u51b3\u7b56\u5c42\u9762\u800c\u975e\u9884\u62a5\u5c42\u9762\u8bc4\u4f30\u9884\u62a5\u6027\u80fd\uff0c\u6bd4\u8f83\u673a\u5668\u5b66\u4e60\u4e0e\u4f20\u7edf\u6570\u503c\u5929\u6c14\u9884\u62a5\u6a21\u578b\u5728\u5404\u79cd\u5929\u6c14\u4f9d\u8d56\u578b\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u8868\u73b0", "result": "\u6a21\u578b\u5728\u9884\u62a5\u5c42\u9762\u7684\u6027\u80fd\u4e0d\u80fd\u53ef\u9760\u5730\u8f6c\u5316\u4e3a\u4e0b\u6e38\u51b3\u7b56\u6027\u80fd\uff1a\u4e00\u4e9b\u6027\u80fd\u5dee\u5f02\u53ea\u5728\u51b3\u7b56\u5c42\u9762\u663e\u73b0\uff0c\u4e0d\u540c\u51b3\u7b56\u4efb\u52a1\u4e2d\u6a21\u578b\u6392\u540d\u4f1a\u53d1\u751f\u53d8\u5316", "conclusion": "\u5178\u578b\u7684\u9884\u62a5\u8bc4\u4f30\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u4e3a\u7279\u5b9a\u51b3\u7b56\u4efb\u52a1\u9009\u62e9\u6700\u4f18\u9884\u62a5\u6a21\u578b\uff0c\u9700\u8981\u91c7\u7528\u51b3\u7b56\u5c42\u9762\u7684\u8bc4\u4f30\u6846\u67b6"}}
{"id": "2512.14879", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14879", "abs": "https://arxiv.org/abs/2512.14879", "authors": ["Jingwei Chen"], "title": "Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse", "comment": null, "summary": "Self-referential learning -- training a model on data it generated itself -- promises boundless scalability but chronically suffers from model collapse: language models degenerate into repetitive text, GANs drop modes, and reinforcement-learning policies over-exploit. Although practitioners employ ad~hoc fixes such as real-data mixing, entropy bonuses, knowledge distillation, or retrieval-augmented generation, a single principle that explains both the failure mode and the success of these fixes has remained elusive. We present Entropy-Reservoir Bregman Projection (ERBP), an information-geometric framework that unifies these phenomena. We model the closed loop as a stochastic Bregman projection sequence in distribution space. Without external coupling, finite-sample noise forces the system to project onto an ever-shrinking empirical support, causing exponential entropy decay and eventual collapse. Introducing an Entropy Reservoir -- a high-entropy distribution mixed into each projection -- injects a controllable entropy flux that provably stabilises the dynamics. Our theory yields (i) a necessary condition for collapse, (ii) a sufficient condition that guarantees a non-trivial entropy floor, and (iii) closed-form rates that depend only on sample size and the strong-convexity/Lipschitz constants of the Bregman generator. Experiments on large-language-model self-training, Soft Actor-Critic in reinforcement learning, and GAN optimisation validate our predictions and show that disparate stabilisation heuristics correspond to specific reservoir choices and coupling coefficients. ERBP thus transforms a collection of folk remedies into a single, quantitative design rule: monitor and budget your entropy flux.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faERBP\u6846\u67b6\uff0c\u7528\u4fe1\u606f\u51e0\u4f55\u65b9\u6cd5\u7edf\u4e00\u89e3\u91ca\u81ea\u6307\u5b66\u4e60\u4e2d\u7684\u6a21\u578b\u5d29\u6e83\u73b0\u8c61\uff0c\u5e76\u901a\u8fc7\u71b5\u50a8\u5c42\u6ce8\u5165\u53ef\u63a7\u71b5\u6d41\u6765\u7a33\u5b9a\u7cfb\u7edf\u3002", "motivation": "\u81ea\u6307\u5b66\u4e60\uff08\u6a21\u578b\u5728\u81ea\u8eab\u751f\u6210\u7684\u6570\u636e\u4e0a\u8bad\u7ec3\uff09\u867d\u7136\u5177\u6709\u65e0\u9650\u6269\u5c55\u6f5c\u529b\uff0c\u4f46\u666e\u904d\u5b58\u5728\u6a21\u578b\u5d29\u6e83\u95ee\u9898\u3002\u5c3d\u7ba1\u5b9e\u8df5\u4e2d\u5df2\u6709\u5404\u79cd\u4e34\u65f6\u4fee\u590d\u65b9\u6cd5\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u89e3\u91ca\u5931\u8d25\u6a21\u5f0f\u548c\u4fee\u590d\u65b9\u6cd5\u7684\u6210\u529f\u539f\u7406\u3002", "method": "\u63d0\u51fa\u71b5\u50a8\u5c42Bregman\u6295\u5f71\uff08ERBP\uff09\u6846\u67b6\uff0c\u5c06\u81ea\u6307\u5b66\u4e60\u5efa\u6a21\u4e3a\u5206\u5e03\u7a7a\u95f4\u4e2d\u7684\u968f\u673aBregman\u6295\u5f71\u5e8f\u5217\u3002\u901a\u8fc7\u5f15\u5165\u71b5\u50a8\u5c42\uff08\u9ad8\u71b5\u5206\u5e03\uff09\u6df7\u5408\u5230\u6bcf\u6b21\u6295\u5f71\u4e2d\uff0c\u6ce8\u5165\u53ef\u63a7\u7684\u71b5\u6d41\u6765\u7a33\u5b9a\u52a8\u529b\u5b66\u3002", "result": "\u7406\u8bba\u5206\u6790\u5f97\u51fa\uff1a(1)\u6a21\u578b\u5d29\u6e83\u7684\u5fc5\u8981\u6761\u4ef6\uff1b(2)\u4fdd\u8bc1\u975e\u5e73\u51e1\u71b5\u5e95\u9650\u7684\u5145\u5206\u6761\u4ef6\uff1b(3)\u4ec5\u4f9d\u8d56\u4e8e\u6837\u672c\u91cf\u548cBregman\u751f\u6210\u5668\u7684\u5f3a\u51f8\u6027/Lipschitz\u5e38\u6570\u7684\u95ed\u5f0f\u6536\u655b\u7387\u3002\u5728\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u8bad\u7ec3\u3001\u5f3a\u5316\u5b66\u4e60\u548cGAN\u4f18\u5316\u4e2d\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u9884\u6d4b\u3002", "conclusion": "ERBP\u5c06\u5404\u79cd\u7ecf\u9a8c\u6027\u4fee\u590d\u65b9\u6cd5\u7edf\u4e00\u4e3a\u5355\u4e00\u91cf\u5316\u8bbe\u8ba1\u89c4\u5219\uff1a\u76d1\u63a7\u548c\u9884\u7b97\u71b5\u6d41\u3002\u8be5\u6846\u67b6\u4e3a\u81ea\u6307\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5c06\u96f6\u6563\u7684\u6c11\u95f4\u7597\u6cd5\u8f6c\u5316\u4e3a\u7cfb\u7edf\u5316\u7684\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2512.14880", "categories": ["cs.LG", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.14880", "abs": "https://arxiv.org/abs/2512.14880", "authors": ["Darrin O' Brien", "Dhikshith Gajulapalli", "Eric Xia"], "title": "Task Matrices: Linear Maps for Cross-Model Finetuning Transfer", "comment": "NeurIPS Unireps 2025", "summary": "Results in interpretability suggest that large vision and language models learn implicit linear encodings when models are biased by in-context prompting. However, the existence of similar linear representations in more general adaptation regimes has not yet been demonstrated. In this work, we develop the concept of a task matrix, a linear transformation from a base to finetuned embedding state. We demonstrate that for vision and text models and ten different datasets, a base model augmented with a task matrix achieves results surpassing linear probes, sometimes approaching finetuned levels. Our results validate the existence of cross-layer linear encodings between pretrained and finetuned architectures. Moreover, we show that a data-based approximation for such encodings is both efficient and generalizable to multiple domains. We make our implementation publicly available.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u4efb\u52a1\u77e9\u9635\"\u6982\u5ff5\uff0c\u8bc1\u660e\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u8de8\u5c42\u7ebf\u6027\u7f16\u7801\uff0c\u901a\u8fc7\u7ebf\u6027\u53d8\u6362\u63d0\u5347\u57fa\u7840\u6a21\u578b\u6027\u80fd\u63a5\u8fd1\u5fae\u8c03\u6c34\u5e73", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u5927\u578b\u89c6\u89c9\u548c\u8bed\u8a00\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u63d0\u793a\u504f\u7f6e\u4e0b\u5b66\u4e60\u9690\u5f0f\u7ebf\u6027\u7f16\u7801\uff0c\u4f46\u66f4\u901a\u7528\u7684\u9002\u5e94\u673a\u5236\u4e2d\u662f\u5426\u5b58\u5728\u7c7b\u4f3c\u7ebf\u6027\u8868\u793a\u5c1a\u672a\u5f97\u5230\u8bc1\u5b9e", "method": "\u63d0\u51fa\"\u4efb\u52a1\u77e9\u9635\"\u6982\u5ff5\uff0c\u4f5c\u4e3a\u4ece\u57fa\u7840\u5d4c\u5165\u72b6\u6001\u5230\u5fae\u8c03\u5d4c\u5165\u72b6\u6001\u7684\u7ebf\u6027\u53d8\u6362\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u8fd1\u4f3c\u8fd9\u79cd\u7f16\u7801\uff0c\u5e76\u5728\u89c6\u89c9\u548c\u6587\u672c\u6a21\u578b\u53ca\u5341\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1", "result": "\u57fa\u7840\u6a21\u578b\u7ed3\u5408\u4efb\u52a1\u77e9\u9635\u7684\u6027\u80fd\u8d85\u8d8a\u7ebf\u6027\u63a2\u9488\uff0c\u6709\u65f6\u63a5\u8fd1\u5fae\u8c03\u6c34\u5e73\uff0c\u9a8c\u8bc1\u4e86\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u67b6\u6784\u95f4\u5b58\u5728\u8de8\u5c42\u7ebf\u6027\u7f16\u7801\uff0c\u4e14\u6570\u636e\u9a71\u52a8\u8fd1\u4f3c\u65b9\u6cd5\u9ad8\u6548\u4e14\u53ef\u6cdb\u5316\u5230\u591a\u4e2a\u9886\u57df", "conclusion": "\u4efb\u52a1\u77e9\u9635\u8bc1\u660e\u4e86\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u6a21\u578b\u95f4\u5b58\u5728\u53ef\u5b66\u4e60\u7684\u7ebf\u6027\u7f16\u7801\u5173\u7cfb\uff0c\u8fd9\u79cd\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u4e3a\u6a21\u578b\u9002\u5e94\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u6cdb\u5316\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.14892", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14892", "abs": "https://arxiv.org/abs/2512.14892", "authors": ["Mohammad Abu-Shaira", "Alejandro Rodriguez", "Greg Speegle", "Victor Sheng", "Ishfaq Ahmad"], "title": "OLR-WA: Online Weighted Average Linear Regression in Multivariate Data Streams", "comment": null, "summary": "Online learning updates models incrementally with new data, avoiding large storage requirements and costly model recalculations. In this paper, we introduce \"OLR-WA; OnLine Regression with Weighted Average\", a novel and versatile multivariate online linear regression model. We also investigate scenarios involving drift, where the underlying patterns in the data evolve over time, conduct convergence analysis, and compare our approach with existing online regression models. The results of OLR-WA demonstrate its ability to achieve performance comparable to the batch regression, while also showcasing comparable or superior performance when compared with other state-of-the-art online models, thus establishing its effectiveness. Moreover, OLR-WA exhibits exceptional performance in terms of rapid convergence, surpassing other online models with consistently achieving high r2 values as a performance measure from the first iteration to the last iteration, even when initialized with minimal amount of data points, as little as 1% to 10% of the total data points. In addition to its ability to handle time-based (temporal drift) scenarios, remarkably, OLR-WA stands out as the only model capable of effectively managing confidence-based challenging scenarios. It achieves this by adopting a conservative approach in its updates, giving priority to older data points with higher confidence levels. In summary, OLR-WA's performance further solidifies its versatility and utility across different contexts, making it a valuable solution for online linear regression tasks.", "AI": {"tldr": "\u63d0\u51faOLR-WA\u5728\u7ebf\u56de\u5f52\u6a21\u578b\uff0c\u901a\u8fc7\u52a0\u6743\u5e73\u5747\u5904\u7406\u6570\u636e\u6f02\u79fb\uff0c\u5b9e\u73b0\u4e0e\u6279\u91cf\u56de\u5f52\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5728\u6536\u655b\u901f\u5ea6\u548c\u7f6e\u4fe1\u5ea6\u573a\u666f\u5904\u7406\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5728\u7ebf\u5b66\u4e60\u9700\u8981\u589e\u91cf\u66f4\u65b0\u6a21\u578b\u4ee5\u907f\u514d\u5927\u89c4\u6a21\u5b58\u50a8\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u9700\u8981\u5904\u7406\u6570\u636e\u6f02\u79fb\u95ee\u9898\u3002\u73b0\u6709\u5728\u7ebf\u56de\u5f52\u6a21\u578b\u5728\u6536\u655b\u901f\u5ea6\u548c\u5904\u7406\u7f6e\u4fe1\u5ea6\u573a\u666f\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51faOLR-WA\uff08\u5728\u7ebf\u56de\u5f52\u52a0\u6743\u5e73\u5747\uff09\u6a21\u578b\uff0c\u91c7\u7528\u52a0\u6743\u5e73\u5747\u65b9\u6cd5\uff0c\u4fdd\u5b88\u66f4\u65b0\u7b56\u7565\uff0c\u4f18\u5148\u8003\u8651\u7f6e\u4fe1\u5ea6\u8f83\u9ad8\u7684\u65e7\u6570\u636e\u70b9\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u65f6\u95f4\u6f02\u79fb\u548c\u7f6e\u4fe1\u5ea6\u573a\u666f\u3002", "result": "OLR-WA\u6027\u80fd\u4e0e\u6279\u91cf\u56de\u5f52\u76f8\u5f53\uff0c\u6536\u655b\u901f\u5ea6\u5feb\uff0c\u4ece\u7b2c\u4e00\u6b21\u8fed\u4ee3\u5230\u6700\u540e\u4e00\u6b21\u8fed\u4ee3\u90fd\u80fd\u4fdd\u6301\u9ad8r\u00b2\u503c\uff0c\u5373\u4f7f\u4ec5\u75281%-10%\u7684\u6570\u636e\u521d\u59cb\u5316\u4e5f\u80fd\u8868\u73b0\u826f\u597d\u3002\u5728\u7f6e\u4fe1\u5ea6\u573a\u666f\u5904\u7406\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "OLR-WA\u662f\u4e00\u4e2a\u591a\u529f\u80fd\u4e14\u5b9e\u7528\u7684\u5728\u7ebf\u7ebf\u6027\u56de\u5f52\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u5904\u7406\u6570\u636e\u6f02\u79fb\u548c\u7f6e\u4fe1\u5ea6\u573a\u666f\u65b9\u9762\u5177\u6709\u72ec\u7279\u4f18\u52bf\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u5728\u7ebf\u56de\u5f52\u4efb\u52a1\u3002"}}
{"id": "2512.14932", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14932", "abs": "https://arxiv.org/abs/2512.14932", "authors": ["Daniel Gomes de Pinho Zanco", "Leszek Szczecinski", "Jacob Benesty", "Eduardo Vinicius Kuhn"], "title": "Low-rank MMSE filters, Kronecker-product representation, and regularization: a new perspective", "comment": null, "summary": "In this work, we propose a method to efficiently find the regularization parameter for low-rank MMSE filters based on a Kronecker-product representation. We show that the regularization parameter is surprisingly linked to the problem of rank selection and, thus, properly choosing it, is crucial for low-rank settings. The proposed method is validated through simulations, showing significant gains over commonly used methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKronecker\u79ef\u8868\u793a\u7684\u4f4e\u79e9MMSE\u6ee4\u6ce2\u5668\u6b63\u5219\u5316\u53c2\u6570\u9ad8\u6548\u9009\u62e9\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e0e\u79e9\u9009\u62e9\u95ee\u9898\u76f8\u5173\uff0c\u5728\u4f4e\u79e9\u8bbe\u7f6e\u4e2d\u81f3\u5173\u91cd\u8981", "motivation": "\u4f4e\u79e9MMSE\u6ee4\u6ce2\u5668\u4e2d\u6b63\u5219\u5316\u53c2\u6570\u7684\u9009\u62e9\u5bf9\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u6548\u7387\u4e0d\u9ad8\uff0c\u4e14\u6b63\u5219\u5316\u53c2\u6570\u4e0e\u79e9\u9009\u62e9\u95ee\u9898\u5b58\u5728\u5173\u8054\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u9009\u62e9\u65b9\u6cd5", "method": "\u57fa\u4e8eKronecker\u79ef\u8868\u793a\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u6b63\u5219\u5316\u53c2\u6570\u9009\u62e9\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u6b63\u5219\u5316\u53c2\u6570\u9009\u62e9\u4e0e\u79e9\u9009\u62e9\u95ee\u9898\u8054\u7cfb\u8d77\u6765\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u65b9\u6cd5\u786e\u5b9a\u6700\u4f18\u53c2\u6570", "result": "\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\uff0c\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4\u5e38\u7528\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u6b63\u5219\u5316\u53c2\u6570\u9009\u62e9\u5bf9\u4f4e\u79e9MMSE\u6ee4\u6ce2\u5668\u6027\u80fd\u7684\u91cd\u8981\u6027", "conclusion": "\u6b63\u5219\u5316\u53c2\u6570\u9009\u62e9\u4e0e\u79e9\u9009\u62e9\u95ee\u9898\u5bc6\u5207\u76f8\u5173\uff0c\u63d0\u51fa\u7684\u57fa\u4e8eKronecker\u79ef\u8868\u793a\u7684\u9ad8\u6548\u9009\u62e9\u65b9\u6cd5\u5728\u4f4e\u79e9\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u4f4e\u79e9MMSE\u6ee4\u6ce2\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.14980", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14980", "abs": "https://arxiv.org/abs/2512.14980", "authors": ["Victor M. Yeom Song", "Severi Rissanen", "Arno Solin", "Samuel Kaski", "Mingfei Sun"], "title": "Softly Constrained Denoisers for Diffusion Models", "comment": "18 pages including appendix, 8 figures including appendix, preprint", "summary": "Diffusion models struggle to produce samples that respect constraints, a common requirement in scientific applications. Recent approaches have introduced regularization terms in the loss or guidance methods during sampling to enforce such constraints, but they bias the generative model away from the true data distribution. This is a problem, especially when the constraint is misspecified, a common issue when formulating constraints on scientific data. In this paper, instead of changing the loss or the sampling loop, we integrate a guidance-inspired adjustment into the denoiser itself, giving it a soft inductive bias towards constraint-compliant samples. We show that these softly constrained denoisers exploit constraint knowledge to improve compliance over standard denoisers, and maintain enough flexibility to deviate from it when there is misspecification with observed data.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7ea6\u675f\u5f15\u5bfc\u6574\u5408\u5230\u53bb\u566a\u5668\u672c\u8eab\u4e2d\uff0c\u4f7f\u6269\u6563\u6a21\u578b\u80fd\u591f\u751f\u6210\u7b26\u5408\u7ea6\u675f\u7684\u6837\u672c\uff0c\u540c\u65f6\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u5728\u7ea6\u675f\u9519\u8bef\u6307\u5b9a\u65f6\u504f\u79bb\u771f\u5b9e\u6570\u636e\u5206\u5e03\u7684\u95ee\u9898\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u79d1\u5b66\u5e94\u7528\u4e2d\u7ecf\u5e38\u9700\u8981\u751f\u6210\u7b26\u5408\u7279\u5b9a\u7ea6\u675f\u7684\u6837\u672c\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u635f\u5931\u51fd\u6570\u6b63\u5219\u5316\u6216\u91c7\u6837\u5f15\u5bfc\uff09\u4f1a\u4f7f\u751f\u6210\u6a21\u578b\u504f\u79bb\u771f\u5b9e\u6570\u636e\u5206\u5e03\uff0c\u7279\u522b\u662f\u5728\u7ea6\u675f\u9519\u8bef\u6307\u5b9a\u65f6\u95ee\u9898\u66f4\u52a0\u4e25\u91cd\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u4e0d\u6539\u53d8\u635f\u5931\u51fd\u6570\u6216\u91c7\u6837\u5faa\u73af\uff0c\u800c\u662f\u5c06\u5f15\u5bfc\u542f\u53d1\u7684\u8c03\u6574\u6574\u5408\u5230\u53bb\u566a\u5668\u672c\u8eab\u4e2d\uff0c\u8d4b\u4e88\u5176\u8f6f\u5f52\u7eb3\u504f\u7f6e\uff0c\u4f7f\u5176\u503e\u5411\u4e8e\u751f\u6210\u7b26\u5408\u7ea6\u675f\u7684\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u8f6f\u7ea6\u675f\u53bb\u566a\u5668\u80fd\u591f\u5229\u7528\u7ea6\u675f\u77e5\u8bc6\u63d0\u9ad8\u6837\u672c\u7684\u5408\u89c4\u6027\uff0c\u540c\u65f6\u5728\u7ea6\u675f\u4e0e\u89c2\u6d4b\u6570\u636e\u5b58\u5728\u9519\u8bef\u6307\u5b9a\u65f6\u4fdd\u6301\u8db3\u591f\u7684\u7075\u6d3b\u6027\u6765\u504f\u79bb\u7ea6\u675f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6269\u6563\u6a21\u578b\u7075\u6d3b\u6027\u7684\u540c\u65f6\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u751f\u6210\u6837\u672c\u7684\u7ea6\u675f\u5408\u89c4\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7ea6\u675f\u53ef\u80fd\u9519\u8bef\u6307\u5b9a\u7684\u79d1\u5b66\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2512.14982", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.14982", "abs": "https://arxiv.org/abs/2512.14982", "authors": ["Yaniv Leviathan", "Matan Kalman", "Yossi Matias"], "title": "Prompt Repetition Improves Non-Reasoning LLMs", "comment": null, "summary": "When not using reasoning, repeating the input prompt improves performance for popular models (Gemini, GPT, Claude, and Deepseek) without increasing the number of generated tokens or latency.", "AI": {"tldr": "\u91cd\u590d\u8f93\u5165\u63d0\u793a\u8bcd\u80fd\u63d0\u5347\u4e3b\u6d41\u5927\u6a21\u578b\uff08Gemini\u3001GPT\u3001Claude\u3001Deepseek\uff09\u5728\u4e0d\u4f7f\u7528\u63a8\u7406\u65f6\u7684\u6027\u80fd\uff0c\u4e14\u4e0d\u589e\u52a0\u751f\u6210token\u6570\u6216\u5ef6\u8fdf", "motivation": "\u63a2\u7d22\u5982\u4f55\u5728\u4e0d\u589e\u52a0\u8ba1\u7b97\u6210\u672c\uff08token\u6570\u548c\u5ef6\u8fdf\uff09\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u9488\u5bf9\u975e\u63a8\u7406\u4efb\u52a1", "method": "\u901a\u8fc7\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u5bf9\u591a\u4e2a\u4e3b\u6d41\u5927\u6a21\u578b\uff08Gemini\u3001GPT\u3001Claude\u3001Deepseek\uff09\u6d4b\u8bd5\u91cd\u590d\u8f93\u5165\u63d0\u793a\u8bcd\u7684\u6548\u679c\uff0c\u6bd4\u8f83\u4f7f\u7528\u63a8\u7406\u548c\u4e0d\u4f7f\u7528\u63a8\u7406\u4e24\u79cd\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u5dee\u5f02", "result": "\u5728\u4e0d\u4f7f\u7528\u63a8\u7406\u65f6\uff0c\u91cd\u590d\u8f93\u5165\u63d0\u793a\u8bcd\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4e14\u4e0d\u589e\u52a0\u751f\u6210\u7684token\u6570\u91cf\u6216\u54cd\u5e94\u5ef6\u8fdf\uff1b\u4f46\u5728\u4f7f\u7528\u63a8\u7406\u65f6\uff0c\u8fd9\u79cd\u91cd\u590d\u53ef\u80fd\u4e0d\u4f1a\u5e26\u6765\u540c\u6837\u7684\u6548\u679c\u63d0\u5347", "conclusion": "\u5bf9\u4e8e\u975e\u63a8\u7406\u4efb\u52a1\uff0c\u7b80\u5355\u7684\u63d0\u793a\u8bcd\u91cd\u590d\u662f\u4e00\u79cd\u6709\u6548\u4e14\u6210\u672c\u4f4e\u5ec9\u7684\u6027\u80fd\u63d0\u5347\u7b56\u7565\uff0c\u4e3a\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u4f7f\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5"}}
{"id": "2512.14991", "categories": ["cs.LG", "math.OC", "q-fin.PM"], "pdf": "https://arxiv.org/pdf/2512.14991", "abs": "https://arxiv.org/abs/2512.14991", "authors": ["Hanqing Jin", "Renyuan Xu", "Yanzhao Yang"], "title": "Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes", "comment": null, "summary": "We study reinforcement learning for controlled diffusion processes with unbounded continuous state spaces, bounded continuous actions, and polynomially growing rewards: settings that arise naturally in finance, economics, and operations research. To overcome the challenges of continuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint state-action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing results for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u65e0\u754c\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u6269\u6563\u8fc7\u7a0b\u7684\u81ea\u9002\u5e94\u5206\u533a\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u5e73\u8861\u63a2\u7d22\u4e0e\u8fd1\u4f3c\uff0c\u5728\u91d1\u878d\u3001\u7ecf\u6d4e\u7b49\u9886\u57df\u7684\u9ad8\u7ef4\u95ee\u9898\u4e2d\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60\u3002", "motivation": "\u91d1\u878d\u3001\u7ecf\u6d4e\u548c\u8fd0\u7b79\u5b66\u4e2d\u7ecf\u5e38\u9047\u5230\u5177\u6709\u65e0\u754c\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u3001\u6709\u754c\u8fde\u7eed\u52a8\u4f5c\u548c\u591a\u9879\u5f0f\u589e\u957f\u5956\u52b1\u7684\u6269\u6563\u8fc7\u7a0b\u63a7\u5236\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u8fd9\u7c7b\u8fde\u7eed\u9ad8\u7ef4\u9886\u57df\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u7684\u81ea\u9002\u5e94\u5206\u533a\u7b97\u6cd5\uff0c\u5728\u8054\u5408\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u8fdb\u884c\u81ea\u9002\u5e94\u5212\u5206\uff0c\u7ef4\u62a4\u6bcf\u4e2a\u5206\u533a\u5185\u7684\u6f02\u79fb\u3001\u6ce2\u52a8\u7387\u548c\u5956\u52b1\u4f30\u8ba1\u5668\uff0c\u5f53\u4f30\u8ba1\u504f\u5dee\u8d85\u8fc7\u7edf\u8ba1\u7f6e\u4fe1\u5ea6\u65f6\u7ec6\u5316\u79bb\u6563\u5316\u3002", "result": "\u5efa\u7acb\u4e86\u540e\u6094\u754c\uff0c\u4f9d\u8d56\u4e8e\u95ee\u9898\u65f6\u95f4\u8303\u56f4\u3001\u72b6\u6001\u7ef4\u5ea6\u3001\u5956\u52b1\u589e\u957f\u9636\u6570\u4ee5\u53ca\u4e3a\u65e0\u754c\u6269\u6563\u8fc7\u7a0b\u5b9a\u5236\u7684\u65b0\u5b9a\u4e49\u7684\"\u7f29\u653e\u7ef4\u5ea6\"\uff0c\u5728\u6570\u503c\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u81ea\u9002\u5e94\u65b9\u6848\u5e73\u8861\u4e86\u63a2\u7d22\u4e0e\u8fd1\u4f3c\uff0c\u80fd\u591f\u9ad8\u6548\u5b66\u4e60\u65e0\u754c\u9886\u57df\u95ee\u9898\uff0c\u5c06\u7406\u8bba\u4fdd\u8bc1\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684\u6269\u6563\u7c7b\u578b\u95ee\u9898\u7c7b\u522b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9ad8\u7ef4\u591a\u8d44\u4ea7\u5747\u503c-\u65b9\u5dee\u6295\u8d44\u7ec4\u5408\u9009\u62e9\u7b49\u5e94\u7528\u3002"}}
{"id": "2512.15000", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.15000", "abs": "https://arxiv.org/abs/2512.15000", "authors": ["Ruiyi Zhang", "Peijia Qin", "Qi Cao", "Pengtao Xie"], "title": "DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding", "comment": null, "summary": "Process Reward Models (PRMs) have become essential for improving Large Language Models (LLMs) via test-time scaling, yet their effectiveness in coding remains limited due to the lack of meaningful step decompositions in code and the noise of Monte-Carlo-generated partial labels. We propose DreamPRM-Code, a coding-focused PRM that treats functions as reasoning steps using a Chain-of-Function prompting strategy to induce modular code generation, enabling PRM training and application analogous to mathematical reasoning tasks. To address label noise, DreamPRM-Code introduces a meta-learning-based correction mechanism that leverages clean final-solution unit-test labels and performs bi-level optimization to refine intermediate labels. Applying on test-time scaling, DreamPRM-Code achieved state-of-the-art performance on LiveCodeBench with 80.9 pass@1 rate, surpassing OpenAI o4-mini.", "AI": {"tldr": "DreamPRM-Code\uff1a\u9488\u5bf9\u4ee3\u7801\u4efb\u52a1\u7684\u6d41\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u901a\u8fc7\u51fd\u6570\u94fe\u63d0\u793a\u7b56\u7565\u5c06\u51fd\u6570\u4f5c\u4e3a\u63a8\u7406\u6b65\u9aa4\uff0c\u7ed3\u5408\u5143\u5b66\u4e60\u6821\u6b63\u673a\u5236\u5904\u7406\u6807\u7b7e\u566a\u58f0\uff0c\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6d41\u7a0b\u5956\u52b1\u6a21\u578b\u5728\u4ee3\u7801\u4efb\u52a1\u4e0a\u6548\u679c\u6709\u9650\uff0c\u4e3b\u8981\u56e0\u4e3a\u4ee3\u7801\u7f3a\u4e4f\u6709\u610f\u4e49\u7684\u6b65\u9aa4\u5206\u89e3\uff0c\u4ee5\u53ca\u8499\u7279\u5361\u6d1b\u751f\u6210\u7684\u4e2d\u95f4\u6807\u7b7e\u5b58\u5728\u566a\u58f0\u95ee\u9898\u3002", "method": "1. \u63d0\u51fa\u51fd\u6570\u94fe\u63d0\u793a\u7b56\u7565\uff0c\u5c06\u51fd\u6570\u4f5c\u4e3a\u63a8\u7406\u6b65\u9aa4\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u4ee3\u7801\u751f\u6210\uff1b2. \u5f15\u5165\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u6821\u6b63\u673a\u5236\uff0c\u5229\u7528\u5e72\u51c0\u7684\u6700\u7ec8\u89e3\u51b3\u65b9\u6848\u5355\u5143\u6d4b\u8bd5\u6807\u7b7e\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u7cbe\u70bc\u4e2d\u95f4\u6807\u7b7e\u3002", "result": "\u5728LiveCodeBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523080.9%\u7684pass@1\u7387\uff0c\u8d85\u8d8aOpenAI o4-mini\uff0c\u53d6\u5f97\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "DreamPRM-Code\u901a\u8fc7\u521b\u65b0\u7684\u51fd\u6570\u94fe\u5206\u89e3\u548c\u5143\u5b66\u4e60\u6821\u6b63\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ee3\u7801\u4efb\u52a1\u4e2d\u6d41\u7a0b\u5956\u52b1\u6a21\u578b\u7684\u5173\u952e\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2512.15008", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15008", "abs": "https://arxiv.org/abs/2512.15008", "authors": ["Sandeep Neela"], "title": "Stock Pattern Assistant (SPA): A Deterministic and Explainable Framework for Structural Price Run Extraction and Event Correlation in Equity Markets", "comment": null, "summary": "Understanding how prices evolve over time often requires peeling back the layers of market noise to identify clear, structural behavior. Many of the tools commonly used for this purpose technical indicators, chart heuristics, or even sophisticated predictive models leave important questions unanswered. Technical indicators depend on platform-specific rules, and predictive systems typically offer little in terms of explanation. In settings that demand transparency or auditability, this poses a significant challenge. We introduce the Stock Pattern Assistant (SPA), a deterministic framework designed to extract monotonic price runs, attach relevant public events through a symmetric correlation window, and generate explanations that are factual, historical, and guardrailed. SPA relies only on daily OHLCV data and a normalized event stream, making the pipeline straight-forward to audit and easy to reproduce. To illustrate SPA's behavior in practice, we evaluate it across four equities-AAPL, NVDA, SCHW, and PGR-chosen to span a range of volatility regimes and sector characteristics. Although the evaluation period is modest, the results demonstrate how SPA consistently produces stable structural decompositions and contextual narratives. Ablation experiments further show how deterministic segmentation, event alignment, and constrained explanation each contribute to interpretability. SPA is not a forecasting system, nor is it intended to produce trading signals. Its value lies in offering a transparent, reproducible view of historical price structure that can complement analyst workflows, risk reviews, and broader explainable-AI pipelines.", "AI": {"tldr": "SPA\u662f\u4e00\u4e2a\u786e\u5b9a\u6027\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u53d6\u5355\u8c03\u4ef7\u683c\u8d70\u52bf\u3001\u5173\u8054\u516c\u5f00\u4e8b\u4ef6\u5e76\u751f\u6210\u53ef\u89e3\u91ca\u7684\u53d9\u8ff0\uff0c\u65e8\u5728\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u590d\u73b0\u7684\u5386\u53f2\u4ef7\u683c\u7ed3\u6784\u5206\u6790\uff0c\u800c\u975e\u9884\u6d4b\u6216\u4ea4\u6613\u4fe1\u53f7\u3002", "motivation": "\u73b0\u6709\u6280\u672f\u6307\u6807\u548c\u9884\u6d4b\u6a21\u578b\u5728\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5ba1\u8ba1\u548c\u89e3\u91ca\u7684\u5e02\u573a\u5206\u6790\u573a\u666f\u4e2d\uff0c\u7f3a\u4e4f\u80fd\u591f\u63d0\u4f9b\u6e05\u6670\u7ed3\u6784\u5206\u89e3\u548c\u4e0a\u4e0b\u6587\u89e3\u91ca\u7684\u5de5\u5177\u3002", "method": "SPA\u4f7f\u7528\u786e\u5b9a\u6027\u6846\u67b6\uff0c\u57fa\u4e8e\u6bcf\u65e5OHLCV\u6570\u636e\u548c\u6807\u51c6\u5316\u4e8b\u4ef6\u6d41\uff0c\u63d0\u53d6\u5355\u8c03\u4ef7\u683c\u8d70\u52bf\uff0c\u901a\u8fc7\u5bf9\u79f0\u76f8\u5173\u7a97\u53e3\u5173\u8054\u516c\u5f00\u4e8b\u4ef6\uff0c\u5e76\u751f\u6210\u53d7\u7ea6\u675f\u7684\u4e8b\u5b9e\u6027\u5386\u53f2\u89e3\u91ca\u3002", "result": "\u5728AAPL\u3001NVDA\u3001SCHW\u3001PGR\u56db\u79cd\u80a1\u7968\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cSPA\u80fd\u591f\u7a33\u5b9a\u751f\u6210\u7ed3\u6784\u5206\u89e3\u548c\u4e0a\u4e0b\u6587\u53d9\u8ff0\u3002\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u786e\u5b9a\u6027\u5206\u5272\u3001\u4e8b\u4ef6\u5bf9\u9f50\u548c\u7ea6\u675f\u89e3\u91ca\u5bf9\u53ef\u89e3\u91ca\u6027\u7684\u8d21\u732e\u3002", "conclusion": "SPA\u4f5c\u4e3a\u4e00\u4e2a\u975e\u9884\u6d4b\u6027\u5de5\u5177\uff0c\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u590d\u73b0\u7684\u5386\u53f2\u4ef7\u683c\u7ed3\u6784\u89c6\u56fe\uff0c\u53ef\u8865\u5145\u5206\u6790\u5e08\u5de5\u4f5c\u6d41\u7a0b\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u53ef\u89e3\u91caAI\u7ba1\u9053\uff0c\u586b\u8865\u4e86\u5e02\u573a\u5206\u6790\u4e2d\u900f\u660e\u5ea6\u548c\u53ef\u5ba1\u8ba1\u6027\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.15011", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.15011", "abs": "https://arxiv.org/abs/2512.15011", "authors": ["Damian Hodel", "Jevin D. West"], "title": "Epistemic diversity across language models mitigates knowledge collapse", "comment": "16 pages, 7 figures", "summary": "The growing use of artificial intelligence (AI) raises concerns of knowledge collapse, i.e., a reduction to the most dominant and central set of ideas. Prior work has demonstrated single-model collapse, defined as performance decay in an AI model trained on its own output. Inspired by ecology, we ask whether AI ecosystem diversity, that is, diversity among models, can mitigate such a collapse. We build on the single-model approach but focus on ecosystems of models trained on their collective output. To study the effect of diversity on model performance, we segment the training data across language models and evaluate the resulting ecosystems over ten, self-training iterations. We find that increased epistemic diversity mitigates collapse, but, interestingly, only up to an optimal level. Our results suggest that an ecosystem containing only a few diverse models fails to express the rich mixture of the full, true distribution, resulting in rapid performance decay. Yet distributing the data across too many models reduces each model's approximation capacity on the true distribution, leading to poor performance already in the first iteration step. In the context of AI monoculture, our results suggest the need to monitor diversity across AI systems and to develop policies that incentivize more domain- and community-specific models.", "AI": {"tldr": "AI\u751f\u6001\u7cfb\u7edf\u591a\u6837\u6027\u53ef\u4ee5\u7f13\u89e3\u77e5\u8bc6\u5d29\u6e83\uff0c\u4f46\u5b58\u5728\u6700\u4f18\u591a\u6837\u6027\u6c34\u5e73\uff0c\u8fc7\u591a\u6216\u8fc7\u5c11\u7684\u6a21\u578b\u591a\u6837\u6027\u90fd\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d", "motivation": "\u968f\u7740AI\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u51fa\u73b0\u4e86\"\u77e5\u8bc6\u5d29\u6e83\"\u7684\u62c5\u5fe7\uff0c\u5373\u77e5\u8bc6\u5411\u6700\u4e3b\u5bfc\u548c\u6838\u5fc3\u7684\u601d\u60f3\u96c6\u7f29\u51cf\u3002\u5148\u524d\u7814\u7a76\u5c55\u793a\u4e86\u5355\u4e00\u6a21\u578b\u5728\u81ea\u8eab\u8f93\u51fa\u4e0a\u8bad\u7ec3\u65f6\u7684\u6027\u80fd\u8870\u51cf\u3002\u672c\u7814\u7a76\u53d7\u751f\u6001\u5b66\u542f\u53d1\uff0c\u63a2\u8ba8AI\u751f\u6001\u7cfb\u7edf\u591a\u6837\u6027\uff08\u6a21\u578b\u95f4\u7684\u591a\u6837\u6027\uff09\u662f\u5426\u80fd\u7f13\u89e3\u8fd9\u79cd\u5d29\u6e83\u3002", "method": "\u5728\u5355\u4e00\u6a21\u578b\u65b9\u6cd5\u57fa\u7840\u4e0a\uff0c\u805a\u7126\u4e8e\u5728\u96c6\u4f53\u8f93\u51fa\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u751f\u6001\u7cfb\u7edf\u3002\u901a\u8fc7\u5728\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u95f4\u5206\u5272\u8bad\u7ec3\u6570\u636e\uff0c\u8bc4\u4f30\u7531\u6b64\u4ea7\u751f\u7684\u751f\u6001\u7cfb\u7edf\u5728\u5341\u6b21\u81ea\u6211\u8bad\u7ec3\u8fed\u4ee3\u4e2d\u7684\u8868\u73b0\uff0c\u7814\u7a76\u591a\u6837\u6027\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u589e\u52a0\u8ba4\u77e5\u591a\u6837\u6027\u786e\u5b9e\u80fd\u7f13\u89e3\u5d29\u6e83\uff0c\u4f46\u53ea\u8fbe\u5230\u6700\u4f18\u6c34\u5e73\u3002\u5305\u542b\u8fc7\u5c11\u591a\u6837\u5316\u6a21\u578b\u7684\u751f\u6001\u7cfb\u7edf\u65e0\u6cd5\u8868\u8fbe\u5b8c\u6574\u771f\u5b9e\u5206\u5e03\u7684\u4e30\u5bcc\u6df7\u5408\uff0c\u5bfc\u81f4\u6027\u80fd\u5feb\u901f\u8870\u51cf\u3002\u800c\u5c06\u6570\u636e\u5206\u5e03\u5728\u8fc7\u591a\u6a21\u578b\u4e2d\u4f1a\u964d\u4f4e\u6bcf\u4e2a\u6a21\u578b\u5bf9\u771f\u5b9e\u5206\u5e03\u7684\u8fd1\u4f3c\u80fd\u529b\uff0c\u5bfc\u81f4\u5728\u7b2c\u4e00\u6b21\u8fed\u4ee3\u6b65\u9aa4\u4e2d\u5c31\u51fa\u73b0\u6027\u80fd\u4e0d\u4f73\u3002", "conclusion": "\u5728AI\u5355\u4e00\u6587\u5316\u80cc\u666f\u4e0b\uff0c\u9700\u8981\u76d1\u63a7AI\u7cfb\u7edf\u95f4\u7684\u591a\u6837\u6027\uff0c\u5e76\u5236\u5b9a\u653f\u7b56\u6fc0\u52b1\u66f4\u591a\u9886\u57df\u548c\u793e\u533a\u7279\u5b9a\u7684\u6a21\u578b\u53d1\u5c55\uff0c\u4ee5\u7ef4\u6301\u5065\u5eb7\u7684AI\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2512.15068", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.15068", "abs": "https://arxiv.org/abs/2512.15068", "authors": ["Debu Sinha"], "title": "The Semantic Illusion: Certified Limits of Embedding-Based Hallucination Detection in RAG Systems", "comment": "12 pages, 2 figures, 6 tables", "summary": "Retrieval-Augmented Generation (RAG) systems remain susceptible to hallucinations despite grounding in retrieved evidence. Current detection methods rely on semantic similarity and natural language inference (NLI), but their fundamental limitations have not been rigorously characterized. We apply conformal prediction to hallucination detection, providing finite-sample coverage guarantees that enable precise quantification of detection capabilities. Using calibration sets of approximately 600 examples, we achieve 94% coverage with 0% false positive rate on synthetic hallucinations (Natural Questions). However, on three real hallucination benchmarks spanning multiple LLMs (GPT-4, ChatGPT, GPT-3, Llama-2, Mistral), embedding-based methods - including state-of-the-art OpenAI text-embedding-3-large and cross-encoder models - exhibit unacceptable false positive rates: 100% on HaluEval, 88% on RAGTruth, and 50% on WikiBio. Crucially, GPT-4 as an LLM judge achieves only 7% FPR (95% CI: [3.4%, 13.7%]) on the same data, proving the task is solvable through reasoning. We term this the \"semantic illusion\": semantically plausible hallucinations preserve similarity to source documents while introducing factual errors invisible to embeddings. This limitation persists across embedding architectures, LLM generators, and task types, suggesting embedding-based detection is insufficient for production RAG deployment.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5e94\u7528\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\u68c0\u6d4bRAG\u7cfb\u7edf\u4e2d\u7684\u5e7b\u89c9\uff0c\u53d1\u73b0\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\u5728\u771f\u5b9e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b58\u5728\u9ad8\u8bef\u62a5\u7387\uff0c\u800cGPT-4\u4f5c\u4e3aLLM\u6cd5\u5b98\u8868\u73b0\u66f4\u4f18\uff0c\u63ed\u793a\u4e86\"\u8bed\u4e49\u5e7b\u89c9\"\u73b0\u8c61\u3002", "motivation": "\u5c3d\u7ba1\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u57fa\u4e8e\u68c0\u7d22\u8bc1\u636e\uff0c\u4f46\u4ecd\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u3002\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff0c\u4f46\u5176\u6839\u672c\u5c40\u9650\u6027\u5c1a\u672a\u5f97\u5230\u4e25\u683c\u8868\u5f81\u3002", "method": "\u5e94\u7528\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\u8fdb\u884c\u5e7b\u89c9\u68c0\u6d4b\uff0c\u63d0\u4f9b\u6709\u9650\u6837\u672c\u8986\u76d6\u4fdd\u8bc1\uff0c\u4f7f\u7528\u7ea6600\u4e2a\u793a\u4f8b\u7684\u6821\u51c6\u96c6\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u5e7b\u89c9\u57fa\u51c6\u4e0a\u6d4b\u8bd5\u4e0d\u540c\u65b9\u6cd5\u3002", "result": "\u5728\u5408\u6210\u5e7b\u89c9\u4e0a\u8fbe\u523094%\u8986\u76d6\u7387\u4e140%\u8bef\u62a5\u7387\uff0c\u4f46\u5728\u771f\u5b9e\u57fa\u51c6\u4e0a\uff0c\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\u8bef\u62a5\u7387\u6781\u9ad8\uff1aHaluEval 100%\u3001RAGTruth 88%\u3001WikiBio 50%\u3002GPT-4\u4f5c\u4e3aLLM\u6cd5\u5b98\u4ec57%\u8bef\u62a5\u7387\u3002", "conclusion": "\u63ed\u793a\u4e86\"\u8bed\u4e49\u5e7b\u89c9\"\u73b0\u8c61\uff1a\u8bed\u4e49\u5408\u7406\u7684\u5e7b\u89c9\u4fdd\u6301\u4e0e\u6e90\u6587\u6863\u7684\u76f8\u4f3c\u6027\uff0c\u4f46\u5f15\u5165\u5d4c\u5165\u65b9\u6cd5\u65e0\u6cd5\u68c0\u6d4b\u7684\u4e8b\u5b9e\u9519\u8bef\u3002\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u7528\u4e8e\u751f\u4ea7RAG\u90e8\u7f72\u3002"}}
{"id": "2512.15082", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15082", "abs": "https://arxiv.org/abs/2512.15082", "authors": ["Wanfu Gao", "Zebin He", "Jun Gao"], "title": "The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks", "comment": null, "summary": "Existing feature engineering methods based on large language models (LLMs) have not yet been applied to multi-label learning tasks. They lack the ability to model complex label dependencies and are not specifically adapted to the characteristics of multi-label tasks. To address the above issues, we propose Feature Engineering Automation for Multi-Label Learning (FEAML), an automated feature engineering method for multi-label classification which leverages the code generation capabilities of LLMs. By utilizing metadata and label co-occurrence matrices, LLMs are guided to understand the relationships between data features and task objectives, based on which high-quality features are generated. The newly generated features are evaluated in terms of model accuracy to assess their effectiveness, while Pearson correlation coefficients are used to detect redundancy. FEAML further incorporates the evaluation results as feedback to drive LLMs to continuously optimize code generation in subsequent iterations. By integrating LLMs with a feedback mechanism, FEAML realizes an efficient, interpretable and self-improving feature engineering paradigm. Empirical results on various multi-label datasets demonstrate that our FEAML outperforms other feature engineering methods.", "AI": {"tldr": "FEAML\u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u591a\u6807\u7b7e\u5b66\u4e60\u4efb\u52a1\uff0c\u901a\u8fc7\u4ee3\u7801\u751f\u6210\u3001\u53cd\u9988\u673a\u5236\u548c\u6807\u7b7e\u4f9d\u8d56\u5efa\u6a21\u6765\u63d0\u5347\u591a\u6807\u7b7e\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\u5c1a\u672a\u5e94\u7528\u4e8e\u591a\u6807\u7b7e\u5b66\u4e60\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u590d\u6742\u6807\u7b7e\u4f9d\u8d56\u5173\u7cfb\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u4e14\u672a\u9488\u5bf9\u591a\u6807\u7b7e\u4efb\u52a1\u7279\u6027\u8fdb\u884c\u4e13\u95e8\u9002\u914d\u3002", "method": "FEAML\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u901a\u8fc7\u5143\u6570\u636e\u548c\u6807\u7b7e\u5171\u73b0\u77e9\u9635\u5f15\u5bfcLLM\u7406\u89e3\u6570\u636e\u7279\u5f81\u4e0e\u4efb\u52a1\u76ee\u6807\u7684\u5173\u7cfb\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u7279\u5f81\u3002\u4f7f\u7528\u6a21\u578b\u51c6\u786e\u7387\u8bc4\u4f30\u7279\u5f81\u6709\u6548\u6027\uff0c\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\u68c0\u6d4b\u5197\u4f59\uff0c\u5e76\u5c06\u8bc4\u4f30\u7ed3\u679c\u4f5c\u4e3a\u53cd\u9988\u9a71\u52a8LLM\u5728\u540e\u7eed\u8fed\u4ee3\u4e2d\u6301\u7eed\u4f18\u5316\u4ee3\u7801\u751f\u6210\u3002", "result": "\u5728\u5404\u79cd\u591a\u6807\u7b7e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cFEAML\u4f18\u4e8e\u5176\u4ed6\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\u3002", "conclusion": "FEAML\u901a\u8fc7\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u53cd\u9988\u673a\u5236\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u4e14\u81ea\u6211\u6539\u8fdb\u7684\u7279\u5f81\u5de5\u7a0b\u8303\u5f0f\u3002"}}
{"id": "2512.15116", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15116", "abs": "https://arxiv.org/abs/2512.15116", "authors": ["Runze Li", "Hanchen Wang", "Wenjie Zhang", "Binghao Li", "Yu Zhang", "Xuemin Lin", "Ying Zhang"], "title": "FADTI: Fourier and Attention Driven Diffusion for Multivariate Time Series Imputation", "comment": "This work has been submitted to the IEEE for possible publication. 15 pages, 8 figures", "summary": "Multivariate time series imputation is fundamental in applications such as healthcare, traffic forecasting, and biological modeling, where sensor failures and irregular sampling lead to pervasive missing values. However, existing Transformer- and diffusion-based models lack explicit inductive biases and frequency awareness, limiting their generalization under structured missing patterns and distribution shifts. We propose FADTI, a diffusion-based framework that injects frequency-informed feature modulation via a learnable Fourier Bias Projection (FBP) module and combines it with temporal modeling through self-attention and gated convolution. FBP supports multiple spectral bases, enabling adaptive encoding of both stationary and non-stationary patterns. This design injects frequency-domain inductive bias into the generative imputation process. Experiments on multiple benchmarks, including a newly introduced biological time series dataset, show that FADTI consistently outperforms state-of-the-art methods, particularly under high missing rates. Code is available at https://anonymous.4open.science/r/TimeSeriesImputation-52BF", "AI": {"tldr": "FADTI\uff1a\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u63d2\u8865\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5085\u91cc\u53f6\u504f\u7f6e\u6295\u5f71\u6a21\u5757\u6ce8\u5165\u9891\u7387\u611f\u77e5\u7279\u5f81\u8c03\u5236\uff0c\u7ed3\u5408\u81ea\u6ce8\u610f\u529b\u548c\u95e8\u63a7\u5377\u79ef\u8fdb\u884c\u65f6\u5e8f\u5efa\u6a21\uff0c\u5728\u7ed3\u6784\u5316\u7f3a\u5931\u6a21\u5f0f\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eTransformer\u548c\u6269\u6563\u7684\u6a21\u578b\u7f3a\u4e4f\u663e\u5f0f\u5f52\u7eb3\u504f\u7f6e\u548c\u9891\u7387\u611f\u77e5\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u5728\u7ed3\u6784\u5316\u7f3a\u5931\u6a21\u5f0f\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6cdb\u5316\u6027\u80fd\u3002\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u63d2\u8865\u5728\u533b\u7597\u3001\u4ea4\u901a\u9884\u6d4b\u548c\u751f\u7269\u5efa\u6a21\u7b49\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u611f\u5668\u6545\u969c\u548c\u4e0d\u89c4\u5219\u91c7\u6837\u5bfc\u81f4\u666e\u904d\u7f3a\u5931\u503c\u3002", "method": "\u63d0\u51faFADTI\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5085\u91cc\u53f6\u504f\u7f6e\u6295\u5f71\u6a21\u5757\u6ce8\u5165\u9891\u7387\u611f\u77e5\u7279\u5f81\u8c03\u5236\uff1b2\uff09\u652f\u6301\u591a\u79cd\u8c31\u57fa\uff0c\u80fd\u591f\u81ea\u9002\u5e94\u7f16\u7801\u5e73\u7a33\u548c\u975e\u5e73\u7a33\u6a21\u5f0f\uff1b3\uff09\u7ed3\u5408\u81ea\u6ce8\u610f\u529b\u548c\u95e8\u63a7\u5377\u79ef\u8fdb\u884c\u65f6\u5e8f\u5efa\u6a21\uff1b4\uff09\u5c06\u9891\u57df\u5f52\u7eb3\u504f\u7f6e\u6ce8\u5165\u751f\u6210\u5f0f\u63d2\u8865\u8fc7\u7a0b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u65b0\u5f15\u5165\u7684\u751f\u7269\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\uff09\u4e0a\uff0cFADTI\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7f3a\u5931\u7387\u4e0b\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "FADTI\u901a\u8fc7\u6ce8\u5165\u9891\u7387\u611f\u77e5\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u63d2\u8865\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u7ed3\u6784\u5316\u7f3a\u5931\u6a21\u5f0f\u548c\u5206\u5e03\u504f\u79fb\u4e0b\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.15134", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.15134", "abs": "https://arxiv.org/abs/2512.15134", "authors": ["Aaron Mueller", "Andrew Lee", "Shruti Joshi", "Ekdeep Singh Lubana", "Dhanya Sridhar", "Patrik Reizinger"], "title": "From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?", "comment": null, "summary": "A central goal of interpretability is to recover representations of causally relevant concepts from the activations of neural networks. The quality of these concept representations is typically evaluated in isolation, and under implicit independence assumptions that may not hold in practice. Thus, it is unclear whether common featurization methods - including sparse autoencoders (SAEs) and sparse probes - recover disentangled representations of these concepts. This study proposes a multi-concept evaluation setting where we control the correlations between textual concepts, such as sentiment, domain, and tense, and analyze performance under increasing correlations between them. We first evaluate the extent to which featurizers can learn disentangled representations of each concept under increasing correlational strengths. We observe a one-to-many relationship from concepts to features: features correspond to no more than one concept, but concepts are distributed across many features. Then, we perform steering experiments, measuring whether each concept is independently manipulable. Even when trained on uniform distributions of concepts, SAE features generally affect many concepts when steered, indicating that they are neither selective nor independent; nonetheless, features affect disjoint subspaces. These results suggest that correlational metrics for measuring disentanglement are generally not sufficient for establishing independence when steering, and that affecting disjoint subspaces is not sufficient for concept selectivity. These results underscore the importance of compositional evaluations in interpretability research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u7a00\u758f\u81ea\u7f16\u7801\u5668\u548c\u7a00\u758f\u63a2\u9488\u7b49\u7279\u5f81\u5316\u65b9\u6cd5\u5728\u591a\u6982\u5ff5\u76f8\u5173\u573a\u666f\u4e0b\u7684\u89e3\u8026\u80fd\u529b\uff0c\u53d1\u73b0\u7279\u5f81\u4e0e\u6982\u5ff5\u4e4b\u95f4\u5b58\u5728\u4e00\u5bf9\u591a\u5173\u7cfb\uff0c\u4e14\u5373\u4f7f\u7279\u5f81\u5f71\u54cd\u4e0d\u76f8\u4ea4\u5b50\u7a7a\u95f4\uff0c\u4e5f\u4e0d\u8db3\u4ee5\u5b9e\u73b0\u6982\u5ff5\u9009\u62e9\u6027\u3002", "motivation": "\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u901a\u5e38\u5b64\u7acb\u8bc4\u4f30\u6982\u5ff5\u8868\u793a\u8d28\u91cf\uff0c\u5e76\u9690\u542b\u72ec\u7acb\u6027\u5047\u8bbe\uff0c\u4f46\u8fd9\u4e9b\u5047\u8bbe\u5728\u5b9e\u8df5\u4e2d\u53ef\u80fd\u4e0d\u6210\u7acb\u3002\u9700\u8981\u7814\u7a76\u5e38\u89c1\u7279\u5f81\u5316\u65b9\u6cd5\uff08\u5982\u7a00\u758f\u81ea\u7f16\u7801\u5668\u548c\u7a00\u758f\u63a2\u9488\uff09\u662f\u5426\u80fd\u5728\u6982\u5ff5\u76f8\u5173\u7684\u60c5\u51b5\u4e0b\u6062\u590d\u89e3\u8026\u7684\u6982\u5ff5\u8868\u793a\u3002", "method": "\u63d0\u51fa\u591a\u6982\u5ff5\u8bc4\u4f30\u6846\u67b6\uff0c\u63a7\u5236\u6587\u672c\u6982\u5ff5\uff08\u5982\u60c5\u611f\u3001\u9886\u57df\u3001\u65f6\u6001\uff09\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u5206\u6790\u5728\u76f8\u5173\u6027\u589e\u5f3a\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u3002\u9996\u5148\u8bc4\u4f30\u7279\u5f81\u5316\u65b9\u6cd5\u5728\u4e0d\u540c\u76f8\u5173\u5f3a\u5ea6\u4e0b\u5b66\u4e60\u89e3\u8026\u6982\u5ff5\u8868\u793a\u7684\u80fd\u529b\uff0c\u7136\u540e\u8fdb\u884c\u64cd\u63a7\u5b9e\u9a8c\uff0c\u6d4b\u91cf\u6bcf\u4e2a\u6982\u5ff5\u662f\u5426\u53ef\u72ec\u7acb\u64cd\u63a7\u3002", "result": "\u53d1\u73b0\u7279\u5f81\u4e0e\u6982\u5ff5\u4e4b\u95f4\u5b58\u5728\u4e00\u5bf9\u591a\u5173\u7cfb\uff1a\u7279\u5f81\u6700\u591a\u5bf9\u5e94\u4e00\u4e2a\u6982\u5ff5\uff0c\u4f46\u6982\u5ff5\u5206\u5e03\u5728\u591a\u4e2a\u7279\u5f81\u4e2d\u3002\u5373\u4f7f\u5728\u5747\u5300\u5206\u5e03\u6982\u5ff5\u4e0a\u8bad\u7ec3\uff0c\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7279\u5f81\u5728\u64cd\u63a7\u65f6\u901a\u5e38\u5f71\u54cd\u591a\u4e2a\u6982\u5ff5\uff0c\u8868\u660e\u5b83\u4eec\u65e2\u4e0d\u5177\u9009\u62e9\u6027\u4e5f\u4e0d\u72ec\u7acb\uff1b\u4f46\u7279\u5f81\u5f71\u54cd\u4e0d\u76f8\u4ea4\u7684\u5b50\u7a7a\u95f4\u3002", "conclusion": "\u76f8\u5173\u6027\u5ea6\u91cf\u901a\u5e38\u4e0d\u8db3\u4ee5\u5728\u64cd\u63a7\u65f6\u5efa\u7acb\u72ec\u7acb\u6027\uff0c\u5f71\u54cd\u4e0d\u76f8\u4ea4\u5b50\u7a7a\u95f4\u4e5f\u4e0d\u8db3\u4ee5\u5b9e\u73b0\u6982\u5ff5\u9009\u62e9\u6027\u3002\u8fd9\u4e9b\u7ed3\u679c\u5f3a\u8c03\u4e86\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u4e2d\u7ec4\u5408\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2512.15140", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15140", "abs": "https://arxiv.org/abs/2512.15140", "authors": ["Roland Baatz"], "title": "Generalization and Feature Attribution in Machine Learning Models for Crop Yield and Anomaly Prediction in Germany", "comment": "13 pages, 3 figures", "summary": "This study examines the generalization performance and interpretability of machine learning (ML) models used for predicting crop yield and yield anomalies in Germany's NUTS-3 regions. Using a high-quality, long-term dataset, the study systematically compares the evaluation and temporal validation behavior of ensemble tree-based models (XGBoost, Random Forest) and deep learning approaches (LSTM, TCN).\n  While all models perform well on spatially split, conventional test sets, their performance degrades substantially on temporally independent validation years, revealing persistent limitations in generalization. Notably, models with strong test-set accuracy, but weak temporal validation performance can still produce seemingly credible SHAP feature importance values. This exposes a critical vulnerability in post hoc explainability methods: interpretability may appear reliable even when the underlying model fails to generalize.\n  These findings underscore the need for validation-aware interpretation of ML predictions in agricultural and environmental systems. Feature importance should not be accepted at face value unless models are explicitly shown to generalize to unseen temporal and spatial conditions. The study advocates for domain-aware validation, hybrid modeling strategies, and more rigorous scrutiny of explainability methods in data-driven agriculture. Ultimately, this work addresses a growing challenge in environmental data science: how can we evaluate generalization robustly enough to trust model explanations?", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5fb7\u56fd\u519c\u4e1a\u4ea7\u91cf\u9884\u6d4b\u4e2d\u7684\u6cdb\u5316\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u65f6\u95f4\u72ec\u7acb\u9a8c\u8bc1\u4e2d\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u5373\u4f7f\u6a21\u578b\u6cdb\u5316\u5931\u8d25\uff0cSHAP\u7279\u5f81\u91cd\u8981\u6027\u4ecd\u53ef\u80fd\u663e\u793a\u53ef\u4fe1\u7ed3\u679c\uff0c\u63ed\u793a\u4e86\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u5728\u519c\u4e1a\u548c\u73af\u5883\u7cfb\u7edf\u4e2d\u9884\u6d4b\u7684\u6cdb\u5316\u80fd\u529b\u95ee\u9898\uff0c\u7279\u522b\u662f\u5f53\u6a21\u578b\u5728\u4f20\u7edf\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u826f\u597d\u4f46\u5728\u65f6\u95f4\u72ec\u7acb\u9a8c\u8bc1\u4e2d\u5931\u8d25\u65f6\uff0c\u5982\u4f55\u4fe1\u4efb\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u7ed3\u679c\u3002", "method": "\u4f7f\u7528\u5fb7\u56fdNUTS-3\u533a\u57df\u7684\u9ad8\u8d28\u91cf\u957f\u671f\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e86\u96c6\u6210\u6811\u6a21\u578b\uff08XGBoost\u3001\u968f\u673a\u68ee\u6797\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff08LSTM\u3001TCN\uff09\u7684\u8bc4\u4f30\u548c\u65f6\u95f4\u9a8c\u8bc1\u884c\u4e3a\uff0c\u91cd\u70b9\u5173\u6ce8SHAP\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u3002", "result": "\u6240\u6709\u6a21\u578b\u5728\u7a7a\u95f4\u5206\u5272\u7684\u4f20\u7edf\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u65f6\u95f4\u72ec\u7acb\u9a8c\u8bc1\u5e74\u4efd\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u51c6\u786e\u4f46\u5728\u65f6\u95f4\u9a8c\u8bc1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4ecd\u80fd\u4ea7\u751f\u770b\u4f3c\u53ef\u4fe1\u7684SHAP\u7279\u5f81\u91cd\u8981\u6027\u503c\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u519c\u4e1a\u548c\u73af\u5883\u7cfb\u7edf\u4e2d\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u9700\u8981\u9a8c\u8bc1\u611f\u77e5\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u7279\u5f81\u91cd\u8981\u6027\u4e0d\u5e94\u88ab\u8868\u9762\u63a5\u53d7\uff0c\u9664\u975e\u6a21\u578b\u660e\u786e\u5c55\u793a\u4e86\u5bf9\u672a\u89c1\u65f6\u7a7a\u6761\u4ef6\u7684\u6cdb\u5316\u80fd\u529b\u3002\u63d0\u5021\u9886\u57df\u611f\u77e5\u9a8c\u8bc1\u3001\u6df7\u5408\u5efa\u6a21\u7b56\u7565\u4ee5\u53ca\u5bf9\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u66f4\u4e25\u683c\u7684\u5ba1\u67e5\u3002"}}
{"id": "2512.15143", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.15143", "abs": "https://arxiv.org/abs/2512.15143", "authors": ["Pablo Monta\u00f1a-Fern\u00e1ndez", "Ines Ortega-Fernandez"], "title": "An Efficient Gradient-Based Inference Attack for Federated Learning", "comment": "This paper was supported by the TRUMPET project, funded by the European Union under Grant Agreement No. 101070038", "summary": "Federated Learning is a machine learning setting that reduces direct data exposure, improving the privacy guarantees of machine learning models. Yet, the exchange of model updates between the participants and the aggregator can still leak sensitive information. In this work, we present a new gradient-based membership inference attack for federated learning scenarios that exploits the temporal evolution of last-layer gradients across multiple federated rounds. Our method uses the shadow technique to learn round-wise gradient patterns of the training records, requiring no access to the private dataset, and is designed to consider both semi-honest and malicious adversaries (aggregators or data owners). Beyond membership inference, we also provide a natural extension of the proposed attack to discrete attribute inference by contrasting gradient responses under alternative attribute hypotheses. The proposed attacks are model-agnostic, and therefore applicable to any gradient-based model and can be applied to both classification and regression settings. We evaluate the attack on CIFAR-100 and Purchase100 datasets for membership inference and on Breast Cancer Wisconsin for attribute inference. Our findings reveal strong attack performance and comparable computational and memory overhead in membership inference when compared to another attack from the literature. The obtained results emphasize that multi-round federated learning can increase the vulnerability to inference attacks, that aggregators pose a more substantial threat than data owners, and that attack performance is strongly influenced by the nature of the training dataset, with richer, high-dimensional data leading to stronger leakage than simpler tabular data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u68af\u5ea6\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u8f6e\u8bad\u7ec3\u4e2d\u6700\u540e\u4e00\u5c42\u68af\u5ea6\u7684\u65f6\u5e8f\u6f14\u5316\u6a21\u5f0f\uff0c\u65e0\u9700\u8bbf\u95ee\u79c1\u6709\u6570\u636e\u96c6\uff0c\u9002\u7528\u4e8e\u534a\u8bda\u5b9e\u548c\u6076\u610f\u653b\u51fb\u8005\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u5c5e\u6027\u63a8\u7406\u653b\u51fb\u3002", "motivation": "\u5c3d\u7ba1\u8054\u90a6\u5b66\u4e60\u51cf\u5c11\u4e86\u76f4\u63a5\u6570\u636e\u66b4\u9732\uff0c\u4f46\u53c2\u4e0e\u8005\u4e0e\u805a\u5408\u5668\u4e4b\u95f4\u4ea4\u6362\u7684\u6a21\u578b\u66f4\u65b0\u4ecd\u53ef\u80fd\u6cc4\u9732\u654f\u611f\u4fe1\u606f\u3002\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u591a\u8f6e\u8054\u90a6\u5b66\u4e60\u9690\u79c1\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5f71\u5b50\u6280\u672f\u5b66\u4e60\u8bad\u7ec3\u8bb0\u5f55\u7684\u591a\u8f6e\u68af\u5ea6\u6a21\u5f0f\uff0c\u901a\u8fc7\u5206\u6790\u591a\u8f6e\u8054\u90a6\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u6700\u540e\u4e00\u5c42\u68af\u5ea6\u7684\u65f6\u5e8f\u6f14\u5316\u6765\u6267\u884c\u6210\u5458\u63a8\u7406\u653b\u51fb\u3002\u8be5\u65b9\u6cd5\u6a21\u578b\u65e0\u5173\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u57fa\u4e8e\u68af\u5ea6\u7684\u6a21\u578b\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u3002\u8fd8\u63d0\u51fa\u4e86\u901a\u8fc7\u5bf9\u6bd4\u4e0d\u540c\u5c5e\u6027\u5047\u8bbe\u4e0b\u7684\u68af\u5ea6\u54cd\u5e94\u6765\u6267\u884c\u79bb\u6563\u5c5e\u6027\u63a8\u7406\u7684\u81ea\u7136\u6269\u5c55\u3002", "result": "\u5728CIFAR-100\u548cPurchase100\u6570\u636e\u96c6\u4e0a\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u4e0e\u6587\u732e\u4e2d\u5176\u4ed6\u653b\u51fb\u76f8\u6bd4\u5177\u6709\u53ef\u6bd4\u8f83\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u3002\u5728Breast Cancer Wisconsin\u6570\u636e\u96c6\u4e0a\u7684\u5c5e\u6027\u63a8\u7406\u653b\u51fb\u4e5f\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u7ed3\u679c\u8868\u660e\u591a\u8f6e\u8054\u90a6\u5b66\u4e60\u589e\u52a0\u4e86\u63a8\u7406\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u805a\u5408\u5668\u6bd4\u6570\u636e\u6240\u6709\u8005\u6784\u6210\u66f4\u5927\u5a01\u80c1\uff0c\u4e14\u653b\u51fb\u6027\u80fd\u53d7\u8bad\u7ec3\u6570\u636e\u96c6\u6027\u8d28\u5f71\u54cd\uff0c\u9ad8\u7ef4\u6570\u636e\u6bd4\u7b80\u5355\u8868\u683c\u6570\u636e\u5bfc\u81f4\u66f4\u5f3a\u7684\u4fe1\u606f\u6cc4\u9732\u3002", "conclusion": "\u591a\u8f6e\u8054\u90a6\u5b66\u4e60\u53ef\u80fd\u589e\u52a0\u9690\u79c1\u98ce\u9669\uff0c\u63d0\u51fa\u7684\u68af\u5ea6\u65f6\u5e8f\u6f14\u5316\u653b\u51fb\u65b9\u6cd5\u5728\u6210\u5458\u63a8\u7406\u548c\u5c5e\u6027\u63a8\u7406\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u5f3a\u5927\u6027\u80fd\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u66f4\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u6765\u9632\u5fa1\u6b64\u7c7b\u65f6\u5e8f\u68af\u5ea6\u653b\u51fb\u3002"}}
{"id": "2512.15169", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15169", "abs": "https://arxiv.org/abs/2512.15169", "authors": ["Chengguang Ou", "Yixin Zhuang"], "title": "Understanding NTK Variance in Implicit Neural Representations", "comment": null, "summary": "Implicit Neural Representations (INRs) often converge slowly and struggle to recover high-frequency details due to spectral bias. While prior work links this behavior to the Neural Tangent Kernel (NTK), how specific architectural choices affect NTK conditioning remains unclear. We show that many INR mechanisms can be understood through their impact on a small set of pairwise similarity factors and scaling terms that jointly determine NTK eigenvalue variance. For standard coordinate MLPs, limited input-feature interactions induce large eigenvalue dispersion and poor conditioning. We derive closed-form variance decompositions for common INR components and show that positional encoding reshapes input similarity, spherical normalization reduces variance via layerwise scaling, and Hadamard modulation introduces additional similarity factors strictly below one, yielding multiplicative variance reduction. This unified view explains how diverse INR architectures mitigate spectral bias by improving NTK conditioning. Experiments across multiple tasks confirm the predicted variance reductions and demonstrate faster, more stable convergence with improved reconstruction quality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INRs\uff09\u7684\u8c31\u504f\u5dee\u95ee\u9898\uff0c\u901a\u8fc7\u795e\u7ecf\u6b63\u5207\u6838\uff08NTK\uff09\u7406\u8bba\u89e3\u91ca\u4e86\u4e0d\u540c\u67b6\u6784\u9009\u62e9\u5982\u4f55\u5f71\u54cdNTK\u6761\u4ef6\u6570\uff0c\u5e76\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\u7406\u89e3\u5404\u79cdINR\u673a\u5236\u5982\u4f55\u6539\u5584\u8c31\u504f\u5dee\u3002", "motivation": "\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INRs\uff09\u901a\u5e38\u6536\u655b\u7f13\u6162\u4e14\u96be\u4ee5\u6062\u590d\u9ad8\u9891\u7ec6\u8282\uff0c\u8fd9\u5f52\u56e0\u4e8e\u8c31\u504f\u5dee\u3002\u867d\u7136\u5148\u524d\u5de5\u4f5c\u5c06\u5176\u4e0e\u795e\u7ecf\u6b63\u5207\u6838\uff08NTK\uff09\u8054\u7cfb\u8d77\u6765\uff0c\u4f46\u5177\u4f53\u67b6\u6784\u9009\u62e9\u5982\u4f55\u5f71\u54cdNTK\u6761\u4ef6\u6570\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u4f5c\u8005\u8868\u660e\u8bb8\u591aINR\u673a\u5236\u53ef\u4ee5\u901a\u8fc7\u5b83\u4eec\u5bf9\u5c11\u91cf\u6210\u5bf9\u76f8\u4f3c\u6027\u56e0\u5b50\u548c\u7f29\u653e\u9879\u7684\u5f71\u54cd\u6765\u7406\u89e3\uff0c\u8fd9\u4e9b\u56e0\u5b50\u5171\u540c\u51b3\u5b9aNTK\u7279\u5f81\u503c\u65b9\u5dee\u3002\u63a8\u5bfc\u4e86\u5e38\u89c1INR\u7ec4\u4ef6\u7684\u95ed\u5f0f\u65b9\u5dee\u5206\u89e3\uff0c\u5206\u6790\u4e86\u4f4d\u7f6e\u7f16\u7801\u3001\u7403\u9762\u5f52\u4e00\u5316\u548cHadamard\u8c03\u5236\u7b49\u673a\u5236\u5982\u4f55\u5f71\u54cdNTK\u6761\u4ef6\u6570\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u9884\u6d4b\u7684\u65b9\u5dee\u51cf\u5c11\uff0c\u5e76\u5c55\u793a\u4e86\u66f4\u5feb\u901f\u3001\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u4ee5\u53ca\u6539\u8fdb\u7684\u91cd\u5efa\u8d28\u91cf\u3002\u5177\u4f53\u6765\u8bf4\uff1a\u6807\u51c6\u5750\u6807MLP\u6709\u9650\u7684\u8f93\u5165\u7279\u5f81\u4ea4\u4e92\u5bfc\u81f4\u5927\u7684\u7279\u5f81\u503c\u79bb\u6563\u548c\u4e0d\u826f\u6761\u4ef6\u6570\uff1b\u4f4d\u7f6e\u7f16\u7801\u91cd\u5851\u8f93\u5165\u76f8\u4f3c\u6027\uff1b\u7403\u9762\u5f52\u4e00\u5316\u901a\u8fc7\u9010\u5c42\u7f29\u653e\u51cf\u5c11\u65b9\u5dee\uff1bHadamard\u8c03\u5236\u5f15\u5165\u4e25\u683c\u5c0f\u4e8e1\u7684\u989d\u5916\u76f8\u4f3c\u6027\u56e0\u5b50\uff0c\u4ea7\u751f\u4e58\u6cd5\u65b9\u5dee\u51cf\u5c11\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u89c6\u89d2\uff0c\u89e3\u91ca\u4e86\u591a\u6837\u5316\u7684INR\u67b6\u6784\u5982\u4f55\u901a\u8fc7\u6539\u5584NTK\u6761\u4ef6\u6570\u6765\u7f13\u89e3\u8c31\u504f\u5dee\u95ee\u9898\uff0c\u4e3a\u7406\u89e3INR\u673a\u5236\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2512.15250", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15250", "abs": "https://arxiv.org/abs/2512.15250", "authors": ["Youssef Ghallab", "Omar Iraqy", "Mohamed Kandil", "Mohamed Ashraf", "Saadeldine Eletter", "Morougue Ghazal", "Ayman Khalafallah", "Nagwa El-Makky"], "title": "Leveraging Foundational Models and Simple Fusion for Multi-modal Physiological Signal Analysis", "comment": "Published at NeurIPS 2025 Workshop on Foundation Models for the Brain and Body", "summary": "Physiological signals such as electrocardiograms (ECG) and electroencephalograms (EEG) provide complementary insights into human health and cognition, yet multi-modal integration is challenging due to limited multi-modal labeled data, and modality-specific differences . In this work, we adapt the CBraMod encoder for large-scale self-supervised ECG pretraining, introducing a dual-masking strategy to capture intra- and inter-lead dependencies. To overcome the above challenges, we utilize a pre-trained CBraMod encoder for EEG and pre-train a symmetric ECG encoder, equipping each modality with a rich foundational representation. These representations are then fused via simple embedding concatenation, allowing the classification head to learn cross-modal interactions, together enabling effective downstream learning despite limited multi-modal supervision. Evaluated on emotion recognition, our approach achieves near state-of-the-art performance, demonstrating that carefully designed physiological encoders, even with straightforward fusion, substantially improve downstream performance. These results highlight the potential of foundation-model approaches to harness the holistic nature of physiological signals, enabling scalable, label-efficient, and generalizable solutions for healthcare and affective computing.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u878d\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u7684ECG\u7f16\u7801\u5668\u548c\u9884\u8bad\u7ec3\u7684EEG\u7f16\u7801\u5668\uff0c\u7ed3\u5408\u7b80\u5355\u7684\u5d4c\u5165\u62fc\u63a5\u878d\u5408\u7b56\u7565\uff0c\u5728\u6709\u9650\u591a\u6a21\u6001\u6807\u6ce8\u6570\u636e\u4e0b\u5b9e\u73b0\u6709\u6548\u7684\u60c5\u7eea\u8bc6\u522b\u3002", "motivation": "\u5fc3\u7535\u56fe\uff08ECG\uff09\u548c\u8111\u7535\u56fe\uff08EEG\uff09\u7b49\u751f\u7406\u4fe1\u53f7\u80fd\u63d0\u4f9b\u5173\u4e8e\u4eba\u7c7b\u5065\u5eb7\u548c\u8ba4\u77e5\u7684\u4e92\u8865\u4fe1\u606f\uff0c\u4f46\u591a\u6a21\u6001\u878d\u5408\u9762\u4e34\u6311\u6218\uff1a\u591a\u6a21\u6001\u6807\u6ce8\u6570\u636e\u6709\u9650\uff0c\u4e14\u4e0d\u540c\u6a21\u6001\u4e4b\u95f4\u5b58\u5728\u7279\u5f02\u6027\u5dee\u5f02\u3002", "method": "1. \u91c7\u7528CBraMod\u7f16\u7801\u5668\u8fdb\u884c\u5927\u89c4\u6a21\u81ea\u76d1\u7763ECG\u9884\u8bad\u7ec3\uff0c\u5f15\u5165\u53cc\u63a9\u7801\u7b56\u7565\u6355\u6349\u5fc3\u7535\u4fe1\u53f7\u5185\u90e8\u548c\u5bfc\u8054\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff1b2. \u4f7f\u7528\u9884\u8bad\u7ec3\u7684CBraMod\u7f16\u7801\u5668\u5904\u7406EEG\u4fe1\u53f7\uff1b3. \u901a\u8fc7\u7b80\u5355\u7684\u5d4c\u5165\u62fc\u63a5\u878d\u5408\u4e24\u79cd\u6a21\u6001\u7684\u8868\u793a\uff0c\u8ba9\u5206\u7c7b\u5934\u5b66\u4e60\u8de8\u6a21\u6001\u4ea4\u4e92\u3002", "result": "\u5728\u60c5\u7eea\u8bc6\u522b\u4efb\u52a1\u4e0a\uff0c\u8be5\u65b9\u6cd5\u8fbe\u5230\u4e86\u63a5\u8fd1\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8868\u660e\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u751f\u7406\u4fe1\u53f7\u7f16\u7801\u5668\u5373\u4f7f\u91c7\u7528\u7b80\u5355\u7684\u878d\u5408\u7b56\u7565\uff0c\u4e5f\u80fd\u663e\u8457\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u65b9\u6cd5\u80fd\u591f\u5145\u5206\u5229\u7528\u751f\u7406\u4fe1\u53f7\u7684\u6574\u4f53\u7279\u6027\uff0c\u4e3a\u533b\u7597\u4fdd\u5065\u548c\u60c5\u611f\u8ba1\u7b97\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u6807\u7b7e\u9ad8\u6548\u4e14\u53ef\u6cdb\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.15206", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15206", "abs": "https://arxiv.org/abs/2512.15206", "authors": ["Liyu Zhang", "Yejia Liu", "Kwun Ho Liu", "Runxi Huang", "Xiaomin Ouyang"], "title": "Chorus: Harmonizing Context and Sensing Signals for Data-Free Model Customization in IoT", "comment": null, "summary": "In real-world IoT applications, sensor data is usually collected under diverse and dynamic contextual conditions where factors such as sensor placements or ambient environments can significantly affect data patterns and downstream performance. Traditional domain adaptation or generalization methods often ignore such context information or use simplistic integration strategies, making them ineffective in handling unseen context shifts after deployment. In this paper, we propose Chorus, a context-aware, data-free model customization approach that adapts models to unseen deployment conditions without requiring target-domain data. The key idea is to learn effective context representations that capture their influence on sensor data patterns and to adaptively integrate them based on the degree of context shift. Specifically, Chorus first performs unsupervised cross-modal reconstruction between unlabeled sensor data and language-based context embeddings, while regularizing the context embedding space to learn robust, generalizable context representations. Then, it trains a lightweight gated head on limited labeled samples to dynamically balance sensor and context contributions-favoring context when sensor evidence is ambiguous and vice versa. To further reduce inference latency, Chorus employs a context-caching mechanism that reuses cached context representations and updates only upon detected context shifts. Experiments on IMU, speech, and WiFi sensing tasks under diverse context shifts show that Chorus outperforms state-of-the-art baselines by up to 11.3% in unseen contexts, while maintaining comparable latency on smartphone and edge devices.", "AI": {"tldr": "Chorus\u662f\u4e00\u79cd\u9762\u5411\u7269\u8054\u7f51\u5e94\u7528\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u65e0\u6570\u636e\u6a21\u578b\u5b9a\u5236\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u65e0\u9700\u76ee\u6807\u57df\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u9002\u5e94\u672a\u89c1\u8fc7\u7684\u90e8\u7f72\u6761\u4ef6\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u91cd\u5efa\u5b66\u4e60\u4e0a\u4e0b\u6587\u8868\u793a\uff0c\u5e76\u52a8\u6001\u5e73\u8861\u4f20\u611f\u5668\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u8d21\u732e\u3002", "motivation": "\u73b0\u5b9e\u7269\u8054\u7f51\u5e94\u7528\u4e2d\uff0c\u4f20\u611f\u5668\u6570\u636e\u901a\u5e38\u5728\u591a\u6837\u5316\u548c\u52a8\u6001\u7684\u4e0a\u4e0b\u6587\u6761\u4ef6\u4e0b\u6536\u96c6\uff0c\u4f20\u611f\u5668\u653e\u7f6e\u4f4d\u7f6e\u6216\u73af\u5883\u56e0\u7d20\u4f1a\u663e\u8457\u5f71\u54cd\u6570\u636e\u6a21\u5f0f\u548c\u4e0b\u6e38\u6027\u80fd\u3002\u4f20\u7edf\u57df\u9002\u5e94\u6216\u6cdb\u5316\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u4e0a\u4e0b\u6587\u4fe1\u606f\u6216\u4f7f\u7528\u7b80\u5355\u96c6\u6210\u7b56\u7565\uff0c\u5bfc\u81f4\u5728\u90e8\u7f72\u540e\u5904\u7406\u672a\u89c1\u4e0a\u4e0b\u6587\u53d8\u5316\u65f6\u6548\u679c\u4e0d\u4f73\u3002", "method": "Chorus\u9996\u5148\u5728\u672a\u6807\u8bb0\u4f20\u611f\u5668\u6570\u636e\u548c\u57fa\u4e8e\u8bed\u8a00\u7684\u4e0a\u4e0b\u6587\u5d4c\u5165\u4e4b\u95f4\u6267\u884c\u65e0\u76d1\u7763\u8de8\u6a21\u6001\u91cd\u5efa\uff0c\u540c\u65f6\u6b63\u5219\u5316\u4e0a\u4e0b\u6587\u5d4c\u5165\u7a7a\u95f4\u4ee5\u5b66\u4e60\u9c81\u68d2\u3001\u53ef\u6cdb\u5316\u7684\u4e0a\u4e0b\u6587\u8868\u793a\u3002\u7136\u540e\uff0c\u5728\u6709\u9650\u6807\u8bb0\u6837\u672c\u4e0a\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u95e8\u63a7\u5934\uff0c\u52a8\u6001\u5e73\u8861\u4f20\u611f\u5668\u548c\u4e0a\u4e0b\u6587\u7684\u8d21\u732e\u2014\u2014\u5f53\u4f20\u611f\u5668\u8bc1\u636e\u6a21\u7cca\u65f6\u504f\u5411\u4e0a\u4e0b\u6587\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\u4e3a\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf\uff0c\u91c7\u7528\u4e0a\u4e0b\u6587\u7f13\u5b58\u673a\u5236\uff0c\u91cd\u7528\u7f13\u5b58\u7684\u4e0a\u4e0b\u6587\u8868\u793a\uff0c\u4ec5\u5728\u68c0\u6d4b\u5230\u4e0a\u4e0b\u6587\u53d8\u5316\u65f6\u66f4\u65b0\u3002", "result": "\u5728IMU\u3001\u8bed\u97f3\u548cWiFi\u611f\u77e5\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cChorus\u5728\u672a\u89c1\u4e0a\u4e0b\u6587\u6761\u4ef6\u4e0b\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe11.3%\uff0c\u540c\u65f6\u5728\u667a\u80fd\u624b\u673a\u548c\u8fb9\u7f18\u8bbe\u5907\u4e0a\u4fdd\u6301\u53ef\u6bd4\u7684\u5ef6\u8fdf\u3002", "conclusion": "Chorus\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u65e0\u6570\u636e\u6a21\u578b\u5b9a\u5236\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7269\u8054\u7f51\u5e94\u7528\u4e2d\u52a8\u6001\u4e0a\u4e0b\u6587\u53d8\u5316\u5e26\u6765\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u5728\u672a\u89c1\u90e8\u7f72\u6761\u4ef6\u4e0b\u7684\u9ad8\u6027\u80fd\u9002\u5e94\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2512.15229", "categories": ["cs.LG", "cs.SD", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15229", "abs": "https://arxiv.org/abs/2512.15229", "authors": ["Elio Gruttadauria", "Mathieu Fontaine", "Jonathan Le Roux", "Slim Essid"], "title": "O-EENC-SD: Efficient Online End-to-End Neural Clustering for Speaker Diarization", "comment": null, "summary": "We introduce O-EENC-SD: an end-to-end online speaker diarization system based on EEND-EDA, featuring a novel RNN-based stitching mechanism for online prediction. In particular, we develop a novel centroid refinement decoder whose usefulness is assessed through a rigorous ablation study. Our system provides key advantages over existing methods: a hyperparameter-free solution compared to unsupervised clustering approaches, and a more efficient alternative to current online end-to-end methods, which are computationally costly. We demonstrate that O-EENC-SD is competitive with the state of the art in the two-speaker conversational telephone speech domain, as tested on the CallHome dataset. Our results show that O-EENC-SD provides a great trade-off between DER and complexity, even when working on independent chunks with no overlap, making the system extremely efficient.", "AI": {"tldr": "O-EENC-SD\u662f\u4e00\u79cd\u57fa\u4e8eEEND-EDA\u7684\u7aef\u5230\u7aef\u5728\u7ebf\u8bf4\u8bdd\u4eba\u65e5\u5fd7\u7cfb\u7edf\uff0c\u91c7\u7528RNN\u62fc\u63a5\u673a\u5236\u548c\u8d28\u5fc3\u7ec6\u5316\u89e3\u7801\u5668\uff0c\u5728\u53cc\u4eba\u7535\u8bdd\u5bf9\u8bdd\u573a\u666f\u4e2d\u4e0eSOTA\u7ade\u4e89\uff0c\u5728DER\u548c\u590d\u6742\u5ea6\u4e4b\u95f4\u63d0\u4f9b\u826f\u597d\u5e73\u8861\u3002", "motivation": "\u73b0\u6709\u5728\u7ebf\u7aef\u5230\u7aef\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u800c\u65e0\u76d1\u7763\u805a\u7c7b\u65b9\u6cd5\u9700\u8981\u8d85\u53c2\u6570\u8c03\u6574\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u65e0\u9700\u8d85\u53c2\u6570\u8c03\u6574\u7684\u5728\u7ebf\u8bf4\u8bdd\u4eba\u65e5\u5fd7\u7cfb\u7edf\u3002", "method": "\u57fa\u4e8eEEND-EDA\u6846\u67b6\uff0c\u5f15\u5165RNN\u62fc\u63a5\u673a\u5236\u5904\u7406\u5728\u7ebf\u9884\u6d4b\uff0c\u5f00\u53d1\u8d28\u5fc3\u7ec6\u5316\u89e3\u7801\u5668\uff0c\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002\u7cfb\u7edf\u5728\u72ec\u7acb\u5757\u4e0a\u5de5\u4f5c\uff0c\u65e0\u91cd\u53e0\uff0c\u5b9e\u73b0\u9ad8\u6548\u5904\u7406\u3002", "result": "\u5728CallHome\u6570\u636e\u96c6\u7684\u53cc\u4eba\u7535\u8bdd\u5bf9\u8bdd\u6d4b\u8bd5\u4e2d\uff0cO-EENC-SD\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u7ade\u4e89\uff0c\u5728DER\u548c\u590d\u6742\u5ea6\u4e4b\u95f4\u63d0\u4f9b\u826f\u597d\u5e73\u8861\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u91cd\u53e0\u7684\u72ec\u7acb\u5757\u4e0a\u5de5\u4f5c\u4e5f\u80fd\u4fdd\u6301\u9ad8\u6548\u3002", "conclusion": "O-EENC-SD\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u8d85\u53c2\u6570\u8c03\u6574\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u5728\u7ebf\u8bf4\u8bdd\u4eba\u65e5\u5fd7\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u53cc\u4eba\u7535\u8bdd\u5bf9\u8bdd\u9886\u57df\u5177\u6709\u7ade\u4e89\u529b\uff0c\u662f\u73b0\u6709\u65b9\u6cd5\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2512.15344", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15344", "abs": "https://arxiv.org/abs/2512.15344", "authors": ["Hiroyoshi Nagahama", "Katsufumi Inoue", "Masayoshi Todorokihara", "Michifumi Yoshioka"], "title": "Empirical Investigation of the Impact of Phase Information on Fault Diagnosis of Rotating Machinery", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Predictive maintenance of rotating machinery increasingly relies on vibration signals, yet most learning-based approaches either discard phase during spectral feature extraction or use raw time-waveforms without explicitly leveraging phase information. This paper introduces two phase-aware preprocessing strategies to address random phase variations in multi-axis vibration data: (1) three-axis independent phase adjustment that aligns each axis individually to zero phase (2) single-axis reference phase adjustment that preserves inter-axis relationships by applying uniform time shifts. Using a newly constructed rotor dataset acquired with a synchronized three-axis sensor, we evaluate six deep learning architectures under a two-stage learning framework. Results demonstrate architecture-independent improvements: the three-axis independent method achieves consistent gains (+2.7\\% for Transformer), while the single-axis reference approach delivers superior performance with up to 96.2\\% accuracy (+5.4\\%) by preserving spatial phase relationships. These findings establish both phase alignment strategies as practical and scalable enhancements for predictive maintenance systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u76f8\u4f4d\u611f\u77e5\u9884\u5904\u7406\u7b56\u7565\u6765\u6539\u5584\u65cb\u8f6c\u673a\u68b0\u632f\u52a8\u4fe1\u53f7\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\uff0c\u901a\u8fc7\u76f8\u4f4d\u5bf9\u9f50\u5904\u7406\u968f\u673a\u76f8\u4f4d\u53d8\u5316\uff0c\u5728\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u4e0a\u83b7\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5b66\u4e60\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u65b9\u6cd5\u8981\u4e48\u5728\u9891\u8c31\u7279\u5f81\u63d0\u53d6\u65f6\u4e22\u5f03\u76f8\u4f4d\u4fe1\u606f\uff0c\u8981\u4e48\u4f7f\u7528\u539f\u59cb\u65f6\u57df\u6ce2\u5f62\u800c\u4e0d\u663e\u5f0f\u5229\u7528\u76f8\u4f4d\u4fe1\u606f\u3002\u591a\u8f74\u632f\u52a8\u6570\u636e\u4e2d\u7684\u968f\u673a\u76f8\u4f4d\u53d8\u5316\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff0c\u9700\u8981\u6709\u6548\u7684\u76f8\u4f4d\u9884\u5904\u7406\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u76f8\u4f4d\u611f\u77e5\u9884\u5904\u7406\u7b56\u7565\uff1a1\uff09\u4e09\u8f74\u72ec\u7acb\u76f8\u4f4d\u8c03\u6574\uff0c\u5c06\u6bcf\u4e2a\u8f74\u5355\u72ec\u5bf9\u9f50\u5230\u96f6\u76f8\u4f4d\uff1b2\uff09\u5355\u8f74\u53c2\u8003\u76f8\u4f4d\u8c03\u6574\uff0c\u901a\u8fc7\u7edf\u4e00\u65f6\u95f4\u504f\u79fb\u4fdd\u6301\u8f74\u95f4\u76f8\u4f4d\u5173\u7cfb\u3002\u4f7f\u7528\u65b0\u6784\u5efa\u7684\u540c\u6b65\u4e09\u8f74\u4f20\u611f\u5668\u8f6c\u5b50\u6570\u636e\u96c6\uff0c\u5728\u4e24\u7ea7\u5b66\u4e60\u6846\u67b6\u4e0b\u8bc4\u4f30\u516d\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u3002", "result": "\u4e24\u79cd\u7b56\u7565\u5747\u5e26\u6765\u67b6\u6784\u65e0\u5173\u7684\u6027\u80fd\u63d0\u5347\uff1a\u4e09\u8f74\u72ec\u7acb\u65b9\u6cd5\u83b7\u5f97\u4e00\u81f4\u589e\u76ca\uff08Transformer\u63d0\u53472.7%\uff09\uff1b\u5355\u8f74\u53c2\u8003\u65b9\u6cd5\u901a\u8fc7\u4fdd\u6301\u7a7a\u95f4\u76f8\u4f4d\u5173\u7cfb\u5b9e\u73b0\u66f4\u4f18\u6027\u80fd\uff0c\u6700\u9ad8\u8fbe96.2%\u51c6\u786e\u7387\uff08\u63d0\u53475.4%\uff09\u3002", "conclusion": "\u4e24\u79cd\u76f8\u4f4d\u5bf9\u9f50\u7b56\u7565\u88ab\u8bc1\u660e\u662f\u9884\u6d4b\u6027\u7ef4\u62a4\u7cfb\u7edf\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u589e\u5f3a\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u5904\u7406\u632f\u52a8\u4fe1\u53f7\u4e2d\u7684\u968f\u673a\u76f8\u4f4d\u53d8\u5316\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2512.15439", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15439", "abs": "https://arxiv.org/abs/2512.15439", "authors": ["Akihiro Kubo", "Paavo Parmas", "Shin Ishii"], "title": "Double Horizon Model-Based Policy Optimization", "comment": "Accepted to Transactions on Machine Learning Research (TMLR) Code available at https://github.com/4kubo/erl_lib", "summary": "Model-based reinforcement learning (MBRL) reduces the cost of real-environment sampling by generating synthetic trajectories (called rollouts) from a learned dynamics model. However, choosing the length of the rollouts poses two dilemmas: (1) Longer rollouts better preserve on-policy training but amplify model bias, indicating the need for an intermediate horizon to mitigate distribution shift (i.e., the gap between on-policy and past off-policy samples). (2) Moreover, a longer model rollout may reduce value estimation bias but raise the variance of policy gradients due to backpropagation through multiple steps, implying another intermediate horizon for stable gradient estimates. However, these two optimal horizons may differ. To resolve this conflict, we propose Double Horizon Model-Based Policy Optimization (DHMBPO), which divides the rollout procedure into a long \"distribution rollout\" (DR) and a short \"training rollout\" (TR). The DR generates on-policy state samples for mitigating distribution shift. In contrast, the short TR leverages differentiable transitions to offer accurate value gradient estimation with stable gradient updates, thereby requiring fewer updates and reducing overall runtime. We demonstrate that the double-horizon approach effectively balances distribution shift, model bias, and gradient instability, and surpasses existing MBRL methods on continuous-control benchmarks in terms of both sample efficiency and runtime.", "AI": {"tldr": "DHMBPO\u63d0\u51fa\u53cc\u89c6\u91ce\u6a21\u578b\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u957f\u5206\u5e03\u89c6\u91ce\u548c\u77ed\u8bad\u7ec3\u89c6\u91ce\u89e3\u51b3MBRL\u4e2d\u89c6\u91ce\u9009\u62e9\u7684\u4e24\u4e2a\u56f0\u5883\uff0c\u5e73\u8861\u5206\u5e03\u504f\u79fb\u3001\u6a21\u578b\u504f\u5dee\u548c\u68af\u5ea6\u7a33\u5b9a\u6027\u3002", "motivation": "\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u89c6\u91ce\u957f\u5ea6\u9009\u62e9\u9762\u4e34\u4e24\u4e2a\u56f0\u5883\uff1a\u957f\u89c6\u91ce\u80fd\u66f4\u597d\u5730\u4fdd\u6301\u540c\u7b56\u7565\u8bad\u7ec3\u4f46\u4f1a\u653e\u5927\u6a21\u578b\u504f\u5dee\uff1b\u957f\u89c6\u91ce\u53ef\u80fd\u51cf\u5c11\u4ef7\u503c\u4f30\u8ba1\u504f\u5dee\u4f46\u4f1a\u589e\u52a0\u7b56\u7565\u68af\u5ea6\u65b9\u5dee\u3002\u8fd9\u4e24\u4e2a\u6700\u4f18\u89c6\u91ce\u53ef\u80fd\u4e0d\u540c\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u51b2\u7a81\u3002", "method": "\u63d0\u51fa\u53cc\u89c6\u91ce\u6a21\u578b\u7b56\u7565\u4f18\u5316\uff08DHMBPO\uff09\uff0c\u5c06\u89c6\u91ce\u8fc7\u7a0b\u5206\u4e3a\u957f\"\u5206\u5e03\u89c6\u91ce\"\uff08DR\uff09\u548c\u77ed\"\u8bad\u7ec3\u89c6\u91ce\"\uff08TR\uff09\u3002DR\u751f\u6210\u540c\u7b56\u7565\u72b6\u6001\u6837\u672c\u6765\u7f13\u89e3\u5206\u5e03\u504f\u79fb\uff0c\u800c\u77edTR\u5229\u7528\u53ef\u5fae\u5206\u8f6c\u79fb\u63d0\u4f9b\u51c6\u786e\u7684\u4ef7\u503c\u68af\u5ea6\u4f30\u8ba1\u548c\u7a33\u5b9a\u7684\u68af\u5ea6\u66f4\u65b0\u3002", "result": "\u53cc\u89c6\u91ce\u65b9\u6cd5\u6709\u6548\u5e73\u8861\u4e86\u5206\u5e03\u504f\u79fb\u3001\u6a21\u578b\u504f\u5dee\u548c\u68af\u5ea6\u4e0d\u7a33\u5b9a\u6027\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u7684MBRL\u65b9\u6cd5\uff0c\u5728\u6837\u672c\u6548\u7387\u548c\u8fd0\u884c\u65f6\u95f4\u65b9\u9762\u90fd\u6709\u4f18\u52bf\u3002", "conclusion": "DHMBPO\u901a\u8fc7\u5206\u79bb\u5206\u5e03\u89c6\u91ce\u548c\u8bad\u7ec3\u89c6\u91ce\uff0c\u89e3\u51b3\u4e86MBRL\u4e2d\u89c6\u91ce\u9009\u62e9\u7684\u4e24\u4e2a\u56f0\u5883\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u5e73\u8861\uff0c\u4e3a\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u8bad\u7ec3\u6846\u67b6\u3002"}}
{"id": "2512.15285", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.15285", "abs": "https://arxiv.org/abs/2512.15285", "authors": ["Aleksei Shestov", "Anton Klenitskiy", "Daria Denisova", "Amurkhan Dzagkoev", "Daniil Petrovich", "Andrey Savchenko", "Maksim Makarenko"], "title": "Topological Metric for Unsupervised Embedding Quality Evaluation", "comment": null, "summary": "Modern representation learning increasingly relies on unsupervised and self-supervised methods trained on large-scale unlabeled data. While these approaches achieve impressive generalization across tasks and domains, evaluating embedding quality without labels remains an open challenge. In this work, we propose Persistence, a topology-aware metric based on persistent homology that quantifies the geometric structure and topological richness of embedding spaces in a fully unsupervised manner. Unlike metrics that assume linear separability or rely on covariance structure, Persistence captures global and multi-scale organization. Empirical results across diverse domains show that Persistence consistently achieves top-tier correlations with downstream performance, outperforming existing unsupervised metrics and enabling reliable model and hyperparameter selection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6301\u4e45\u540c\u8c03\u7684\u65e0\u76d1\u7763\u5d4c\u5165\u8d28\u91cf\u8bc4\u4f30\u6307\u6807Persistence\uff0c\u80fd\u591f\u91cf\u5316\u5d4c\u5165\u7a7a\u95f4\u7684\u51e0\u4f55\u7ed3\u6784\u548c\u62d3\u6251\u4e30\u5bcc\u5ea6\uff0c\u65e0\u9700\u6807\u7b7e\u5373\u53ef\u8bc4\u4f30\u8868\u793a\u5b66\u4e60\u8d28\u91cf\u3002", "motivation": "\u968f\u7740\u65e0\u76d1\u7763\u548c\u81ea\u76d1\u7763\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u65e0\u6807\u7b7e\u6570\u636e\u4e0a\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5982\u4f55\u5728\u6ca1\u6709\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\u8bc4\u4f30\u5d4c\u5165\u8d28\u91cf\u6210\u4e3a\u4e00\u4e2a\u5f00\u653e\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u7ebf\u6027\u53ef\u5206\u6027\u6216\u4f9d\u8d56\u534f\u65b9\u5dee\u7ed3\u6784\uff0c\u65e0\u6cd5\u6355\u6349\u5d4c\u5165\u7a7a\u95f4\u7684\u5168\u5c40\u548c\u591a\u5c3a\u5ea6\u7ec4\u7ec7\u7279\u5f81\u3002", "method": "\u63d0\u51faPersistence\u6307\u6807\uff0c\u57fa\u4e8e\u6301\u4e45\u540c\u8c03\uff08persistent homology\uff09\u8fd9\u4e00\u62d3\u6251\u5b66\u5de5\u5177\uff0c\u91cf\u5316\u5d4c\u5165\u7a7a\u95f4\u7684\u51e0\u4f55\u7ed3\u6784\u548c\u62d3\u6251\u4e30\u5bcc\u5ea6\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u6355\u6349\u5168\u5c40\u548c\u591a\u5c3a\u5ea6\u7ec4\u7ec7\u7279\u5f81\uff0c\u4e0d\u4f9d\u8d56\u6807\u7b7e\u4fe1\u606f\uff0c\u5b8c\u5168\u65e0\u76d1\u7763\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cPersistence\u6307\u6807\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u5177\u6709\u9876\u7ea7\u76f8\u5173\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u65e0\u76d1\u7763\u8bc4\u4f30\u6307\u6807\uff0c\u80fd\u591f\u53ef\u9760\u5730\u7528\u4e8e\u6a21\u578b\u9009\u62e9\u548c\u8d85\u53c2\u6570\u8c03\u4f18\u3002", "conclusion": "Persistence\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65e0\u76d1\u7763\u5d4c\u5165\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u62d3\u6251\u5b66\u89c6\u89d2\u6355\u6349\u5d4c\u5165\u7a7a\u95f4\u7684\u51e0\u4f55\u7ed3\u6784\u7279\u5f81\uff0c\u4e3a\u8868\u793a\u5b66\u4e60\u6a21\u578b\u7684\u8bc4\u4f30\u548c\u9009\u62e9\u63d0\u4f9b\u4e86\u53ef\u9760\u5de5\u5177\u3002"}}
{"id": "2512.15600", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15600", "abs": "https://arxiv.org/abs/2512.15600", "authors": ["Alexandre Dussolle", "Pietro Li\u00f2"], "title": "How Smoothing is N-simplicial Attention?", "comment": "arXiv preprint", "summary": "Going from pure Multilayer Perceptron (MLP) to a learnable graph message-passing mechanism at each layer has been foundational to state-of-the-art results, despite the computational trade-off (e.g. GATs or Transformers). To go a step further, in this work, we introduce N-simplicial attention, going from pairwise token similarity to higher-order interactions, and adapt it for Rotary Position Embeddings (RoPE). To help manage the increased complexity, we propose a cost-effective simplex selection enabling the model to focus its computation load onto the more task-sensitive interactions. Beyond these core mechanisms, we study how smoothing N-simplicial attention is by deriving a Lipschitz upper-bound and by demonstrating that by itself it also suffers from over-smoothing, despite opening the attention message-passing to higher-order interactions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86N-\u5355\u7eaf\u5f62\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4ece\u4f20\u7edf\u7684\u6210\u5bf9token\u76f8\u4f3c\u5ea6\u6269\u5c55\u5230\u9ad8\u9636\u4ea4\u4e92\uff0c\u5e76\u9002\u914d\u4e86RoPE\u4f4d\u7f6e\u7f16\u7801\uff0c\u540c\u65f6\u8bbe\u8ba1\u4e86\u6210\u672c\u6709\u6548\u7684\u5355\u7eaf\u5f62\u9009\u62e9\u65b9\u6cd5\u6765\u7ba1\u7406\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u6d88\u606f\u4f20\u9012\u7684\u6ce8\u610f\u529b\u673a\u5236\uff08\u5982GAT\u6216Transformer\uff09\u4e3b\u8981\u5173\u6ce8\u6210\u5bf9token\u4ea4\u4e92\uff0c\u4f5c\u8005\u5e0c\u671b\u8fdb\u4e00\u6b65\u63a2\u7d22\u9ad8\u9636\u4ea4\u4e92\u7684\u53ef\u80fd\u6027\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86N-\u5355\u7eaf\u5f62\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5c06\u6ce8\u610f\u529b\u4ece\u6210\u5bf9\u76f8\u4f3c\u5ea6\u6269\u5c55\u5230\u9ad8\u9636\u4ea4\u4e92\uff1b\u9002\u914d\u4e86Rotary Position Embeddings\uff1b\u8bbe\u8ba1\u4e86\u6210\u672c\u6709\u6548\u7684\u5355\u7eaf\u5f62\u9009\u62e9\u65b9\u6cd5\uff0c\u8ba9\u6a21\u578b\u80fd\u805a\u7126\u4e8e\u5bf9\u4efb\u52a1\u66f4\u654f\u611f\u7684\u9ad8\u9636\u4ea4\u4e92\u3002", "result": "\u901a\u8fc7\u63a8\u5bfcLipschitz\u4e0a\u754c\uff0c\u7814\u7a76\u4e86N-\u5355\u7eaf\u5f62\u6ce8\u610f\u529b\u7684\u5e73\u6ed1\u6027\uff1b\u53d1\u73b0\u5c3d\u7ba1\u5f15\u5165\u4e86\u9ad8\u9636\u4ea4\u4e92\uff0c\u8be5\u673a\u5236\u4ecd\u7136\u5b58\u5728\u8fc7\u5e73\u6ed1\u95ee\u9898\u3002", "conclusion": "N-\u5355\u7eaf\u5f62\u6ce8\u610f\u529b\u4e3a\u6ce8\u610f\u529b\u673a\u5236\u63d0\u4f9b\u4e86\u4ece\u6210\u5bf9\u4ea4\u4e92\u5230\u9ad8\u9636\u4ea4\u4e92\u7684\u6269\u5c55\u6846\u67b6\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u89e3\u51b3\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u8fc7\u5e73\u6ed1\u7b49\u6311\u6218\u3002"}}
{"id": "2512.15687", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15687", "abs": "https://arxiv.org/abs/2512.15687", "authors": ["Zhenwen Liang", "Sidi Lu", "Wenhao Yu", "Kishan Panaganti", "Yujun Zhou", "Haitao Mi", "Dong Yu"], "title": "Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning", "comment": null, "summary": "Reinforcement learning has become essential for strengthening the reasoning abilities of large language models, yet current exploration mechanisms remain fundamentally misaligned with how these models actually learn. Entropy bonuses and external semantic comparators encourage surface level variation but offer no guarantee that sampled trajectories differ in the update directions that shape optimization. We propose G2RL, a gradient guided reinforcement learning framework in which exploration is driven not by external heuristics but by the model own first order update geometry. For each response, G2RL constructs a sequence level feature from the model final layer sensitivity, obtainable at negligible cost from a standard forward pass, and measures how each trajectory would reshape the policy by comparing these features within a sampled group. Trajectories that introduce novel gradient directions receive a bounded multiplicative reward scaler, while redundant or off manifold updates are deemphasized, yielding a self referential exploration signal that is naturally aligned with PPO style stability and KL control. Across math and general reasoning benchmarks (MATH500, AMC, AIME24, AIME25, GPQA, MMLUpro) on Qwen3 base 1.7B and 4B models, G2RL consistently improves pass@1, maj@16, and pass@k over entropy based GRPO and external embedding methods. Analyzing the induced geometry, we find that G2RL expands exploration into substantially more orthogonal and often opposing gradient directions while maintaining semantic coherence, revealing that a policy own update space provides a far more faithful and effective basis for guiding exploration in large language model reinforcement learning.", "AI": {"tldr": "G2RL\u662f\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u578b\u81ea\u8eab\u7684\u68af\u5ea6\u66f4\u65b0\u51e0\u4f55\u6765\u9a71\u52a8\u63a2\u7d22\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u5916\u90e8\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22\u673a\u5236\uff08\u5982\u71b5\u5956\u52b1\u548c\u5916\u90e8\u8bed\u4e49\u6bd4\u8f83\u5668\uff09\u4e0e\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9645\u5b66\u4e60\u65b9\u5f0f\u5b58\u5728\u6839\u672c\u6027\u4e0d\u5339\u914d\u3002\u8fd9\u4e9b\u65b9\u6cd5\u9f13\u52b1\u8868\u9762\u53d8\u5316\uff0c\u4f46\u4e0d\u80fd\u4fdd\u8bc1\u91c7\u6837\u8f68\u8ff9\u5728\u4f18\u5316\u65b9\u5411\u4e0a\u7684\u5dee\u5f02\u6027\uff0c\u5bfc\u81f4\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\u3002", "method": "G2RL\u6846\u67b6\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7684\u68af\u5ea6\u66f4\u65b0\u51e0\u4f55\u6765\u6307\u5bfc\u63a2\u7d22\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u54cd\u5e94\uff0c\u4ece\u6a21\u578b\u6700\u540e\u4e00\u5c42\u7684\u654f\u611f\u6027\u6784\u5efa\u5e8f\u5217\u7ea7\u7279\u5f81\uff08\u53ef\u901a\u8fc7\u6807\u51c6\u524d\u5411\u4f20\u64ad\u4f4e\u6210\u672c\u83b7\u5f97\uff09\uff0c\u5728\u91c7\u6837\u7ec4\u5185\u6bd4\u8f83\u8fd9\u4e9b\u7279\u5f81\u4ee5\u8861\u91cf\u6bcf\u4e2a\u8f68\u8ff9\u5982\u4f55\u91cd\u5851\u7b56\u7565\u3002\u5f15\u5165\u65b0\u9896\u68af\u5ea6\u65b9\u5411\u7684\u8f68\u8ff9\u83b7\u5f97\u6709\u754c\u4e58\u6cd5\u5956\u52b1\u7f29\u653e\uff0c\u800c\u5197\u4f59\u6216\u79bb\u6d41\u5f62\u66f4\u65b0\u5219\u88ab\u5f31\u5316\u3002", "result": "\u5728\u6570\u5b66\u548c\u901a\u7528\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08MATH500\u3001AMC\u3001AIME24\u3001AIME25\u3001GPQA\u3001MMLUpro\uff09\u4e0a\uff0c\u4f7f\u7528Qwen3\u57fa\u78401.7B\u548c4B\u6a21\u578b\uff0cG2RL\u5728pass@1\u3001maj@16\u548cpass@k\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u57fa\u4e8e\u71b5\u7684GRPO\u548c\u5916\u90e8\u5d4c\u5165\u65b9\u6cd5\u3002\u5206\u6790\u8868\u660e\uff0cG2RL\u5c06\u63a2\u7d22\u6269\u5c55\u5230\u66f4\u591a\u6b63\u4ea4\u4e14\u901a\u5e38\u76f8\u53cd\u7684\u68af\u5ea6\u65b9\u5411\uff0c\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u8fde\u8d2f\u6027\u3002", "conclusion": "\u7b56\u7565\u81ea\u8eab\u7684\u66f4\u65b0\u7a7a\u95f4\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22\u63d0\u4f9b\u4e86\u66f4\u5fe0\u5b9e\u548c\u6709\u6548\u7684\u57fa\u7840\uff0cG2RL\u901a\u8fc7\u68af\u5ea6\u5f15\u5bfc\u7684\u63a2\u7d22\u673a\u5236\u5b9e\u73b0\u4e86\u4e0ePPO\u98ce\u683c\u7a33\u5b9a\u6027\u548cKL\u63a7\u5236\u81ea\u7136\u5bf9\u9f50\u7684\u81ea\u6211\u53c2\u7167\u63a2\u7d22\u4fe1\u53f7\u3002"}}
{"id": "2512.15378", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.15378", "abs": "https://arxiv.org/abs/2512.15378", "authors": ["Honey Singh Chauhan", "Zahraa S. Abdallah"], "title": "A Regime-Aware Fusion Framework for Time Series Classification", "comment": null, "summary": "Kernel-based methods such as Rocket are among the most effective default approaches for univariate time series classification (TSC), yet they do not perform equally well across all datasets. We revisit the long-standing intuition that different representations capture complementary structure and show that selectively fusing them can yield consistent improvements over Rocket on specific, systematically identifiable kinds of datasets. We introduce Fusion-3 (F3), a lightweight framework that adaptively fuses Rocket, Sax, and Sfa representations. To understand when fusion helps, we cluster UCR datasets into six groups using meta-features capturing series length, spectral structure, roughness, and class imbalance, and treat these clusters as interpretable data-structure regimes. Our analysis shows that fusion typically outperforms strong baselines in regimes with structured variability or rich frequency content, while offering diminishing returns in highly irregular or outlier-heavy settings. To support these findings, we combine three complementary analyses: non-parametric paired statistics across datasets, ablation studies isolating the roles of individual representations, and attribution via SHAP to identify which dataset properties predict fusion gains. Sample-level case studies further reveal the underlying mechanism: fusion primarily improves performance by rescuing specific errors, with adaptive increases in frequency-domain weighting precisely where corrections occur. Using 5-fold cross-validation on the 113 UCR datasets, F3 yields small but consistent average improvements over Rocket, supported by frequentist and Bayesian evidence and accompanied by clearly identifiable failure cases. Our results show that selectively applied fusion provides dependable and interpretable extension to strong kernel-based methods, correcting their weaknesses precisely where the data support it.", "AI": {"tldr": "Fusion-3 (F3)\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u878d\u5408Rocket\u3001Sax\u548cSfa\u4e09\u79cd\u65f6\u95f4\u5e8f\u5217\u8868\u793a\uff0c\u5728\u7279\u5b9a\u7c7b\u578b\u7684\u6570\u636e\u96c6\u4e0a\u80fd\u6301\u7eed\u6539\u8fdbRocket\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u7ed3\u6784\u5316\u53d8\u5f02\u6216\u4e30\u5bcc\u9891\u7387\u5185\u5bb9\u7684\u6570\u636e\u96c6\u4e0a\u6548\u679c\u663e\u8457\u3002", "motivation": "\u867d\u7136\u57fa\u4e8e\u6838\u7684\u65b9\u6cd5\u5982Rocket\u662f\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684\u6709\u6548\u9ed8\u8ba4\u65b9\u6cd5\uff0c\u4f46\u5b83\u4eec\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u5e76\u4e0d\u4e00\u81f4\u3002\u7814\u7a76\u57fa\u4e8e\u4e0d\u540c\u8868\u793a\u80fd\u6355\u83b7\u4e92\u8865\u7ed3\u6784\u7684\u957f\u671f\u76f4\u89c9\uff0c\u63a2\u7d22\u901a\u8fc7\u9009\u62e9\u6027\u878d\u5408\u8fd9\u4e9b\u8868\u793a\u6765\u5728\u7279\u5b9a\u7c7b\u578b\u7684\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u6301\u7eed\u6539\u8fdb\u3002", "method": "\u63d0\u51faFusion-3 (F3)\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u81ea\u9002\u5e94\u878d\u5408Rocket\u3001Sax\u548cSfa\u4e09\u79cd\u8868\u793a\u3002\u901a\u8fc7\u5143\u7279\u5f81\uff08\u5e8f\u5217\u957f\u5ea6\u3001\u9891\u8c31\u7ed3\u6784\u3001\u7c97\u7cd9\u5ea6\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\uff09\u5c06UCR\u6570\u636e\u96c6\u805a\u7c7b\u4e3a6\u4e2a\u7ec4\u4f5c\u4e3a\u53ef\u89e3\u91ca\u7684\u6570\u636e\u7ed3\u6784\u673a\u5236\u3002\u91c7\u7528\u4e09\u79cd\u4e92\u8865\u5206\u6790\uff1a\u8de8\u6570\u636e\u96c6\u7684\u975e\u53c2\u6570\u914d\u5bf9\u7edf\u8ba1\u3001\u9694\u79bb\u5355\u4e2a\u8868\u793a\u4f5c\u7528\u7684\u6d88\u878d\u7814\u7a76\u3001\u4ee5\u53ca\u901a\u8fc7SHAP\u8bc6\u522b\u54ea\u4e9b\u6570\u636e\u96c6\u5c5e\u6027\u9884\u6d4b\u878d\u5408\u589e\u76ca\u3002", "result": "\u5728113\u4e2aUCR\u6570\u636e\u96c6\u4e0a\u4f7f\u75285\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff0cF3\u76f8\u6bd4Rocket\u4ea7\u751f\u5c0f\u800c\u6301\u7eed\u7684\u5e73\u5747\u6539\u8fdb\uff0c\u5f97\u5230\u9891\u7387\u8bba\u548c\u8d1d\u53f6\u65af\u8bc1\u636e\u652f\u6301\u3002\u878d\u5408\u901a\u5e38\u5728\u5177\u6709\u7ed3\u6784\u5316\u53d8\u5f02\u6216\u4e30\u5bcc\u9891\u7387\u5185\u5bb9\u7684\u673a\u5236\u4e2d\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u800c\u5728\u9ad8\u5ea6\u4e0d\u89c4\u5219\u6216\u5f02\u5e38\u503c\u591a\u7684\u8bbe\u7f6e\u4e2d\u6536\u76ca\u9012\u51cf\u3002\u6837\u672c\u7ea7\u6848\u4f8b\u7814\u7a76\u663e\u793a\u878d\u5408\u4e3b\u8981\u901a\u8fc7\u7ea0\u6b63\u7279\u5b9a\u9519\u8bef\u6765\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u9009\u62e9\u6027\u5e94\u7528\u7684\u878d\u5408\u4e3a\u5f3a\u6838\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u7684\u6269\u5c55\uff0c\u5728\u6570\u636e\u652f\u6301\u7684\u60c5\u51b5\u4e0b\u7cbe\u786e\u7ea0\u6b63\u5176\u5f31\u70b9\u3002\u878d\u5408\u5728\u53ef\u7cfb\u7edf\u8bc6\u522b\u7684\u7279\u5b9a\u6570\u636e\u96c6\u7c7b\u578b\u4e0a\u63d0\u4f9b\u4e00\u81f4\u6539\u8fdb\uff0c\u540c\u65f6\u5177\u6709\u660e\u786e\u7684\u5931\u8d25\u6848\u4f8b\u53ef\u8bc6\u522b\u6027\u3002"}}
{"id": "2512.15385", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15385", "abs": "https://arxiv.org/abs/2512.15385", "authors": ["Julian Oelhaf", "Mehran Pashaei", "Georg Kordowich", "Christian Bergler", "Andreas Maier", "Johann J\u00e4ger", "Siming Bayer"], "title": "Robustness Evaluation of Machine Learning Models for Fault Classification and Localization In Power System Protection", "comment": "This paper is a postprint of a paper submitted to and accepted for publication in the 20th IET International Conference on Developments in Power System Protection (DPSP Global 2026) and is subject to Institution of Engineering and Technology Copyright. The copy of record is available at the IET Digital Library", "summary": "The growing penetration of renewable and distributed generation is transforming power systems and challenging conventional protection schemes that rely on fixed settings and local measurements. Machine learning (ML) offers a data-driven alternative for centralized fault classification (FC) and fault localization (FL), enabling faster and more adaptive decision-making. However, practical deployment critically depends on robustness. Protection algorithms must remain reliable even when confronted with missing, noisy, or degraded sensor data. This work introduces a unified framework for systematically evaluating the robustness of ML models in power system protection.\n  High-fidelity EMT simulations are used to model realistic degradation scenarios, including sensor outages, reduced sampling rates, and transient communication losses. The framework provides a consistent methodology for benchmarking models, quantifying the impact of limited observability, and identifying critical measurement channels required for resilient operation. Results show that FC remains highly stable under most degradation types but drops by about 13% under single-phase loss, while FL is more sensitive overall, with voltage loss increasing localization error by over 150%. These findings offer actionable guidance for robustness-aware design of future ML-assisted protection systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u7535\u529b\u7cfb\u7edf\u4fdd\u62a4\u4e2d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9c81\u68d2\u6027\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u4fdd\u771f\u7535\u78c1\u6682\u6001\u4eff\u771f\u6a21\u62df\u4f20\u611f\u5668\u6545\u969c\u3001\u91c7\u6837\u7387\u964d\u4f4e\u7b49\u5b9e\u9645\u9000\u5316\u573a\u666f\uff0c\u53d1\u73b0\u6545\u969c\u5206\u7c7b\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u7a33\u5b9a\u4f46\u5355\u76f8\u635f\u5931\u65f6\u4e0b\u964d13%\uff0c\u800c\u6545\u969c\u5b9a\u4f4d\u5bf9\u7535\u538b\u635f\u5931\u66f4\u654f\u611f\uff0c\u8bef\u5dee\u589e\u52a0\u8d85\u8fc7150%\u3002", "motivation": "\u968f\u7740\u53ef\u518d\u751f\u80fd\u6e90\u548c\u5206\u5e03\u5f0f\u53d1\u7535\u6e17\u900f\u7387\u589e\u52a0\uff0c\u4f20\u7edf\u4f9d\u8d56\u56fa\u5b9a\u8bbe\u7f6e\u548c\u672c\u5730\u6d4b\u91cf\u7684\u4fdd\u62a4\u65b9\u6848\u9762\u4e34\u6311\u6218\u3002\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u6570\u636e\u9a71\u52a8\u7684\u96c6\u4e2d\u5f0f\u6545\u969c\u5206\u7c7b\u548c\u5b9a\u4f4d\u65b9\u6848\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u9700\u8981\u9c81\u68d2\u6027\u4fdd\u8bc1\uff0c\u4fdd\u62a4\u7b97\u6cd5\u5fc5\u987b\u5728\u4f20\u611f\u5668\u6570\u636e\u7f3a\u5931\u3001\u566a\u58f0\u6216\u9000\u5316\u65f6\u4ecd\u80fd\u53ef\u9760\u5de5\u4f5c\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9c81\u68d2\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u9ad8\u4fdd\u771f\u7535\u78c1\u6682\u6001\u4eff\u771f\u6a21\u62df\u73b0\u5b9e\u9000\u5316\u573a\u666f\uff0c\u5305\u62ec\u4f20\u611f\u5668\u4e2d\u65ad\u3001\u91c7\u6837\u7387\u964d\u4f4e\u548c\u77ac\u6001\u901a\u4fe1\u4e22\u5931\u3002\u8be5\u6846\u67b6\u63d0\u4f9b\u4e00\u81f4\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u91cf\u5316\u6709\u9650\u53ef\u89c2\u6d4b\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u8bc6\u522b\u5f39\u6027\u8fd0\u884c\u6240\u9700\u7684\u5173\u952e\u6d4b\u91cf\u901a\u9053\u3002", "result": "\u6545\u969c\u5206\u7c7b\u5728\u5927\u591a\u6570\u9000\u5316\u7c7b\u578b\u4e0b\u4fdd\u6301\u9ad8\u5ea6\u7a33\u5b9a\uff0c\u4f46\u5728\u5355\u76f8\u635f\u5931\u65f6\u6027\u80fd\u4e0b\u964d\u7ea613%\u3002\u6545\u969c\u5b9a\u4f4d\u6574\u4f53\u66f4\u4e3a\u654f\u611f\uff0c\u7535\u538b\u635f\u5931\u5bfc\u81f4\u5b9a\u4f4d\u8bef\u5dee\u589e\u52a0\u8d85\u8fc7150%\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u9000\u5316\u573a\u666f\u4e0b\u7684\u6027\u80fd\u91cf\u5316\u5206\u6790\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u672a\u6765\u673a\u5668\u5b66\u4e60\u8f85\u52a9\u4fdd\u62a4\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u5f3a\u8c03\u4e86\u5728\u4fdd\u62a4\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u8003\u8651\u6570\u636e\u9000\u5316\u573a\u666f\u7684\u91cd\u8981\u6027\uff0c\u7279\u522b\u662f\u6545\u969c\u5b9a\u4f4d\u5bf9\u7535\u538b\u6d4b\u91cf\u5b8c\u6574\u6027\u7684\u654f\u611f\u6027\u3002"}}
{"id": "2512.15405", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15405", "abs": "https://arxiv.org/abs/2512.15405", "authors": ["Jianfei Ma", "Wee Sun Lee"], "title": "EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning", "comment": null, "summary": "At the boundary between the known and the unknown, an agent inevitably confronts the dilemma of whether to explore or to exploit. Epistemic uncertainty reflects such boundaries, representing systematic uncertainty due to limited knowledge. In this paper, we propose a Bayesian reinforcement learning (RL) algorithm, $\\texttt{EUBRL}$, which leverages epistemic guidance to achieve principled exploration. This guidance adaptively reduces per-step regret arising from estimation errors. We establish nearly minimax-optimal regret and sample complexity guarantees for a class of sufficiently expressive priors in infinite-horizon discounted MDPs. Empirically, we evaluate $\\texttt{EUBRL}$ on tasks characterized by sparse rewards, long horizons, and stochasticity. Results demonstrate that $\\texttt{EUBRL}$ achieves superior sample efficiency, scalability, and consistency.", "AI": {"tldr": "\u63d0\u51faEUBRL\u8d1d\u53f6\u65af\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5229\u7528\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6307\u5bfc\u63a2\u7d22\uff0c\u5728\u65e0\u9650\u65f6\u57df\u6298\u6263MDP\u4e2d\u5b9e\u73b0\u63a5\u8fd1\u6781\u5c0f\u6781\u5927\u6700\u4f18\u7684\u9057\u61be\u548c\u6837\u672c\u590d\u6742\u5ea6\u4fdd\u8bc1", "motivation": "\u667a\u80fd\u4f53\u5728\u5df2\u77e5\u4e0e\u672a\u77e5\u8fb9\u754c\u9762\u4e34\u63a2\u7d22-\u5229\u7528\u56f0\u5883\uff0c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u53cd\u6620\u4e86\u77e5\u8bc6\u6709\u9650\u5bfc\u81f4\u7684\u7cfb\u7edf\u6027\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u8bbe\u8ba1\u80fd\u5229\u7528\u8ba4\u77e5\u6307\u5bfc\u8fdb\u884c\u539f\u5219\u6027\u63a2\u7d22\u7684\u7b97\u6cd5", "method": "\u63d0\u51faEUBRL\u8d1d\u53f6\u65af\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6307\u5bfc\u81ea\u9002\u5e94\u51cf\u5c11\u4f30\u8ba1\u8bef\u5dee\u5e26\u6765\u7684\u6bcf\u6b65\u9057\u61be\uff0c\u9002\u7528\u4e8e\u5177\u6709\u5145\u5206\u8868\u8fbe\u80fd\u529b\u5148\u9a8c\u7684\u65e0\u9650\u65f6\u57df\u6298\u6263MDP", "result": "\u7406\u8bba\u8bc1\u660eEUBRL\u5728\u65e0\u9650\u65f6\u57df\u6298\u6263MDP\u4e2d\u8fbe\u5230\u63a5\u8fd1\u6781\u5c0f\u6781\u5927\u6700\u4f18\u7684\u9057\u61be\u548c\u6837\u672c\u590d\u6742\u5ea6\u4fdd\u8bc1\uff1b\u5b9e\u9a8c\u5728\u7a00\u758f\u5956\u52b1\u3001\u957f\u65f6\u57df\u548c\u968f\u673a\u6027\u4efb\u52a1\u4e2d\u663e\u793aEUBRL\u5177\u6709\u4f18\u8d8a\u7684\u6837\u672c\u6548\u7387\u3001\u53ef\u6269\u5c55\u6027\u548c\u4e00\u81f4\u6027", "conclusion": "EUBRL\u901a\u8fc7\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6307\u5bfc\u5b9e\u73b0\u4e86\u539f\u5219\u6027\u63a2\u7d22\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22-\u5229\u7528\u5e73\u8861\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.15420", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15420", "abs": "https://arxiv.org/abs/2512.15420", "authors": ["Yeonwoo Cha", "Semin Kim", "Jinhyeon Kwon", "Seunghoon Hong"], "title": "FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows", "comment": "https://yeonwoo378.github.io/official_flowbind", "summary": "Any-to-any generation seeks to translate between arbitrary subsets of modalities, enabling flexible cross-modal synthesis. Despite recent success, existing flow-based approaches are challenged by their inefficiency, as they require large-scale datasets often with restrictive pairing constraints, incur high computational cost from modeling joint distribution, and rely on complex multi-stage training. We propose FlowBind, an efficient framework for any-to-any generation. Our approach is distinguished by its simplicity: it learns a shared latent space capturing cross-modal information, with modality-specific invertible flows bridging this latent to each modality. Both components are optimized jointly under a single flow-matching objective, and at inference the invertible flows act as encoders and decoders for direct translation across modalities. By factorizing interactions through the shared latent, FlowBind naturally leverages arbitrary subsets of modalities for training, and achieves competitive generation quality while substantially reducing data requirements and computational cost. Experiments on text, image, and audio demonstrate that FlowBind attains comparable quality while requiring up to 6x fewer parameters and training 10x faster than prior methods. The project page with code is available at https://yeonwoo378.github.io/official_flowbind.", "AI": {"tldr": "FlowBind\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u591a\u6a21\u6001\u4efb\u610f\u5230\u4efb\u610f\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u548c\u6a21\u6001\u7279\u5b9a\u7684\u53ef\u9006\u6d41\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6570\u636e\u9700\u6c42\u548c\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6d41\u7684\u4efb\u610f\u5230\u4efb\u610f\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u95ee\u9898\uff1a\u9700\u8981\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e14\u914d\u5bf9\u9650\u5236\u4e25\u683c\u3001\u5efa\u6a21\u8054\u5408\u5206\u5e03\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u4f9d\u8d56\u590d\u6742\u7684\u591a\u9636\u6bb5\u8bad\u7ec3\u3002\u9700\u8981\u66f4\u7b80\u5355\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "FlowBind\u5b66\u4e60\u4e00\u4e2a\u6355\u83b7\u8de8\u6a21\u6001\u4fe1\u606f\u7684\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\uff0c\u4f7f\u7528\u6a21\u6001\u7279\u5b9a\u7684\u53ef\u9006\u6d41\u5c06\u6bcf\u4e2a\u6a21\u6001\u6865\u63a5\u5230\u8fd9\u4e2a\u6f5c\u5728\u7a7a\u95f4\u3002\u4e24\u4e2a\u7ec4\u4ef6\u5728\u5355\u4e00\u6d41\u5339\u914d\u76ee\u6807\u4e0b\u8054\u5408\u4f18\u5316\uff0c\u63a8\u7406\u65f6\u8fd9\u4e9b\u53ef\u9006\u6d41\u4f5c\u4e3a\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u5b9e\u73b0\u8de8\u6a21\u6001\u76f4\u63a5\u8f6c\u6362\u3002", "result": "\u5728\u6587\u672c\u3001\u56fe\u50cf\u548c\u97f3\u9891\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFlowBind\u5728\u8fbe\u5230\u53ef\u6bd4\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u53c2\u6570\u6570\u91cf\u51cf\u5c11\u9ad8\u8fbe6\u500d\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u534710\u500d\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6570\u636e\u9700\u6c42\u548c\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "FlowBind\u901a\u8fc7\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u548c\u6a21\u6001\u7279\u5b9a\u53ef\u9006\u6d41\u7684\u7b80\u5355\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u591a\u6a21\u6001\u4efb\u610f\u5230\u4efb\u610f\u751f\u6210\uff0c\u4e3a\u8de8\u6a21\u6001\u5408\u6210\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.15427", "categories": ["cs.LG", "cond-mat.stat-mech", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.15427", "abs": "https://arxiv.org/abs/2512.15427", "authors": ["Hyakka Nakada", "Shu Tanaka"], "title": "Statistics of Min-max Normalized Eigenvalues in Random Matrices", "comment": "4 pages, 4 figures", "summary": "Random matrix theory has played an important role in various areas of pure mathematics, mathematical physics, and machine learning. From a practical perspective of data science, input data are usually normalized prior to processing. Thus, this study investigates the statistical properties of min-max normalized eigenvalues in random matrices. Previously, the effective distribution for such normalized eigenvalues has been proposed. In this study, we apply it to evaluate a scaling law of the cumulative distribution. Furthermore, we derive the residual error that arises during matrix factorization of random matrices. We conducted numerical experiments to verify these theoretical predictions.", "AI": {"tldr": "\u7814\u7a76\u968f\u673a\u77e9\u9635\u4e2dmin-max\u5f52\u4e00\u5316\u7279\u5f81\u503c\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u5305\u62ec\u7d2f\u79ef\u5206\u5e03\u7684\u6807\u5ea6\u5f8b\u548c\u77e9\u9635\u5206\u89e3\u4e2d\u7684\u6b8b\u5dee\u8bef\u5dee", "motivation": "\u968f\u673a\u77e9\u9635\u7406\u8bba\u5728\u7eaf\u6570\u5b66\u3001\u6570\u5b66\u7269\u7406\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u90fd\u5f88\u91cd\u8981\u3002\u4ece\u6570\u636e\u79d1\u5b66\u5b9e\u8df5\u89d2\u5ea6\u770b\uff0c\u8f93\u5165\u6570\u636e\u901a\u5e38\u9700\u8981\u5f52\u4e00\u5316\u5904\u7406\uff0c\u56e0\u6b64\u7814\u7a76\u5f52\u4e00\u5316\u7279\u5f81\u503c\u7684\u7edf\u8ba1\u7279\u6027\u5177\u6709\u5b9e\u9645\u610f\u4e49", "method": "\u5e94\u7528\u5148\u524d\u63d0\u51fa\u7684\u5f52\u4e00\u5316\u7279\u5f81\u503c\u6709\u6548\u5206\u5e03\uff0c\u63a8\u5bfc\u7d2f\u79ef\u5206\u5e03\u7684\u6807\u5ea6\u5f8b\u548c\u77e9\u9635\u5206\u89e3\u4e2d\u7684\u6b8b\u5dee\u8bef\u5dee\uff0c\u5e76\u8fdb\u884c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u9884\u6d4b", "result": "\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u9884\u6d4b\uff0c\u5305\u62ec\u5f52\u4e00\u5316\u7279\u5f81\u503c\u7d2f\u79ef\u5206\u5e03\u7684\u6807\u5ea6\u5f8b\u548c\u77e9\u9635\u5206\u89e3\u6b8b\u5dee\u8bef\u5dee\u7684\u51c6\u786e\u6027", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u968f\u673a\u77e9\u9635\u4e2d\u5f52\u4e00\u5316\u7279\u5f81\u503c\u7684\u7edf\u8ba1\u7279\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5bf9\u6570\u636e\u79d1\u5b66\u4e2d\u7684\u5f52\u4e00\u5316\u5904\u7406\u6709\u5b9e\u9645\u6307\u5bfc\u610f\u4e49"}}
{"id": "2512.15442", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15442", "abs": "https://arxiv.org/abs/2512.15442", "authors": ["Neeraj Sarna", "Yuanyuan Li", "Michael von Gablenz"], "title": "Copyright Infringement Risk Reduction via Chain-of-Thought and Task Instruction Prompting", "comment": null, "summary": "Large scale text-to-image generation models can memorize and reproduce their training dataset. Since the training dataset often contains copyrighted material, reproduction of training dataset poses a copyright infringement risk, which could result in legal liabilities and financial losses for both the AI user and the developer. The current works explores the potential of chain-of-thought and task instruction prompting in reducing copyrighted content generation. To this end, we present a formulation that combines these two techniques with two other copyright mitigation strategies: a) negative prompting, and b) prompt re-writing. We study the generated images in terms their similarity to a copyrighted image and their relevance of the user input. We present numerical experiments on a variety of models and provide insights on the effectiveness of the aforementioned techniques for varying model complexity.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u601d\u7ef4\u94fe\u548c\u4efb\u52a1\u6307\u4ee4\u63d0\u793a\u7b49\u6280\u672f\u51cf\u5c11\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u4e2d\u7684\u7248\u6743\u5185\u5bb9\u8f93\u51fa\uff0c\u7ed3\u5408\u8d1f\u5411\u63d0\u793a\u548c\u63d0\u793a\u91cd\u5199\u7b56\u7565\uff0c\u8bc4\u4f30\u751f\u6210\u56fe\u50cf\u4e0e\u7248\u6743\u56fe\u50cf\u7684\u76f8\u4f3c\u5ea6\u53ca\u5176\u4e0e\u7528\u6237\u8f93\u5165\u7684\u76f8\u5173\u6027\u3002", "motivation": "\u5927\u89c4\u6a21\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u53ef\u80fd\u4f1a\u8bb0\u5fc6\u5e76\u590d\u5236\u5176\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u7684\u5185\u5bb9\uff0c\u800c\u8bad\u7ec3\u6570\u636e\u901a\u5e38\u5305\u542b\u53d7\u7248\u6743\u4fdd\u62a4\u7684\u6750\u6599\u3002\u8fd9\u79cd\u590d\u5236\u884c\u4e3a\u5b58\u5728\u7248\u6743\u4fb5\u6743\u98ce\u9669\uff0c\u53ef\u80fd\u5bfc\u81f4AI\u7528\u6237\u548c\u5f00\u53d1\u8005\u9762\u4e34\u6cd5\u5f8b\u8d23\u4efb\u548c\u7ecf\u6d4e\u635f\u5931\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u601d\u7ef4\u94fe\u548c\u4efb\u52a1\u6307\u4ee4\u63d0\u793a\u7684\u6846\u67b6\uff0c\u5e76\u4e0e\u4e24\u79cd\u7248\u6743\u7f13\u89e3\u7b56\u7565\u76f8\u7ed3\u5408\uff1aa) \u8d1f\u5411\u63d0\u793a\uff0cb) \u63d0\u793a\u91cd\u5199\u3002\u7814\u7a76\u751f\u6210\u56fe\u50cf\u4e0e\u7248\u6743\u56fe\u50cf\u7684\u76f8\u4f3c\u5ea6\u4ee5\u53ca\u5b83\u4eec\u4e0e\u7528\u6237\u8f93\u5165\u7684\u76f8\u5173\u6027\u3002", "result": "\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u6570\u503c\u5b9e\u9a8c\uff0c\u63d0\u4f9b\u4e86\u5173\u4e8e\u4e0a\u8ff0\u6280\u672f\u6709\u6548\u6027\u7684\u89c1\u89e3\uff0c\u5206\u6790\u4e86\u5404\u79cd\u6280\u672f\u5728\u51cf\u5c11\u7248\u6743\u5185\u5bb9\u751f\u6210\u65b9\u9762\u7684\u6548\u679c\u3002", "conclusion": "\u901a\u8fc7\u601d\u7ef4\u94fe\u3001\u4efb\u52a1\u6307\u4ee4\u63d0\u793a\u3001\u8d1f\u5411\u63d0\u793a\u548c\u63d0\u793a\u91cd\u5199\u7b49\u6280\u672f\u7684\u7ec4\u5408\uff0c\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u4e2d\u7684\u7248\u6743\u5185\u5bb9\u8f93\u51fa\uff0c\u4e3a\u964d\u4f4e\u7248\u6743\u4fb5\u6743\u98ce\u9669\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2512.15460", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15460", "abs": "https://arxiv.org/abs/2512.15460", "authors": ["Xiangrui Xu", "Zhize Li", "Yufei Han", "Bin Wang", "Jiqiang Liu", "Wei Wang"], "title": "From Risk to Resilience: Towards Assessing and Mitigating the Risk of Data Reconstruction Attacks in Federated Learning", "comment": null, "summary": "Data Reconstruction Attacks (DRA) pose a significant threat to Federated Learning (FL) systems by enabling adversaries to infer sensitive training data from local clients. Despite extensive research, the question of how to characterize and assess the risk of DRAs in FL systems remains unresolved due to the lack of a theoretically-grounded risk quantification framework. In this work, we address this gap by introducing Invertibility Loss (InvLoss) to quantify the maximum achievable effectiveness of DRAs for a given data instance and FL model. We derive a tight and computable upper bound for InvLoss and explore its implications from three perspectives. First, we show that DRA risk is governed by the spectral properties of the Jacobian matrix of exchanged model updates or feature embeddings, providing a unified explanation for the effectiveness of defense methods. Second, we develop InvRE, an InvLoss-based DRA risk estimator that offers attack method-agnostic, comprehensive risk evaluation across data instances and model architectures. Third, we propose two adaptive noise perturbation defenses that enhance FL privacy without harming classification accuracy. Extensive experiments on real-world datasets validate our framework, demonstrating its potential for systematic DRA risk evaluation and mitigation in FL systems.", "AI": {"tldr": "\u63d0\u51faInvertibility Loss (InvLoss)\u91cf\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u91cd\u6784\u653b\u51fb\u98ce\u9669\uff0c\u63a8\u5bfc\u5176\u53ef\u8ba1\u7b97\u4e0a\u754c\uff0c\u5f00\u53d1InvRE\u98ce\u9669\u4f30\u8ba1\u5668\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u81ea\u9002\u5e94\u566a\u58f0\u9632\u5fa1\u65b9\u6cd5\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u4e2d\u6570\u636e\u91cd\u6784\u653b\u51fb(DRA)\u5a01\u80c1\u4e25\u91cd\uff0c\u4f46\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u7684\u91cf\u5316\u6846\u67b6\u6765\u8bc4\u4f30\u98ce\u9669\uff0c\u73b0\u6709\u7814\u7a76\u65e0\u6cd5\u7cfb\u7edf\u5730\u8868\u5f81\u548c\u8bc4\u4f30DRA\u98ce\u9669\u3002", "method": "\u5f15\u5165Invertibility Loss (InvLoss)\u91cf\u5316\u6570\u636e\u5b9e\u4f8b\u548cFL\u6a21\u578b\u7684\u6700\u5927\u53ef\u8fbe\u5230\u653b\u51fb\u6548\u679c\uff0c\u63a8\u5bfc\u5176\u7d27\u81f4\u53ef\u8ba1\u7b97\u4e0a\u754c\uff0c\u5f00\u53d1InvRE\u98ce\u9669\u4f30\u8ba1\u5668\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u81ea\u9002\u5e94\u566a\u58f0\u6270\u52a8\u9632\u5fa1\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff1a1) DRA\u98ce\u9669\u7531Jacobian\u77e9\u9635\u7684\u8c31\u7279\u6027\u63a7\u5236\uff1b2) InvRE\u63d0\u4f9b\u653b\u51fb\u65b9\u6cd5\u65e0\u5173\u7684\u5168\u9762\u98ce\u9669\u8bc4\u4f30\uff1b3) \u81ea\u9002\u5e94\u566a\u58f0\u9632\u5fa1\u80fd\u589e\u5f3a\u9690\u79c1\u800c\u4e0d\u635f\u5bb3\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684InvLoss\u6846\u67b6\u4e3a\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684DRA\u98ce\u9669\u8bc4\u4f30\u548c\u7f13\u89e3\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u7406\u8bba\u91cf\u5316\u6846\u67b6\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.15492", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15492", "abs": "https://arxiv.org/abs/2512.15492", "authors": ["Adri\u00e1n Detavernier", "Jasper De Bock"], "title": "Robustness and uncertainty: two complementary aspects of the reliability of the predictions of a classifier", "comment": "workshop paper (not published)", "summary": "We consider two conceptually different approaches for assessing the reliability of the individual predictions of a classifier: Robustness Quantification (RQ) and Uncertainty Quantification (UQ). We compare both approaches on a number of benchmark datasets and show that there is no clear winner between the two, but that they are complementary and can be combined to obtain a hybrid approach that outperforms both RQ and UQ. As a byproduct of our approach, for each dataset, we also obtain an assessment of the relative importance of uncertainty and robustness as sources of unreliability.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u8bc4\u4f30\u5206\u7c7b\u5668\u4e2a\u4f53\u9884\u6d4b\u53ef\u9760\u6027\u7684\u4e24\u79cd\u65b9\u6cd5\uff1a\u9c81\u68d2\u6027\u91cf\u5316(RQ)\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316(UQ)\uff0c\u53d1\u73b0\u4e24\u8005\u4e92\u8865\uff0c\u7ed3\u5408\u540e\u7684\u6df7\u5408\u65b9\u6cd5\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u79cd\u65b9\u6cd5\u3002", "motivation": "\u8bc4\u4f30\u5206\u7c7b\u5668\u4e2a\u4f53\u9884\u6d4b\u7684\u53ef\u9760\u6027\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u91cd\u8981\u95ee\u9898\uff0c\u76ee\u524d\u5b58\u5728\u4e24\u79cd\u6982\u5ff5\u4e0a\u4e0d\u540c\u7684\u65b9\u6cd5\uff1a\u9c81\u68d2\u6027\u91cf\u5316(RQ)\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316(UQ)\u3002\u7814\u7a76\u65e8\u5728\u6bd4\u8f83\u8fd9\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u52a3\uff0c\u63a2\u7d22\u5b83\u4eec\u662f\u5426\u4e92\u8865\uff0c\u4ee5\u53ca\u80fd\u5426\u7ed3\u5408\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u53ef\u9760\u6027\u8bc4\u4f30\u3002", "method": "\u7814\u7a76\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7cfb\u7edf\u6bd4\u8f83\u4e86RQ\u548cUQ\u4e24\u79cd\u65b9\u6cd5\u3002\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u4e24\u79cd\u65b9\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u7684\u6df7\u5408\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u7814\u7a76\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u79cd\u8bc4\u4f30\u6846\u67b6\u6765\u8861\u91cf\u4e0d\u786e\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u4f5c\u4e3a\u4e0d\u53ef\u9760\u6027\u6765\u6e90\u7684\u76f8\u5bf9\u91cd\u8981\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cRQ\u548cUQ\u4e4b\u95f4\u6ca1\u6709\u660e\u786e\u7684\u4f18\u52a3\u4e4b\u5206\uff0c\u4f46\u4e24\u8005\u5177\u6709\u4e92\u8865\u6027\u3002\u7ed3\u5408\u4e24\u79cd\u65b9\u6cd5\u7684\u6df7\u5408\u65b9\u6cd5\u5728\u53ef\u9760\u6027\u8bc4\u4f30\u65b9\u9762\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528RQ\u6216UQ\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u80fd\u4e3a\u6bcf\u4e2a\u6570\u636e\u96c6\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u4f5c\u4e3a\u4e0d\u53ef\u9760\u6027\u6765\u6e90\u7684\u76f8\u5bf9\u91cd\u8981\u6027\u8bc4\u4f30\u3002", "conclusion": "\u9c81\u68d2\u6027\u91cf\u5316\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u662f\u8bc4\u4f30\u5206\u7c7b\u5668\u9884\u6d4b\u53ef\u9760\u6027\u7684\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e24\u8005\u7684\u6df7\u5408\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u4f18\u7684\u53ef\u9760\u6027\u8bc4\u4f30\u3002\u8be5\u7814\u7a76\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8fd8\u80fd\u5e2e\u52a9\u7406\u89e3\u4e0d\u540c\u6570\u636e\u96c6\u4e2d\u4e0d\u786e\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u5bf9\u9884\u6d4b\u4e0d\u53ef\u9760\u6027\u7684\u76f8\u5bf9\u8d21\u732e\u3002"}}
{"id": "2512.15538", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.15538", "abs": "https://arxiv.org/abs/2512.15538", "authors": ["Taichi Aida", "Mamoru Komachi", "Toshinobu Ogiso", "Hiroya Takamura", "Daichi Mochihashi"], "title": "Tracking Temporal Dynamics of Vector Sets with Gaussian Process", "comment": "Work in Progress", "summary": "Understanding the temporal evolution of sets of vectors is a fundamental challenge across various domains, including ecology, crime analysis, and linguistics. For instance, ecosystem structures evolve due to interactions among plants, herbivores, and carnivores; the spatial distribution of crimes shifts in response to societal changes; and word embedding vectors reflect cultural and semantic trends over time. However, analyzing such time-varying sets of vectors is challenging due to their complicated structures, which also evolve over time. In this work, we propose a novel method for modeling the distribution underlying each set of vectors using infinite-dimensional Gaussian processes. By approximating the latent function in the Gaussian process with Random Fourier Features, we obtain compact and comparable vector representations over time. This enables us to track and visualize temporal transitions of vector sets in a low-dimensional space. We apply our method to both sociological data (crime distributions) and linguistic data (word embeddings), demonstrating its effectiveness in capturing temporal dynamics. Our results show that the proposed approach provides interpretable and robust representations, offering a powerful framework for analyzing structural changes in temporally indexed vector sets across diverse domains.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u65e0\u9650\u7ef4\u9ad8\u65af\u8fc7\u7a0b\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5efa\u6a21\u968f\u65f6\u95f4\u53d8\u5316\u7684\u5411\u91cf\u96c6\u5206\u5e03\uff0c\u901a\u8fc7\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u8fd1\u4f3c\u83b7\u5f97\u7d27\u51d1\u53ef\u6bd4\u7684\u65f6\u5e8f\u5411\u91cf\u8868\u793a\uff0c\u53ef\u8ffd\u8e2a\u548c\u53ef\u89c6\u5316\u5411\u91cf\u96c6\u5728\u4f4e\u7ef4\u7a7a\u95f4\u4e2d\u7684\u65f6\u95f4\u6f14\u53d8\u3002", "motivation": "\u7406\u89e3\u5411\u91cf\u96c6\u7684\u65f6\u95f4\u6f14\u5316\u662f\u751f\u6001\u5b66\u3001\u72af\u7f6a\u5206\u6790\u548c\u8bed\u8a00\u5b66\u7b49\u591a\u4e2a\u9886\u57df\u7684\u57fa\u7840\u6311\u6218\u3002\u8fd9\u4e9b\u5411\u91cf\u96c6\u5177\u6709\u590d\u6742\u7ed3\u6784\u4e14\u968f\u65f6\u95f4\u6f14\u53d8\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5206\u6790\u5176\u52a8\u6001\u53d8\u5316\u3002", "method": "\u4f7f\u7528\u65e0\u9650\u7ef4\u9ad8\u65af\u8fc7\u7a0b\u5efa\u6a21\u6bcf\u4e2a\u5411\u91cf\u96c6\u7684\u57fa\u7840\u5206\u5e03\uff0c\u901a\u8fc7\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u8fd1\u4f3c\u9ad8\u65af\u8fc7\u7a0b\u4e2d\u7684\u6f5c\u5728\u51fd\u6570\uff0c\u83b7\u5f97\u7d27\u51d1\u4e14\u53ef\u6bd4\u8f83\u7684\u65f6\u5e8f\u5411\u91cf\u8868\u793a\uff0c\u4ece\u800c\u5728\u4f4e\u7ef4\u7a7a\u95f4\u4e2d\u8ffd\u8e2a\u548c\u53ef\u89c6\u5316\u5411\u91cf\u96c6\u7684\u65f6\u95f4\u6f14\u53d8\u3002", "result": "\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u793e\u4f1a\u5b66\u6570\u636e\uff08\u72af\u7f6a\u5206\u5e03\uff09\u548c\u8bed\u8a00\u5b66\u6570\u636e\uff08\u8bcd\u5d4c\u5165\uff09\uff0c\u6709\u6548\u6355\u6349\u4e86\u65f6\u95f4\u52a8\u6001\u3002\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u4e14\u7a33\u5065\u7684\u8868\u793a\uff0c\u4e3a\u5206\u6790\u8de8\u9886\u57df\u65f6\u95f4\u7d22\u5f15\u5411\u91cf\u96c6\u7684\u7ed3\u6784\u53d8\u5316\u63d0\u4f9b\u4e86\u5f3a\u5927\u6846\u67b6\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5efa\u6a21\u548c\u5206\u6790\u968f\u65f6\u95f4\u53d8\u5316\u7684\u5411\u91cf\u96c6\u5206\u5e03\uff0c\u901a\u8fc7\u4f4e\u7ef4\u8868\u793a\u8ffd\u8e2a\u7ed3\u6784\u6f14\u53d8\uff0c\u4e3a\u8de8\u9886\u57df\u7684\u65f6\u5e8f\u5411\u91cf\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u9896\u4e14\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.15574", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15574", "abs": "https://arxiv.org/abs/2512.15574", "authors": ["Yuxin Cai", "Yanyong Huang", "Jinyuan Chang", "Dongjie Wang", "Tianrui Li", "Xiaoyi Jiang"], "title": "Joint Learning of Unsupervised Multi-view Feature and Instance Co-selection with Cross-view Imputation", "comment": null, "summary": "Feature and instance co-selection, which aims to reduce both feature dimensionality and sample size by identifying the most informative features and instances, has attracted considerable attention in recent years. However, when dealing with unlabeled incomplete multi-view data, where some samples are missing in certain views, existing methods typically first impute the missing data and then concatenate all views into a single dataset for subsequent co-selection. Such a strategy treats co-selection and missing data imputation as two independent processes, overlooking potential interactions between them. The inter-sample relationships gleaned from co-selection can aid imputation, which in turn enhances co-selection performance. Additionally, simply merging multi-view data fails to capture the complementary information among views, ultimately limiting co-selection effectiveness. To address these issues, we propose a novel co-selection method, termed Joint learning of Unsupervised multI-view feature and instance Co-selection with cross-viEw imputation (JUICE). JUICE first reconstructs incomplete multi-view data using available observations, bringing missing data recovery and feature and instance co-selection together in a unified framework. Then, JUICE leverages cross-view neighborhood information to learn inter-sample relationships and further refine the imputation of missing values during reconstruction. This enables the selection of more representative features and instances. Extensive experiments demonstrate that JUICE outperforms state-of-the-art methods.", "AI": {"tldr": "JUICE\u662f\u4e00\u79cd\u8054\u5408\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u7f3a\u5931\u6570\u636e\u6062\u590d\u4e0e\u591a\u89c6\u56fe\u7279\u5f81\u548c\u5b9e\u4f8b\u534f\u540c\u9009\u62e9\u7edf\u4e00\u8d77\u6765\uff0c\u901a\u8fc7\u8de8\u89c6\u56fe\u90bb\u57df\u4fe1\u606f\u5b66\u4e60\u6837\u672c\u5173\u7cfb\uff0c\u63d0\u5347\u7279\u5f81\u548c\u5b9e\u4f8b\u9009\u62e9\u7684\u4ee3\u8868\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u672a\u6807\u8bb0\u7684\u4e0d\u5b8c\u6574\u591a\u89c6\u56fe\u6570\u636e\u65f6\uff0c\u901a\u5e38\u5148\u586b\u8865\u7f3a\u5931\u6570\u636e\uff0c\u7136\u540e\u5c06\u6240\u6709\u89c6\u56fe\u62fc\u63a5\u4e3a\u5355\u4e00\u6570\u636e\u96c6\u8fdb\u884c\u534f\u540c\u9009\u62e9\u3002\u8fd9\u79cd\u7b56\u7565\u5c06\u534f\u540c\u9009\u62e9\u548c\u7f3a\u5931\u6570\u636e\u586b\u8865\u89c6\u4e3a\u4e24\u4e2a\u72ec\u7acb\u8fc7\u7a0b\uff0c\u5ffd\u7565\u4e86\u5b83\u4eec\u4e4b\u95f4\u7684\u6f5c\u5728\u4ea4\u4e92\u3002\u540c\u65f6\uff0c\u7b80\u5355\u5408\u5e76\u591a\u89c6\u56fe\u6570\u636e\u65e0\u6cd5\u6355\u6349\u89c6\u56fe\u95f4\u7684\u4e92\u8865\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u534f\u540c\u9009\u62e9\u6548\u679c\u3002", "method": "JUICE\u9996\u5148\u4f7f\u7528\u53ef\u7528\u89c2\u6d4b\u91cd\u5efa\u4e0d\u5b8c\u6574\u591a\u89c6\u56fe\u6570\u636e\uff0c\u5c06\u7f3a\u5931\u6570\u636e\u6062\u590d\u4e0e\u7279\u5f81\u548c\u5b9e\u4f8b\u534f\u540c\u9009\u62e9\u7edf\u4e00\u5728\u4e00\u4e2a\u6846\u67b6\u4e2d\u3002\u7136\u540e\u5229\u7528\u8de8\u89c6\u56fe\u90bb\u57df\u4fe1\u606f\u5b66\u4e60\u6837\u672c\u95f4\u5173\u7cfb\uff0c\u5728\u91cd\u5efa\u8fc7\u7a0b\u4e2d\u8fdb\u4e00\u6b65\u4f18\u5316\u7f3a\u5931\u503c\u7684\u586b\u8865\uff0c\u4ece\u800c\u9009\u62e9\u66f4\u5177\u4ee3\u8868\u6027\u7684\u7279\u5f81\u548c\u5b9e\u4f8b\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cJUICE\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "JUICE\u901a\u8fc7\u8054\u5408\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u672a\u6807\u8bb0\u4e0d\u5b8c\u6574\u591a\u89c6\u56fe\u6570\u636e\u7684\u7279\u5f81\u548c\u5b9e\u4f8b\u534f\u540c\u9009\u62e9\u95ee\u9898\uff0c\u901a\u8fc7\u6574\u5408\u7f3a\u5931\u6570\u636e\u586b\u8865\u548c\u534f\u540c\u9009\u62e9\u8fc7\u7a0b\uff0c\u5e76\u5229\u7528\u8de8\u89c6\u56fe\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9009\u62e9\u6548\u679c\u3002"}}
{"id": "2512.15596", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15596", "abs": "https://arxiv.org/abs/2512.15596", "authors": ["Shuibai Zhang", "Fred Zhangzhi Peng", "Yiheng Zhang", "Jin Pan", "Grigorios G. Chrysos"], "title": "Corrective Diffusion Language Models", "comment": "18 pages", "summary": "Diffusion language models are structurally well-suited for iterative error correction, as their non-causal denoising dynamics allow arbitrary positions in a sequence to be revised. However, standard masked diffusion language model (MDLM) training fails to reliably induce this behavior, as models often cannot identify unreliable tokens in a complete input, rendering confidence-guided refinement ineffective. We study corrective behavior in diffusion language models, defined as the ability to assign lower confidence to incorrect tokens and iteratively refine them while preserving correct content. We show that this capability is not induced by conventional masked diffusion objectives and propose a correction-oriented post-training principle that explicitly supervises visible incorrect tokens, enabling error-aware confidence and targeted refinement. To evaluate corrective behavior, we introduce the Code Revision Benchmark (CRB), a controllable and executable benchmark for assessing error localization and in-place correction. Experiments on code revision tasks and controlled settings demonstrate that models trained with our approach substantially outperform standard MDLMs in correction scenarios, while also improving pure completion performance. Our code is publicly available at https://github.com/zhangshuibai/CDLM.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u7ea0\u9519\u80fd\u529b\uff0c\u53d1\u73b0\u4f20\u7edf\u63a9\u7801\u6269\u6563\u8bad\u7ec3\u65e0\u6cd5\u53ef\u9760\u8bf1\u5bfc\u7ea0\u9519\u884c\u4e3a\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u7ea0\u9519\u5bfc\u5411\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u9519\u8bef\u5b9a\u4f4d\u548c\u4fee\u6b63\u65b9\u9762\u7684\u6027\u80fd\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u4e0a\u9002\u5408\u8fed\u4ee3\u9519\u8bef\u4fee\u6b63\uff0c\u4f46\u6807\u51c6\u7684\u63a9\u7801\u6269\u6563\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65e0\u6cd5\u53ef\u9760\u5730\u8bf1\u5bfc\u8fd9\u79cd\u7ea0\u9519\u884c\u4e3a\uff0c\u56e0\u4e3a\u6a21\u578b\u5f80\u5f80\u65e0\u6cd5\u8bc6\u522b\u5b8c\u6574\u8f93\u5165\u4e2d\u7684\u4e0d\u53ef\u9760\u6807\u8bb0\uff0c\u5bfc\u81f4\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u4fee\u6b63\u65e0\u6548\u3002", "method": "\u63d0\u51fa\u4e86\u7ea0\u9519\u5bfc\u5411\u7684\u540e\u8bad\u7ec3\u539f\u5219\uff0c\u660e\u786e\u76d1\u7763\u53ef\u89c1\u7684\u9519\u8bef\u6807\u8bb0\uff0c\u4f7f\u6a21\u578b\u5177\u5907\u9519\u8bef\u611f\u77e5\u7684\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u548c\u9488\u5bf9\u6027\u4fee\u6b63\u80fd\u529b\u3002\u540c\u65f6\u5f15\u5165\u4e86\u4ee3\u7801\u4fee\u8ba2\u57fa\u51c6\uff08CRB\uff09\u6765\u8bc4\u4f30\u7ea0\u9519\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528\u8be5\u65b9\u6cd5\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u4ee3\u7801\u4fee\u8ba2\u4efb\u52a1\u548c\u53d7\u63a7\u8bbe\u7f6e\u4e2d\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u63a9\u7801\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u7ea0\u9519\u573a\u666f\u7684\u6027\u80fd\uff0c\u8fd8\u6539\u5584\u4e86\u7eaf\u8865\u5168\u4efb\u52a1\u7684\u6027\u80fd\u3002", "conclusion": "\u4f20\u7edf\u63a9\u7801\u6269\u6563\u76ee\u6807\u65e0\u6cd5\u8bf1\u5bfc\u6709\u6548\u7684\u7ea0\u9519\u884c\u4e3a\uff0c\u800c\u63d0\u51fa\u7684\u7ea0\u9519\u5bfc\u5411\u540e\u8bad\u7ec3\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u7ea0\u9519\u80fd\u529b\uff0c\u4e3a\u8fed\u4ee3\u9519\u8bef\u4fee\u6b63\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.15605", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.15605", "abs": "https://arxiv.org/abs/2512.15605", "authors": ["Mathieu Blondel", "Michael E. Sander", "Germain Vivier-Ardisson", "Tianlin Liu", "Vincent Roulet"], "title": "Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction", "comment": null, "summary": "Autoregressive models (ARMs) currently constitute the dominant paradigm for large language models (LLMs). Energy-based models (EBMs) represent another class of models, which have historically been less prevalent in LLM development, yet naturally characterize the optimal policy in post-training alignment. In this paper, we provide a unified view of these two model classes. Taking the chain rule of probability as a starting point, we establish an explicit bijection between ARMs and EBMs in function space, which we show to correspond to a special case of the soft Bellman equation in maximum entropy reinforcement learning. Building upon this bijection, we derive the equivalence between supervised learning of ARMs and EBMs. Furthermore, we analyze the distillation of EBMs into ARMs by providing theoretical error bounds. Our results provide insights into the ability of ARMs to plan ahead, despite being based on the next-token prediction paradigm.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u81ea\u56de\u5f52\u6a21\u578b\uff08ARMs\uff09\u4e0e\u80fd\u91cf\u6a21\u578b\uff08EBMs\uff09\u5728\u51fd\u6570\u7a7a\u95f4\u4e2d\u7684\u663e\u5f0f\u53cc\u5c04\u5173\u7cfb\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u76d1\u7763\u5b66\u4e60\u548c\u84b8\u998f\u4e2d\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u89e3\u91ca\u4e86ARMs\u4e3a\u4f55\u80fd\u591f\u8fdb\u884c\u524d\u77bb\u6027\u89c4\u5212\u3002", "motivation": "\u81ea\u56de\u5f52\u6a21\u578b\uff08ARMs\uff09\u662f\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e3b\u5bfc\u8303\u5f0f\uff0c\u800c\u80fd\u91cf\u6a21\u578b\uff08EBMs\uff09\u867d\u7136\u5728LLM\u5f00\u53d1\u4e2d\u8f83\u5c11\u4f7f\u7528\uff0c\u4f46\u81ea\u7136\u5730\u8868\u5f81\u4e86\u540e\u8bad\u7ec3\u5bf9\u9f50\u4e2d\u7684\u6700\u4f18\u7b56\u7565\u3002\u8bba\u6587\u65e8\u5728\u4e3a\u8fd9\u4e24\u7c7b\u6a21\u578b\u63d0\u4f9b\u7edf\u4e00\u89c6\u89d2\uff0c\u7406\u89e3\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u4ee5\u6982\u7387\u94fe\u5f0f\u6cd5\u5219\u4e3a\u8d77\u70b9\uff0c\u5728\u51fd\u6570\u7a7a\u95f4\u4e2d\u5efa\u7acbARMs\u548cEBMs\u4e4b\u95f4\u7684\u663e\u5f0f\u53cc\u5c04\u5173\u7cfb\uff0c\u8bc1\u660e\u8fd9\u5bf9\u5e94\u4e8e\u6700\u5927\u71b5\u5f3a\u5316\u5b66\u4e60\u4e2d\u8f6f\u8d1d\u5c14\u66fc\u65b9\u7a0b\u7684\u7279\u6b8a\u60c5\u51b5\u3002\u57fa\u4e8e\u6b64\u53cc\u5c04\uff0c\u63a8\u5bfcARMs\u548cEBMs\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u5206\u6790EBMs\u84b8\u998f\u5230ARMs\u7684\u7406\u8bba\u8bef\u5dee\u754c\u9650\u3002", "result": "\u5efa\u7acb\u4e86ARMs\u548cEBMs\u4e4b\u95f4\u7684\u6570\u5b66\u7b49\u4ef7\u5173\u7cfb\uff0c\u8bc1\u660e\u4e86\u76d1\u7763\u5b66\u4e60\u7684\u7b49\u4ef7\u6027\uff0c\u63d0\u4f9b\u4e86EBMs\u84b8\u998f\u5230ARMs\u7684\u7406\u8bba\u8bef\u5dee\u754c\u9650\uff0c\u4e3a\u7406\u89e3ARMs\u7684\u524d\u77bb\u89c4\u5212\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aARMs\u548cEBMs\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u4e4b\u95f4\u7684\u6df1\u523b\u8054\u7cfb\uff0c\u89e3\u91ca\u4e86\u57fa\u4e8e\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u7684ARMs\u4e3a\u4f55\u80fd\u591f\u8fdb\u884c\u524d\u77bb\u6027\u89c4\u5212\uff0c\u4e3aLLM\u7684\u7406\u8bba\u7406\u89e3\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2512.15614", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15614", "abs": "https://arxiv.org/abs/2512.15614", "authors": ["Xinshun Feng", "Mingzhe Liu", "Yi Qiao", "Tongyu Zhu", "Leilei Sun", "Shuai Wang"], "title": "Behavior Tokens Speak Louder: Disentangled Explainable Recommendation with Behavior Vocabulary", "comment": "accepted by AAAI 2026", "summary": "Recent advances in explainable recommendations have explored the integration of language models to analyze natural language rationales for user-item interactions. Despite their potential, existing methods often rely on ID-based representations that obscure semantic meaning and impose structural constraints on language models, thereby limiting their applicability in open-ended scenarios. These challenges are intensified by the complex nature of real-world interactions, where diverse user intents are entangled and collaborative signals rarely align with linguistic semantics. To overcome these limitations, we propose BEAT, a unified and transferable framework that tokenizes user and item behaviors into discrete, interpretable sequences. We construct a behavior vocabulary via a vector-quantized autoencoding process that disentangles macro-level interests and micro-level intentions from graph-based representations. We then introduce multi-level semantic supervision to bridge the gap between behavioral signals and language space. A semantic alignment regularization mechanism is designed to embed behavior tokens directly into the input space of frozen language models. Experiments on three public datasets show that BEAT improves zero-shot recommendation performance while generating coherent and informative explanations. Further analysis demonstrates that our behavior tokens capture fine-grained semantics and offer a plug-and-play interface for integrating complex behavior patterns into large language models.", "AI": {"tldr": "BEAT\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u3001\u53ef\u8fc1\u79fb\u7684\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7528\u6237\u548c\u7269\u54c1\u884c\u4e3a\u8f6c\u5316\u4e3a\u79bb\u6563\u3001\u53ef\u89e3\u91ca\u7684\u5e8f\u5217\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u53ef\u89e3\u91ca\u63a8\u8350\u65b9\u6cd5\u5728\u8bed\u4e49\u8868\u8fbe\u548c\u5f00\u653e\u573a\u666f\u9002\u7528\u6027\u65b9\u9762\u7684\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u53ef\u89e3\u91ca\u63a8\u8350\u65b9\u6cd5\u4f9d\u8d56\u57fa\u4e8eID\u7684\u8868\u793a\uff0c\u8fd9\u6a21\u7cca\u4e86\u8bed\u4e49\u542b\u4e49\u5e76\u5bf9\u8bed\u8a00\u6a21\u578b\u65bd\u52a0\u4e86\u7ed3\u6784\u7ea6\u675f\uff0c\u9650\u5236\u4e86\u5728\u5f00\u653e\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u7684\u590d\u6742\u6027\uff08\u7528\u6237\u610f\u56fe\u7ea0\u7f20\u3001\u534f\u4f5c\u4fe1\u53f7\u4e0e\u8bed\u8a00\u8bed\u4e49\u4e0d\u5bf9\u9f50\uff09\u52a0\u5267\u4e86\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51faBEAT\u6846\u67b6\uff1a1) \u901a\u8fc7\u5411\u91cf\u91cf\u5316\u81ea\u7f16\u7801\u8fc7\u7a0b\u6784\u5efa\u884c\u4e3a\u8bcd\u6c47\u8868\uff0c\u4ece\u56fe\u8868\u793a\u4e2d\u89e3\u8026\u5b8f\u89c2\u5174\u8da3\u548c\u5fae\u89c2\u610f\u56fe\uff1b2) \u5f15\u5165\u591a\u7ea7\u8bed\u4e49\u76d1\u7763\u6765\u6865\u63a5\u884c\u4e3a\u4fe1\u53f7\u548c\u8bed\u8a00\u7a7a\u95f4\uff1b3) \u8bbe\u8ba1\u8bed\u4e49\u5bf9\u9f50\u6b63\u5219\u5316\u673a\u5236\uff0c\u5c06\u884c\u4e3a\u6807\u8bb0\u76f4\u63a5\u5d4c\u5165\u5230\u51bb\u7ed3\u8bed\u8a00\u6a21\u578b\u7684\u8f93\u5165\u7a7a\u95f4\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cBEAT\u63d0\u9ad8\u4e86\u96f6\u6837\u672c\u63a8\u8350\u6027\u80fd\uff0c\u540c\u65f6\u751f\u6210\u8fde\u8d2f\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u89e3\u91ca\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u663e\u793a\uff0c\u884c\u4e3a\u6807\u8bb0\u6355\u83b7\u4e86\u7ec6\u7c92\u5ea6\u8bed\u4e49\uff0c\u5e76\u4e3a\u5c06\u590d\u6742\u884c\u4e3a\u6a21\u5f0f\u96c6\u6210\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u63d0\u4f9b\u4e86\u5373\u63d2\u5373\u7528\u63a5\u53e3\u3002", "conclusion": "BEAT\u901a\u8fc7\u5c06\u884c\u4e3a\u8f6c\u5316\u4e3a\u79bb\u6563\u3001\u53ef\u89e3\u91ca\u7684\u6807\u8bb0\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u53ef\u89e3\u91ca\u63a8\u8350\u4e2d\u7684\u8bed\u4e49\u5bf9\u9f50\u95ee\u9898\uff0c\u4e3a\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u96c6\u6210\u590d\u6742\u884c\u4e3a\u6a21\u5f0f\u63d0\u4f9b\u4e86\u7edf\u4e00\u4e14\u53ef\u8fc1\u79fb\u7684\u6846\u67b6\u3002"}}
{"id": "2512.15657", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.15657", "abs": "https://arxiv.org/abs/2512.15657", "authors": ["Tianze Luo", "Haotian Yuan", "Zhuang Liu"], "title": "SoFlow: Solution Flow Models for One-Step Generative Modeling", "comment": "Our code is available at https://github.com/zlab-princeton/SoFlow", "summary": "The multi-step denoising process in diffusion and Flow Matching models causes major efficiency issues, which motivates research on few-step generation. We present Solution Flow Models (SoFlow), a framework for one-step generation from scratch. By analyzing the relationship between the velocity function and the solution function of the velocity ordinary differential equation (ODE), we propose a Flow Matching loss and a solution consistency loss to train our models. The Flow Matching loss allows our models to provide estimated velocity fields for Classifier-Free Guidance (CFG) during training, which improves generation performance. Notably, our consistency loss does not require the calculation of the Jacobian-vector product (JVP), a common requirement in recent works that is not well-optimized in deep learning frameworks like PyTorch. Experimental results indicate that, when trained from scratch using the same Diffusion Transformer (DiT) architecture and an equal number of training epochs, our models achieve better FID-50K scores than MeanFlow models on the ImageNet 256x256 dataset.", "AI": {"tldr": "SoFlow\u6846\u67b6\u901a\u8fc7\u5206\u6790\u901f\u5ea6\u51fd\u6570\u4e0eODE\u89e3\u51fd\u6570\u7684\u5173\u7cfb\uff0c\u63d0\u51faFlow Matching\u635f\u5931\u548c\u89e3\u4e00\u81f4\u6027\u635f\u5931\uff0c\u5b9e\u73b0\u4ece\u96f6\u5f00\u59cb\u7684\u4e00\u6b65\u751f\u6210\uff0c\u65e0\u9700\u8ba1\u7b97Jacobian-vector\u4e58\u79ef\uff0c\u5728ImageNet 256\u00d7256\u4e0a\u4f18\u4e8eMeanFlow\u6a21\u578b\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u548cFlow Matching\u6a21\u578b\u7684\u591a\u6b65\u53bb\u566a\u8fc7\u7a0b\u5b58\u5728\u6548\u7387\u95ee\u9898\uff0c\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7d22\u5c11\u6b65\u751f\u6210\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u751f\u6210\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4ece\u96f6\u5f00\u59cb\u7684\u4e00\u6b65\u751f\u6210\u3002", "method": "\u63d0\u51faSolution Flow Models (SoFlow)\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u901f\u5ea6\u51fd\u6570\u4e0e\u901f\u5ea6\u5e38\u5fae\u5206\u65b9\u7a0b\u89e3\u51fd\u6570\u7684\u5173\u7cfb\uff0c\u8bbe\u8ba1\u4e86Flow Matching\u635f\u5931\u548c\u89e3\u4e00\u81f4\u6027\u635f\u5931\u6765\u8bad\u7ec3\u6a21\u578b\u3002Flow Matching\u635f\u5931\u5141\u8bb8\u6a21\u578b\u5728\u8bad\u7ec3\u671f\u95f4\u4e3aClassifier-Free Guidance\u63d0\u4f9b\u4f30\u8ba1\u7684\u901f\u5ea6\u573a\uff0c\u800c\u4e00\u81f4\u6027\u635f\u5931\u65e0\u9700\u8ba1\u7b97Jacobian-vector\u4e58\u79ef\uff0c\u8fd9\u5728\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e2d\u901a\u5e38\u4f18\u5316\u4e0d\u4f73\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u76f8\u540c\u7684Diffusion Transformer (DiT)\u67b6\u6784\u548c\u76f8\u540c\u8bad\u7ec3\u8f6e\u6570\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u65f6\uff0cSoFlow\u6a21\u578b\u5728ImageNet 256\u00d7256\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u4e86\u6bd4MeanFlow\u6a21\u578b\u66f4\u597d\u7684FID-50K\u5206\u6570\u3002", "conclusion": "SoFlow\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u4e00\u6b65\u751f\u6210\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u907f\u514d\u4e86\u8ba1\u7b97\u590d\u6742\u7684Jacobian-vector\u4e58\u79ef\uff0c\u5728\u56fe\u50cf\u751f\u6210\u8d28\u91cf\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u7684MeanFlow\u6a21\u578b\uff0c\u4e3a\u5c11\u6b65\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.15685", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15685", "abs": "https://arxiv.org/abs/2512.15685", "authors": ["Oleg Melnikov", "Yurii Dorofieiev", "Yurii Shakhnovskiy", "Huy Truong", "Victoria Degeler"], "title": "A Multivariate Statistical Framework for Detection, Classification and Pre-localization of Anomalies in Water Distribution Networks", "comment": "48 pages, 18 figures, 3 tables", "summary": "This paper presents a unified framework, for the detection, classification, and preliminary localization of anomalies in water distribution networks using multivariate statistical analysis. The approach, termed SICAMS (Statistical Identification and Classification of Anomalies in Mahalanobis Space), processes heterogeneous pressure and flow sensor data through a whitening transformation to eliminate spatial correlations among measurements. Based on the transformed data, the Hotelling's $T^2$ statistic is constructed, enabling the formulation of anomaly detection as a statistical hypothesis test of network conformity to normal operating conditions. It is shown that Hotelling's $T^2$ statistic can serve as an integral indicator of the overall \"health\" of the system, exhibiting correlation with total leakage volume, and thereby enabling approximate estimation of water losses via a regression model. A heuristic algorithm is developed to analyze the $T^2$ time series and classify detected anomalies into abrupt leaks, incipient leaks, and sensor malfunctions. Furthermore, a coarse leak localization method is proposed, which ranks sensors according to their statistical contribution and employs Laplacian interpolation to approximate the affected region within the network. Application of the proposed framework to the BattLeDIM L-Town benchmark dataset demonstrates high sensitivity and reliability in leak detection, maintaining robust performance even under multiple leaks. These capabilities make the method applicable to real-world operational environments without the need for a calibrated hydraulic model.", "AI": {"tldr": "SICAMS\u6846\u67b6\u4f7f\u7528\u591a\u5143\u7edf\u8ba1\u5206\u6790\u68c0\u6d4b\u3001\u5206\u7c7b\u548c\u521d\u6b65\u5b9a\u4f4d\u4f9b\u6c34\u7ba1\u7f51\u5f02\u5e38\uff0c\u65e0\u9700\u6821\u51c6\u6c34\u529b\u6a21\u578b\uff0c\u5728BattLeDIM L-Town\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u9ad8\u7075\u654f\u5ea6\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u4f9b\u6c34\u7ba1\u7f51\u4e2d\u7684\u5f02\u5e38\uff08\u5982\u6cc4\u6f0f\u3001\u4f20\u611f\u5668\u6545\u969c\uff09\u68c0\u6d4b\u548c\u5b9a\u4f4d\u5bf9\u4e8e\u51cf\u5c11\u6c34\u8d44\u6e90\u635f\u5931\u548c\u4fdd\u969c\u7cfb\u7edf\u6b63\u5e38\u8fd0\u884c\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u6821\u51c6\u7684\u6c34\u529b\u6a21\u578b\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u6821\u51c6\u6a21\u578b\u3001\u80fd\u5904\u7406\u5f02\u8d28\u4f20\u611f\u5668\u6570\u636e\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51faSICAMS\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u767d\u5316\u53d8\u6362\u6d88\u9664\u538b\u529b\u6d41\u91cf\u4f20\u611f\u5668\u6570\u636e\u7684\u7a7a\u95f4\u76f8\u5173\u6027\uff1b2\uff09\u6784\u5efaHotelling's T\u00b2\u7edf\u8ba1\u91cf\u4f5c\u4e3a\u7cfb\u7edf\u6574\u4f53\"\u5065\u5eb7\"\u6307\u6807\uff1b3\uff09\u5c06\u5f02\u5e38\u68c0\u6d4b\u8f6c\u5316\u4e3a\u7edf\u8ba1\u5047\u8bbe\u68c0\u9a8c\uff1b4\uff09\u5f00\u53d1\u542f\u53d1\u5f0f\u7b97\u6cd5\u5206\u6790T\u00b2\u65f6\u95f4\u5e8f\u5217\uff0c\u5c06\u5f02\u5e38\u5206\u7c7b\u4e3a\u7a81\u53d1\u6cc4\u6f0f\u3001\u6e10\u8fdb\u6cc4\u6f0f\u548c\u4f20\u611f\u5668\u6545\u969c\uff1b5\uff09\u63d0\u51fa\u7c97\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u6839\u636e\u7edf\u8ba1\u8d21\u732e\u5ea6\u6392\u5e8f\u4f20\u611f\u5668\uff0c\u4f7f\u7528\u62c9\u666e\u62c9\u65af\u63d2\u503c\u8fd1\u4f3c\u53d7\u5f71\u54cd\u533a\u57df\u3002", "result": "\u5728BattLeDIM L-Town\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5e94\u7528\u663e\u793a\uff1a1\uff09\u6cc4\u6f0f\u68c0\u6d4b\u5177\u6709\u9ad8\u7075\u654f\u5ea6\u548c\u53ef\u9760\u6027\uff1b2\uff09\u5373\u4f7f\u5728\u591a\u91cd\u6cc4\u6f0f\u60c5\u51b5\u4e0b\u4ecd\u4fdd\u6301\u7a33\u5065\u6027\u80fd\uff1b3\uff09T\u00b2\u7edf\u8ba1\u91cf\u4e0e\u603b\u6cc4\u6f0f\u91cf\u76f8\u5173\uff0c\u53ef\u901a\u8fc7\u56de\u5f52\u6a21\u578b\u8fd1\u4f3c\u4f30\u8ba1\u6c34\u635f\u5931\uff1b4\uff09\u80fd\u591f\u6709\u6548\u5206\u7c7b\u4e0d\u540c\u7c7b\u578b\u5f02\u5e38\uff1b5\uff09\u63d0\u4f9b\u7c97\u5b9a\u4f4d\u80fd\u529b\u3002", "conclusion": "SICAMS\u6846\u67b6\u4e3a\u4f9b\u6c34\u7ba1\u7f51\u5f02\u5e38\u68c0\u6d4b\u3001\u5206\u7c7b\u548c\u521d\u6b65\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7edf\u8ba1\u65b9\u6cd5\uff0c\u65e0\u9700\u6821\u51c6\u6c34\u529b\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u8fd0\u884c\u73af\u5883\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.15691", "categories": ["cs.LG", "cs.IT", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15691", "abs": "https://arxiv.org/abs/2512.15691", "authors": ["Matin Mortaheb", "Erciyes Karakaya", "Sennur Ulukus"], "title": "Multi-Modal Semantic Communication", "comment": null, "summary": "Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to identify informative regions within images, but they often struggle in complex scenes with multiple objects, where self-attention lacks explicit task guidance. To address this, we propose a novel Multi-Modal Semantic Communication framework that integrates text-based user queries to guide the information extraction process. Our proposed system employs a cross-modal attention mechanism that fuses visual features with language embeddings to produce soft relevance scores over the visual data. Based on these scores and the instantaneous channel bandwidth, we use an algorithm to transmit image patches at adaptive resolutions using independently trained encoder-decoder pairs, with total bitrate matching the channel capacity. At the receiver, the patches are reconstructed and combined to preserve task-critical information. This flexible and goal-driven design enables efficient semantic communication in complex and bandwidth-constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u6a21\u6001\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u6587\u672c\u67e5\u8be2\u5f15\u5bfc\u89c6\u89c9\u4fe1\u606f\u63d0\u53d6\uff0c\u4f7f\u7528\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u751f\u6210\u8f6f\u76f8\u5173\u6027\u5206\u6570\uff0c\u6839\u636e\u4fe1\u9053\u5e26\u5bbd\u81ea\u9002\u5e94\u4f20\u8f93\u4e0d\u540c\u5206\u8fa8\u7387\u7684\u56fe\u50cf\u5757\uff0c\u5b9e\u73b0\u4efb\u52a1\u9a71\u52a8\u7684\u8bed\u4e49\u901a\u4fe1\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8etransformer\u7684\u81ea\u6ce8\u610f\u529b\u65b9\u6cd5\u5728\u590d\u6742\u591a\u7269\u4f53\u573a\u666f\u4e2d\u7f3a\u4e4f\u660e\u786e\u7684\u4efb\u52a1\u6307\u5bfc\uff0c\u96be\u4ee5\u6709\u6548\u8bc6\u522b\u5173\u952e\u4fe1\u606f\u533a\u57df\u3002\u4e3a\u4e86\u5728\u5e26\u5bbd\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u8bed\u4e49\u901a\u4fe1\uff0c\u9700\u8981\u7ed3\u5408\u7528\u6237\u67e5\u8be2\u6765\u5f15\u5bfc\u4fe1\u606f\u63d0\u53d6\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u96c6\u6210\u6587\u672c\u67e5\u8be2\u5f15\u5bfc\u4fe1\u606f\u63d0\u53d6\uff1b\u4f7f\u7528\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u89c6\u89c9\u7279\u5f81\u548c\u8bed\u8a00\u5d4c\u5165\uff0c\u751f\u6210\u8f6f\u76f8\u5173\u6027\u5206\u6570\uff1b\u57fa\u4e8e\u5206\u6570\u548c\u77ac\u65f6\u4fe1\u9053\u5e26\u5bbd\uff0c\u91c7\u7528\u7b97\u6cd5\u81ea\u9002\u5e94\u4f20\u8f93\u4e0d\u540c\u5206\u8fa8\u7387\u7684\u56fe\u50cf\u5757\uff1b\u4f7f\u7528\u72ec\u7acb\u8bad\u7ec3\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u5bf9\uff0c\u603b\u6bd4\u7279\u7387\u5339\u914d\u4fe1\u9053\u5bb9\u91cf\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u5728\u590d\u6742\u573a\u666f\u4e2d\u6839\u636e\u7528\u6237\u67e5\u8be2\u6709\u6548\u8bc6\u522b\u4efb\u52a1\u5173\u952e\u4fe1\u606f\uff0c\u81ea\u9002\u5e94\u8c03\u6574\u4f20\u8f93\u7b56\u7565\uff0c\u5728\u5e26\u5bbd\u53d7\u9650\u73af\u5883\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u8bed\u4e49\u901a\u4fe1\uff0c\u4fdd\u6301\u4efb\u52a1\u5173\u952e\u4fe1\u606f\u7684\u5b8c\u6574\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6587\u672c\u67e5\u8be2\u5f15\u5bfc\u7684\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u548c\u81ea\u9002\u5e94\u5206\u8fa8\u7387\u4f20\u8f93\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u7075\u6d3b\u3001\u76ee\u6807\u9a71\u52a8\u7684\u8bed\u4e49\u901a\u4fe1\u8bbe\u8ba1\uff0c\u7279\u522b\u9002\u7528\u4e8e\u590d\u6742\u548c\u5e26\u5bbd\u53d7\u9650\u73af\u5883\u4e2d\u7684\u9ad8\u6548\u901a\u4fe1\u5e94\u7528\u3002"}}
{"id": "2512.15699", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.15699", "abs": "https://arxiv.org/abs/2512.15699", "authors": ["Qiuyang Mang", "Wenhao Chai", "Zhifei Li", "Huanzhi Mao", "Shang Zhou", "Alexander Du", "Hanchen Li", "Shu Liu", "Edwin Chen", "Yichuan Wang", "Xieting Chu", "Zerui Cheng", "Yuan Xu", "Tian Xia", "Zirui Wang", "Tianneng Shi", "Jianzhu Yao", "Yilong Zhao", "Qizheng Zhang", "Charlie Ruan", "Zeyu Shen", "Kaiyuan Liu", "Runyuan He", "Dong Xing", "Zerui Li", "Zirong Zeng", "Yige Jiang", "Lufeng Cheng", "Ziyi Zhao", "Youran Sun", "Wesley Zheng", "Meiyuwang Zhang", "Ruyi Ji", "Xuechang Tu", "Zihan Zheng", "Zexing Chen", "Kangyang Zhou", "Zhaozi Wang", "Jingbang Chen", "Aleksandra Korolova", "Peter Henderson", "Pramod Viswanath", "Vijay Ganesh", "Saining Xie", "Zhuang Liu", "Dawn Song", "Sewon Min", "Ion Stoica", "Joseph E. Gonzalez", "Jingbo Shang", "Alvin Cheung"], "title": "FrontierCS: Evolving Challenges for Evolving Intelligence", "comment": "Code with instruction: https://github.com/FrontierCS/Frontier-CS", "summary": "We introduce FrontierCS, a benchmark of 156 open-ended problems across diverse areas of computer science, designed and reviewed by experts, including CS PhDs and top-tier competitive programming participants and problem setters. Unlike existing benchmarks that focus on tasks with known optimal solutions, FrontierCS targets problems where the optimal solution is unknown, but the quality of a solution can be objectively evaluated. Models solve these tasks by implementing executable programs rather than outputting a direct answer. FrontierCS includes algorithmic problems, which are often NP-hard variants of competitive programming problems with objective partial scoring, and research problems with the same property. For each problem we provide an expert reference solution and an automatic evaluator. Combining open-ended design, measurable progress, and expert curation, FrontierCS provides a benchmark at the frontier of computer-science difficulty. Empirically, we find that frontier reasoning models still lag far behind human experts on both the algorithmic and research tracks, that increasing reasoning budgets alone does not close this gap, and that models often over-optimize for generating merely workable code instead of discovering high-quality algorithms and system designs.", "AI": {"tldr": "FrontierCS\u662f\u4e00\u4e2a\u5305\u542b156\u4e2a\u5f00\u653e\u5f0f\u8ba1\u7b97\u673a\u79d1\u5b66\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8fd9\u4e9b\u95ee\u9898\u7531\u4e13\u5bb6\u8bbe\u8ba1\uff0c\u65e8\u5728\u8bc4\u4f30\u6a21\u578b\u5728\u672a\u77e5\u6700\u4f18\u89e3\u4f46\u53ef\u5ba2\u89c2\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u7684\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u5df2\u77e5\u6700\u4f18\u89e3\u7684\u4efb\u52a1\uff0c\u800c\u8ba1\u7b97\u673a\u79d1\u5b66\u524d\u6cbf\u5f80\u5f80\u6d89\u53ca\u672a\u77e5\u6700\u4f18\u89e3\u7684\u95ee\u9898\u3002\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u8fd9\u4e9b\u5f00\u653e\u5f0f\u3001\u524d\u6cbf\u8ba1\u7b97\u673a\u79d1\u5b66\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u80fd\u529b\u3002", "method": "\u521b\u5efa\u4e86\u5305\u542b156\u4e2a\u5f00\u653e\u5f0f\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u7b97\u6cd5\u95ee\u9898\u548c\u7814\u7a76\u95ee\u9898\u3002\u6bcf\u4e2a\u95ee\u9898\u90fd\u63d0\u4f9b\u4e13\u5bb6\u53c2\u8003\u89e3\u51b3\u65b9\u6848\u548c\u81ea\u52a8\u8bc4\u4f30\u5668\u3002\u6a21\u578b\u901a\u8fc7\u5b9e\u73b0\u53ef\u6267\u884c\u7a0b\u5e8f\u800c\u975e\u76f4\u63a5\u8f93\u51fa\u7b54\u6848\u6765\u89e3\u51b3\u95ee\u9898\u3002", "result": "\u524d\u6cbf\u63a8\u7406\u6a21\u578b\u5728\u7b97\u6cd5\u548c\u7814\u7a76\u4e24\u4e2a\u8f68\u9053\u4e0a\u90fd\u8fdc\u8fdc\u843d\u540e\u4e8e\u4eba\u7c7b\u4e13\u5bb6\uff1b\u4ec5\u589e\u52a0\u63a8\u7406\u9884\u7b97\u65e0\u6cd5\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\uff1b\u6a21\u578b\u5f80\u5f80\u8fc7\u5ea6\u4f18\u5316\u751f\u6210\u4ec5\u80fd\u5de5\u4f5c\u7684\u4ee3\u7801\uff0c\u800c\u4e0d\u662f\u53d1\u73b0\u9ad8\u8d28\u91cf\u7684\u7b97\u6cd5\u548c\u7cfb\u7edf\u8bbe\u8ba1\u3002", "conclusion": "FrontierCS\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4f4d\u4e8e\u8ba1\u7b97\u673a\u79d1\u5b66\u96be\u5ea6\u524d\u6cbf\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u89e3\u51b3\u5f00\u653e\u5f0f\u8ba1\u7b97\u673a\u79d1\u5b66\u95ee\u9898\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u8868\u660e\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u6a21\u578b\u5728\u8fd9\u4e9b\u524d\u6cbf\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002"}}
