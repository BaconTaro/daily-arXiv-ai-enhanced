<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Querying Labeled Time Series Data with Scenario Programs](https://arxiv.org/abs/2511.10627)
*Edward Kim,Devan Shanker,Varun Bharadwaj,Hongbeen Park,Jinkyu Kim,Hazem Torfah,Daniel J Fremont,Sanjit A Seshia*

Main category: cs.AI

TL;DR: 本文提出了一种验证模拟环境中发现的自动驾驶故障场景在真实世界中可重现性的方法，通过定义场景匹配的正式规范，开发了在真实世界数据集中查询匹配场景的高效算法。


<details>
  <summary>Details</summary>
Motivation: 解决仿真测试中发现的自动驾驶故障场景是否能在真实世界中重现的问题，弥补仿真与现实之间的差距，确保仿真测试结果的有效性。

Method: 引入场景匹配的正式定义，使用Scenic概率编程语言表示抽象场景，开发查询算法在标注的时间序列传感器数据中识别匹配指定场景的数据子集。

Result: 实验表明，该算法比最先进的商业视觉大语言模型更准确，查询速度提高数个数量级，并且能够随着查询时间序列数据长度的增加而扩展。

Conclusion: 提出的方法能够有效验证仿真发现的故障场景在真实世界中的可重现性，为仿真测试结果的有效性验证提供了实用工具。

Abstract: Simulation-based testing has become a crucial complement to road testing for ensuring the safety of cyber physical systems (CPS). As a result, significant research efforts have been directed toward identifying failure scenarios within simulation environments. However, a critical question remains. Are the AV failure scenarios discovered in simulation reproducible on actual systems in the real world? The sim-to-real gap caused by differences between simulated and real sensor data means that failure scenarios identified in simulation might either be artifacts of synthetic sensor data or actual issues that also occur with real sensor data. To address this, an effective approach to validating simulated failure scenarios is to locate occurrences of these scenarios within real-world datasets and verify whether the failure persists on the datasets. To this end, we introduce a formal definition of how labeled time series sensor data can match an abstract scenario, represented as a scenario program using the Scenic probabilistic programming language. We present a querying algorithm that, given a scenario program and a labeled dataset, identifies the subset of data that matches the specified scenario. Our experiment shows that our algorithm is more accurate and orders of magnitude faster in querying scenarios than the state-of-the-art commercial vision large language models, and can scale with the duration of queried time series data.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Algorithm Design and Stronger Guarantees for the Improving Multi-Armed Bandits Problem](https://arxiv.org/abs/2511.10619)
*Avrim Blum,Marten Garicano,Kavya Ravichandran,Dravyansh Sharma*

Main category: cs.LG

TL;DR: 本文提出了两个参数化的多臂老虎机算法族，通过离线数据学习近最优算法，在满足特定凹性条件的奖励曲线下获得更强的性能保证，同时保证在良好实例上的最优臂识别和恶劣实例上的最坏情况保证。


<details>
  <summary>Details</summary>
Motivation: 改进型多臂老虎机问题用于在不确定性下分配努力，如技术投资、临床试验等场景。现有算法的最坏情况性能保证较为悲观，存在Ω(k)和Ω(√k)的下界。本文旨在通过参数化算法族和数据依赖分析获得更强的性能保证。

Method: 提出了两个参数化算法族：第一个包含先前工作中的最优随机算法，在奖励曲线满足额外凹性性质时可获得更强的k依赖保证；第二个算法族保证在良好实例上识别最优臂，在恶劣实例上回退到最坏情况保证。采用统计学习视角，通过离线数据学习近最优算法。

Result: 展示了从第一个算法族中适当选择的算法可以在奖励曲线满足特定凹性条件时获得更强的性能保证，具有最优的k依赖。第二个算法族实现了数据依赖的保证，无需验证假设是否满足。

Conclusion: 通过参数化算法族和统计学习视角，本文在改进型多臂老虎机问题上获得了比现有工作更强的数据依赖性能保证，特别是在奖励曲线满足额外性质时能够突破已知下界限制。

Abstract: The improving multi-armed bandits problem is a formal model for allocating effort under uncertainty, motivated by scenarios such as investing research effort into new technologies, performing clinical trials, and hyperparameter selection from learning curves. Each pull of an arm provides reward that increases monotonically with diminishing returns. A growing line of work has designed algorithms for improving bandits, albeit with somewhat pessimistic worst-case guarantees. Indeed, strong lower bounds of $Ω(k)$ and $Ω(\sqrt{k})$ multiplicative approximation factors are known for both deterministic and randomized algorithms (respectively) relative to the optimal arm, where $k$ is the number of bandit arms. In this work, we propose two new parameterized families of bandit algorithms and bound the sample complexity of learning the near-optimal algorithm from each family using offline data. The first family we define includes the optimal randomized algorithm from prior work. We show that an appropriately chosen algorithm from this family can achieve stronger guarantees, with optimal dependence on $k$, when the arm reward curves satisfy additional properties related to the strength of concavity. Our second family contains algorithms that both guarantee best-arm identification on well-behaved instances and revert to worst case guarantees on poorly-behaved instances. Taking a statistical learning perspective on the bandit rewards optimization problem, we achieve stronger data-dependent guarantees without the need for actually verifying whether the assumptions are satisfied.

</details>
