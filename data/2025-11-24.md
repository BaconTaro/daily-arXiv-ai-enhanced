<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 11]
- [cs.HC](#cs.HC) [Total: 6]
- [cs.LG](#cs.LG) [Total: 36]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Stable diffusion models reveal a persisting human and AI gap in visual creativity](https://arxiv.org/abs/2511.16814)
*Silvia Rondini,Claudia Alvarez-Martin,Paula Angermair-Barkai,Olivier Penacchio,M. Paz,Matthew Pelowski,Dan Dediu,Antoni Rodriguez-Fornells,Xim Cerda-Company*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two prompting conditions with varying human input: high for Human Inspired, low for Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the resulting images. We found a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. Increased human guidance strongly improved GenAI's creative output, bringing its productions close to those of Non Artists. Notably, human and AI raters also showed vastly different creativity judgment patterns. These results suggest that, in contrast to language centered tasks, GenAI models may face unique challenges in visual domains, where creativity depends on perceptual nuance and contextual sensitivity, distinctly human capacities that may not be readily transferable from language models.

</details>


### [2] [Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs](https://arxiv.org/abs/2511.16837)
*Oliver Kramer*

Main category: cs.AI

TL;DR: Cognitive BASIC是一种基于BASIC风格的最小化提示语言和模型内解释器，将大语言模型的推理过程结构化，形成显式的逐步执行轨迹。


<details>
  <summary>Details</summary>
Motivation: 受复古BASIC简单性的启发，重新利用编号行和简单命令作为可解释的认知控制层，使现代LLM能够可靠地模拟这类短程序，实现模型内部透明的多步推理。

Method: 使用自然语言解释器文件指定命令语义、内存更新和日志行为，通过心智模型解释器提取声明性和程序性知识，检测矛盾并在必要时产生解决方案。

Result: 在三个LLM上对知识提取、冲突检测和推理任务的基准测试表明，所有模型都能执行Cognitive BASIC程序，整体表现强劲但不统一。

Conclusion: Cognitive BASIC为LLM推理提供了结构化的认知控制框架，实现了透明且可解释的多步推理过程。

Abstract: Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines and simple commands as an interpretable cognitive control layer. Modern LLMs can reliably simulate such short programs, enabling transparent multi-step reasoning inside the model. A natural-language interpreter file specifies command semantics, memory updates, and logging behavior. Our mental-model interpreter extracts declarative and procedural knowledge, detects contradictions, and produces resolutions when necessary. A comparison across three LLMs on a benchmark of knowledge extraction, conflict detection, and reasoning tasks shows that all models can execute Cognitive BASIC programs, with overall strong but not uniform performance.

</details>


### [3] [Fantastic Bugs and Where to Find Them in AI Benchmarks](https://arxiv.org/abs/2511.16842)
*Sang Truong,Yuheng Tu,Michael Hardy,Anka Reuel,Zeyu Tang,Jirayu Burapacheep,Jonathan Perera,Chibuike Uwakwe,Ben Domingue,Nick Haber,Sanmi Koyejo*

Main category: cs.AI

TL;DR: 提出了一个系统性基准修订框架，利用响应模式的统计分析来标记潜在无效问题，结合LLM法官初步审查，显著减少人工工作量。


<details>
  <summary>Details</summary>
Motivation: 基准测试对AI进展至关重要，但无效基准问题经常破坏其可靠性。手动识别和纠正数千个基准问题中的错误既不可行，也是可靠评估的关键瓶颈。

Method: 基于AI评估中常用的核心假设——平均分足以概括模型性能，构建统计分析方法。当项目统计量的经验估计值超出预期范围时，该项目更可能存在问题。结合LLM法官进行初步审查。

Result: 在九个广泛使用的基准测试中，该方法指导专家审查识别问题问题的精度高达84%。LLM法官初步审查进一步减少了人工工作量。

Conclusion: 该框架为系统性基准修订提供了高效且可扩展的解决方案，显著提高了基准测试的可靠性。

Abstract: Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottleneck for reliable evaluation. In this work, we introduce a framework for systematic benchmark revision that leverages statistical analysis of response patterns to flag potentially invalid questions for further expert review. Our approach builds on a core assumption commonly used in AI evaluations that the mean score sufficiently summarizes model performance. This implies a unidimensional latent construct underlying the measurement experiment, yielding expected ranges for various statistics for each item. When empirically estimated values for these statistics fall outside the expected range for an item, the item is more likely to be problematic. Across nine widely used benchmarks, our method guides expert review to identify problematic questions with up to 84\% precision. In addition, we introduce an LLM-judge first pass to review questions, further reducing human effort. Together, these components provide an efficient and scalable framework for systematic benchmark revision.

</details>


### [4] [Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving](https://arxiv.org/abs/2511.16916)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种混合差分奖励机制来解决多车辆协同驾驶中传统基于状态的奖励函数存在的奖励差异消失问题，该机制结合了基于全局势函数的时序差分奖励和直接测量动作边际效用的动作梯度奖励。


<details>
  <summary>Details</summary>
Motivation: 在多车辆协同驾驶任务中，传统基于状态的奖励函数存在奖励差异消失问题，导致策略梯度的信噪比低，严重影响算法收敛和性能提升。

Method: 提出混合差分奖励机制，包含两个互补组件：基于全局势函数的时序差分奖励，利用势能演化趋势确保最优策略不变性和长期目标一致性；动作梯度奖励，直接测量动作的边际效用以提供高信噪比的局部指导信号。

Result: 通过在线规划和多智能体强化学习算法的广泛实验表明，HDR机制显著提高了收敛速度和策略稳定性，引导智能体学习到平衡交通效率和安全的高质量协同策略。

Conclusion: HDR机制有效解决了多车辆协同驾驶中奖励信号失效的问题，为高频率连续控制任务提供了有效的奖励设计方法。

Abstract: In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for policy gradients, significantly hindering algorithm convergence and performance improvement. To address this challenge, this paper proposes a novel Hybrid Differential Reward (HDR) mechanism. We first theoretically elucidate how the temporal quasi-steady nature of traffic states and the physical proximity of actions lead to the failure of traditional reward signals. Building on this analysis, the HDR framework innovatively integrates two complementary components: (1) a Temporal Difference Reward (TRD) based on a global potential function, which utilizes the evolutionary trend of potential energy to ensure optimal policy invariance and consistency with long-term objectives; and (2) an Action Gradient Reward (ARG), which directly measures the marginal utility of actions to provide a local guidance signal with a high SNR. Furthermore, we formulate the cooperative driving problem as a Multi-Agent Partially Observable Markov Game (POMDPG) with a time-varying agent set and provide a complete instantiation scheme for HDR within this framework. Extensive experiments conducted using both online planning (MCTS) and Multi-Agent Reinforcement Learning (QMIX, MAPPO, MADDPG) algorithms demonstrate that the HDR mechanism significantly improves convergence speed and policy stability. The results confirm that HDR guides agents to learn high-quality cooperative policies that effectively balance traffic efficiency and safety.

</details>


### [5] [MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists](https://arxiv.org/abs/2511.16997)
*Qingbin Zeng,Bingbing Fan,Zhiyu Chen,Sijian Ren,Zhilun Zhou,Xuhua Zhang,Yuanyi Zhen,Fengli Xu,Yong Li,Tie-Yan Liu*

Main category: cs.AI

TL;DR: MirrorMind是一个分层认知架构，通过整合双记忆表示来解决AI科学家在科学发现中的局限性，将个体认知轨迹与集体学科记忆相结合，实现结构化的科学推理。


<details>
  <summary>Details</summary>
Motivation: 现有AI科学方法将科学发现视为孤立的优化过程，忽视了知识生产的社会性和历史性本质。人类科学洞察来自个体认知轨迹和集体学科记忆两个相互关联的来源，而现有LLM难以表示这些结构化的认知和社会背景。

Method: 提出MirrorMind分层认知架构：个体层面构建研究者的认知模型（情景、语义、人格记忆）；领域层面将集体知识映射为结构化学科概念图；跨学科层面作为正交编排引擎。该架构将记忆存储与智能执行分离。

Result: 在四个综合任务中评估MirrorMind：作者级认知模拟、互补推理、跨学科合作促进、多智能体科学问题解决。结果表明MirrorMind超越了简单事实检索，实现了结构化、个性化和洞察生成的科学推理。

Conclusion: 通过整合个体认知深度与集体学科广度，MirrorMind能够实现更具结构性和洞察力的科学推理，为AI科学家提供了更接近人类科学发现过程的认知架构。

Abstract: The emergence of AI Scientists has demonstrated remarkable potential in automating scientific research. However, current approaches largely conceptualize scientific discovery as a solitary optimization or search process, overlooking that knowledge production is inherently a social and historical endeavor. Human scientific insight stems from two distinct yet interconnected sources. First is the individual cognitive trajectory, where a researcher's unique insight is shaped by their evolving research history and stylistic preferences; another is the collective disciplinary memory, where knowledge is sedimented into vast, interconnected networks of citations and concepts. Existing LLMs still struggle to represent these structured, high-fidelity cognitive and social contexts. To bridge this gap, we introduce MirrorMind, a hierarchical cognitive architecture that integrates dual-memory representations within a three-level framework. The Individual Level constructs high-fidelity cognitive models of individual researchers by capturing their episodic, semantic, and persona memories; the Domain Level maps collective knowledge into structured disciplinary concept graphs; and the Interdisciplinary Level that acts as an orthogonal orchestration engine. Crucially, our architecture separates memory storage from agentic execution, enabling AI scientist agents to flexibly access individual memories for unique perspectives or collective structures to reason. We evaluate MirrorMind across four comprehensive tasks, including author-level cognitive simulation, complementary reasoning, cross-disciplinary collaboration promotion, and multi-agent scientific problem solving. The results show that by integrating individual cognitive depth with collective disciplinary breadth, MirrorMind moves beyond simple fact retrieval toward structural, personalized, and insight-generating scientific reasoning.

</details>


### [6] [DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing](https://arxiv.org/abs/2511.17038)
*Hao Chen,Renzheng Zhang,Scott S. Howard*

Main category: cs.AI

TL;DR: 论文重新解释了扩散模型在逆问题求解中的作用，提出DAPS++方法将扩散阶段与数据驱动优化解耦，显著提高了计算效率和重建性能。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯视角下的基于分数的扩散方法无法解释实际行为：先验提供有限指导，重建主要由测量一致性项驱动，导致推理过程与扩散动力学脱节。

Method: 将扩散重新解释为期望最大化框架中的初始化阶段，引入DAPS++方法，让似然项更直接地指导推理，同时保持数值稳定性。

Result: DAPS++需要更少的函数评估和测量优化步骤，在多种图像恢复任务中实现了高计算效率和鲁棒的重建性能。

Conclusion: 扩散在逆问题求解中的主要作用是提供初始化，DAPS++通过解耦扩散和数据驱动优化，为统一扩散轨迹的有效性提供了理论解释。

Abstract: From a Bayesian perspective, score-based diffusion solves inverse problems through joint inference, embedding the likelihood with the prior to guide the sampling process. However, this formulation fails to explain its practical behavior: the prior offers limited guidance, while reconstruction is largely driven by the measurement-consistency term, leading to an inference process that is effectively decoupled from the diffusion dynamics. To clarify this structure, we reinterpret the role of diffusion in inverse problem solving as an initialization stage within an expectation--maximization (EM)--style framework, where the diffusion stage and the data-driven refinement are fully decoupled. We introduce \textbf{DAPS++}, which allows the likelihood term to guide inference more directly while maintaining numerical stability and providing insight into why unified diffusion trajectories remain effective in practice. By requiring fewer function evaluations (NFEs) and measurement-optimization steps, \textbf{DAPS++} achieves high computational efficiency and robust reconstruction performance across diverse image restoration tasks.

</details>


### [7] [MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward](https://arxiv.org/abs/2511.17165)
*Kesheng Chen,Wenjian Luo,Bang Zhang,Zeping Yin,Zipeng Ye*

Main category: cs.AI

TL;DR: 本文提出了一种名为MIR的相互内在奖励方法，用于解决多智能体强化学习中稀疏奖励（特别是情节奖励）的挑战。该方法通过激励智能体探索影响队友的行为，结合原始策略有效促进团队探索并提升算法性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的情节奖励面临两个主要挑战：联合行动轨迹的指数级稀疏性，以及现有方法未能充分考虑影响团队状态的联合行动。

Method: 提出MIR方法，激励个体智能体探索能够影响队友的行为，并将该方法与原始策略相结合。同时创建了MiniGrid-MA环境用于实验验证。

Result: 在MiniGrid-MA环境中与最先进方法进行比较，实验结果显示所提方法具有优越性能。

Conclusion: MIR是一种简单有效的增强策略，能够有效解决多智能体强化学习中稀疏奖励问题，促进团队探索并提升算法性能。

Abstract: Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods have demonstrated effectiveness in single-agent rein-forcement learning scenarios, their application to multi-agent reinforcement learn-ing (MARL) remains problematic. The primary difficulties stem from two fac-tors: (1) the exponential sparsity of joint action trajectories that lead to rewards as the exploration space expands, and (2) existing methods often fail to account for joint actions that can influence team states. To address these challenges, this paper introduces Mutual Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL with extremely sparse rewards like episodic rewards. MIR incentivizes individual agents to explore actions that affect their teammates, and when combined with original strategies, effectively stimulates team exploration and improves algorithm performance. For comprehensive experimental valida-tion, we extend the representative single-agent MiniGrid environment to create MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation compares the proposed method against state-of-the-art approaches in the MiniGrid-MA setting, with experimental results demonstrating superior perfor-mance.

</details>


### [8] [Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism](https://arxiv.org/abs/2511.17198)
*Kaiyu Li,Jiayu Wang,Zhi Wang,Hui Qiao,Weizhan Zhang,Deyu Meng,Xiangyong Cao*

Main category: cs.AI

TL;DR: 本文提出了HTAM框架，通过分层任务抽象机制构建面向专业领域（如遥感）的多智能体系统，解决了通用智能体在需要严格结构化工作流程的专业领域中表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 通用智能体框架（如ReAct或角色扮演）在需要专门工具和多步骤程序的专业领域（如遥感）中表现不佳，因为这些领域要求严格的结构化工作流程。

Method: 引入分层任务抽象机制（HTAM），将多智能体系统构建为逻辑层次结构，反映特定领域的任务依赖图，将复杂问题分解为顺序层，每层子智能体在前一层输出上操作。

Result: 基于HTAM构建的EarthAgent在复杂地理空间分析中显著优于现有的单智能体和多智能体系统，在GeoPlan-bench基准测试中表现出色。

Conclusion: 将智能体架构与领域固有任务结构对齐是构建鲁棒可靠专业自主系统的关键步骤。

Abstract: LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.

</details>


### [9] [Agentifying Agentic AI](https://arxiv.org/abs/2511.17332)
*Virginia Dignum,Frank Dignum*

Main category: cs.AI

TL;DR: 本文主张AAMAS社区开发的BDI架构、通信协议、机制设计和制度建模等概念工具为智能体AI提供了认知、合作和治理的明确模型基础，旨在实现既具备能力又透明、合作和可问责的智能体系统。


<details>
  <summary>Details</summary>
Motivation: 智能体AI需要持续的自主性、推理和交互能力，但必须辅以明确的认知、合作和治理模型来实现这一愿景。

Method: 利用AAMAS社区开发的概念工具，包括BDI架构、通信协议、机制设计和制度建模，将自适应数据驱动方法与结构化推理和协调模型相结合。

Result: 提出了一个连接形式理论和实践自主性的智能体视角，为构建既具备能力又透明、合作和可问责的智能体系统奠定了基础。

Conclusion: 通过将自适应方法与结构化模型对齐，可以构建不仅能力强且灵活，而且透明、合作和可问责的智能体系统，从而在形式理论和实践自主性之间架起桥梁。

Abstract: Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize this vision, its assumptions about agency must be complemented by explicit models of cognition, cooperation, and governance. This paper argues that the conceptual tools developed within the Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI architectures, communication protocols, mechanism design, and institutional modelling, provide precisely such a foundation. By aligning adaptive, data-driven approaches with structured models of reasoning and coordination, we outline a path toward agentic systems that are not only capable and flexible, but also transparent, cooperative, and accountable. The result is a perspective on agency that bridges formal theory and practical autonomy.

</details>


### [10] [That's not natural: The Impact of Off-Policy Training Data on Probe Performance](https://arxiv.org/abs/2511.17408)
*Nathalie Kirch,Samuel Dower,Adrians Skapars,Ekdeep Singh Lubana,Dmitrii Krasheninnikov*

Main category: cs.AI

TL;DR: 本文系统评估了使用合成数据和离策略数据对LLM行为探测泛化性能的影响，发现在缺乏同策略数据时，使用同域离策略数据比不同域同策略数据更可靠，且训练数据域偏移会导致更大性能下降。


<details>
  <summary>Details</summary>
Motivation: 由于许多LLM行为的自然示例稀少，研究人员不得不依赖合成或离策略的LLM响应来训练探测模型，但这种方法对探测泛化性能的影响尚不清楚。

Method: 在八个不同的LLM行为上测试线性和注意力探测模型，比较不同响应生成策略对探测性能的影响，评估从离策略数据到同策略数据的泛化能力。

Result: 响应生成策略显著影响探测性能，但影响程度因行为而异；从离策略数据到激励产生目标行为的测试集的成功泛化可预测同策略泛化成功；训练数据域偏移导致的性能下降比策略偏移更大。

Conclusion: 在缺乏同策略数据时，使用同域离策略数据比不同域同策略数据产生更可靠的探测模型，强调了需要更好处理LLM监控中分布偏移的方法。

Abstract: Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time detection of concerning behaviours such as deception and sycophancy. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how the use of synthetic and off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention probes across multiple LLMs, we find that the response generation strategy can significantly affect probe performance, though the magnitude of this effect varies by behaviour. We find that successful generalisation from off-policy data, to test sets where the model is incentivised to produce the target behaviour, is predictive of successful on-policy generalisation. Leveraging this result, we predict that Deception and Sandbagging probes may fail to generalise from off-policy to on-policy data when used in real monitoring scenarios. Notably, shifts in the training data domain still cause even larger performance degradation, with different-domain test scores being consistently lower than the same-domain ones. These results indicate that, in the absence of on-policy data, using same-domain off-policy data yields more reliable probes than using on-policy data from a different domain, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.

</details>


### [11] [SRA-CP: Spontaneous Risk-Aware Selective Cooperative Perception](https://arxiv.org/abs/2511.17461)
*Jiaxi Liu,Chengyuan Ma,Hang Zhou,Weizhe Tang,Shixiao Liang,Haoyang Ding,Xiaopeng Li,Bin Ran*

Main category: cs.AI

TL;DR: 提出SRA-CP框架，通过风险感知的选择性协作感知，在保持安全关键对象检测精度的同时，仅使用20%通信带宽，相比无风险感知的选择性CP方法性能提升15%。


<details>
  <summary>Details</summary>
Motivation: 现有通用CP方法传输大量与驾驶安全无关的感知数据，超出可用通信带宽，且依赖预定义通信伙伴，不适合动态交通环境。

Method: 采用去中心化协议，车辆持续广播轻量级感知覆盖摘要，仅在检测到风险相关盲区时启动针对性协作。包含感知风险识别模块和选择性信息交换融合模块。

Result: 相比通用CP，安全关键对象的平均精度损失小于1%，仅使用20%通信带宽；相比无风险感知的选择性CP方法，感知性能提升15%。

Conclusion: SRA-CP框架有效解决了CP中的通信带宽和动态环境适应性问题，通过风险感知的选择性协作实现了高效可靠的协作感知。

Abstract: Cooperative perception (CP) offers significant potential to overcome the limitations of single-vehicle sensing by enabling information sharing among connected vehicles (CVs). However, existing generic CP approaches need to transmit large volumes of perception data that are irrelevant to the driving safety, exceeding available communication bandwidth. Moreover, most CP frameworks rely on pre-defined communication partners, making them unsuitable for dynamic traffic environments. This paper proposes a Spontaneous Risk-Aware Selective Cooperative Perception (SRA-CP) framework to address these challenges. SRA-CP introduces a decentralized protocol where connected agents continuously broadcast lightweight perception coverage summaries and initiate targeted cooperation only when risk-relevant blind zones are detected. A perceptual risk identification module enables each CV to locally assess the impact of occlusions on its driving task and determine whether cooperation is necessary. When CP is triggered, the ego vehicle selects appropriate peers based on shared perception coverage and engages in selective information exchange through a fusion module that prioritizes safety-critical content and adapts to bandwidth constraints. We evaluate SRA-CP on a public dataset against several representative baselines. Results show that SRA-CP achieves less than 1% average precision (AP) loss for safety-critical objects compared to generic CP, while using only 20% of the communication bandwidth. Moreover, it improves the perception performance by 15% over existing selective CP methods that do not incorporate risk awareness.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [12] [Generative Augmented Reality: Paradigms, Technologies, and Future Applications](https://arxiv.org/abs/2511.16783)
*Chen Liang,Jiawen Zheng,Yufeng Zeng,Yi Tan,Hengye Lyu,Yuhui Zheng,Zisu Li,Yueting Weng,Jiaxin Shi,Hanwang Zhang*

Main category: cs.HC

TL;DR: 本文提出生成增强现实(GAR)作为下一代增强现实范式，将增强重新定义为世界重合成过程，而不是传统AR引擎的世界组合。GAR用统一的生成主干取代传统AR引擎的多阶段模块，将环境感知、虚拟内容和交互信号联合编码为连续视频生成的条件输入。


<details>
  <summary>Details</summary>
Motivation: 传统AR引擎采用多阶段模块进行世界组合，存在局限性。GAR旨在通过统一生成模型提供更高保真度的体验，在真实性、交互性和沉浸感方面实现突破。

Method: 用统一的生成主干取代传统AR引擎的多阶段模块，将环境感知、虚拟内容和交互信号联合编码为连续视频生成的条件输入，建立AR与GAR之间的计算对应关系。

Result: GAR被形式化为一种新的AR范式，能够实现实时生成增强，提供高保真度的增强现实体验，并开辟了新的研究方向。

Conclusion: GAR有望成为未来AR范式，在提供高保真体验的同时，也引发了关于技术、内容生态系统以及伦理和社会影响的新研究挑战。

Abstract: This paper introduces Generative Augmented Reality (GAR) as a next-generation paradigm that reframes augmentation as a process of world re-synthesis rather than world composition by a conventional AR engine. GAR replaces the conventional AR engine's multi-stage modules with a unified generative backbone, where environmental sensing, virtual content, and interaction signals are jointly encoded as conditioning inputs for continuous video generation. We formalize the computational correspondence between AR and GAR, survey the technical foundations that make real-time generative augmentation feasible, and outline prospective applications that leverage its unified inference model. We envision GAR as a future AR paradigm that delivers high-fidelity experiences in terms of realism, interactivity, and immersion, while eliciting new research challenges on technologies, content ecosystems, and the ethical and societal implications.

</details>


### [13] [Scene Awareness While Using Multiple Navigation Aids in AR Search](https://arxiv.org/abs/2511.16805)
*Radha Kumaran,You-Jin Kim,Emily Machniak,Shane Dirksen,Junhyung Yoon,Tom Bullock,Barry Giesbrecht,Tobias Höllerer*

Main category: cs.HC

TL;DR: 研究探讨了在移动增强现实中同时使用多种导航辅助工具对用户对象回忆能力的影响，发现导航辅助工具会损害用户对环境中对象的记忆。


<details>
  <summary>Details</summary>
Motivation: 探索在移动增强现实环境中，同时使用多种导航辅助工具（如世界锁定箭头和屏幕雷达）对用户感知和认知的影响，特别是对对象回忆能力的影响。

Method: 用户在大型增强现实环境中搜索虚拟宝石，可选择独立或同时使用两种导航辅助工具（世界锁定箭头和屏幕雷达），搜索完成后测试参与者对场景中可能存在或不存在的对象的回忆能力。

Result: 导航辅助工具的使用影响了对象回忆，当辅助工具开启时，用户对环境中的对象回忆能力受损。

Conclusion: 研究揭示了移动AR中对象感知的潜在影响因素，并强调了可适应界面在支持用户导航物理世界方面的潜力。

Abstract: Augmented reality (AR) allows virtual information to be presented in the real world, providing support for numerous tasks including search and navigation. Allowing users access to multiple navigation aids may help leverage the benefits of different navigational guidance methods, but may also have negative perceptual and cognitive impacts. In this study, users performed searches for virtual gems within a large-scale augmented environment while choosing to deploy two different navigation aids either independently or simultaneously: world-locked arrows and an on-screen radar. After completing the search, participants were asked to recall objects that may or may not have been present in the scene. The use of navigation aids impacted object recall, with impaired recall of objects in the environment when an aid was switched on. The results point at possible impact factors of object awareness in mobile AR and underscore the potential for adaptable interfaces to support users navigating the physical world.

</details>


### [14] [IsharaKotha: A Comprehensive Avatar-based Bangla Sign Language Corpus](https://arxiv.org/abs/2511.16896)
*MD. Ashikul Islam,Prato Dewan,Md Fuadul Islam,Md. Ataullha,M. Shahidur Rahman*

Main category: cs.HC

TL;DR: IsharaKotha是首个基于HamNoSys的孟加拉手语语料库，包含3823个单词，集成了深度学习词形还原器来提取词根，能够生成完整句子的手语动画。评估显示系统在4分制中获得3.14分，表现良好。


<details>
  <summary>Details</summary>
Motivation: 为帮助听力受损群体与听力正常人群之间的沟通，以及支持手语学习者，需要开发文本到手语的翻译系统。

Method: 创建了基于HamNoSys的孟加拉手语语料库，集成深度学习词形还原器提取词根，开发了评估界面来评估手语动画质量。

Result: 系统包含3823个单词，两名专业翻译和一名真实手语用户使用分类数字评分对动画进行评估，平均得分为3.14/4.00，表现介于良好和优秀之间。

Conclusion: IsharaKotha展示了在动态手语翻译系统中支持未来进展的潜力。

Abstract: Sign language is a vital communication medium for the hearing-impaired community, enabling effective interaction and self-expression. To help bridge the communication gap between hearing and hearing-impaired individuals, a text-to-sign translation system is essential. Such systems can also support learners interested in acquiring sign language skills. This work presents IsharaKotha, the first HamNoSys-based Bangla Sign Language corpus, containing 3823 words. A deep learning based lemmatizer was integrated to extract root words, enabling sign generation for complete sentences. An evaluation interface was developed to assess the quality of sign animations for letters, digits, and sentences. Two professional interpreters and one real sign language user rated the animations using categorical numeric scores. The system achieved an average rating of 3.14 out of 4.00, indicating high quality performance between Good and Excellent. These results demonstrate the potential of IsharaKotha to support future advancements in dynamic sign language translation systems. The evaluation system is available at http://bdsl-isharakotha.ap-1.evennode.com

</details>


### [15] [The Wireless Charger as a Gesture Sensor: A Novel Approach to Ubiquitous Interaction](https://arxiv.org/abs/2511.16989)
*Weiyi Wang,Lanqing Yang,Linqian Gan,Guangtao Xue*

Main category: cs.HC

TL;DR: EMGesture是一种利用Qi无线充电器电磁信号进行手势识别的非接触式交互技术，通过分析独特的电磁特征和稳健的分类模型，实现了超过97%的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 传统交互方式如物理按钮或摄像头存在接触要求、隐私问题和高成本限制，而无线充电器产生的电磁信号强度大、可测量且富含手势相关信息，为开发新型非接触式交互提供了机会。

Method: 提出EMGesture技术，利用Qi无线充电器的电磁信号进行手势识别，分析电磁特征并采用稳健的分类模型，构建端到端框架来准确解释用户意图。

Result: 在涉及30名参与者、10台移动设备和5个充电器的实验中，EMGesture实现了超过97%的识别准确率，用户研究也证实了更高的可用性和便利性。

Conclusion: EMGesture是一种实用、注重隐私且成本效益高的普及交互解决方案，为非接触式人机交互提供了新的可能性。

Abstract: Advancements in information technology have increased demand for natural human-computer interaction in areas such as gaming, smart homes, and vehicles. However, conventional approaches like physical buttons or cameras are often limited by contact requirements, privacy concerns, and high costs.Motivated by the observation that these EM signals are not only strong and measurable but also rich in gesture-related information, we propose EMGesture, a novel contactless interaction technique that leverages the electromagnetic (EM) signals from Qi wireless chargers for gesture recognition. EMGesture analyzes the distinctive EM features and employs a robust classification model. The end-to-end framework enables it capable of accurately interpreting user intent. Experiments involving 30 participants, 10 mobile devices, and 5 chargers showed that EMGesture achieves over 97% recognition accuracy. Corresponding user studies also confirmed higher usability and convenience, which demonstrating that EMGesture is a practical, privacy-conscious, and cost-effective solution for pervasive interaction.

</details>


### [16] [Senti-iFusion: An Integrity-centered Hierarchical Fusion Framework for Multimodal Sentiment Analysis under Uncertain Modality Missingness](https://arxiv.org/abs/2511.16990)
*Liling Li,Guoyang Xu,Xiongri Shen,Zhifei Xu,Yanbo Zhang,Zhiguo Zhang,Zhenxi Song*

Main category: cs.HC

TL;DR: Senti-iFusion是一个完整性为中心的分层融合框架，用于处理多模态情感分析中的模态缺失问题，通过完整性估计、完整性加权补全和完整性引导融合三个组件，在语言、声学和视觉模态上实现精确的情感特征恢复。


<details>
  <summary>Details</summary>
Motivation: 解决多模态情感分析中模态不完整或缺失的现实挑战，现有方法通常假设预定义的缺失模态或固定缺失率，限制了实际应用。

Method: 提出完整性为中心的分层融合框架，包含三个组件：完整性估计模块预测每个模态的完整性并减轻不完整数据的噪声；完整性加权跨模态补全模块使用新颖的加权机制从模态特定表示中分离一致的语义结构；完整性引导自适应融合机制动态选择主导模态进行基于注意力的融合。

Result: 在流行的多模态情感分析数据集上的实验结果表明，Senti-iFusion优于现有方法，特别是在细粒度情感分析任务中表现突出。

Conclusion: Senti-iFusion通过完整性为中心的分层融合方法有效解决了多模态情感分析中的模态缺失问题，在细粒度情感分析任务中表现出色，代码和模型将公开提供。

Abstract: Multimodal Sentiment Analysis (MSA) is critical for human-computer interaction but faces challenges when the modalities are incomplete or missing. Existing methods often assume pre-defined missing modalities or fixed missing rates, limiting their real-world applicability. To address this challenge, we propose Senti-iFusion, an integrity-centered hierarchical fusion framework capable of handling both inter- and intra-modality missingness simultaneously. It comprises three hierarchical components: Integrity Estimation, Integrity-weighted Completion, and Integrity-guided Fusion. First, the Integrity Estimation module predicts the completeness of each modality and mitigates the noise caused by incomplete data. Second, the Integrity-weighted Cross-modal Completion module employs a novel weighting mechanism to disentangle consistent semantic structures from modality-specific representations, enabling the precise recovery of sentiment-related features across language, acoustic, and visual modalities. To ensure consistency in reconstruction, a dual-depth validation with semantic- and feature-level losses ensures consistent reconstruction at both fine-grained (low-level) and semantic (high-level) scales. Finally, the Integrity-guided Adaptive Fusion mechanism dynamically selects the dominant modality for attention-based fusion, ensuring that the most reliable modality, based on completeness and quality, contributes more significantly to the final prediction. Senti-iFusion employs a progressive training approach to ensure stable convergence. Experimental results on popular MSA datasets demonstrate that Senti-iFusion outperforms existing methods, particularly in fine-grained sentiment analysis tasks. The code and our proposed Senti-iFusion model will be publicly available.

</details>


### [17] [Mixed Reality Scenic Live Streaming for Cultural Heritage: Visual Interactions in a Historic Landscape](https://arxiv.org/abs/2511.17246)
*Zeyu Huang,Zuyu Xu,Yuanhao Zhang,Chengzhong Liu,Yanwei Zhao,Chuhan Shi,Jason Chen Zhao,Xiaojuan Ma*

Main category: cs.HC

TL;DR: 该论文提出了一种名为MRSLS的交互式混合现实风景直播系统，通过在固定摄像头拍摄的风景直播上叠加与地理结构和当地文化背景匹配的混合现实内容，增强风景直播的互动性和文化传播效果。


<details>
  <summary>Details</summary>
Motivation: 风景直播(SLS)虽然能实时展示偏远景点，但缺乏动态性和互动性。作者旨在通过混合现实技术最大化SLS的潜力，使其更具交互性，特别是在文化遗产地互动方面具有显著优势。

Method: 开发MRSLS原型，在中国联合国教科文组织遗产地进行实践。设计过程包括访谈(N=6)确定当地风景文化特征，以及两次迭代设计研究(N=15, 14)。采用混合方法、组间研究设计(N=43, 37)评估系统效果。

Result: 研究表明MRSLS能够提供沉浸式风景欣赏、有效的文化印记和生动的共享体验。系统在文化性、参与性和真实性之间达到了良好平衡。

Conclusion: 呼吁HCI领域更多关注(MR)SLS这一未被充分探索的设计空间，特别是在文化遗产传播和互动体验方面的应用潜力。

Abstract: Scenic Live Streams (SLS), capturing real-world scenic sites from fixed cameras without streamers, have gained increasing popularity recently. They afford unique real-time lenses into remote sites for viewers' synchronous and collective engagement. Foregrounding its lack of dynamism and interactivity, we aim to maximize the potential of SLS by making it interactive. Namely MRSLS, we overlaid plain SLS with interactive Mixed Reality content that matches the site's geographical structures and local cultural backgrounds. We further highlight the substantial benefit of MRSLS to cultural heritage site interactions, and we demonstrate this design proposal with an MRSLS prototype at a UNESCO-listed heritage site in China. The design process includes an interview (N=6) to pinpoint local scenery and culture, as well as two iterative design studies (N=15, 14). A mixed-methods, between-subjects study (N=43, 37) shows that MRSLS affords immersive scenery appreciation, effective cultural imprints, and vivid shared experience. With its balance between cultural, participatory, and authentic attributes, we appeal for more HCI attention to (MR)SLS as an under-explored design space.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [18] [DDTime: Dataset Distillation with Spectral Alignment and Information Bottleneck for Time-Series Forecasting](https://arxiv.org/abs/2511.16715)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Hao Wang,Haoxuan Wang,Huiran Duan,Junming Liu,Yingli Tian*

Main category: cs.LG

TL;DR: DDTime是一个轻量级的时间序列数据集蒸馏框架，通过频域对齐和样本间正则化解决时间序列蒸馏中的时间偏差和多样性不足问题，在20个基准数据集上相比现有方法获得约30%的相对精度提升。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测通常需要大规模数据集和大量计算资源，而数据集蒸馏提供了一种有前景的替代方案。但将数据集蒸馏扩展到时间序列预测面临两个基本挑战：时间偏差和样本多样性不足。

Method: 基于一阶凝聚分解构建DDTime框架：1）通过时间统计和频域对齐机制解决时间偏差问题；2）基于信息瓶颈原理设计样本间正则化以增强多样性。该框架与多种凝聚范式兼容并支持稳定的一阶优化。

Result: 在20个基准数据集和多种预测架构上的广泛实验表明，DDTime始终优于现有蒸馏方法，实现约30%的相对精度提升，同时仅引入约2.49%的计算开销。

Conclusion: DDTime是一个有效的时间序列数据集蒸馏框架，通过频域对齐和多样性增强机制成功解决了时间序列蒸馏中的关键挑战，在保持计算效率的同时显著提升了预测精度。

Abstract: Time-series forecasting is fundamental across many domains, yet training accurate models often requires large-scale datasets and substantial computational resources. Dataset distillation offers a promising alternative by synthesizing compact datasets that preserve the learning behavior of full data. However, extending dataset distillation to time-series forecasting is non-trivial due to two fundamental challenges: 1.temporal bias from strong autocorrelation, which leads to distorted value-term alignment between teacher and student models; and 2.insufficient diversity among synthetic samples, arising from the absence of explicit categorical priors to regularize trajectory variety.
  In this work, we propose DDTime, a lightweight and plug-in distillation framework built upon first-order condensation decomposition. To tackle Challenge 1, it revisits value-term alignment through temporal statistics and introduces a frequency-domain alignment mechanism to mitigate autocorrelation-induced bias, ensuring spectral consistency and temporal fidelity. To address Challenge 2, we further design an inter-sample regularization inspired by the information bottleneck principle, which enhances diversity and maximizes information density across synthetic trajectories. The combined objective is theoretically compatible with a wide range of condensation paradigms and supports stable first-order optimization. Extensive experiments on 20 benchmark datasets and diverse forecasting architectures demonstrate that DDTime consistently outperforms existing distillation methods, achieving about 30% relative accuracy gains while introducing about 2.49% computational overhead. All code and distilled datasets will be released.

</details>


### [19] [When Structure Doesn't Help: LLMs Do Not Read Text-Attributed Graphs as Effectively as We Expected](https://arxiv.org/abs/2511.16767)
*Haotian Xu,Yuning You,Tengfei Ma*

Main category: cs.LG

TL;DR: 本文研究发现，在文本属性图上，仅使用节点文本描述的LLM已经能取得强大性能，大多数结构编码策略仅带来边际收益甚至负面影响，表明在强大语言模型时代需要重新思考结构表示方式。


<details>
  <summary>Details</summary>
Motivation: 探索不同图结构编码策略如何影响LLM在文本属性图上的性能，挑战传统图学习中结构必然有益的假设。

Method: 通过系统性实验比较不同图结构编码策略，包括模板化图模板和使用GNN编码结构信息的方法。

Result: 令人惊讶地发现：(i)仅使用节点文本描述的LLM已在各项任务中表现强劲；(ii)大多数结构编码策略仅带来边际收益或负面影响。

Conclusion: 当涉及强大语言模型时，显式结构先验通常不必要，有时甚至适得其反，这标志着与传统图学习范式的重大背离，需要重新思考LLM时代的结构表示和利用方式。

Abstract: Graphs provide a unified representation of semantic content and relational structure, making them a natural fit for domains such as molecular modeling, citation networks, and social graphs. Meanwhile, large language models (LLMs) have excelled at understanding natural language and integrating cross-modal signals, sparking interest in their potential for graph reasoning. Recent work has explored this by either designing template-based graph templates or using graph neural networks (GNNs) to encode structural information. In this study, we investigate how different strategies for encoding graph structure affect LLM performance on text-attributed graphs. Surprisingly, our systematic experiments reveal that: (i) LLMs leveraging only node textual descriptions already achieve strong performance across tasks; and (ii) most structural encoding strategies offer marginal or even negative gains. We show that explicit structural priors are often unnecessary and, in some cases, counterproductive when powerful language models are involved. This represents a significant departure from traditional graph learning paradigms and highlights the need to rethink how structure should be represented and utilized in the LLM era. Our study is to systematically challenge the foundational assumption that structure is inherently beneficial for LLM-based graph reasoning, opening the door to new, semantics-driven approaches for graph learning.

</details>


### [20] [GCL-OT: Graph Contrastive Learning with Optimal Transport for Heterophilic Text-Attributed Graphs](https://arxiv.org/abs/2511.16778)
*Yating Ren,Yikun Ban,Huobin Tan*

Main category: cs.LG

TL;DR: 本文提出GCL-OT框架，通过最优传输解决文本属性图中的多粒度异质性挑战，包括完全异质性、部分异质性和潜在同质性，实现结构-文本的灵活双向对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖同质性假设和硬优化目标，在处理异质性图时效果受限，且通常将文本嵌入视为静态目标，导致对齐效果不佳。本文识别了文本属性图中的多粒度异质性挑战。

Method: 提出GCL-OT框架：1) 针对部分异质性，设计RealSoftMax相似度估计器强调关键邻居-词交互；2) 针对完全异质性，引入基于提示的过滤器自适应排除噪声；3) 结合OT引导的软监督发现潜在语义相似邻居。

Result: 在9个基准测试上的广泛实验表明，GCL-OT持续优于最先进方法，验证了其有效性和鲁棒性。理论分析显示GCL-OT能改进互信息边界和贝叶斯误差保证。

Conclusion: GCL-OT通过最优传输和针对性机制有效解决了文本属性图中的多粒度异质性挑战，实现了更灵活的结构-文本对齐，在异质性图上表现出优越性能。

Abstract: Recently, structure-text contrastive learning has shown promising performance on text-attributed graphs by leveraging the complementary strengths of graph neural networks and language models. However, existing methods typically rely on homophily assumptions in similarity estimation and hard optimization objectives, which limit their applicability to heterophilic graphs. Although existing methods can mitigate heterophily through structural adjustments or neighbor aggregation, they usually treat textual embeddings as static targets, leading to suboptimal alignment. In this work, we identify the multi-granular heterophily in text-attributed graphs, including complete heterophily, partial heterophily, and latent homophily, which makes structure-text alignment particularly challenging due to mixed, noisy, and missing semantic correlations. To achieve flexible and bidirectional alignment, we propose GCL-OT, a novel graph contrastive learning framework with optimal transport, equipped with tailored mechanisms for each type of heterophily. Specifically, for partial heterophily, we design a RealSoftMax-based similarity estimator to emphasize key neighbor-word interactions while easing background noise. For complete heterophily, we introduce a prompt-based filter that adaptively excludes irrelevant noise during optimal transport alignment. Furthermore, we incorporate OT-guided soft supervision to uncover potential neighbors with similar semantics, enhancing the learning of latent homophily. Theoretical analysis shows that GCL-OT can improve the mutual information bound and Bayes error guarantees. Extensive experiments on nine benchmarks show that GCL-OT consistently outperforms state-of-the-art methods, verifying its effectiveness and robustness.

</details>


### [21] [Revisiting Multimodal KV Cache Compression: A Frequency-Domain-Guided Outlier-KV-Aware Approach](https://arxiv.org/abs/2511.16786)
*Yaoxin Yang,Peng Ye,Xudong Tan,Chongjun Tu,Maosen Zhao,Jia Hao,Tao Chen*

Main category: cs.LG

TL;DR: FlashCache是一个基于频域分析和异常KV感知的多模态KV缓存压缩框架，通过识别和保留关键异常KV对，在保持任务性能的同时显著提升推理速度并降低内存使用。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在显著的推理开销问题，因为多模态KV缓存随视觉输入长度线性增长。现有的压缩方法主要依赖注意力分数，与高效注意力内核不兼容且忽略了值向量的贡献。

Method: 从KV矩阵分布角度重新审视压缩问题，发现多模态KV矩阵的频域能量集中在低频。提出FlashCache框架：1）异常KV识别模块，在频域建模主成分并优先保留显著偏离的KV对；2）动态预算分配模块，自适应确定每层KV缓存大小以保留更多异常KV。

Result: 在多个MLLM和基准测试上的实验表明，FlashCache优于最先进的多模态KV压缩方法，实现高达1.69倍的解码加速和80%的KV内存使用降低，同时保持任务性能。

Conclusion: FlashCache通过频域引导的异常KV感知压缩方法，有效解决了多模态KV缓存的高开销问题，在保持模型性能的前提下显著提升了推理效率。

Abstract: Multimodal large language models suffer from substantial inference overhead since multimodal KV Cache grows proportionally with the visual input length. Existing multimodal KV Cache compression methods mostly rely on attention score to reduce cache size, which makes them are incompatible with established efficient attention kernels (e.g., FlashAttention) and ignores the contribution of value vectors to the attention output. In this work, we revisit multimodal KV Cache compression from the perspective of the KV matrices' distribution. First, we observe that frequency-domain energy of multimodal KV matrices is predominantly concentrated in low-frequency and extract this principal energy via a low-pass filter. Further, we find that removing KV pairs that deviate substantially from this principal energy leads to a pronounced performance drop, which we define as Outlier KVs. Considering Outlier KVs are more likely to encode features critical for inference, we propose FlashCache, a frequency-domain-guided, Outlier-KV-aware KV Cache compression framework. First, we introduce an Outlier KV Recognition Module that models the principal component of multimodal KV matrices in the frequency domain and preferentially retains KV pairs that significantly deviate from it. Furthermore, Dynamic Budget Allocation Module is designed to adaptively determine the per-layer KV Cache size to retain more Outlier KVs. Experiments on multiple MLLMs and benchmarks demonstrate that FlashCache outperforms state-of-the-art multimoal KV compression methods, achieving up to 1.69 times faster decoding with 80% lower KV memory usage while maintaining task performance.

</details>


### [22] [A Vector Symbolic Approach to Multiple Instance Learning](https://arxiv.org/abs/2511.16795)
*Ehsan Ahmed Dhrubo,Mohammad Mahmudul Alam,Edward Raff,Tim Oates,James Holt*

Main category: cs.LG

TL;DR: 提出基于向量符号架构(VSA)的多示例学习(MIL)框架，通过高维向量和代数运算直接编码MIL的iff约束，在保持严格MIL公式的同时实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法大多违反MIL的iff约束(包为正当且仅当至少一个实例为正)，导致性能指标虚高和泛化能力差，需要设计严格遵循MIL假设的模型。

Method: 使用向量符号架构(VSA)将实例和概念表示为近似正交的高维向量，通过代数运算在分类时强制执行iff约束；设计学习编码器将原始数据转换为VSA兼容向量；包含VSA驱动的MaxNetwork分类器。

Result: 在标准MIL基准和医学影像数据集上实现了有效MIL模型的最先进结果，优于现有方法，同时严格遵循MIL公式。

Conclusion: 为依赖学习启发式的现有MIL方法提供了原则性、可解释且有效的替代方案，通过VSA直接编码MIL约束实现更好的性能。

Abstract: Multiple Instance Learning (MIL) tasks impose a strict logical constraint: a bag is labeled positive if and only if at least one instance within it is positive. While this iff constraint aligns with many real-world applications, recent work has shown that most deep learning-based MIL approaches violate it, leading to inflated performance metrics and poor generalization. We propose a novel MIL framework based on Vector Symbolic Architectures (VSAs), which provide a differentiable mechanism for performing symbolic operations in high-dimensional space. Our method encodes the MIL assumption directly into the model's structure by representing instances and concepts as nearly orthogonal high-dimensional vectors and using algebraic operations to enforce the iff constraint during classification. To bridge the gap between raw data and VSA representations, we design a learned encoder that transforms input instances into VSA-compatible vectors while preserving key distributional properties. Our approach, which includes a VSA-driven MaxNetwork classifier, achieves state-of-the-art results for a valid MIL model on standard MIL benchmarks and medical imaging datasets, outperforming existing methods while maintaining strict adherence to the MIL formulation. This work offers a principled, interpretable, and effective alternative to existing MIL approaches that rely on learned heuristics.

</details>


### [23] [A Robust Federated Learning Approach for Combating Attacks Against IoT Systems Under non-IID Challenges](https://arxiv.org/abs/2511.16822)
*Eyad Gad,Zubair Md Fadlullah,Mostafa M. Fouda*

Main category: cs.LG

TL;DR: 本文研究了联邦学习算法（FedAvg、FedProx、Scaffold）在非独立同分布数据下的性能，专注于物联网攻击检测场景，使用CICIoT2023数据集进行大规模分类任务。


<details>
  <summary>Details</summary>
Motivation: 随着物联网设备激增和数据量增长，传统机器学习在资源受限和隐私敏感环境中面临挑战。联邦学习虽能解决这些问题，但非独立同分布数据的统计异质性严重影响了其有效性，特别是在物联网攻击检测领域缺乏系统比较研究。

Method: 使用CICIoT2023数据集，在非独立同分布数据分布下，系统比较FedAvg、FedProx和Scaffold三种联邦学习算法的性能表现。

Result: 通过细致的分析和实验，揭示了这些联邦学习方法在统计异质性条件下的性能差异和特点。

Conclusion: 研究为物联网攻击检测领域的联邦学习应用提供了有价值的见解，帮助研究者和实践者更好地理解和应对统计异质性挑战。

Abstract: In the context of the growing proliferation of user devices and the concurrent surge in data volumes, the complexities arising from the substantial increase in data have posed formidable challenges to conventional machine learning model training. Particularly, this is evident within resource-constrained and security-sensitive environments such as those encountered in networks associated with the Internet of Things (IoT). Federated Learning has emerged as a promising remedy to these challenges by decentralizing model training to edge devices or parties, effectively addressing privacy concerns and resource limitations. Nevertheless, the presence of statistical heterogeneity in non-Independently and Identically Distributed (non-IID) data across different parties poses a significant hurdle to the effectiveness of FL. Many FL approaches have been proposed to enhance learning effectiveness under statistical heterogeneity. However, prior studies have uncovered a gap in the existing research landscape, particularly in the absence of a comprehensive comparison between federated methods addressing statistical heterogeneity in detecting IoT attacks. In this research endeavor, we delve into the exploration of FL algorithms, specifically FedAvg, FedProx, and Scaffold, under different data distributions. Our focus is on achieving a comprehensive understanding of and addressing the challenges posed by statistical heterogeneity. In this study, We classify large-scale IoT attacks by utilizing the CICIoT2023 dataset. Through meticulous analysis and experimentation, our objective is to illuminate the performance nuances of these FL methods, providing valuable insights for researchers and practitioners in the domain.

</details>


### [24] [Monte Carlo Expected Threat (MOCET) Scoring](https://arxiv.org/abs/2511.16823)
*Joseph Kim,Saahith Potluri*

Main category: cs.LG

TL;DR: 论文提出MOCET指标，用于评估AI安全级别威胁，特别是针对ASL-3+模型在生物安全领域提升非国家行为体能力的风险。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标如LAB-Bench、BioLP-bench和WMDP能够可靠评估模型提升效果和领域知识，但缺乏能够更好量化"现实世界风险"的指标，需要可扩展的开放式指标来跟上LLM的快速发展。

Method: 引入MOCET指标，这是一个可解释且双重可扩展（可自动化和开放式）的指标，能够量化现实世界风险。

Result: MOCET指标能够解决现有评估指标的不足，提供对AI安全威胁的更准确评估。

Conclusion: MOCET指标填补了现有AI安全评估的空白，为LLM安全案例提供了更好的风险评估工具，能够跟上AI技术的快速发展。

Abstract: Evaluating and measuring AI Safety Level (ASL) threats are crucial for guiding stakeholders to implement safeguards that keep risks within acceptable limits. ASL-3+ models present a unique risk in their ability to uplift novice non-state actors, especially in the realm of biosecurity. Existing evaluation metrics, such as LAB-Bench, BioLP-bench, and WMDP, can reliably assess model uplift and domain knowledge. However, metrics that better contextualize "real-world risks" are needed to inform the safety case for LLMs, along with scalable, open-ended metrics to keep pace with their rapid advancements. To address both gaps, we introduce MOCET, an interpretable and doubly-scalable metric (automatable and open-ended) that can quantify real-world risks.

</details>


### [25] [ManifoldFormer: Geometric Deep Learning for Neural Dynamics on Riemannian Manifolds](https://arxiv.org/abs/2511.16828)
*Yihang Fu,Lifang He,Qingyu Chen*

Main category: cs.LG

TL;DR: ManifoldFormer提出了一种几何深度学习框架，通过显式学习神经流形表示来解决现有EEG基础模型忽略神经动态内在几何结构的问题，在四个公共数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有EEG基础模型主要将神经信号视为欧几里得空间中的通用时间序列，忽略了约束大脑活动到低维流形的神经动态内在几何结构，这种模型假设与神经几何之间的不匹配限制了表示质量和跨被试泛化能力。

Method: 该架构集成了三个关键创新：用于保持几何结构的流形嵌入的黎曼VAE、直接在神经流形上操作的具有测地线感知注意力机制的几何Transformer，以及利用神经ODE进行流形约束时间演化的动态预测器。

Result: 在四个公共数据集上的广泛评估显示，与最先进方法相比，准确率提高了4.6-4.8%，Cohen's Kappa提高了6.2-10.2%，同时保持了强大的跨被试泛化能力。

Conclusion: 几何方法揭示了与神经生理学原理一致的有意义的神经模式，确立了几何约束对于有效EEG基础模型的重要性。

Abstract: Existing EEG foundation models mainly treat neural signals as generic time series in Euclidean space, ignoring the intrinsic geometric structure of neural dynamics that constrains brain activity to low-dimensional manifolds. This fundamental mismatch between model assumptions and neural geometry limits representation quality and cross-subject generalization. ManifoldFormer addresses this limitation through a novel geometric deep learning framework that explicitly learns neural manifold representations. The architecture integrates three key innovations: a Riemannian VAE for manifold embedding that preserves geometric structure, a geometric Transformer with geodesic-aware attention mechanisms operating directly on neural manifolds, and a dynamics predictor leveraging neural ODEs for manifold-constrained temporal evolution. Extensive evaluation across four public datasets demonstrates substantial improvements over state-of-the-art methods, with 4.6-4.8% higher accuracy and 6.2-10.2% higher Cohen's Kappa, while maintaining robust cross-subject generalization. The geometric approach reveals meaningful neural patterns consistent with neurophysiological principles, establishing geometric constraints as essential for effective EEG foundation models.

</details>


### [26] [Analysis of heart failure patient trajectories using sequence modeling](https://arxiv.org/abs/2511.16839)
*Falk Dippela,Yinan Yu,Annika Rosengren,Martin Lindgren,Christina E. Lundberg,Erik Aerts,Martin Adiels,Helen Sjöland*

Main category: cs.LG

TL;DR: 本文系统比较了六种序列模型在三个架构类别中的表现，发现在瑞典心衰队列中，Llama在预测性能、校准和鲁棒性方面表现最佳，Mamba次之，两者在模型规模相同时使用更少训练数据即可达到优越性能。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer和Mamba架构在临床预测任务中表现出色，但医学领域缺乏系统分析模型性能和效率的方法。本文旨在通过系统消融研究填补这一空白。

Method: 使用瑞典心衰队列数据，比较了Transformer、Transformer++和Mamba三类架构的六种序列模型，评估了三种一年预测任务，并进行了输入序列修改、架构配置和时间预处理技术的消融实验。

Result: Llama在所有任务中实现了最高的预测区分度、最佳校准和鲁棒性，其次是Mamba。两种架构都展示了高效的表示学习能力，小配置模型超越了其他大型Transformer。在相同模型规模下，Llama和Mamba使用25%更少的训练数据即可达到优越性能。

Conclusion: 本研究首次提供了针对输入标记化、模型配置和时间数据预处理的系统消融研究，为未来基于电子健康记录的临床预测任务模型开发提供了重要参考起点。

Abstract: Transformers have defined the state-of-the-art for clinical prediction tasks involving electronic health records (EHRs). The recently introduced Mamba architecture outperformed an advanced Transformer (Transformer++) based on Llama in handling long context lengths, while using fewer model parameters. Despite the impressive performance of these architectures, a systematic approach to empirically analyze model performance and efficiency under various settings is not well established in the medical domain. The performances of six sequence models were investigated across three architecture classes (Transformers, Transformers++, Mambas) in a large Swedish heart failure (HF) cohort (N = 42820), providing a clinically relevant case study. Patient data included diagnoses, vital signs, laboratories, medications and procedures extracted from in-hospital EHRs. The models were evaluated on three one-year prediction tasks: clinical instability (a readmission phenotype) after initial HF hospitalization, mortality after initial HF hospitalization and mortality after latest hospitalization. Ablations account for modifications of the EHR-based input patient sequence, architectural model configurations, and temporal preprocessing techniques for data collection. Llama achieves the highest predictive discrimination, best calibration, and showed robustness across all tasks, followed by Mambas. Both architectures demonstrate efficient representation learning, with tiny configurations surpassing other large-scaled Transformers. At equal model size, Llama and Mambas achieve superior performance using 25% less training data. This paper presents a first ablation study with systematic design choices for input tokenization, model configuration and temporal data preprocessing. Future model development in clinical prediction tasks using EHRs could build upon this study's recommendation as a starting point.

</details>


### [27] [Provably Minimum-Length Conformal Prediction Sets for Ordinal Classification](https://arxiv.org/abs/2511.16845)
*Zijian Zhang,Xinyu Chen,Yuanjie Shi,Liyuan Lillian Ma,Zifan Xu,Yan Yan*

Main category: cs.LG

TL;DR: 本文提出了一种新的序数分类的保形预测方法，该方法具有模型无关性，并提供实例级别的最优预测区间，显著提高了预测效率。


<details>
  <summary>Details</summary>
Motivation: 现有的序数保形预测方法主要关注启发式算法或限制基础模型预测单峰分布，这限制了覆盖效率权衡的洞察力，也缺乏保形预测方法所偏好的模型无关和分布无关特性。

Method: 将序数保形预测表述为实例级别的最小长度覆盖问题，开发了一种滑动窗口算法，在K个标签候选中具有线性时间复杂度，并提出了长度正则化变体来缩小预测集大小同时保持覆盖。

Result: 在四个不同领域的基准数据集上的实验表明，所提方法相比基线显著提高了预测效率（在四个数据集上平均减少15%）。

Conclusion: 该方法填补了序数保形预测领域的空白，提供了模型无关、实例级别最优的预测区间，在保持统计有效保证的同时显著提升了预测效率。

Abstract: Ordinal classification has been widely applied in many high-stakes applications, e.g., medical imaging and diagnosis, where reliable uncertainty quantification (UQ) is essential for decision making. Conformal prediction (CP) is a general UQ framework that provides statistically valid guarantees, which is especially useful in practice. However, prior ordinal CP methods mainly focus on heuristic algorithms or restrictively require the underlying model to predict a unimodal distribution over ordinal labels. Consequently, they provide limited insight into coverage-efficiency trade-offs, or a model-agnostic and distribution-free nature favored by CP methods. To this end, we fill this gap by propose an ordinal-CP method that is model-agnostic and provides instance-level optimal prediction intervals. Specifically, we formulate conformal ordinal classification as a minimum-length covering problem at the instance level. To solve this problem, we develop a sliding-window algorithm that is optimal on each calibration data, with only a linear time complexity in K, the number of label candidates. The local optimality per instance further also improves predictive efficiency in expectation. Moreover, we propose a length-regularized variant that shrinks prediction set size while preserving coverage. Experiments on four benchmark datasets from diverse domains are conducted to demonstrate the significantly improved predictive efficiency of the proposed methods over baselines (by 15% decrease on average over four datasets).

</details>


### [28] [Sex and age determination in European lobsters using AI-Enhanced bioacoustics](https://arxiv.org/abs/2511.16848)
*Feliciano Pedro Francisco Domingos,Isibor Kennedy Ihianle,Omprakash Kaiwartya,Ahmad Lotfi,Nicola Khan,Nicholas Beaudreau,Amaya Albalat,Pedro Machado*

Main category: cs.LG

TL;DR: 本研究利用被动声学监测和人工智能技术，基于欧洲龙虾的生物声学特征（嗡嗡声/甲壳振动）来分类龙虾的年龄（幼体/成体）和性别（雄/雌），在年龄分类上达到97%以上准确率，性别分类上超过93%准确率。


<details>
  <summary>Details</summary>
Motivation: 监测水生生物（特别是像龙虾这样的难以观察的物种）存在挑战。了解龙虾的栖息地、福利、繁殖、性别和年龄对于管理和保护至关重要。

Method: 在苏格兰Johnshaven使用水听器收集数据集，探索深度学习模型（1D-CNN、1D-DCNN）和六种机器学习模型（SVM、k-NN、朴素贝叶斯、随机森林、XGBoost、MLP），使用梅尔频率倒谱系数作为特征。

Result: 年龄分类（成体vs幼体）大多数模型准确率超过97%（朴素贝叶斯：91.31%）；性别分类除朴素贝叶斯外所有模型准确率超过93.23%。

Conclusion: 研究证明了监督机器学习和深度学习从龙虾声音中提取年龄和性别相关特征的潜力，为龙虾保护、检测和管理提供了一种有前景的非侵入性被动声学监测方法。

Abstract: Monitoring aquatic species, especially elusive ones like lobsters, presents challenges. This study focuses on Homarus gammarus (European lobster), a key species for fisheries and aquaculture, and leverages non-invasive Passive Acoustic Monitoring (PAM). Understanding lobster habitats, welfare, reproduction, sex, and age is crucial for management and conservation. While bioacoustic emissions have classified various aquatic species using Artificial Intelligence (AI) models, this research specifically uses H. gammarus bioacoustics (buzzing/carapace vibrations) to classify lobsters by age (juvenile/adult) and sex (male/female).
  The dataset was collected at Johnshaven, Scotland, using hydrophones in concrete tanks. We explored the efficacy of Deep Learning (DL) models (1D-CNN, 1D-DCNN) and six Machine Learning (ML) models (SVM, k-NN, Naive Bayes, Random Forest, XGBoost, MLP). Mel-frequency cepstral coefficients (MFCCs) were used as features.
  For age classification (adult vs. juvenile), most models achieved over 97% accuracy (Naive Bayes: 91.31%). For sex classification, all models except Naive Bayes surpassed 93.23%. These strong results demonstrate the potential of supervised ML and DL to extract age- and sex-related features from lobster sounds. This research offers a promising non-invasive PAM approach for lobster conservation, detection, and management in aquaculture and fisheries, enabling real-world edge computing applications for underwater species.

</details>


### [29] [PepEVOLVE: Position-Aware Dynamic Peptide Optimization via Group-Relative Advantage](https://arxiv.org/abs/2511.16912)
*Trieu Nguyen,Hao-Wei Pang,Shasha Feng*

Main category: cs.LG

TL;DR: PepEVOLVE是一个位置感知的动态框架，用于多目标优化大环肽序列，相比现有方法PepINVENT在优化效率和设计质量方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有的大环肽生成方法需要预先指定可突变位置，且依赖静态预训练和优化算法，限制了模型的泛化能力和优化效果。

Method: 采用动态掩码和CHUCKLES移位增强预训练；使用上下文无关多臂老虎机路由器发现高奖励残基；结合演化优化算法和组相对优势稳定强化学习更新。

Result: 在Rev结合大环肽基准测试中，PepEVOLVE达到更高平均分数（约0.8 vs 0.6），最佳候选分数0.95（vs 0.87），且收敛步数更少。

Conclusion: PepEVOLVE为未知最优编辑位点的大环肽先导优化提供了实用、可复现的路径，能更高效地探索多目标设计空间。

Abstract: Macrocyclic peptides are an emerging modality that combines biologics-like affinity with small-molecule-like developability, but their vast combinatorial space and multi-parameter objectives make lead optimization slow and challenging. Prior generative approaches such as PepINVENT require chemists to pre-specify mutable positions for optimization, choices that are not always known a priori, and rely on static pretraining and optimization algorithms that limit the model's ability to generalize and effectively optimize peptide sequences. We introduce PepEVOLVE, a position-aware, dynamic framework that learns both where to edit and how to dynamically optimize peptides for multi-objective improvement. PepEVOLVE (i) augments pretraining with dynamic masking and CHUCKLES shifting to improve generalization, (ii) uses a context-free multi-armed bandit router that discovers high-reward residues, and (iii) couples a novel evolving optimization algorithm with group-relative advantage to stabilize reinforcement updates. During in silico evaluations, the router policy reliably learns and concentrates probability on chemically meaningful sites that influence the peptide's properties. On a therapeutically motivated Rev-binding macrocycle benchmark, PepEVOLVE outperformed PepINVENT by reaching higher mean scores (approximately 0.8 vs. 0.6), achieving best candidates with a score of 0.95 (vs. 0.87), and converging in fewer steps under the task of optimizing permeability and lipophilicity with structural constraints. Overall, PepEVOLVE offers a practical, reproducible path to peptide lead optimization when optimal edit sites are unknown, enabling more efficient exploration and improving design quality across multiple objectives.

</details>


### [30] [A Hybrid Computational Intelligence Framework for scRNA-seq Imputation: Integrating scRecover and Random Forests](https://arxiv.org/abs/2511.16923)
*Ali Anaissi,Deshao Liu,Yuanzhe Jia,Weidong Huang,Widad Alyassine,Junaid Akram*

Main category: cs.LG

TL;DR: SCR-MF是一个模块化两阶段工作流，结合了scRecover的dropout检测和missForest的非参数插补，在单细胞RNA测序中实现稳健且可解释的性能。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序存在普遍的dropout事件，这会掩盖生物信号，需要有效的插补方法来恢复丢失的转录组信息。

Method: 采用模块化两阶段工作流：第一阶段使用scRecover进行dropout检测，第二阶段使用missForest进行非参数插补。

Result: 在公共和模拟数据集上，SCR-MF在大多数情况下达到或超过现有插补方法的性能，同时保持生物保真度和透明度。

Conclusion: SCR-MF在准确性和计算效率之间提供了有竞争力的平衡，适用于中等规模单细胞数据集。

Abstract: Single-cell RNA sequencing (scRNA-seq) enables transcriptomic profiling at cellular resolution but suffers from pervasive dropout events that obscure biological signals. We present SCR-MF, a modular two-stage workflow that combines principled dropout detection using scRecover with robust non-parametric imputation via missForest. Across public and simulated datasets, SCR-MF achieves robust and interpretable performance comparable to or exceeding existing imputation methods in most cases, while preserving biological fidelity and transparency. Runtime analysis demonstrates that SCR-MF provides a competitive balance between accuracy and computational efficiency, making it suitable for mid-scale single-cell datasets.

</details>


### [31] [CroTad: A Contrastive Reinforcement Learning Framework for Online Trajectory Anomaly Detection](https://arxiv.org/abs/2511.16929)
*Rui Xue,Dan He,Fengmei Jin,Chen Zhang,Xiaofang Zhou*

Main category: cs.LG

TL;DR: CroTad是一个基于对比强化学习的在线轨迹异常检测框架，无需阈值设置且对噪声和不规则采样数据具有鲁棒性，能够在子轨迹和点级别实时检测异常行为。


<details>
  <summary>Details</summary>
Motivation: 当前智能交通系统中的轨迹异常检测面临三个主要挑战：子轨迹异常检测研究不足、现有方法依赖人工调参阈值、不规则采样和训练集噪声影响模型性能。

Method: 提出对比强化学习框架CroTad，结合对比学习提取多样化正常出行模式，利用深度强化学习进行在线实时异常评分，实现细粒度异常检测。

Result: 在两个真实数据集上的广泛实验表明，该框架在各种评估场景下都具有有效性和鲁棒性。

Conclusion: CroTad框架成功解决了轨迹异常检测中的关键挑战，提供了一种无需阈值、抗噪声的在线检测解决方案。

Abstract: Detecting trajectory anomalies is a vital task in modern Intelligent Transportation Systems (ITS), enabling the identification of unsafe, inefficient, or irregular travel behaviours. While deep learning has emerged as the dominant approach, several key challenges remain unresolved. First, sub-trajectory anomaly detection, capable of pinpointing the precise segments where anomalies occur, remains underexplored compared to whole-trajectory analysis. Second, many existing methods depend on carefully tuned thresholds, limiting their adaptability in real-world applications. Moreover, the irregular sampling of trajectory data and the presence of noise in training sets further degrade model performance, making it difficult to learn reliable representations of normal routes. To address these challenges, we propose a contrastive reinforcement learning framework for online trajectory anomaly detection, CroTad. Our method is threshold-free and robust to noisy, irregularly sampled data. By incorporating contrastive learning, CroTad learns to extract diverse normal travel patterns for different itineraries and effectively distinguish anomalous behaviours at both sub-trajectory and point levels. The detection module leverages deep reinforcement learning to perform online, real-time anomaly scoring, enabling timely and fine-grained identification of abnormal segments. Extensive experiments on two real-world datasets demonstrate the effectiveness and robustness of our framework across various evaluation scenarios.

</details>


### [32] [A novel approach to classification of ECG arrhythmia types with latent ODEs](https://arxiv.org/abs/2511.16933)
*Angelina Yan,Matt L. Sampson,Peter Melchior*

Main category: cs.LG

TL;DR: 提出了一种端到端的心电图分类方法，使用潜在ODE建模连续ECG波形，通过降采样创建鲁棒特征向量，在360Hz、90Hz和45Hz采样频率下性能稳定，解决了可穿戴设备信号保真度与电池寿命的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决12导联ECG短时监测易漏诊间歇性事件，以及可穿戴ECG因电池限制导致采样频率不规则、形态分析困难的问题。

Method: 训练潜在ODE模型连续ECG波形，从高频单通道信号创建鲁棒特征向量，通过降采样（360Hz→90Hz→45Hz）构建三个潜在向量，使用梯度提升树进行分类。

Result: 在不同采样频率下性能下降极小，宏平均AUC-ROC值分别为：360Hz时0.984、90Hz时0.978、45Hz时0.976。

Conclusion: 该方法能够绕过信号保真度与电池寿命的权衡，实现更小的可穿戴设备，促进长期心脏健康监测。

Abstract: 12-lead ECGs with high sampling frequency are the clinical gold standard for arrhythmia detection, but their short-term, spot-check nature often misses intermittent events. Wearable ECGs enable long-term monitoring but suffer from irregular, lower sampling frequencies due to battery constraints, making morphology analysis challenging. We present an end-to-end classification pipeline to address these issues. We train a latent ODE to model continuous ECG waveforms and create robust feature vectors from high-frequency single-channel signals. We construct three latent vectors per waveform via downsampling the initial 360 Hz ECG to 90 Hz and 45 Hz. We then use a gradient boosted tree to classify these vectors and test robustness across frequencies. Performance shows minimal degradation, with macro-averaged AUC-ROC values of 0.984, 0.978, and 0.976 at 360 Hz, 90 Hz, and 45 Hz, respectively, suggesting a way to sidestep the trade-off between signal fidelity and battery life. This enables smaller wearables, promoting long-term monitoring of cardiac health.

</details>


### [33] [ToC: Tree-of-Claims Search with Multi-Agent Language Models](https://arxiv.org/abs/2511.16972)
*Shuyang Yu,Jianan Liang,Hui Hu*

Main category: cs.LG

TL;DR: 提出了Tree of Claims (ToC)框架，将专利权利要求编辑重新定义为引导搜索问题，通过结合蒙特卡洛树搜索和多智能体系统来优化专利权利要求的新颖性、范围保留和语义连贯性。


<details>
  <summary>Details</summary>
Motivation: 专利权利要求优化是一项关键但具有挑战性的任务，需要在新颖性最大化和法律范围保留之间取得平衡。手动权利要求起草劳动密集、成本高昂且不一致，而传统大语言模型缺乏精确权利要求细化所需的结构化迭代推理。

Method: ToC框架协同整合蒙特卡洛树搜索与协作多智能体系统，包括基于LLM的EditorAgent提出上下文基础编辑，以及ExaminerAgent通过结构化思维链分析新颖性和现有技术披露来模拟专利审查员批评。

Result: 在1145个权利要求基准上的实验评估表明，ToC在零样本和少样本场景中显著优于标准LLM，平均综合得分提高8%，在某些情况下高达9%。消融研究验证了ToC在生成优质、法律稳健权利要求修订方面的有效性。

Conclusion: ToC建立了一种透明、可控和可解释的方法论，有效将先进的LLM推理能力与战略性MCTS规划相结合，用于结构化专利权利要求优化。

Abstract: Optimizing patent claims is a critical yet challenging task, demanding careful balance between maximizing novelty and preserving legal scope. Manual claim drafting is labor-intensive, costly, and inherently inconsistent, while conventional Large Language Models (LLMs) often lack the structured, iterative reasoning essential for precise claim refinement. To address these challenges, we introduce Tree of Claims (ToC), an innovative framework that redefines claim editing as a guided search problem. ToC synergistically integrates Monte Carlo Tree Search (MCTS) with a collaborative multi-agent system, comprising an LLM-based EditorAgent that proposes contextually grounded edits, and an ExaminerAgent that mimics patent examiner critiques through structured, chain-of-thought analyses of novelty and prior art disclosure. Driven by a carefully designed multi-objective reward function, ToC jointly optimizes novelty, scope retention, and semantic coherence. Experimental evaluation on a benchmark of 1145 claims demonstrates that ToC significantly outperforms standard LLMs in zero-shot and few-shot scenarios, achieving an average composite score improvement of 8\%, and up to 9\% in certain cases. Extensive experiments, including detailed ablation studies, validate ToC's efficacy in generating superior, legally robust claim revisions. Overall, ToC establishes a transparent, controllable, and interpretable methodology that effectively bridges advanced LLM reasoning capabilities with strategic MCTS planning for structured patent claim optimization.The source code is available at https://github.com/ysy2003/ToC.

</details>


### [34] [FIRM: Federated In-client Regularized Multi-objective Alignment for Large Language Models](https://arxiv.org/abs/2511.16992)
*Fatemeh,Nourzad,Amirhossein Roknilamouki,Eylem Ekici,Jia,Liu,Ness B. Shroff*

Main category: cs.LG

TL;DR: FIRM是一种联邦多目标对齐算法，通过客户端内正则化解决多目标优化问题，避免多梯度传输，实现通信效率和客户端分歧漂移缓解。


<details>
  <summary>Details</summary>
Motivation: 现有联邦多目标优化方法存在严重通信瓶颈，依赖传输多个梯度对大模型不可扩展，且集中化训练存在数据隐私问题。

Method: 每个客户端本地解决正则化多目标优化问题，通过客户端内正则化直接缓解客户端分歧漂移，只需传输单组适应参数。

Result: FIRM实现更平滑的训练动态、减少客户端分歧漂移、改善奖励权衡，并能根据偏好平滑调整目标间权衡。

Conclusion: FIRM在联邦多目标对齐中实现了通信效率和收敛保证，为联邦学习中的多目标对齐提供了有效解决方案。

Abstract: Aligning Large Language Models (LLMs) with human values often involves balancing multiple, conflicting objectives such as helpfulness and harmlessness. Training these models is computationally intensive, and centralizing the process raises significant data privacy concerns. Federated Learning (FL) offers a compelling alternative, but existing Federated Multi-Objective Optimization (FMOO) methods face severe communication bottlenecks as their reliance on transmitting multiple gradients to a server is unscalable for large models. We introduce FIRM (Federated In-client Regularized Multi-objective alignment), a novel algorithm that achieves both client disagreement drift mitigation and communication efficiency. In FIRM, each client locally solves a regularized multi-objective optimization problem. By directly mitigating client disagreement drift through in-client regularization, our method eliminates the need for the multi-gradient transmissions common in prior works. Consequently, clients need only to transmit a single set of adapted parameters, maintaining high communication efficiency. We prove that our algorithm converges to Pareto-stationary points and, to our knowledge, provide the first finite-time convergence guarantees for this federated multi-objective alignment setting. Empirically, we show that FIRM leads to smoother training dynamics, reduced client disagreement drift, and improved reward trade-offs compared to baselines. We further propose a method to incorporate a preference over the objectives and report empirical Pareto plots, demonstrating that FIRM can smoothly adapt trade-offs between objectives in response to specified preferences.

</details>


### [35] [Mask the Redundancy: Evolving Masking Representation Learning for Multivariate Time-Series Clustering](https://arxiv.org/abs/2511.17008)
*Zexi Tan,Xiaopeng Luo,Yunlin Liu,Yiqun Zhang*

Main category: cs.LG

TL;DR: 本文提出了演化掩码多变量时间序列聚类方法，通过重要性感知的变量级掩码和多内生视图表示学习模块，解决时间序列中冗余信息对聚类性能的影响问题。


<details>
  <summary>Details</summary>
Motivation: 多变量时间序列中存在大量冗余信息，如稳态机器运行记录和太阳能发电的零输出期，这些冗余会降低对判别性时间戳的关注度，导致聚类性能瓶颈。现有掩码策略多为独立预处理步骤，无法动态适应聚类关键时间戳的重要性变化。

Method: 提出EMTC方法，包含重要性感知变量级掩码和多内生视图表示学习模块。IVM自适应引导模型学习更具判别性的聚类表示，MEV通过重构和对比学习路径增强泛化能力。

Result: 在15个真实基准数据集上的广泛实验表明，EMTC优于8种最先进方法，平均比最强基线提升4.85%。

Conclusion: EMTC方法通过动态掩码和多视角学习机制，有效提升了多变量时间序列聚类的性能，解决了冗余信息对表示学习的干扰问题。

Abstract: Multivariate Time-Series (MTS) clustering discovers intrinsic grouping patterns of temporal data samples. Although time-series provide rich discriminative information, they also contain substantial redundancy, such as steady-state machine operation records and zero-output periods of solar power generation. Such redundancy diminishes the attention given to discriminative timestamps in representation learning, thus leading to performance bottlenecks in MTS clustering. Masking has been widely adopted to enhance the MTS representation, where temporal reconstruction tasks are designed to capture critical information from MTS. However, most existing masking strategies appear to be standalone preprocessing steps, isolated from the learning process, which hinders dynamic adaptation to the importance of clustering-critical timestamps. Accordingly, this paper proposes the Evolving-masked MTS Clustering (EMTC) method, with its model architecture composed of Importance-aware Variate-wise Masking (IVM) and Multi-Endogenous Views (MEV) representation learning modules. IVM adaptively guides the model in learning more discriminative representations for clustering, while the MEV-based reconstruction and contrastive learning pathways enhance the generalization. That is, the MEV reconstruction facilitates multi-perspective complementary to prevent the masking from premature convergence, and the clustering-guided contrastive learning facilitates the joint optimization of representation and clustering. Extensive experiments on 15 real benchmark datasets demonstrate the superiority of EMTC in comparison with eight SOTA methods, where the EMTC achieves an average improvement of 4.85% over the strongest baselines.

</details>


### [36] [Energy Scaling Laws for Diffusion Models: Quantifying Compute and Carbon Emissions in Image Generation](https://arxiv.org/abs/2511.17031)
*Aniketh Iyengar,Jiaqi Han,Boris Ruf,Vincent Grari,Marcin Detyniecki,Stefano Ermon*

Main category: cs.LG

TL;DR: 本文提出基于计算复杂度（FLOPs）的扩散模型GPU能耗预测方法，通过Kaplan缩放定律实现跨模型和硬件的能耗准确预测。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成中的计算需求快速增长，引发了能耗和环境影响的担忧，但缺乏系统性的能耗预测方法。

Method: 将扩散模型推理分解为文本编码、迭代去噪和解码组件，基于计算复杂度建立能耗缩放定律，在多种模型和GPU架构上进行实验验证。

Result: 能耗缩放定律在单个架构内预测精度高（R平方>0.9），具有良好的跨架构泛化能力，能可靠估计未见过的模型-硬件组合的能耗。

Conclusion: 验证了扩散推理的计算密集型特性，为可持续AI部署规划和碳足迹估算提供了基础。

Abstract: The rapidly growing computational demands of diffusion models for image generation have raised significant concerns about energy consumption and environmental impact. While existing approaches to energy optimization focus on architectural improvements or hardware acceleration, there is a lack of principled methods to predict energy consumption across different model configurations and hardware setups. We propose an adaptation of Kaplan scaling laws to predict GPU energy consumption for diffusion models based on computational complexity (FLOPs). Our approach decomposes diffusion model inference into text encoding, iterative denoising, and decoding components, with the hypothesis that denoising operations dominate energy consumption due to their repeated execution across multiple inference steps. We conduct comprehensive experiments across four state-of-the-art diffusion models (Stable Diffusion 2, Stable Diffusion 3.5, Flux, and Qwen) on three GPU architectures (NVIDIA A100, A4000, A6000), spanning various inference configurations including resolution (256x256 to 1024x1024), precision (fp16/fp32), step counts (10-50), and classifier-free guidance settings. Our energy scaling law achieves high predictive accuracy within individual architectures (R-squared > 0.9) and exhibits strong cross-architecture generalization, maintaining high rank correlations across models and enabling reliable energy estimation for unseen model-hardware combinations. These results validate the compute-bound nature of diffusion inference and provide a foundation for sustainable AI deployment planning and carbon footprint estimation.

</details>


### [37] [Hash Collisions in Molecular Fingerprints: Effects on Property Prediction and Bayesian Optimization](https://arxiv.org/abs/2511.17078)
*Walter Virany,Austin Tripp*

Main category: cs.LG

TL;DR: 本文研究了在分子性质预测和贝叶斯优化中使用精确指纹相比标准压缩指纹是否能提高准确性。研究发现精确指纹在预测准确性上有小幅但一致的改进，但在贝叶斯优化性能上没有显著提升。


<details>
  <summary>Details</summary>
Motivation: 分子指纹方法使用哈希函数创建分子的固定长度向量表示，但哈希冲突导致不同子结构具有相同特征，从而在分子相似性计算中产生高估。

Method: 使用精确指纹与标准压缩指纹进行比较，在DOCKSTRING数据集的五个分子性质预测基准上，基于高斯过程作为底层预测模型进行实验。

Result: 在分子性质预测中，使用精确指纹相比压缩指纹产生了小幅但一致的准确性改进；但在贝叶斯优化任务中，这些改进并未转化为显著的性能提升。

Conclusion: 精确指纹在分子性质预测中能提供更好的准确性，但在贝叶斯优化应用中可能不是关键因素。

Abstract: Molecular fingerprinting methods use hash functions to create fixed-length vector representations of molecules. However, hash collisions cause distinct substructures to be represented with the same feature, leading to overestimates in molecular similarity calculations. We investigate whether using exact fingerprints improves accuracy compared to standard compressed fingerprints in molecular property prediction and Bayesian optimization where the underlying predictive model is a Gaussian process. We find that using exact fingerprints yields a small yet consistent improvement in predictive accuracy on five molecular property prediction benchmarks from the DOCKSTRING dataset. However, these gains did not translate to significant improvements in Bayesian optimization performance.

</details>


### [38] [Geometric-Disentangelment Unlearning](https://arxiv.org/abs/2511.17100)
*Duo Zhou,Yuji Zhang,Tianxin Wei,Ruizhong Qiu,Ke Yang,Xiao Lin,Cheng Qian,Jingrui He,Hanghang Tong,Heng Ji,Huan Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于几何解耦的机器学习遗忘方法(GU)，通过将遗忘梯度更新分解为保留梯度子空间的正交和切向分量，仅执行正交分量来避免对保留知识的损害。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习遗忘方法在有效遗忘和保留知识保护之间存在权衡，缺乏对遗忘更新如何损害保留知识的理论分析。本文旨在探索具有理论保证的解决方案。

Method: 基于一阶分析，将遗忘梯度更新分解为保留梯度子空间的切向和正交分量，仅执行正交分量。在信任区域预算下，推导出最优的投影方向。

Result: GU方法在TOFU、MUSE和WMDP三个基准测试中均实现了持续改进，能够有效缓解副作用。

Conclusion: 几何解耦遗忘方法提供了一种理论上有保证的简单解决方案，可以即插即用地与现有基于梯度的遗忘方法结合，在保持保留知识的同时实现有效遗忘。

Abstract: Machine unlearning, the removal of a training subset's influence from a deployed model, is critical for privacy preservation and model reliability, yet gradient ascent on forget samples often harms retained knowledge. Existing approaches face a persistent tradeoff between effective forgetting and preservation on the retain set. While previous methods provide useful heuristics, they often lack a formal analysis on how exactly forgetting updates harm retained knowledge, and whether the side effects can be removed with theoretical guarantees. To explore a theoretically sound and simple solution, we start from the first principle on how performance on the retain set is actually affected: a first-order analysis of the local change of the retain loss under small parameter updates during model training. We start from a crisp equivalence: the retain loss is unchanged to first order iff the update direction is orthogonal to the subspace spanned by retain gradients ("retain-invariant"). This identifies the entangled component as the tangential part of forget update within the retain-gradient subspace, and characterizes disentanglement as orthogonality. Guided by this, we propose the Geometric-disentanglement Unlearning (GU) that decomposes any candidate forget gradient update into tangential and normal components to retain space and executes only the normal component. Under a standard trust-region budget, the projected direction aligned with the raw forget gradient is optimal among all first-order retain-invariant moves, and we also derive the optimal projected direction for joint forget-retain updating objectives. Our method is plug-and-play and can be attached to existing gradient-based unlearning procedures to mitigate side effects. GU achieves consistent improvement on various methods across three benchmarks TOFU, MUSE, and WMDP.

</details>


### [39] [Four decades of circumpolar super-resolved satellite land surface temperature data](https://arxiv.org/abs/2511.17134)
*Sonia Dupuis,Nando Metzger,Konrad Schindler,Frank Göttsche,Stefan Wunderle*

Main category: cs.LG

TL;DR: 本文开发了一个42年泛北极地表温度数据集，通过深度各向异性扩散模型将AVHRR GAC数据从粗分辨率降尺度到1公里，用于改善北极地区多年冻土建模和气候监测。


<details>
  <summary>Details</summary>
Motivation: 北极地区快速变暖，但AVHRR全球覆盖数据的粗空间分辨率限制了其在精细尺度多年冻土动态分析中的应用，需要高分辨率长期LST记录来支持气候趋势检测。

Method: 使用基于深度各向异性扩散模型的超分辨率算法，以MODIS LST数据为训练集，结合高分辨率土地覆盖、数字高程和植被高度图作为指导，将AVHRR GAC数据降尺度到1公里。

Result: 生成了覆盖整个泛北极地区42年、每日两次的1公里LST观测数据集，显著提高了空间分辨率，支持多年冻土建模、近地表气温重建和格陵兰冰盖表面质量平衡评估。

Conclusion: 该数据集填补了MODIS前时代的气候监测空白，为北极地区精细尺度地表过程分析提供了重要工具，并为未来卫星热红外观测和气候数据记录连续性提供了适应性框架。

Abstract: Land surface temperature (LST) is an essential climate variable (ECV) crucial for understanding land-atmosphere energy exchange and monitoring climate change, especially in the rapidly warming Arctic. Long-term satellite-based LST records, such as those derived from the Advanced Very High Resolution Radiometer (AVHRR), are essential for detecting climate trends. However, the coarse spatial resolution of AVHRR's global area coverage (GAC) data limit their utility for analyzing fine-scale permafrost dynamics and other surface processes in the Arctic. This paper presents a new 42 years pan-Arctic LST dataset, downscaled from AVHRR GAC to 1 km with a super-resolution algorithm based on a deep anisotropic diffusion model. The model is trained on MODIS LST data, using coarsened inputs and native-resolution outputs, guided by high-resolution land cover, digital elevation, and vegetation height maps. The resulting dataset provides twice-daily, 1 km LST observations for the entire pan-Arctic region over four decades. This enhanced dataset enables improved modelling of permafrost, reconstruction of near-surface air temperature, and assessment of surface mass balance of the Greenland Ice Sheet. Additionally, it supports climate monitoring efforts in the pre-MODIS era and offers a framework adaptable to future satellite missions for thermal infrared observation and climate data record continuity.

</details>


### [40] [Reconstruction of Surface EMG Signal using IMU data for Upper Limb Actions](https://arxiv.org/abs/2511.17200)
*Shubhranil Basak,Mada Hemanth,Madhav Rao*

Main category: cs.LG

TL;DR: 使用深度学习从6轴IMU数据合成归一化sEMG信号，基于扩张因果卷积的滑动窗口波网模型成功预测肌肉激活时机和整体形状。


<details>
  <summary>Details</summary>
Motivation: sEMG信号对肌肉功能分析很重要但易受噪声干扰且采集困难，IMU提供了可穿戴的替代方案，研究探索从IMU数据合成sEMG信号的可行性。

Method: 收集同步的sEMG和IMU数据，使用基于扩张因果卷积的滑动窗口波网模型训练从IMU到sEMG的映射。

Result: 模型成功预测肌肉激活的时机和整体形状，但峰值幅度常被低估，具有高时间保真度。

Conclusion: 该方法在假肢控制和康复生物反馈等应用中用于肌肉意图检测是可行的。

Abstract: Surface Electromyography (sEMG) provides vital insights into muscle function, but it can be noisy and challenging to acquire. Inertial Measurement Units (IMUs) provide a robust and wearable alternative to motion capture systems. This paper investigates the synthesis of normalized sEMG signals from 6-axis IMU data using a deep learning approach. We collected simultaneous sEMG and IMU data sampled at 1~KHz for various arm movements. A Sliding-Window-Wave-Net model, based on dilated causal convolutions, was trained to map the IMU data to the sEMG signal. The results show that the model successfully predicts the timing and general shape of muscle activations. Although peak amplitudes were often underestimated, the high temporal fidelity demonstrates the feasibility of using this method for muscle intent detection in applications such as prosthetics and rehabilitation biofeedback.

</details>


### [41] [DS-Span: Single-Phase Discriminative Subgraph Mining for Efficient Graph Embeddings](https://arxiv.org/abs/2511.17419)
*Yeamin Kaiser,Muhammed Tasnim Bin Anwar,Bholanath Das,Chowdhury Farhan Ahmed,Md. Tanvir Alam*

Main category: cs.LG

TL;DR: DS-Span是一个单阶段判别子图挖掘框架，统一了模式增长、剪枝和监督驱动评分，通过覆盖限制机制和信息增益指导选择，生成紧凑且判别性强的子图特征用于图嵌入和分类。


<details>
  <summary>Details</summary>
Motivation: 现有的频繁或判别子图挖掘方法存在冗余的多阶段流程、高计算成本和挖掘结构与判别相关性之间弱耦合的问题，需要更高效统一的解决方案。

Method: 提出DS-Span框架，在搜索空间的一次遍历中统一模式增长、剪枝和监督驱动评分，引入覆盖限制机制动态限制探索，使用信息增益指导选择具有强类别分离能力的子图。

Result: 在基准测试中，DS-Span比现有多阶段方法生成更紧凑和判别性的子图特征，在显著减少运行时间的同时达到更高或相当的准确率。

Conclusion: 统一的单阶段判别挖掘方法为可扩展和可解释的图表示学习提供了有前景的基础。

Abstract: Graph representation learning seeks to transform complex, high-dimensional graph structures into compact vector spaces that preserve both topology and semantics. Among the various strategies, subgraph-based methods provide an interpretable bridge between symbolic pattern discovery and continuous embedding learning. Yet, existing frequent or discriminative subgraph mining approaches often suffer from redundant multi-phase pipelines, high computational cost, and weak coupling between mined structures and their discriminative relevance. We propose DS-Span, a single-phase discriminative subgraph mining framework that unifies pattern growth, pruning, and supervision-driven scoring within one traversal of the search space. DS-Span introduces a coverage-capped eligibility mechanism that dynamically limits exploration once a graph is sufficiently represented, and an information-gain-guided selection that promotes subgraphs with strong class-separating ability while minimizing redundancy. The resulting subgraph set serves as an efficient, interpretable basis for downstream graph embedding and classification. Extensive experiments across benchmarks demonstrate that DS-Span generates more compact and discriminative subgraph features than prior multi-stage methods, achieving higher or comparable accuracy with significantly reduced runtime. These results highlight the potential of unified, single-phase discriminative mining as a foundation for scalable and interpretable graph representation learning.

</details>


### [42] [FlexiFlow: decomposable flow matching for generation of flexible molecular ensemble](https://arxiv.org/abs/2511.17249)
*Riccardo Tedoldi,Ola Engkvist,Patrick Bryant,Hossein Azizpour,Jon Paul Janet,Alessandro Tibo*

Main category: cs.LG

TL;DR: FlexiFlow是一种新颖的架构，扩展了流匹配模型，能够联合采样分子及其多个构象，同时在药物发现中保持等变性和置换不变性。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的3D从头设计流匹配或扩散模型仅限于生成单一构象，但分子的构象景观决定了其可观察性质和与蛋白质靶标的结合能力。通过生成一组代表性的低能构象体，可以更直接评估这些性质，并可能提高生成具有所需热力学可观察性质的分子能力。

Method: 提出FlexiFlow架构，扩展流匹配模型，允许联合采样分子及其多个构象，同时保持等变性和置换不变性。

Result: 在QM9和GEOM Drugs数据集上验证了方法的有效性，在分子生成任务中取得了最先进的结果。FlexiFlow能够生成有效、无应变、独特且新颖的分子，同时对训练数据分布具有高保真度，并能捕捉分子的构象多样性。此外，该模型生成的构象集合在推理时间的一小部分内提供了与最先进物理方法相似的覆盖范围。

Conclusion: FlexiFlow可以成功转移到蛋白质条件配体生成任务，即使数据集中只包含静态口袋而没有伴随构象。该方法在分子生成和构象多样性捕获方面表现出色，为药物发现提供了更全面的分子结构采样能力。

Abstract: Sampling useful three-dimensional molecular structures along with their most favorable conformations is a key challenge in drug discovery. Current state-of-the-art 3D de-novo design flow matching or diffusion-based models are limited to generating a single conformation. However, the conformational landscape of a molecule determines its observable properties and how tightly it is able to bind to a given protein target. By generating a representative set of low-energy conformers, we can more directly assess these properties and potentially improve the ability to generate molecules with desired thermodynamic observables. Towards this aim, we propose FlexiFlow, a novel architecture that extends flow-matching models, allowing for the joint sampling of molecules along with multiple conformations while preserving both equivariance and permutation invariance. We demonstrate the effectiveness of our approach on the QM9 and GEOM Drugs datasets, achieving state-of-the-art results in molecular generation tasks. Our results show that FlexiFlow can generate valid, unstrained, unique, and novel molecules with high fidelity to the training data distribution, while also capturing the conformational diversity of molecules. Moreover, we show that our model can generate conformational ensembles that provide similar coverage to state-of-the-art physics-based methods at a fraction of the inference time. Finally, FlexiFlow can be successfully transferred to the protein-conditioned ligand generation task, even when the dataset contains only static pockets without accompanying conformations.

</details>


### [43] [PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM](https://arxiv.org/abs/2511.17467)
*Siqi Liang,Yudi Zhang,Yue Guo*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a novel framework for persona-based language model system, motivated by the need for personalized AI agents that adapt to individual user preferences. In our approach, the agent embodies the user's "persona" (e.g. user profile or taste) and is powered by a large language model (LLM). To enable the agent to leverage rich contextual information, we introduce a Knowledge-Graph-enhanced Retrieval-Augmented Generation (Graph RAG) mechanism that constructs an LLM-derived graph index of relevant documents and summarizes communities of related information. Our framework generates personalized prompts by combining: (1) a summary of the user's historical behaviors and preferences extracted from the knowledge graph, and (2) relevant global interaction patterns identified through graph-based community detection. This dynamic prompt engineering approach allows the agent to maintain consistent persona-aligned behaviors while benefiting from collective knowledge. On the LaMP benchmark, our method improves news categorization F1 by 11.1%, movie tagging F1 by 56.1%, and reduces product rating MAE by 10.4% over prior methods. Our code is available at https://anonymous.4open.science/r/PersonaAgentwGraphRAG-DE6F

</details>


### [44] [Automobile demand forecasting: Spatiotemporal and hierarchical modeling, life cycle dynamics, and user-generated online information](https://arxiv.org/abs/2511.17275)
*Tom Nahrendorf,Stefan Minner,Helfried Binder,Richard Zinck*

Main category: cs.LG

TL;DR: 该研究针对德国高端汽车制造商的多产品、多市场、多层次需求预测问题，结合点预测和概率预测方法，使用LightGBM集成模型、分位数回归和混合整数线性规划协调方法，发现时空依赖性和取整偏差对预测精度有重要影响。


<details>
  <summary>Details</summary>
Motivation: 高端汽车制造商面临产品种类多、变体级数据稀疏和市场动态波动等复杂预测挑战，需要解决多产品、多市场、多层次层次结构中的月度汽车需求预测问题。

Method: 结合战略和运营规划层面的点预测和概率预测，利用LightGBM模型集成、池化训练集、分位数回归和混合整数线性规划协调方法。

Result: 时空依赖性和取整偏差显著影响预测精度，强调整数预测对运营可行性的重要性。短期需求受生命周期成熟度、自回归动量和运营信号影响，中期需求反映在线参与、规划目标和竞争指标等预期驱动因素。

Conclusion: 在线行为数据显著提高了分散层面的预测精度，短期需求具有反应性特征，中期需求则体现预期性驱动因素。

Abstract: Premium automotive manufacturers face increasingly complex forecasting challenges due to high product variety, sparse variant-level data, and volatile market dynamics. This study addresses monthly automobile demand forecasting across a multi-product, multi-market, and multi-level hierarchy using data from a German premium manufacturer. The methodology combines point and probabilistic forecasts across strategic and operational planning levels, leveraging ensembles of LightGBM models with pooled training sets, quantile regression, and a mixed-integer linear programming reconciliation approach. Results highlight that spatiotemporal dependencies, as well as rounding bias, significantly affect forecast accuracy, underscoring the importance of integer forecasts for operational feasibility. Shapley analysis shows that short-term demand is reactive, shaped by life cycle maturity, autoregressive momentum, and operational signals, whereas medium-term demand reflects anticipatory drivers such as online engagement, planning targets, and competitive indicators, with online behavioral data considerably improving accuracy at disaggregated levels.

</details>


### [45] [SAVeD: Semantic Aware Version Discovery](https://arxiv.org/abs/2511.17298)
*Artem Frenk,Roee Shraga*

Main category: cs.LG

TL;DR: SAVeD是一个基于对比学习的框架，用于识别结构化数据集的版本，无需依赖元数据、标签或集成假设。它通过生成增强表视图、使用自定义transformer编码器嵌入，并在潜在空间中进行对比优化来学习语义相似性。


<details>
  <summary>Details</summary>
Motivation: 解决数据科学中由于难以识别相似工作或数据集转换而导致的重复劳动问题。

Method: 采用改进的SimCLR流程，通过随机转换（如行删除、编码扰动）生成增强表视图，使用自定义transformer编码器嵌入，并在潜在空间中进行对比学习以优化语义相似性。

Result: 在五个标准数据集上的实验显示，SAVeD在完全未见过的表格上实现了显著更高的准确率，分离分数显著提升，能够有效区分语义改变的版本。

Conclusion: SAVeD在数据集版本检测方面表现出色，相比未训练的基线和现有最先进方法（如Starmie），取得了竞争性或更优的结果。

Abstract: Our work introduces SAVeD (Semantically Aware Version Detection), a contrastive learning-based framework for identifying versions of structured datasets without relying on metadata, labels, or integration-based assumptions. SAVeD addresses a common challenge in data science of repeated labor due to a difficulty of similar work or transformations on datasets. SAVeD employs a modified SimCLR pipeline, generating augmented table views through random transformations (e.g., row deletion, encoding perturbations). These views are embedded via a custom transformer encoder and contrasted in latent space to optimize semantic similarity. Our model learns to minimize distances between augmented views of the same dataset and maximize those between unrelated tables. We evaluate performance using validation accuracy and separation, defined respectively as the proportion of correctly classified version/non-version pairs on a hold-out set, and the difference between average similarities of versioned and non-versioned tables (defined by a benchmark, and not provided to the model). Our experiments span five canonical datasets from the Semantic Versioning in Databases Benchmark, and demonstrate substantial gains post-training. SAVeD achieves significantly higher accuracy on completely unseen tables in, and a significant boost in separation scores, confirming its capability to distinguish semantically altered versions. Compared to untrained baselines and prior state-of-the-art dataset-discovery methods like Starmie, our custom encoder achieves competitive or superior results.

</details>


### [46] [Self-supervised denoising of raw tomography detector data for improved image reconstruction](https://arxiv.org/abs/2511.17312)
*Israt Jahan Tulin,Sebastian Starke,Dominic Windisch,André Bieberle,Peter Steinbach*

Main category: cs.LG

TL;DR: 论文研究了两种自监督深度学习方法用于对超快电子束X射线CT的原始探测器数据进行去噪，并与非学习方法进行对比，发现深度学习方法能有效提升信噪比并改善重建图像质量。


<details>
  <summary>Details</summary>
Motivation: 超快电子束X射线CT由于测量时间短导致数据噪声大，产生重建伪影并限制图像质量，需要有效的去噪方法来改善这一问题。

Method: 采用两种自监督深度学习方法对原始探测器数据进行去噪，并与非学习型去噪方法进行对比评估。

Result: 深度学习方法能够增强探测器数据的信噪比，并在重建图像中带来一致的改进，表现优于非学习方法。

Conclusion: 自监督深度学习方法在超快电子束X射线CT去噪方面具有显著优势，能够有效改善图像质量。

Abstract: Ultrafast electron beam X-ray computed tomography produces noisy data due to short measurement times, causing reconstruction artifacts and limiting overall image quality. To counteract these issues, two self-supervised deep learning methods for denoising of raw detector data were investigated and compared against a non-learning based denoising method. We found that the application of the deep-learning-based methods was able to enhance signal-to-noise ratios in the detector data and also led to consistent improvements of the reconstructed images, outperforming the non-learning based method.

</details>


### [47] [ReBaPL: Repulsive Bayesian Prompt Learning](https://arxiv.org/abs/2511.17339)
*Yassir Bendou,Omar Ezzahir,Eduardo Fernandes Montesuma,Gabriel Mahuas,Victoria Shevchenko,Mike Gartrell*

Main category: cs.LG

TL;DR: 本文提出了Repulsive Bayesian Prompt Learning (ReBaPL)，一种新颖的贝叶斯提示学习方法，通过整合循环步长调度和随机梯度哈密顿蒙特卡洛算法，结合表示空间排斥力，有效探索提示的多模态后验分布，提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统提示学习方法容易过拟合且泛化能力不足，贝叶斯提示学习虽然能增强鲁棒性，但现有方法难以有效探索复杂的多模态后验分布。

Method: 结合循环步长调度与SGHMC算法，交替进行探索和利用阶段；引入基于概率度量的排斥力（MMD和Wasserstein距离），在表示空间产生排斥效应防止过早收敛到单一模式。

Result: 在多个基准数据集上验证了ReBaPL的有效性，相比最先进的提示学习方法表现出更优越的性能。

Conclusion: ReBaPL提供了一种模块化的即插即用贝叶斯扩展方案，能够更全面地刻画提示后验分布，显著提升泛化性能。

Abstract: Prompt learning has emerged as an effective technique for fine-tuning large-scale foundation models for downstream tasks. However, conventional prompt tuning methods are prone to overfitting and can struggle with out-of-distribution generalization. To address these limitations, Bayesian prompt learning has been proposed, which frames prompt optimization as a Bayesian inference problem to enhance robustness. This paper introduces Repulsive Bayesian Prompt Learning (ReBaPL), a novel method for Bayesian prompt learning, designed to efficiently explore the complex and often multimodal posterior landscape of prompts. Our method integrates a cyclical step-size schedule with a stochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm, enabling alternating phases of exploration to discover new modes, and exploitation to refine existing modes. Furthermore, we introduce a repulsive force derived from a potential function over probability metrics (including Maximum Mean Discrepancy and Wasserstein distance) computed on the distributions of representations produced by different prompts. This representation-space repulsion diversifies exploration and prevents premature collapse to a single mode. Our approach allows for a more comprehensive characterization of the prompt posterior distribution, leading to improved generalization. In contrast to prior Bayesian prompt learning methods, our method provides a modular plug-and-play Bayesian extension of any existing prompt learning method based on maximum likelihood estimation. We demonstrate the efficacy of ReBaPL on several benchmark datasets, showing superior performance over state-of-the-art methods for prompt learning.

</details>


### [48] [Convergence and stability of Q-learning in Hierarchical Reinforcement Learning](https://arxiv.org/abs/2511.17351)
*Massimiliano Manenti,Andrea Iannelli*

Main category: cs.LG

TL;DR: 本文提出了封建Q学习方案，研究了其耦合更新的收敛性和稳定性条件，通过随机逼近理论和ODE方法证明了收敛性，并将更新收敛点解释为博弈均衡。


<details>
  <summary>Details</summary>
Motivation: 分层强化学习在捕捉决策问题的时间结构和增强持续学习能力方面具有潜力，但理论保证落后于实践，需要提供收敛性和稳定性分析。

Method: 采用封建Q学习方案，利用随机逼近理论和ODE方法进行理论分析，通过实验验证理论结果。

Result: 证明了封建Q学习的收敛性和稳定性，更新收敛到可解释为博弈均衡的点，实验支持理论预期。

Conclusion: 为封建强化学习提供了原则性的收敛性和稳定性分析，为分层强化学习的博弈论方法打开了大门。

Abstract: Hierarchical Reinforcement Learning promises, among other benefits, to efficiently capture and utilize the temporal structure of a decision-making problem and to enhance continual learning capabilities, but theoretical guarantees lag behind practice. In this paper, we propose a Feudal Q-learning scheme and investigate under which conditions its coupled updates converge and are stable. By leveraging the theory of Stochastic Approximation and the ODE method, we present a theorem stating the convergence and stability properties of Feudal Q-learning. This provides a principled convergence and stability analysis tailored to Feudal RL. Moreover, we show that the updates converge to a point that can be interpreted as an equilibrium of a suitably defined game, opening the door to game-theoretic approaches to Hierarchical RL. Lastly, experiments based on the Feudal Q-learning algorithm support the outcomes anticipated by theory.

</details>


### [49] [R2PS: Worst-Case Robust Real-Time Pursuit Strategies under Partial Observability](https://arxiv.org/abs/2511.17367)
*Runyu Lu,Ruochuan Shi,Yuanheng Zhu,Dongbin Zhao*

Main category: cs.LG

TL;DR: 本文提出了首个在部分可观测性下的最坏情况鲁棒实时追捕策略（R2PS）方法，通过信念保持机制和强化学习框架，实现了在未知图结构上的零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 现有方法在部分可观测性和逃避者能够预测追捕者行动的情况下存在局限，需要开发能够在现实世界图中实时应用的鲁棒追捕策略。

Method: 首先证明传统动态规划算法在异步移动下保持最优性，然后提出信念保持机制扩展DP策略到部分可观测设置，最后将信念保持嵌入EPG框架进行跨图强化学习。

Result: 强化学习后的策略实现了对未见真实世界图结构的鲁棒零样本泛化，并始终优于现有游戏RL方法直接在测试图上训练的策略。

Conclusion: R2PS方法成功解决了部分可观测性下的实时追捕策略问题，具有实际应用价值。

Abstract: Computing worst-case robust strategies in pursuit-evasion games (PEGs) is time-consuming, especially when real-world factors like partial observability are considered. While important for general security purposes, real-time applicable pursuit strategies for graph-based PEGs are currently missing when the pursuers only have imperfect information about the evader's position. Although state-of-the-art reinforcement learning (RL) methods like Equilibrium Policy Generalization (EPG) and Grasper provide guidelines for learning graph neural network (GNN) policies robust to different game dynamics, they are restricted to the scenario of perfect information and do not take into account the possible case where the evader can predict the pursuers' actions. This paper introduces the first approach to worst-case robust real-time pursuit strategies (R2PS) under partial observability. We first prove that a traditional dynamic programming (DP) algorithm for solving Markov PEGs maintains optimality under the asynchronous moves by the evader. Then, we propose a belief preservation mechanism about the evader's possible positions, extending the DP pursuit strategies to a partially observable setting. Finally, we embed the belief preservation into the state-of-the-art EPG framework to finish our R2PS learning scheme, which leads to a real-time pursuer policy through cross-graph reinforcement learning against the asynchronous-move DP evasion strategies. After reinforcement learning, our policy achieves robust zero-shot generalization to unseen real-world graph structures and consistently outperforms the policy directly trained on the test graphs by the existing game RL approach.

</details>


### [50] [Stable Coresets via Posterior Sampling: Aligning Induced and Full Loss Landscapes](https://arxiv.org/abs/2511.17399)
*Wei-Kai Chang,Rajiv Khanna*

Main category: cs.LG

TL;DR: 提出一种基于后验采样的核心集选择框架，解决梯度方法在数据预算有限时面临的挑战，通过连接后验采样和损失景观来提高鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型规模扩大，计算需求增加，需要有效的核心集选择技术来加速训练。梯度方法虽然理论基础强，但面临SGD基线强和代表性随时间崩溃的挑战。

Method: 建立后验采样与损失景观的连接，提出基于模型权重后验采样的平滑损失函数，增强稳定性和泛化能力，同时保持计算效率。

Result: 通过大量实验证明，该方法在多个数据集上比现有技术实现更快的训练和更好的泛化性能。

Conclusion: 提出的基于后验采样的核心集选择框架有效解决了梯度方法的局限性，在数据预算有限的情况下实现了优越的训练加速和泛化能力。

Abstract: As deep learning models continue to scale, the growing computational demands have amplified the need for effective coreset selection techniques. Coreset selection aims to accelerate training by identifying small, representative subsets of data that approximate the performance of the full dataset. Among various approaches, gradient based methods stand out due to their strong theoretical underpinnings and practical benefits, particularly under limited data budgets. However, these methods face challenges such as naive stochastic gradient descent (SGD) acting as a surprisingly strong baseline and the breakdown of representativeness due to loss curvature mismatches over time.
  In this work, we propose a novel framework that addresses these limitations. First, we establish a connection between posterior sampling and loss landscapes, enabling robust coreset selection even in high data corruption scenarios. Second, we introduce a smoothed loss function based on posterior sampling onto the model weights, enhancing stability and generalization while maintaining computational efficiency. We also present a novel convergence analysis for our sampling-based coreset selection method. Finally, through extensive experiments, we demonstrate how our approach achieves faster training and enhanced generalization across diverse datasets than the current state of the art.

</details>


### [51] [Towards fully differentiable neural ocean model with Veros](https://arxiv.org/abs/2511.17427)
*Etienne Meunier,Said Ouala,Hugo Frezat,Julien Le Sommer,Ronan Fablet*

Main category: cs.LG

TL;DR: 本文提出了VEROS海洋模型的可微分扩展，使其能够通过自动微分框架进行梯度计算，并展示了在海洋状态校正和物理参数校准中的应用。


<details>
  <summary>Details</summary>
Motivation: 传统海洋模型难以进行梯度计算，限制了基于梯度的优化方法在海洋建模中的应用。本文旨在通过可微分编程技术，使海洋模型能够支持自动微分，从而促进端到端学习和参数调优。

Method: 对VEROS海洋模型进行关键修改，使其完全兼容JAX自动微分框架，并评估实现结果的数值一致性。

Result: 成功实现了VEROS模型的可微分扩展，验证了数值一致性，并通过两个应用案例展示了其有效性：基于梯度的初始海洋状态校正和从模型观测直接校准未知物理参数。

Conclusion: 可微分编程能够有效促进海洋建模中的端到端学习和参数调优，为海洋科学研究提供了新的工具和方法。

Abstract: We present a differentiable extension of the VEROS ocean model, enabling automatic differentiation through its dynamical core. We describe the key modifications required to make the model fully compatible with JAX autodifferentiation framework and evaluate the numerical consistency of the resulting implementation. Two illustrative applications are then demonstrated: (i) the correction of an initial ocean state through gradient-based optimization, and (ii) the calibration of unknown physical parameters directly from model observations. These examples highlight how differentiable programming can facilitate end-to-end learning and parameter tuning in ocean modeling. Our implementation is available online.

</details>


### [52] [Unmasking Airborne Threats: Guided-Transformers for Portable Aerosol Mass Spectrometry](https://arxiv.org/abs/2511.17446)
*Kyle M. Regan,Michael McLoughlin,Wayne A. Bryden,Gonzalo R. Arce*

Main category: cs.LG

TL;DR: MS-DGFormer是一个基于Transformer的数据驱动框架，可直接处理原始质谱数据，实现单次检测的气溶胶病原体识别，无需复杂的样品预处理。


<details>
  <summary>Details</summary>
Motivation: 传统MALDI-MS依赖繁琐的样品制备和多谱平均，限制了其在实时环境监测中的应用，特别是在新兴气溶胶MALDI-MS系统中，自主采样会产生噪声谱图，需要单次检测能力。

Method: 提出MS-DGFormer框架，采用Transformer架构捕捉时间序列谱的长程依赖关系，并引入基于奇异值分解(SVD)的字典编码器来集成去噪谱信息，增强特征提取能力。

Result: 该方法能够从单次谱图中稳健地识别关键生物分子模式，实现气溶胶样品中病原体的优越识别性能。

Conclusion: 通过消除广泛预处理需求，该方法释放了便携式、可部署MALDI-MS平台的潜力，革新了环境病原体检测和生物威胁快速响应能力。

Abstract: Matrix Assisted Laser Desorption/Ionization Mass Spectrometry (MALDI-MS) is a cornerstone in biomolecular analysis, offering precise identification of pathogens through unique mass spectral signatures. Yet, its reliance on labor-intensive sample preparation and multi-shot spectral averaging restricts its use to laboratory settings, rendering it impractical for real-time environmental monitoring. These limitations are especially pronounced in emerging aerosol MALDI-MS systems, where autonomous sampling generates noisy spectra for unknown aerosol analytes, requiring single-shot detection for effective analysis. Addressing these challenges, we propose the Mass Spectral Dictionary-Guided Transformer (MS-DGFormer): a data-driven framework that redefines spectral analysis by directly processing raw, minimally prepared mass spectral data. MS-DGFormer leverages a transformer architecture, designed to capture the long-range dependencies inherent in these time-series spectra. To enhance feature extraction, we introduce a novel dictionary encoder that integrates denoised spectral information derived from Singular Value Decomposition (SVD), enabling the model to discern critical biomolecular patterns from single-shot spectra with robust performance. This innovation provides a system to achieve superior pathogen identification from aerosol samples, facilitating autonomous, real-time analysis in field conditions. By eliminating the need for extensive preprocessing, our method unlocks the potential for portable, deployable MALDI-MS platforms, revolutionizing environmental pathogen detection and rapid response to biological threats.

</details>


### [53] [Harnessing Data from Clustered LQR Systems: Personalized and Collaborative Policy Optimization](https://arxiv.org/abs/2511.17489)
*Vinay Kanakeri,Shivam Bajaj,Ashwin Verma,Vijay Gupta,Aritra Mitra*

Main category: cs.LG

TL;DR: 该论文提出了一种结合聚类和强化学习的新算法，用于在多个相似线性过程的环境中提高样本效率，通过同时进行聚类和学习来为每个聚类输出个性化策略。


<details>
  <summary>Details</summary>
Motivation: 强化学习通常数据需求量大，为了提升样本效率，可以利用来自'近似相似'过程的数据。但由于过程模型未知，识别哪些过程相似具有挑战性。

Method: 结合顺序消除和零阶策略优化的思想，提出新算法在多智能体LQR设置中同时执行聚类和学习，为每个聚类输出个性化控制器。

Result: 在适当的聚类分离条件下，证明该方法能以高概率保证正确聚类，且每个聚类学习策略的次优性差距与聚类大小成反比，没有额外偏差。

Conclusion: 这是首个揭示聚类如何在数据驱动控制中用于学习个性化策略的工作，既能享受协作带来的统计收益，又不会因包含不相似过程数据而遭受次优性，且通信开销较低。

Abstract: It is known that reinforcement learning (RL) is data-hungry. To improve sample-efficiency of RL, it has been proposed that the learning algorithm utilize data from 'approximately similar' processes. However, since the process models are unknown, identifying which other processes are similar poses a challenge. In this work, we study this problem in the context of the benchmark Linear Quadratic Regulator (LQR) setting. Specifically, we consider a setting with multiple agents, each corresponding to a copy of a linear process to be controlled. The agents' local processes can be partitioned into clusters based on similarities in dynamics and tasks. Combining ideas from sequential elimination and zeroth-order policy optimization, we propose a new algorithm that performs simultaneous clustering and learning to output a personalized policy (controller) for each cluster. Under a suitable notion of cluster separation that captures differences in closed-loop performance across systems, we prove that our approach guarantees correct clustering with high probability. Furthermore, we show that the sub-optimality gap of the policy learned for each cluster scales inversely with the size of the cluster, with no additional bias, unlike in prior works on collaborative learning-based control. Our work is the first to reveal how clustering can be used in data-driven control to learn personalized policies that enjoy statistical gains from collaboration but do not suffer sub-optimality due to inclusion of data from dissimilar processes. From a distributed implementation perspective, our method is attractive as it incurs only a mild logarithmic communication overhead.

</details>
