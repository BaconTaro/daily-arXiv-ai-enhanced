<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 17]
- [cs.AI](#cs.AI) [Total: 11]
- [cs.LG](#cs.LG) [Total: 47]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Motion2Meaning: A Clinician-Centered Framework for Contestable LLM in Parkinson's Disease Gait Interpretation](https://arxiv.org/abs/2512.08934)
*Loc Phuc Truong Nguyen,Hung Thanh Do,Hung Truong Thanh Nguyen,Hung Cao*

Main category: cs.HC

TL;DR: Motion2Meaning是一个面向临床医生的可争议AI框架，用于帕金森病步态分析，结合可穿戴传感器数据、1D-CNN预测模型和可争议解释界面，提高AI决策的透明度和临床监督。


<details>
  <summary>Details</summary>
Motivation: 当前临床仪表板缺乏透明度，临床医生无法质疑或挑战AI决策，需要开发一个支持可争议AI的临床中心框架。

Method: 使用可穿戴传感器采集垂直地面反作用力时间序列数据作为客观生物标志物，系统包含三个关键组件：步态数据可视化界面、1D-CNN预测Hoehn & Yahr严重程度阶段、可争议解释界面（结合跨模态解释差异保障机制和可争议大语言模型）。

Result: 1D-CNN在PhysioNet步态数据集上达到89.0% F1分数；XMED成功识别模型不可靠性，错误预测的解释差异（7.45%）是正确预测（1.56%）的五倍；LLM界面使临床医生能够验证正确预测并成功挑战部分模型错误。

Conclusion: 该工作展示了将可穿戴传感器分析与可解释AI和可争议大语言模型结合的可行性，创建了一个透明、可审计的帕金森病步态解释系统，在利用先进AI能力的同时保持临床监督。

Abstract: AI-assisted gait analysis holds promise for improving Parkinson's Disease (PD) care, but current clinical dashboards lack transparency and offer no meaningful way for clinicians to interrogate or contest AI decisions. To address this issue, we present Motion2Meaning, a clinician-centered framework that advances Contestable AI through a tightly integrated interface designed for interpretability, oversight, and procedural recourse. Our approach leverages vertical Ground Reaction Force (vGRF) time-series data from wearable sensors as an objective biomarker of PD motor states. The system comprises three key components: a Gait Data Visualization Interface (GDVI), a one-dimensional Convolutional Neural Network (1D-CNN) that predicts Hoehn & Yahr severity stages, and a Contestable Interpretation Interface (CII) that combines our novel Cross-Modal Explanation Discrepancy (XMED) safeguard with a contestable Large Language Model (LLM). Our 1D-CNN achieves 89.0% F1-score on the public PhysioNet gait dataset. XMED successfully identifies model unreliability by detecting a five-fold increase in explanation discrepancies in incorrect predictions (7.45%) compared to correct ones (1.56%), while our LLM-powered interface enables clinicians to validate correct predictions and successfully contest a portion of the model's errors. A human-centered evaluation of this contestable interface reveals a crucial trade-off between the LLM's factual grounding and its readability and responsiveness to clinical feedback. This work demonstrates the feasibility of combining wearable sensor analysis with Explainable AI (XAI) and contestable LLMs to create a transparent, auditable system for PD gait interpretation that maintains clinical oversight while leveraging advanced AI capabilities. Our implementation is publicly available at: https://github.com/hungdothanh/motion2meaning.

</details>


### [2] [From Script to Stage: Automating Experimental Design for Social Simulations with LLMs](https://arxiv.org/abs/2512.08935)
*Yuwei Guo,Zihan Zhao,Deyu Zhou,Xiaowei Liu,Ming Zhang*

Main category: cs.HC

TL;DR: 提出基于脚本生成的多智能体实验设计框架，通过编剧、导演、演员工厂三阶段自动化设计社会科学实验，降低实验门槛并提高可靠性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型为社会科学研究开辟了新途径，但传统计算实验依赖跨学科专业知识、操作复杂、门槛高。虽然LLM驱动的智能体在自动化实验设计方面潜力巨大，但其可靠性和科学严谨性仍不足以广泛应用。

Method: 提出基于脚本生成的多智能体实验设计框架，受决策剧场概念启发。实验设计分为三个阶段：1) 脚本生成 - 编剧智能体起草候选实验脚本；2) 脚本定稿 - 导演智能体评估并选择最终脚本；3) 演员生成 - 演员工厂根据最终脚本创建能够在实验"舞台"上表演的演员智能体。

Result: 在多个社会科学实验场景中进行广泛实验，证明生成的演员智能体能够按照设计的脚本执行，并复现与现实情况一致的结果。

Conclusion: 该框架不仅降低了社会科学实验设计的门槛，还为政策制定和研究提供了新颖的决策支持工具。

Abstract: The rise of large language models (LLMs) has opened new avenues for social science research. Multi-agent simulations powered by LLMs are increasingly becoming a vital approach for exploring complex social phenomena and testing theoretical hypotheses. However, traditional computational experiments often rely heavily on interdisciplinary expertise, involve complex operations, and present high barriers to entry. While LLM-driven agents show great potential for automating experimental design, their reliability and scientific rigor remain insufficient for widespread adoption. To address these challenges, this paper proposes an automated multi-agent experiment design framework based on script generation, inspired by the concept of the Decision Theater. The experimental design process is divided into three stages: (1) Script Generation - a Screenwriter Agent drafts candidate experimental scripts; (2) Script Finalization - a Director Agent evaluates and selects the final script; (3) Actor Generation - an Actor Factory creates actor agents capable of performing on the experimental "stage" according to the finalized script. Extensive experiment conducted across multiple social science experimental scenarios demonstrate that the generated actor agents can perform according to the designed scripts and reproduce outcomes consistent with real-world situations. This framework not only lowers the barriers to experimental design in social science but also provides a novel decision-support tool for policy-making and research. The project's source code is available at: https://anonymous.4open.science/r/FSTS-DE1E

</details>


### [3] [A Principle-based Framework for the Development and Evaluation of Large Language Models for Health and Wellness](https://arxiv.org/abs/2512.08936)
*Brent Winslow,Jacqueline Shreibati,Javier Perez,Hao-Wei Su,Nichole Young-Lin,Nova Hammerquist,Daniel McDuff,Jason Guss,Jenny Vafeiadou,Nick Cain,Alex Lin,Erik Schenck,Shiva Rajagopal,Jia-Ru Chung,Anusha Venkatakrishnan,Amy Armento Lee,Maryam Karimzadehgan,Qingyou Meng,Rythm Agarwal,Aravind Natarajan,Tracy Giest*

Main category: cs.HC

TL;DR: 开发了一个基于SHARP原则的框架，用于评估应用于个人健康和健身的LLMs，通过Fitbit Insights explorer案例验证，结合人工评估、自动评分和对抗测试，确保AI健康应用的安全性和有效性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在个人健康应用中的整合带来了个性化健康指导的机会，但也面临用户安全、模型准确性和个人隐私等挑战，需要系统性的评估框架来确保负责任的发展。

Method: 开发了基于SHARP原则（安全、有帮助、准确、相关、个性化）的端到端操作框架，整合了普通用户和临床专家的人工评估、自动评分器评估和对抗测试，应用于Fitbit Insights explorer系统，在超过13,000名用户中进行分阶段部署。

Result: 通过框架应用，系统识别了初始测试中未发现的挑战，指导了针对性改进，证明了技术评估与真实用户反馈结合的必要性，建立了负责任部署LLM健康应用的综合方法。

Conclusion: 建立了一个全面、可操作的负责任开发和部署LLM健康应用的方法，提供了标准化方法论，在促进创新的同时确保新兴技术对用户安全、有效和可信。

Abstract: The incorporation of generative artificial intelligence into personal health applications presents a transformative opportunity for personalized, data-driven health and fitness guidance, yet also poses challenges related to user safety, model accuracy, and personal privacy. To address these challenges, a novel, principle-based framework was developed and validated for the systematic evaluation of LLMs applied to personal health and wellness. First, the development of the Fitbit Insights explorer, a large language model (LLM)-powered system designed to help users interpret their personal health data, is described. Subsequently, the safety, helpfulness, accuracy, relevance, and personalization (SHARP) principle-based framework is introduced as an end-to-end operational methodology that integrates comprehensive evaluation techniques including human evaluation by generalists and clinical specialists, autorater assessments, and adversarial testing, into an iterative development lifecycle. Through the application of this framework to the Fitbit Insights explorer in a staged deployment involving over 13,000 consented users, challenges not apparent during initial testing were systematically identified. This process guided targeted improvements to the system and demonstrated the necessity of combining isolated technical evaluations with real-world user feedback. Finally, a comprehensive, actionable approach is established for the responsible development and deployment of LLM-powered health applications, providing a standardized methodology to foster innovation while ensuring emerging technologies are safe, effective, and trustworthy for users.

</details>


### [4] [The Impact of Artificial Intelligence on Strategic Technology Management: A Mixed-Methods Analysis of Resources, Capabilities, and Human-AI Collaboration](https://arxiv.org/abs/2512.08938)
*Massimo Fascinari,Vincent English*

Main category: cs.HC

TL;DR: AI在战略技术管理中的应用研究：通过混合方法探索AI如何增强技术投资战略对齐，提出AIbSTM框架，强调人机协同而非AI自主领导


<details>
  <summary>Details</summary>
Motivation: 研究AI如何有效整合到战略技术管理实践中，以增强技术投资的战略对齐和有效性，解决在不确定性下AI如何创新STM路线图制定、组织需要哪些资源能力、以及如何设计人机交互等关键问题

Method: 采用混合方法：定量调查数据（n=230）和定性专家访谈（n=14），研究三个关键研究问题：AI在不确定性下创新STM路线图制定的成功因素、AI增强STM所需的组织资源和能力、复杂STM任务的人机交互设计

Result: AI通过数据驱动的战略对齐和持续适应从根本上改变STM；成功取决于培育专有数据生态系统、专业人才和稳健治理能力；提出AIbSTM概念框架，包含战略对齐、资源基础观和人机交互三个层次；最可行的路径是人本增强，AI作为协作伙伴而非人类判断的替代

Conclusion: AI在战略技术管理中的整合需要人机协同而非AI自主领导；研究扩展了资源基础观到AI背景，解决了AI采用中的认知和社会技术鸿沟；为实践者提供了AI整合的规范性框架

Abstract: This paper investigates how artificial intelligence (AI) can be effectively integrated into Strategic Technology Management (STM) practices to enhance the strategic alignment and effectiveness of technology investments. Through a mixed-methods approach combining quantitative survey data (n=230) and qualitative expert interviews (n=14), this study addresses three critical research questions: what success factors AI innovates for STM roadmap formulation under uncertainty; what resources and capabilities organizations require for AI-enhanced STM; and how human-AI interaction should be designed for complex STM tasks. The findings reveal that AI fundamentally transforms STM through data-driven strategic alignment and continuous adaptation, while success depends on cultivating proprietary data ecosystems, specialized human talent, and robust governance capabilities. The study introduces the AI-based Strategic Technology Management (AIbSTM) conceptual framework, which synthesizes technical capabilities with human and organizational dimensions across three layers: strategic alignment, resource-based view, and human-AI interaction. Contrary to visions of autonomous AI leadership, the research demonstrates that the most viable trajectory is human-centric augmentation, where AI serves as a collaborative partner rather than a replacement for human judgment. This work contributes to theory by extending the Resource-Based View to AI contexts and addressing cognitive and socio-technical chasms in AI adoption, while offering practitioners a prescriptive framework for navigating AI integration in strategic technology management.

</details>


### [5] [Assessing the Human-Likeness of LLM-Driven Digital Twins in Simulating Health Care System Trust](https://arxiv.org/abs/2512.08939)
*Yuzhou Wu,Mingyang Wu,Di Liu,Rong Yin,Kang Li*

Main category: cs.HC

TL;DR: LLM驱动的人类数字孪生在模拟医疗系统不信任等复杂心理特质方面存在局限性，虽然能再现主要人口统计模式，但对教育水平等细微差异的敏感性较低，模拟结果更集中且方差较小。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的人类数字孪生在医疗系统研究中显示出巨大潜力，但其模拟复杂人类心理特质（如对医疗系统的不信任）的实际能力尚不明确，这一研究空白影响了健康专业人员对LLM基AI系统的信任和使用。

Method: 基于Twin-2K-500数据集，使用医疗系统不信任量表（HCSDS）系统评估LLM驱动人类数字孪生的模拟结果，与已建立的人类受试者样本进行比较，分析项目级分布、汇总统计和人口统计亚组模式。

Result: 数字孪生模拟的响应显著更集中且方差较低，极端选项选择较少（所有p<0.001）。虽然数字孪生能大致再现年龄和性别等主要人口统计模式，但对教育水平细微差异的敏感性相对较低。

Conclusion: LLM基数字孪生模拟具有模拟人口趋势的潜力，但在对人类亚组进行详细具体区分方面存在挑战。当前LLM驱动数字孪生在建模复杂人类态度方面存在局限性，需要在医疗系统工程中进行仔细校准和验证。

Abstract: Serving as an emerging and powerful tool, Large Language Model (LLM)-driven Human Digital Twins are showing great potential in healthcare system research. However, its actual simulation ability for complex human psychological traits, such as distrust in the healthcare system, remains unclear. This research gap particularly impacts health professionals' trust and usage of LLM-based Artificial Intelligence (AI) systems in assisting their routine work. In this study, based on the Twin-2K-500 dataset, we systematically evaluated the simulation results of the LLM-driven human digital twin using the Health Care System Distrust Scale (HCSDS) with an established human-subject sample, analyzing item-level distributions, summary statistics, and demographic subgroup patterns. Results showed that the simulated responses by the digital twin were significantly more centralized with lower variance and had fewer selections of extreme options (all p<0.001). While the digital twin broadly reproduces human results in major demographic patterns, such as age and gender, it exhibits relatively low sensitivity in capturing minor differences in education levels. The LLM-based digital twin simulation has the potential to simulate population trends, but it also presents challenges in making detailed, specific distinctions in subgroups of human beings. This study suggests that the current LLM-driven Digital Twins have limitations in modeling complex human attitudes, which require careful calibration and validation before applying them in inferential analyses or policy simulations in health systems engineering. Future studies are necessary to examine the emotional reasoning mechanism of LLMs before their use, particularly for studies that involve simulations sensitive to social topics, such as human-automation trust.

</details>


### [6] [Psychlysis: Towards the Creation of a Questionnaire-based Machine Learning Tool to Analyze States of Mind](https://arxiv.org/abs/2512.08940)
*Hemakshi Jani,Mitish Karia,Meet Gohil,Rahul Bhadja,Aznam Yacoub,Shafaq Khan*

Main category: cs.HC

TL;DR: Psychlysis是一个基于问卷调查的机器学习应用，使用OCEAN人格模型分析用户心理状态，提供个性化情绪改善建议，而不仅仅是情绪检测。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够分析用户心理状态并提供个性化情绪改善建议的应用程序，帮助用户提升情绪健康，而不仅仅是检测情绪状态。

Method: 基于问卷调查的机器学习应用，利用OCEAN人格模型理解用户人格特质，通过机器学习算法分析用户心理状态，生成定制化的情绪改善建议。

Result: 初步结果显示该模型在预测用户情绪和提供个性化建议方面具有潜力，能够有效分析用户心理状态并给出改善建议。

Conclusion: 该应用对医生、个人和心理健康组织等不同社会群体都有潜在益处，能够改善情绪健康，减少心理健康问题对日常生活的负面影响。

Abstract: This paper describes the development of Psychlysis, a work-in-progress questionnaire-based machine learning application analyzing the user's current state of mind and suggesting ways to improve their mood using Machine Learning. The application utilizes the OCEAN model to understand the user's personality traits and make customized suggestions to enhance their well-being. The proposed application focus on improving the user's mood rather than just detecting their emotions. Preliminary results of the model are presented, showing the potential of the application in predicting the user's mood and providing personalized recommendations. The paper concludes by highlighting the potential benefits of such an application for various societal segments, including doctors, individuals, and mental health organizations, in improving emotional well-being and reducing the negative impact of mental health issues on daily life.

</details>


### [7] [One Size Fits None: A Personalized Framework for Urban Accessibility Using Exponential Decay](https://arxiv.org/abs/2512.08941)
*Prabhanjana Ghuriki,S. Chanti,Jossy P George*

Main category: cs.HC

TL;DR: 开发了一个个性化可达性框架，结合指数衰减函数和用户可定制权重系统，实现基于个人优先级和生活方式的实时城市评估。


<details>
  <summary>Details</summary>
Motivation: 为实现联合国可持续发展目标11中关于包容性、可持续城市的愿景，需要理解不同人群如何体验相同的城市空间，支持基于证据的政策制定以解决可达性差距。

Method: 采用基于网格的离散化和两阶段计算架构，将密集的预处理与轻量级实时计算分离，通过交互式界面使非技术用户也能进行可达性建模。

Result: 该框架能够实现实时、个性化的城市评估，支持细粒度空间分析，识别社区内部的可达性变化，使可达性建模对非技术用户变得可访问。

Conclusion: 该研究通过提供工具来理解不同人群如何体验相同的城市空间，支持基于证据的政策制定，为创建包容、可持续的城市做出贡献。

Abstract: This study develops a personalized accessibility framework that integrates exponential decay functions with user-customizable weighting systems. The framework enables real-time, personalized urban evaluation based on individual priorities and lifestyle requirements. The methodology employs grid-based discretization and a two-stage computational architecture that separates intensive preprocessing from lightweight real-time calculations. The computational architecture demonstrates that accessibility modelling can be made accessible to non-technical users through interactive interfaces, enabling fine-grained spatial analysis and identification of accessibility variations within neighbourhoods. The research contributes to Sustainable Development Goal 11's vision of inclusive, sustainable cities by providing tools for understanding how different populations experience identical urban spaces, supporting evidence-based policy development that addresses accessibility gaps.

</details>


### [8] [SimClinician: A Multimodal Simulation Testbed for Reliable Psychologist AI Collaboration in Mental Health Diagnosis](https://arxiv.org/abs/2512.08953)
*Filippo Cenacchi,Longbing Cao,Deborah Richards*

Main category: cs.HC

TL;DR: SimClinician是一个交互式模拟平台，用于研究AI心理健康诊断界面设计如何影响心理学家对AI建议的接受、调整或拒绝决策。


<details>
  <summary>Details</summary>
Motivation: 当前AI心理健康诊断研究主要关注基准准确率，但实际价值取决于心理学家如何响应AI建议。心理健康诊断具有特殊性：决策是连续的，且受患者语调、停顿、用词和非语言行为等线索影响。现有研究很少探讨AI诊断界面设计如何影响这些选择，导致在真实研究前缺乏可靠的测试基础。

Method: 开发SimClinician交互式模拟平台，将患者数据转化为心理学家与AI协作诊断。平台包含：(1)集成音频、文本和注视表情模式的仪表板；(2)渲染去识别化动态分析的虚拟形象模块；(3)将AI输出映射到多模态证据的决策层，让心理学家审查AI推理并输入诊断。

Result: 在E-DAIC语料库（276个临床访谈，扩展到480,000个模拟）上测试显示，确认步骤使AI建议接受率提高23%，保持升级率低于9%，并维持流畅的交互流程。

Conclusion: SimClinician平台为研究AI心理健康诊断界面设计如何影响心理学家决策提供了有效工具，确认步骤能显著提高AI建议接受率，同时保持低升级率和良好交互体验。

Abstract: AI based mental health diagnosis is often judged by benchmark accuracy, yet in practice its value depends on how psychologists respond whether they accept, adjust, or reject AI suggestions. Mental health makes this especially challenging: decisions are continuous and shaped by cues in tone, pauses, word choice, and nonverbal behaviors of patients. Current research rarely examines how AI diagnosis interface design influences these choices, leaving little basis for reliable testing before live studies. We present SimClinician, an interactive simulation platform, to transform patient data into psychologist AI collaborative diagnosis. Contributions include: (1) a dashboard integrating audio, text, and gaze-expression patterns; (2) an avatar module rendering de-identified dynamics for analysis; (3) a decision layer that maps AI outputs to multimodal evidence, letting psychologists review AI reasoning, and enter a diagnosis. Tested on the E-DAIC corpus (276 clinical interviews, expanded to 480,000 simulations), SimClinician shows that a confirmation step raises acceptance by 23%, keeping escalations below 9%, and maintaining smooth interaction flow.

</details>


### [9] [PoultryTalk: A Multi-modal Retrieval-Augmented Generation (RAG) System for Intelligent Poultry Management and Decision Support](https://arxiv.org/abs/2512.08995)
*Kapalik Khanal,Biswash Khatiwada,Stephen Afrifa,Ranjan Sapkota,Sanjay Shah,Frank Bai,Ramesh Bahadur Bist*

Main category: cs.HC

TL;DR: PoultryTalk是一个基于多模态检索增强生成(RAG)的智能系统，为中小规模家禽养殖户提供实时专家级指导，通过文本和图像交互解决疾病诊断、营养规划等问题，在准确性和用户满意度方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 家禽产业对全球粮食安全至关重要，但中小规模养殖户经常缺乏及时的专家支持来应对疾病诊断、营养规划和经营管理决策。随着气候压力增加、饲料价格波动和持续疾病威胁，养殖户难以快速做出明智决策，因此急需智能、数据驱动的实时咨询系统。

Method: 提出PoultryTalk多模态检索增强生成(RAG)系统，使用OpenAI的text-embedding-3-small和GPT-4o技术，通过文本和图像交互提供智能、上下文感知的家禽管理建议。系统性能通过200个专家验证查询和34名参与者提交的267个查询进行评估。

Result: 系统在专家验证基准查询中表现出色：语义相似度达84.0%，平均响应延迟3.6秒。与OpenAI GPT-4o相比，PoultryTalk在家禽相关信息方面提供更准确可靠的回答。参与者评估显示响应准确率达89.9%，约9.1%回答被评不正确。用户满意度调查显示95.6%参与者认为回答"总是正确"或"大部分正确"，82.6%会推荐该工具。

Conclusion: PoultryTalk不仅能够提供准确、上下文相关的信息，还展现出强大的用户接受度和可扩展潜力，为解决家禽养殖户面临的实时专家支持需求提供了有效解决方案。

Abstract: The Poultry industry plays a vital role in global food security, yet small- and medium-scale farmers frequently lack timely access to expert-level support for disease diagnosis, nutrition planning, and management decisions. With rising climate stress, unpredictable feed prices, and persistent disease threats, poultry producers often struggle to make quick, informed decisions. Therefore, there is a critical need for intelligent, data-driven systems that can deliver reliable, on-demand consultation. This paper presents PoultryTalk, a novel multi-modal Retrieval-Augmented Generation (RAG) system designed to provide real-time expert guidance through text and image-based interaction. PoultryTalk uses OpenAI's text-embedding-3-small and GPT-4o to provide smart, context-aware poultry management advice from text, images, or questions. System usability and performance were evaluated using 200 expert-verified queries and feedback from 34 participants who submitted 267 queries to the PoultryTalk prototype. The expert-verified benchmark queries confirmed strong technical performance, achieving a semantic similarity of 84.0% and an average response latency of 3.6 seconds. Compared with OpenAI's GPT-4o, PoultryTalk delivered more accurate and reliable information related to poultry. Based on participants' evaluations, PoultryTalk achieved a response accuracy of 89.9%, with about 9.1% of responses rated as incorrect. A post-use survey indicated high user satisfaction: 95.6% of participants reported that the chatbot provided "always correct" and "mostly correct" answers. 82.6% indicated they would recommend the tool, and 17.4% responded "maybe." These results collectively demonstrate that PoultryTalk not only delivers accurate, contextually relevant information but also demonstrates strong user acceptance and scalability potential.

</details>


### [10] [Prototyping and Evaluating a Real-time Neuro-Adaptive Virtual Reality Flight Training System](https://arxiv.org/abs/2512.09014)
*Evy van Weelden,Jos M. Prinsen,Caterina Ceccato,Ethel Pruss,Anita Vrins,Maryam Alimardani,Travis J. Wiltshire,Max M. Louwerse*

Main category: cs.HC

TL;DR: 研究评估了基于脑电信号的神经自适应VR飞行训练系统，该系统根据飞行员实时脑负荷调整训练难度，但结果显示自适应系统与固定难度序列在主观指标和飞行性能上无显著差异。


<details>
  <summary>Details</summary>
Motivation: 实时调整飞行训练难度对于优化飞行员表现和管理工作负荷至关重要。研究旨在评估基于脑机接口的神经自适应训练系统，该系统通过实时脑信号估计工作负荷来调整训练难度。

Method: 开发了基于EEG的神经自适应训练系统，在VR飞行模拟器中与军事飞行学员进行测试。将神经自适应系统与固定难度递增序列进行比较，评估主观指标（用户参与度、工作负荷、模拟器病）和客观指标（飞行性能）。通过半结构化访谈收集飞行员体验。

Result: 自适应和固定序列条件在主观指标和飞行性能上无显著差异。两种条件下，随着主观工作负荷增加，飞行性能均下降。访谈显示飞行员在了解系统后更偏好神经自适应系统，但对难度感知和变化顺序存在个体差异。

Conclusion: 尽管本研究显示性能无变化，但基于BCI的飞行训练系统有潜力提供更个性化和多样化的训练体验。需要进一步研究来优化自适应算法和个性化设置。

Abstract: Real-time adjustments to task difficulty during flight training are crucial for optimizing performance and managing pilot workload. This study evaluated the functionality of a pre-trained brain-computer interface (BCI) that adapts training difficulty based on real-time estimations of workload from brain signals. Specifically, an EEG-based neuro-adaptive training system was developed and tested in Virtual Reality (VR) flight simulations with military student pilots. The neuro-adaptive system was compared to a fixed sequence that progressively increased in difficulty, in terms of self-reported user engagement, workload, and simulator sickness (subjective measures), as well as flight performance (objective metric). Additionally, we explored the relationships between subjective workload and flight performance in the VR simulator for each condition. The experiments concluded with semi-structured interviews to elicit the pilots' experience with the neuro-adaptive prototype. Results revealed no significant differences between the adaptive and fixed sequence conditions in subjective measures or flight performance. In both conditions, flight performance decreased as subjective workload increased. The semi-structured interviews indicated that, upon briefing, the pilots preferred the neuro-adaptive VR training system over the system with a fixed sequence, although individual differences were observed in the perception of difficulty and the order of changes in difficulty. Even though this study shows performance does not change, BCI-based flight training systems hold the potential to provide a more personalized and varied training experience.

</details>


### [11] [Mental Models of Autonomy and Sentience Shape Reactions to AI](https://arxiv.org/abs/2512.09085)
*Janet V. T. Pauketat,Daniel B. Shank,Aikaterina Manoli,Jacy Reese Anthis*

Main category: cs.HC

TL;DR: 研究探讨AI叙事中自主性与感知能力的心理模型差异及其对人类反应的影响


<details>
  <summary>Details</summary>
Motivation: AI叙事常将自主性（自我管理能力）与感知能力（感知和感受能力）混为一谈，但这两者可能激活不同的心理模型并引发不同的人类反应，需要更精确地研究人类与AI的互动

Method: 进行了三项试点研究（N=374）和四项预先注册的短情景实验（N=2,702），将AI描述为自主的、有感知能力的、两者兼具或两者皆无，比较不同心理模型激活的效果

Result: 感知能力比自主性更能增加一般心智感知（认知和情感）和道德考量，但自主性比感知能力更能增加感知到的威胁；感知能力也比自主性更能增加感知到的自主性；元分析显示感知能力平均比自主性更能改变反应

Conclusion: 通过区分AI的不同心理模型，可以更精确地研究人机交互，为拟人化AI和提示界面的详细设计提供指导

Abstract: Narratives about artificial intelligence (AI) entangle autonomy, the capacity to self-govern, with sentience, the capacity to sense and feel. AI agents that perform tasks autonomously and companions that recognize and express emotions may activate mental models of autonomy and sentience, respectively, provoking distinct reactions. To examine this possibility, we conducted three pilot studies (N = 374) and four preregistered vignette experiments describing an AI as autonomous, sentient, both, or neither (N = 2,702). Activating a mental model of sentience increased general mind perception (cognition and emotion) and moral consideration more than autonomy, but autonomy increased perceived threat more than sentience. Sentience also increased perceived autonomy more than vice versa. Based on a within-paper meta-analysis, sentience changed reactions more than autonomy on average. By disentangling different mental models of AI, we can study human-AI interaction with more precision to better navigate the detailed design of anthropomorphized AI and prompting interfaces.

</details>


### [12] [Understanding Mental States in Active and Autonomous Driving with EEG](https://arxiv.org/abs/2512.09190)
*Prithila Angkan,Paul Hungler,Ali Etemad*

Main category: cs.HC

TL;DR: 该研究首次通过脑电图比较主动驾驶与自动驾驶模式下驾驶员的认知负荷、疲劳、效价和唤醒度，发现两种模式存在明显的神经激活分布差异，需要针对特定场景开发驾驶员监控系统。


<details>
  <summary>Details</summary>
Motivation: 理解主动驾驶与自动驾驶模式下驾驶员心理状态的差异对于设计安全的人车界面至关重要，但目前缺乏基于脑电图的系统比较研究。

Method: 使用31名参与者在三种不同复杂度任务下的脑电图数据，分析两种驾驶模式下的时间模式、任务复杂度效应和通道激活差异，并进行迁移学习实验验证模型泛化能力。

Result: 研究发现虽然两种模式在复杂度变化趋势相似，但心理状态强度和神经激活存在显著差异；迁移学习实验显示主动驾驶数据训练的模型在自动驾驶场景泛化能力差，反之亦然；自动驾驶整体皮层激活较低，但仍有可测量的心理状态波动。

Conclusion: 主动驾驶与自动驾驶存在明显的分布偏移，主要源于运动参与和注意力需求的差异；开发下一代自动驾驶车辆驾驶员监控系统需要针对特定场景的数据和模型。

Abstract: Understanding how driver mental states differ between active and autonomous driving is critical for designing safe human-vehicle interfaces. This paper presents the first EEG-based comparison of cognitive load, fatigue, valence, and arousal across the two driving modes. Using data from 31 participants performing identical tasks in both scenarios of three different complexity levels, we analyze temporal patterns, task-complexity effects, and channel-wise activation differences. Our findings show that although both modes evoke similar trends across complexity levels, the intensity of mental states and the underlying neural activation differ substantially, indicating a clear distribution shift between active and autonomous driving. Transfer-learning experiments confirm that models trained on active driving data generalize poorly to autonomous driving and vice versa. We attribute this distribution shift primarily to differences in motor engagement and attentional demands between the two driving modes, which lead to distinct spatial and temporal EEG activation patterns. Although autonomous driving results in lower overall cortical activation, participants continue to exhibit measurable fluctuations in cognitive load, fatigue, valence, and arousal associated with readiness to intervene, task-evoked emotional responses, and monotony-related passive fatigue. These results emphasize the need for scenario-specific data and models when developing next-generation driver monitoring systems for autonomous vehicles.

</details>


### [13] [Advancing Research via Human-AI Interactive Theorem Proving](https://arxiv.org/abs/2512.09443)
*Chenyi Li,Zhijian Lai,Dong An,Jiang Hu,Zaiwen Wen*

Main category: cs.HC

TL;DR: 该论文提出了一种人机协作的工作流程，将大型语言模型作为科学计算的研究工具，在保持数学严谨性的同时加速定理证明和算法设计。


<details>
  <summary>Details</summary>
Motivation: 研究如何将大型语言模型作为科学计算的研究工具，同时保持数学严谨性。当前LLMs在数学推理方面存在局限性，需要人类专家监督以确保严谨性。

Method: 提出人机协作工作流程：人类专家控制问题表述和可接受假设，LLM搜索证明或矛盾、提出候选属性和定理、帮助构建满足约束的结构和参数，并辅以数值实验和简单验证检查。专家将输出作为原始材料进一步精炼，组织成精确陈述和严谨证明。

Result: 在流形优化与Grover量子搜索算法的案例研究中，该流程帮助识别不变子空间、探索Grover兼容的回缩映射，并获得基于回缩的梯度方法的收敛保证。证明了框架在数学研究中的实用性。

Conclusion: 该框架为将大型语言模型集成到前沿数学研究提供了实用模板，能够加速证明空间和算法设计的探索，同时保持透明的推理责任。虽然以量子计算中的流形优化问题为例，但其原理可扩展到科学计算的其他核心领域。

Abstract: We investigate how large language models can be used as research tools in scientific computing while preserving mathematical rigor. We propose a human-in-the-loop workflow for interactive theorem proving and discovery with LLMs. Human experts retain control over problem formulation and admissible assumptions, while the model searches for proofs or contradictions, proposes candidate properties and theorems, and helps construct structures and parameters that satisfy explicit constraints, supported by numerical experiments and simple verification checks. Experts treat these outputs as raw material, further refine them, and organize the results into precise statements and rigorous proofs. We instantiate this workflow in a case study on the connection between manifold optimization and Grover's quantum search algorithm, where the pipeline helps identify invariant subspaces, explore Grover-compatible retractions, and obtain convergence guarantees for the retraction-based gradient method. The framework provides a practical template for integrating large language models into frontier mathematical research, enabling faster exploration of proof space and algorithm design while maintaining transparent reasoning responsibilities. Although illustrated on manifold optimization problems in quantum computing, the principles extend to other core areas of scientific computing.

</details>


### [14] [An Efficient Interaction Human-AI Synergy System Bridging Visual Awareness and Large Language Model for Intensive Care Units](https://arxiv.org/abs/2512.09473)
*Yibowen Zhao,Yiming Cao,Zhiqi Shen,Juan Du,Yonghui Xu,Lizhen Cui,Cyril Leung*

Main category: cs.HC

TL;DR: 提出基于云-边-端架构的人机协同系统，通过视觉感知数据提取和语义交互机制，解决ICU中手动转录数据和信息碎片化问题，降低医护人员认知负担。


<details>
  <summary>Details</summary>
Motivation: ICU作为高风险监控环境，当前依赖手动数据转录和碎片化信息系统，存在患者安全和操作效率风险，需要更智能的解决方案。

Method: 采用云-边-端分层架构：视觉感知边缘模块非侵入式捕获床旁监护仪实时生理数据；语义交互模块基于大语言模型支持医生进行语音查询；确保低延迟通信和可扩展性能。

Result: 系统减少手动录入错误，提高碎片化数据源的可访问性，降低ICU护士和医生的认知负担，在智能医疗系统中展现出广阔应用潜力。

Conclusion: 基于云-边-端架构的人机协同系统有效解决了ICU数据管理问题，为智能医疗系统提供了有前景的技术方案。

Abstract: Intensive Care Units (ICUs) are critical environments characterized by high-stakes monitoring and complex data management. However, current practices often rely on manual data transcription and fragmented information systems, introducing potential risks to patient safety and operational efficiency. To address these issues, we propose a human-AI synergy system based on a cloud-edge-end architecture, which integrates visual-aware data extraction and semantic interaction mechanisms. Specifically, a visual-aware edge module non-invasively captures real-time physiological data from bedside monitors, reducing manual entry errors. To improve accessibility to fragmented data sources, a semantic interaction module, powered by a Large Language Model (LLM), enables physicians to perform efficient and intuitive voice-based queries over structured patient data. The hierarchical cloud-edge-end deployment ensures low-latency communication and scalable system performance. Our system reduces the cognitive burden on ICU nurses and physicians and demonstrates promising potential for broader applications in intelligent healthcare systems.

</details>


### [15] [Auto-BenchmarkCard: Automated Synthesis of Benchmark Documentation](https://arxiv.org/abs/2512.09577)
*Aris Hofmann,Inge Vejsbjerg,Dhaval Salwala,Elizabeth M. Daly*

Main category: cs.HC

TL;DR: Auto-BenchmarkCard是一个用于生成经过验证的AI基准测试描述的工作流程，通过多智能体数据提取和LLM驱动合成来解决基准测试文档不完整或不一致的问题。


<details>
  <summary>Details</summary>
Motivation: AI基准测试文档通常不完整或不一致，这使得跨任务或领域解释和比较基准测试变得困难，需要一种系统化的方法来生成经过验证的基准测试描述。

Method: 结合多智能体从异构源（如Hugging Face、Unitxt、学术论文）提取数据，使用LLM驱动合成，并通过FactReasoner工具的原子蕴含评分进行验证阶段评估事实准确性。

Result: 该工作流程能够生成经过验证的基准测试描述，提高AI基准测试报告的透明度、可比性和可重用性。

Conclusion: Auto-BenchmarkCard有潜力促进AI基准测试报告的透明度、可比性和可重用性，使研究人员和从业者能够更好地导航和评估基准测试选择。

Abstract: We present Auto-BenchmarkCard, a workflow for generating validated descriptions of AI benchmarks. Benchmark documentation is often incomplete or inconsistent, making it difficult to interpret and compare benchmarks across tasks or domains. Auto-BenchmarkCard addresses this gap by combining multi-agent data extraction from heterogeneous sources (e.g., Hugging Face, Unitxt, academic papers) with LLM-driven synthesis. A validation phase evaluates factual accuracy through atomic entailment scoring using the FactReasoner tool. This workflow has the potential to promote transparency, comparability, and reusability in AI benchmark reporting, enabling researchers and practitioners to better navigate and evaluate benchmark choices.

</details>


### [16] [Smart, simple, sincere - Why and how we should rethink connected things in our smart homes](https://arxiv.org/abs/2512.09755)
*Albrecht Kurze,Andreas Bischof,Arne Berger*

Main category: cs.HC

TL;DR: 智能家居设备中的简单传感器数据可能泄露用户隐私，但可以通过重新设计来平衡功能与隐私保护


<details>
  <summary>Details</summary>
Motivation: 智能家居设备越来越多，虽然承诺提供舒适、效率和安全性，但其简单的传感器（如温度、光照、湿度传感器）可能带来严重的隐私风险。这些传感器数据可以推断家庭人员情况、日常活动甚至健康状况，而用户和开发者往往对此缺乏意识或不知道如何应对。

Method: 作者通过ThingsCon社区提出重新思考智能家居设备和服务的理念，展示了他们启动的研究项目和方法，探索如何在智能家居环境中平衡功能与隐私保护。

Result: 文章表明并非所有智能家居技术都是有害的，通过重新设计思路可以找到解决方案。作者展示了他们通过社区和研究项目探索的替代方法。

Conclusion: 智能家居传感器确实存在隐私风险，但通过重新思考设计理念和采取适当措施，可以在享受智能家居便利的同时保护用户隐私，ThingsCon社区正在为此探索可行的解决方案。

Abstract: More and more smart connected things and services turn our homes into smart environments. They promise comfort, efficiency and security. These devices often integrate simple sensors, e.g. for temperature, light or humidity, etc. However, these smart but yet simple sensors can pose a sincere privacy risk. The sensor data enables sense-making of home attendance, domestic activities and even health conditions, often a fact that neither users nor developers are aware of or do not know how to address. Nevertheless, not all is lost or evil. This article makes a plea for how we, the ThingsCon community, might rethink smart connected things and services in our homes. We show this in our approaches and research projects that we initiated.

</details>


### [17] [Building a Data Dashboard for Magic: The Gathering: Initial Design Considerations](https://arxiv.org/abs/2512.09802)
*Tomás Alves,João Moreira*

Main category: cs.HC

TL;DR: 本文介绍了为《万智牌》指挥官格式设计游戏数据可视化仪表板的初期研究，通过用户任务分析确定需求，设计原型并进行用户测试，发现玩家偏好情境相关的结果导向指标，传统图表比复杂图表更易理解。


<details>
  <summary>Details</summary>
Motivation: 为《万智牌》指挥官格式开发专门的数据可视化仪表板，解决玩家在游戏数据分析中的需求和痛点，提升游戏体验和数据分析效率。

Method: 1. 用户任务分析确定仪表板需求；2. 设计基于可视化的仪表板原型；3. 结构化用户测试评估玩家对可视化图表的理解和偏好。

Result: 玩家优先考虑情境相关、结果导向的指标而非外围指标；热力图和折线图等经典图表比散点图或冰柱图等复杂图表支持更高的理解度；强调局部视图、用户定制和渐进式披露的重要性。

Conclusion: 适应性、情境相关性与准确性同等重要；研究为游戏情境下的数据可视化提供了实用设计指南，对参与驱动的仪表板设计具有更广泛意义。

Abstract: This paper presents the initial stages of a design study aimed at developing a dashboard to visualize gameplay data of the Commander format from Magic: The Gathering. We conducted a user-task analysis to identify requirements for a data visualization dashboard tailored to the Commander format. Afterwards, we proposed a design for the dashboard leveraging visualizations to address players' needs and pain points for typical data analysis tasks in the context domain. Then, we followed-up with a structured user test to evaluate players' comprehension and preferences of data visualizations. Results show that players prioritize contextually relevant, outcome-driven metrics over peripheral ones, and that canonical charts like heatmaps and line charts support higher comprehension than complex ones such as scatterplots or icicle plots. Our findings also highlight the importance of localized views, user customization, and progressive disclosure, emphasizing that adaptability and contextual relevance are as essential as accuracy in effective dashboard design. Our study contributes practical design guidelines for data visualization in gaming contexts and highlights broader implications for engagement-driven dashboards.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [18] [Calibrated Trust in Dealing with LLM Hallucinations: A Qualitative Study](https://arxiv.org/abs/2512.09088)
*Adrian Ryser,Florian Allwein,Tim Schlippe*

Main category: cs.AI

TL;DR: 该研究探讨了大语言模型幻觉如何影响用户信任，发现幻觉不会导致全面不信任，而是引发情境敏感的信任校准，并识别了直觉作为新的信任因素。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解大语言模型产生的幻觉（事实错误但看似合理）如何影响用户对LLM的信任以及用户与LLM的互动方式。

Method: 采用定性研究方法，对192名参与者进行研究，探索日常使用中的信任动态。

Result: 研究发现：1）幻觉不会导致全面不信任，而是引发情境敏感的信任校准；2）确认了期望、先前经验、用户专业知识和领域知识作为用户相关信任因素；3）识别了直觉作为幻觉检测的额外因素；4）信任动态还受情境因素影响，特别是感知风险和决策风险；5）验证并扩展了递归信任校准过程。

Conclusion: 基于研究结果，提出了负责任和反思性使用大语言模型的实用建议，强调信任校准的动态性和情境敏感性。

Abstract: Hallucinations are outputs by Large Language Models (LLMs) that are factually incorrect yet appear plausible [1]. This paper investigates how such hallucinations influence users' trust in LLMs and users' interaction with LLMs. To explore this in everyday use, we conducted a qualitative study with 192 participants. Our findings show that hallucinations do not result in blanket mistrust but instead lead to context-sensitive trust calibration. Building on the calibrated trust model by Lee & See [2] and Afroogh et al.'s trust-related factors [3], we confirm expectancy [3], [4], prior experience [3], [4], [5], and user expertise & domain knowledge [3], [4] as userrelated (human) trust factors, and identify intuition as an additional factor relevant for hallucination detection. Additionally, we found that trust dynamics are further influenced by contextual factors, particularly perceived risk [3] and decision stakes [6]. Consequently, we validate the recursive trust calibration process proposed by Blöbaum [7] and extend it by including intuition as a user-related trust factor. Based on these insights, we propose practical recommendations for responsible and reflective LLM use.

</details>


### [19] [AI TIPS 2.0: A Comprehensive Framework for Operationalizing AI Governance](https://arxiv.org/abs/2512.09114)
*Pamela Gupta*

Main category: cs.AI

TL;DR: 论文指出当前AI治理框架存在三个关键缺陷：用例风险评估不足、框架过于概念化缺乏可操作控制、缺乏规模化治理机制，并提出了AI TIPS框架来解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI治理框架无法有效应对实际部署中的挑战，包括：1）组织在用例层面风险评估不足，如Humana集体诉讼案显示AI系统存在显著偏见和高错误率；2）现有框架（如ISO 42001和NIST AI RMF）停留在概念层面，缺乏可操作控制；3）缺乏规模化治理机制，无法将可信AI实践嵌入开发生命周期。

Method: 提出了AI TIPS（人工智能可信集成支柱可持续发展2.0）框架，这是对2019年开发的综合操作框架的更新，旨在直接解决上述治理挑战。

Result: AI TIPS框架提供了针对性的解决方案：为不同AI用例提供定制化治理、将概念原则转化为具体技术实施、建立规模化治理机制，使组织能够将治理要求嵌入整个开发生命周期。

Conclusion: AI TIPS框架填补了当前AI治理框架的空白，通过提供可操作、可扩展的治理方法，帮助组织有效管理AI风险，实现从董事会到数据科学家的角色适当可见性，并量化测量合规性。

Abstract: The deployment of AI systems faces three critical governance challenges that current frameworks fail to adequately address. First, organizations struggle with inadequate risk assessment at the use case level, exemplified by the Humana class action lawsuit and other high impact cases where an AI system deployed to production exhibited both significant bias and high error rates, resulting in improper healthcare claim denials. Each AI use case presents unique risk profiles requiring tailored governance, yet most frameworks provide one size fits all guidance. Second, existing frameworks like ISO 42001 and NIST AI RMF remain at high conceptual levels, offering principles without actionable controls, leaving practitioners unable to translate governance requirements into specific technical implementations. Third, organizations lack mechanisms for operationalizing governance at scale, with no systematic approach to embed trustworthy AI practices throughout the development lifecycle, measure compliance quantitatively, or provide role-appropriate visibility from boards to data scientists. We present AI TIPS, Artificial Intelligence Trust-Integrated Pillars for Sustainability 2.0, update to the comprehensive operational framework developed in 2019,four years before NIST's AI Risk Management Framework, that directly addresses these challenges.

</details>


### [20] [A Categorical Analysis of Large Language Models and Why LLMs Circumvent the Symbol Grounding Problem](https://arxiv.org/abs/2512.09117)
*Luciano Floridi,Yiyang Jia,Fernando Tohmé*

Main category: cs.AI

TL;DR: 该论文提出了一个形式化的范畴论框架，用于分析人类和大型语言模型如何将内容转化为关于可能世界状态空间W的真值命题，并论证LLMs不是解决而是绕过了符号接地问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解人类和大型语言模型在将内容转化为真值命题方面的差异，特别是探讨LLMs如何处理符号接地问题，即符号如何与现实世界建立联系。

Method: 采用形式化的范畴论框架来分析内容到真值命题的转化过程，将可能世界状态空间W作为分析基础，比较人类和LLMs在这一过程中的不同机制。

Result: 分析结果表明大型语言模型并没有真正解决符号接地问题，而是通过不同的机制绕过了这一问题，这与人类处理符号接地的根本方式存在本质区别。

Conclusion: 结论是LLMs通过规避而非解决符号接地问题来实现内容到真值命题的转化，这揭示了当前语言模型在语义理解方面的局限性，对AI语义理解研究具有重要意义。

Abstract: This paper presents a formal, categorical framework for analysing how humans and large language models (LLMs) transform content into truth-evaluated propositions about a state space of possible worlds W , in order to argue that LLMs do not solve but circumvent the symbol grounding problem.

</details>


### [21] [SDialog: A Python Toolkit for End-to-End Agent Building, User Simulation, Dialog Generation, and Evaluation](https://arxiv.org/abs/2512.09142)
*Sergio Burdisso,Séverin Baroudi,Yanis Labrak,David Grunert,Pawel Cyrta,Yiyang Chen,Srikanth Madikeri,Esaú Villatoro-Tello,Thomas Schaaf,Ricard Marxer,Petr Motlicek*

Main category: cs.AI

TL;DR: SDialog是一个开源Python工具包，集成了对话生成、评估和机制可解释性，用于构建和分析基于LLM的对话系统。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏一个统一的端到端框架来系统性地构建、评估和理解基于大语言模型的对话系统，SDialog旨在填补这一空白。

Method: 围绕标准化的Dialog表示构建，提供：1）基于角色的多智能体模拟与可组合编排；2）综合评估（语言指标、LLM作为评判者、功能正确性验证器）；3）机制可解释性工具（激活检查、特征消融和诱导）；4）音频生成与完整声学模拟。

Result: SDialog集成了所有主要LLM后端，支持混合后端实验的统一API，使研究人员能够更系统地构建、基准测试和理解对话系统。

Conclusion: 通过将生成、评估和可解释性耦合在对话中心架构中，SDialog为构建、基准测试和理解对话系统提供了更系统化的方法。

Abstract: We present SDialog, an MIT-licensed open-source Python toolkit that unifies dialog generation, evaluation and mechanistic interpretability into a single end-to-end framework for building and analyzing LLM-based conversational agents. Built around a standardized \texttt{Dialog} representation, SDialog provides: (1) persona-driven multi-agent simulation with composable orchestration for controlled, synthetic dialog generation, (2) comprehensive evaluation combining linguistic metrics, LLM-as-a-judge and functional correctness validators, (3) mechanistic interpretability tools for activation inspection and steering via feature ablation and induction, and (4) audio generation with full acoustic simulation including 3D room modeling and microphone effects. The toolkit integrates with all major LLM backends, enabling mixed-backend experiments under a unified API. By coupling generation, evaluation, and interpretability in a dialog-centric architecture, SDialog enables researchers to build, benchmark and understand conversational systems more systematically.

</details>


### [22] [Visual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration](https://arxiv.org/abs/2512.09340)
*Chethana Prasad Kabgere*

Main category: cs.AI

TL;DR: 对比人类与AI系统在模糊视觉刺激下的图像标注表现，分析两者在表征、推理和置信度校准方面的异同，为未来神经符号架构提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 研究人类和AI系统如何解释模糊视觉刺激，有助于深入理解感知、推理和决策的本质，为构建更接近人类认知的AI系统提供指导。

Method: 结合计算认知科学、认知架构和连接主义-符号混合模型，对比人类策略（类比推理、形状识别、置信度调节）与AI特征处理；基于Marr三层次假设、Simon有限理性和Thagard表征情感框架，分析参与者反应与Grad-CAM可视化模型注意力；通过ACT-R和Soar认知原则解释人类行为。

Result: 揭示了生物系统和人工系统在表征、推理和置信度校准方面的关键相似点和差异，人类在不确定性下采用分层启发式决策策略。

Conclusion: 研究为未来神经符号架构提供了理论基础，这类架构统一结构化符号推理与连接主义表征，结合具身性、可解释性和认知对齐原则，有望开发出既高性能又具可解释性和认知基础的AI系统。

Abstract: Understanding how humans and AI systems interpret ambiguous visual stimuli offers critical insight into the nature of perception, reasoning, and decision-making. This paper examines image labeling performance across human participants and deep neural networks, focusing on low-resolution, perceptually degraded stimuli. Drawing from computational cognitive science, cognitive architectures, and connectionist-symbolic hybrid models, we contrast human strategies such as analogical reasoning, shape-based recognition, and confidence modulation with AI's feature-based processing. Grounded in Marr's tri-level hypothesis, Simon's bounded rationality, and Thagard's frameworks of representation and emotion, we analyze participant responses in relation to Grad-CAM visualizations of model attention. Human behavior is further interpreted through cognitive principles modeled in ACT-R and Soar, revealing layered and heuristic decision strategies under uncertainty. Our findings highlight key parallels and divergences between biological and artificial systems in representation, inference, and confidence calibration. The analysis motivates future neuro-symbolic architectures that unify structured symbolic reasoning with connectionist representations. Such architectures, informed by principles of embodiment, explainability, and cognitive alignment, offer a path toward AI systems that are not only performant but also interpretable and cognitively grounded.

</details>


### [23] [Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search](https://arxiv.org/abs/2512.09566)
*Junkai Ji,Zhangfan Yang,Dong Xu,Ruibin Bai,Jianqiang Li,Tingjun Hou,Zexuan Zhu*

Main category: cs.AI

TL;DR: Trio是一个整合了基于片段的分子语言建模、强化学习和蒙特卡洛树搜索的分子生成框架，用于高效、可解释的闭环靶向分子设计，在结合亲和力、类药性和合成可行性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统药物发现方法耗时昂贵，高通量和基于对接的虚拟筛选成功率低且可扩展性有限。现有的生成模型存在泛化能力不足、可解释性差、过度关注结合亲和力而忽视关键药理学特性等问题，限制了其实际应用价值。

Method: Trio框架整合三个关键组件：1）基于片段的分子语言建模实现上下文感知的片段组装；2）强化学习确保物理化学和合成可行性；3）蒙特卡洛树搜索在探索新化学型和利用有前景的中间体之间实现平衡搜索。

Result: 实验结果显示，Trio能够可靠地生成化学有效且药理学增强的配体，在结合亲和力（+7.85%）、类药性（+11.10%）和合成可行性（+12.05%）方面优于最先进方法，同时将分子多样性扩展了四倍以上。

Conclusion: Trio提供了一个有效且可解释的闭环靶向分子设计框架，通过整合片段组装、强化学习和蒙特卡洛树搜索，在保持化学有效性的同时显著提升了配体的药理学特性，为药物发现提供了有前景的新方法。

Abstract: Drug discovery is a time-consuming and expensive process, with traditional high-throughput and docking-based virtual screening hampered by low success rates and limited scalability. Recent advances in generative modelling, including autoregressive, diffusion, and flow-based approaches, have enabled de novo ligand design beyond the limits of enumerative screening. Yet these models often suffer from inadequate generalization, limited interpretability, and an overemphasis on binding affinity at the expense of key pharmacological properties, thereby restricting their translational utility. Here we present Trio, a molecular generation framework integrating fragment-based molecular language modeling, reinforcement learning, and Monte Carlo tree search, for effective and interpretable closed-loop targeted molecular design. Through the three key components, Trio enables context-aware fragment assembly, enforces physicochemical and synthetic feasibility, and guides a balanced search between the exploration of novel chemotypes and the exploitation of promising intermediates within protein binding pockets. Experimental results show that Trio reliably achieves chemically valid and pharmacologically enhanced ligands, outperforming state-of-the-art approaches with improved binding affinity (+7.85%), drug-likeness (+11.10%) and synthetic accessibility (+12.05%), while expanding molecular diversity more than fourfold.

</details>


### [24] [Gaussian Process Aggregation for Root-Parallel Monte Carlo Tree Search with Continuous Actions](https://arxiv.org/abs/2512.09727)
*Junlin Xiao,Victor-Alexandru Darvariu,Bruno Lacerda,Nick Hawes*

Main category: cs.AI

TL;DR: 本文提出了一种在连续动作空间中使用高斯过程回归来聚合多线程MCTS统计信息的方法，在6个不同领域中都优于现有聚合策略，且推理时间增加有限。


<details>
  <summary>Details</summary>
Motivation: 在连续动作空间中，当计算时间有限但需要最佳性能时，如何有效聚合不同线程的统计信息是一个重要但尚未充分探索的问题。现有的根并行MCTS在连续动作空间中的统计聚合策略需要改进。

Method: 使用高斯过程回归来获取未在环境中试验过的有希望动作的价值估计。该方法通过回归模型来推断未采样动作的价值，从而更有效地聚合多线程统计信息。

Result: 在6个不同领域进行了系统评估，结果表明该方法优于现有的聚合策略，同时只需要适度的推理时间增加。

Conclusion: 提出的基于高斯过程回归的统计聚合方法在连续动作空间的根并行MCTS中表现优异，为在线规划提供了更有效的解决方案。

Abstract: Monte Carlo Tree Search is a cornerstone algorithm for online planning, and its root-parallel variant is widely used when wall clock time is limited but best performance is desired. In environments with continuous action spaces, how to best aggregate statistics from different threads is an important yet underexplored question. In this work, we introduce a method that uses Gaussian Process Regression to obtain value estimates for promising actions that were not trialed in the environment. We perform a systematic evaluation across 6 different domains, demonstrating that our approach outperforms existing aggregation strategies while requiring a modest increase in inference time.

</details>


### [25] [RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning](https://arxiv.org/abs/2512.09829)
*Khurram Khalil,Muhammad Mahad Khaliq,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: RIFT是一个基于强化学习的智能故障定位框架，用于高效发现AI加速器中的最小化高影响故障场景，相比传统方法实现2.2倍加速和99%测试向量减少。


<details>
  <summary>Details</summary>
Motivation: 现代AI加速器的巨大规模给传统故障评估方法带来了严峻挑战，传统方法计算成本过高且对关键故障模式的覆盖率不足，需要更高效的故障评估解决方案。

Method: RIFT将复杂的最坏情况故障搜索转化为序列决策问题，结合混合灵敏度分析进行搜索空间剪枝，使用强化学习智能生成最小化高影响测试套件。

Result: 在基于NVIDIA A100 GPU的十亿参数大语言模型工作负载评估中，RIFT相比进化方法实现2.2倍故障评估加速，相比随机故障注入减少99%以上测试向量，同时获得更优的故障覆盖率。

Conclusion: RIFT框架不仅提供高效的故障评估，还能指导智能硬件保护策略，其引导的选择性错误校正码相比统一三模冗余保护在成本效益上提升12.8倍，并能自动生成UVM兼容的验证工件。

Abstract: The massive scale of modern AI accelerators presents critical challenges to traditional fault assessment methodologies, which face prohibitive computational costs and provide poor coverage of critical failure modes. This paper introduces RIFT (Reinforcement Learning-guided Intelligent Fault Targeting), a scalable framework that automates the discovery of minimal, high-impact fault scenarios for efficient design-time fault assessment. RIFT transforms the complex search for worst-case faults into a sequential decision-making problem, combining hybrid sensitivity analysis for search space pruning with reinforcement learning to intelligently generate minimal, high-impact test suites. Evaluated on billion-parameter Large Language Model (LLM) workloads using NVIDIA A100 GPUs, RIFT achieves a \textbf{2.2$\times$} fault assessment speedup over evolutionary methods and reduces the required test vector volume by over \textbf{99\%} compared to random fault injection, all while achieving \textbf{superior fault coverage}. The proposed framework also provides actionable data to enable intelligent hardware protection strategies, demonstrating that RIFT-guided selective error correction code provides a \textbf{12.8$\times$} improvement in \textbf{cost-effectiveness} (coverage per unit area) compared to uniform triple modular redundancy protection. RIFT automatically generates UVM-compliant verification artifacts, ensuring its findings are directly actionable and integrable into commercial RTL verification workflows.

</details>


### [26] [Interpretation as Linear Transformation: A Cognitive-Geometric Model of Belief and Meaning](https://arxiv.org/abs/2512.09831)
*Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 该论文提出了一个几何框架来建模认知异质智能体之间的信念、动机和影响。通过个性化价值空间表示智能体，将信念形式化为结构化向量，并分析其在认知几何中的传播、变异和消失机制。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解认知异质智能体之间的信念传播和影响机制。传统方法依赖共享信息或理性假设，但无法解释信念在传播过程中的扭曲、误解和消失现象。需要建立一个统一框架来分析抽象概念在不同认知结构中的动态变化。

Method: 方法包括：1）将每个智能体表示为个性化价值空间（向量空间）；2）将信念形式化为结构化向量（抽象存在）；3）使用线性解释映射作为信念传输媒介；4）提出"无零空间领导条件"作为领导力的代数特征；5）基于结构兼容性而非共享信息分析意义保持。

Result: 主要结果：1）信念只有在避免解释映射的零空间时才能在通信中存活；2）信念扭曲、动机漂移、反事实评估和相互理解限制都源于代数约束；3）领导力被表征为表征可达性而非说服或权威；4）解释了抽象存在在多样认知几何中的传播、变异和消失机制。

Conclusion: 结论表明该认知几何视角为分析异质智能体间的信念动态提供了统一基础，将概念空间、社会认识论和AI价值对齐的见解统一起来。该框架通过结构兼容性而非共享信息或理性来基础化意义保持，澄清了人类和人工系统中影响的认知边界。

Abstract: This paper develops a geometric framework for modeling belief, motivation, and influence across cognitively heterogeneous agents. Each agent is represented by a personalized value space, a vector space encoding the internal dimensions through which the agent interprets and evaluates meaning. Beliefs are formalized as structured vectors-abstract beings-whose transmission is mediated by linear interpretation maps. A belief survives communication only if it avoids the null spaces of these maps, yielding a structural criterion for intelligibility, miscommunication, and belief death.
  Within this framework, I show how belief distortion, motivational drift, counterfactual evaluation, and the limits of mutual understanding arise from purely algebraic constraints. A central result-"the No-Null-Space Leadership Condition"-characterizes leadership as a property of representational reachability rather than persuasion or authority. More broadly, the model explains how abstract beings can propagate, mutate, or disappear as they traverse diverse cognitive geometries.
  The account unifies insights from conceptual spaces, social epistemology, and AI value alignment by grounding meaning preservation in structural compatibility rather than shared information or rationality. I argue that this cognitive-geometric perspective clarifies the epistemic boundaries of influence in both human and artificial systems, and offers a general foundation for analyzing belief dynamics across heterogeneous agents.

</details>


### [27] [Human-in-the-Loop and AI: Crowdsourcing Metadata Vocabulary for Materials Science](https://arxiv.org/abs/2512.09895)
*Jane Greenberg,Scott McClellan,Addy Ireland,Robert Sammarco,Colton Gerber,Christopher B. Rauch,Mat Kelly,John Kunze,Yuan An,Eric Toberer*

Main category: cs.AI

TL;DR: MatSci-YAMZ平台结合AI和人工循环（包括众包）支持元数据词汇表开发，在材料科学领域验证了可行性，能提高语义透明度并减少共识构建时间。


<details>
  <summary>Details</summary>
Motivation: 元数据词汇表对推进FAIR和FARR数据原则至关重要，但开发受到人力资源有限和标准化实践不一致的限制，需要更高效的开发方法。

Method: 开发MatSci-YAMZ平台，整合人工智能和人工循环（包括众包），在材料科学领域进行概念验证，6名参与者通过提供术语定义和示例来促进AI定义精炼。

Result: 成功生成19个AI定义，迭代反馈循环证明了AI-HILT精炼的可行性，确认了概念验证成功、与FAIR和开放科学原则一致、提供了未来研究协议指南、具备跨领域扩展潜力。

Conclusion: MatSci-YAMZ模型能够增强语义透明度，减少共识构建和元数据词汇表开发所需时间，为跨领域扩展提供了可行框架。

Abstract: Metadata vocabularies are essential for advancing FAIR and FARR data principles, but their development constrained by limited human resources and inconsistent standardization practices. This paper introduces MatSci-YAMZ, a platform that integrates artificial intelligence (AI) and human-in-the-loop (HILT), including crowdsourcing, to support metadata vocabulary development. The paper reports on a proof-of-concept use case evaluating the AI-HILT model in materials science, a highly interdisciplinary domain Six (6) participants affiliated with the NSF Institute for Data-Driven Dynamical Design (ID4) engaged with the MatSci-YAMZ plaform over several weeks, contributing term definitions and providing examples to prompt the AI-definitions refinement. Nineteen (19) AI-generated definitions were successfully created, with iterative feedback loops demonstrating the feasibility of AI-HILT refinement. Findings confirm the feasibility AI-HILT model highlighting 1) a successful proof of concept, 2) alignment with FAIR and open-science principles, 3) a research protocol to guide future studies, and 4) the potential for scalability across domains. Overall, MatSci-YAMZ's underlying model has the capacity to enhance semantic transparency and reduce time required for consensus building and metadata vocabulary development.

</details>


### [28] [SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments](https://arxiv.org/abs/2512.09897)
*Haoye Lu,Pavan Seshadri,Kaheer Suleman*

Main category: cs.AI

TL;DR: SCOPE是一种一次性分层规划器，利用LLM生成的子目标进行初始化预训练，无需在训练和推理期间重复查询LLM，显著提高了效率，在TextCraft环境中取得了比现有方法更好的成功率和更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的规划方法存在两个主要问题：1）在训练和推理期间需要频繁查询LLM，计算成本高且部署效率低；2）使用预训练且参数固定的LLM，无法针对特定任务进行适配。需要一种更高效的方法来利用LLM的语义知识进行文本环境中的长期规划。

Method: 提出SCOPE（Subgoal-COnditioned Pretraining for Efficient planning），这是一种一次性分层规划器。方法的核心是：仅在初始化时利用LLM生成的子目标来预训练一个轻量级的学生模型。与之前方法不同，SCOPE直接从示例轨迹中推导子目标，避免了训练期间重复查询LLM的需要。

Result: 在TextCraft环境中，SCOPE取得了0.56的成功率，优于ADaPT方法的0.52。更重要的是，推理时间从ADaPT的164.4秒大幅减少到仅3.0秒，实现了显著的效率提升。

Conclusion: 尽管LLM生成的子目标可能不是最优的，但它们仍然可以作为文本规划任务中分层目标分解的良好起点。SCOPE通过一次性预训练方法，在保持良好性能的同时显著提高了效率，为文本环境中的高效规划提供了一种有前景的解决方案。

Abstract: Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods typically employ a pretrained, unaltered LLM whose parameters remain fixed throughout training, providing no opportunity for adaptation to the target task. To address these limitations, we introduce SCOPE (Subgoal-COnditioned Pretraining for Efficient planning), a one-shot hierarchical planner that leverages LLM-generated subgoals only at initialization to pretrain a lightweight student model. Unlike prior approaches that distill LLM knowledge by repeatedly prompting the model to adaptively generate subgoals during training, our method derives subgoals directly from example trajectories. This design removes the need for repeated LLM queries, significantly improving efficiency, though at the cost of reduced explainability and potentially suboptimal subgoals. Despite their suboptimality, our results on the TextCraft environment show that LLM-generated subgoals can still serve as a strong starting point for hierarchical goal decomposition in text-based planning tasks. Compared to the LLM-based hierarchical agent ADaPT (Prasad et al., 2024), which achieves a 0.52 success rate, our method reaches 0.56 and reduces inference time from 164.4 seconds to just 3.0 seconds.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [29] [Optimizing Algorithms for Mobile Health Interventions with Active Querying Optimization](https://arxiv.org/abs/2512.08950)
*Aseel Rawashdeh*

Main category: cs.LG

TL;DR: 论文提出了一种贝叶斯扩展的ATM方法，用卡尔曼滤波器式的贝叶斯更新替代标准Q学习，在移动健康干预中实现更稳定和样本高效的学习。


<details>
  <summary>Details</summary>
Motivation: 移动健康干预中的强化学习需要在干预效果和用户负担之间取得平衡，特别是在状态测量（如用户调查或反馈）成本高昂但至关重要的情况下。标准的ATM算法使用基于时间差分的Q学习方法，在稀疏和嘈杂环境中容易不稳定。

Method: 提出了ATM的贝叶斯扩展，用卡尔曼滤波器式的贝叶斯更新替代标准Q学习，维护Q值的不确定性感知估计，实现更稳定和样本高效的学习。在ACNO-MDP框架内解耦控制和测量动作。

Result: 在小规模表格环境中，贝叶斯ATM实现了相当或改进的标量化回报，方差显著降低，策略行为更稳定。但在更大更复杂的移动健康环境中，标准和贝叶斯ATM变体都表现不佳。

Conclusion: 研究强调了不确定性感知方法在低数据环境中的价值，同时指出需要新的强化学习算法来显式建模因果结构、连续状态和观察成本约束下的延迟反馈。

Abstract: Reinforcement learning in mobile health (mHealth) interventions requires balancing intervention efficacy with user burden, particularly when state measurements (for example, user surveys or feedback) are costly yet essential. The Act-Then-Measure (ATM) heuristic addresses this challenge by decoupling control and measurement actions within the Action-Contingent Noiselessly Observable Markov Decision Process (ACNO-MDP) framework. However, the standard ATM algorithm relies on a temporal-difference-inspired Q-learning method, which is prone to instability in sparse and noisy environments. In this work, we propose a Bayesian extension to ATM that replaces standard Q-learning with a Kalman filter-style Bayesian update, maintaining uncertainty-aware estimates of Q-values and enabling more stable and sample-efficient learning. We evaluate our method in both toy environments and clinically motivated testbeds. In small, tabular environments, Bayesian ATM achieves comparable or improved scalarized returns with substantially lower variance and more stable policy behavior. In contrast, in larger and more complex mHealth settings, both the standard and Bayesian ATM variants perform poorly, suggesting a mismatch between ATM's modeling assumptions and the structural challenges of real-world mHealth domains. These findings highlight the value of uncertainty-aware methods in low-data settings while underscoring the need for new RL algorithms that explicitly model causal structure, continuous states, and delayed feedback under observation cost constraints.

</details>


### [30] [Learning When to Ask: Simulation-Trained Humanoids for Mental-Health Diagnosis](https://arxiv.org/abs/2512.08952)
*Filippo Cenacchi,Deborah Richards,Longbing Cao*

Main category: cs.LG

TL;DR: 研究人员开发了一个虚拟仿真平台，将276名抑郁症和创伤后应激障碍患者的访谈数据转化为可交互的虚拟人，用于训练人形机器人的对话控制策略，避免了实体机器人的磨损和迭代限制。


<details>
  <summary>Details</summary>
Motivation: 测试人形机器人存在速度慢、设备磨损、迭代受限等问题，而现有仿真器大多忽略了非语言动态的策略学习，控制器过于关注任务准确性而忽视了信任、节奏和融洽关系等社交因素。

Method: 创建了一个以智能体为中心的仿真优先流程：将访谈数据转化为276个虚幻引擎MetaHuman虚拟患者，包含同步的语音、注视/面部表情和头躯干姿势。采用感知-融合-策略循环决策何时说话、何时回应、如何避免打断，并使用安全防护机制。训练采用反事实回放（有界非语言扰动）和不确定性感知的轮次管理器。

Result: 在三种控制器的比较中，自定义TD3（Twin Delayed DDPG）优于PPO和CEM，实现了接近上限的覆盖率和更稳定的节奏。决策质量分析显示可忽略的轮次重叠、对齐的打断时机、更少的澄清提示和更短的等待时间。性能在模态丢失和渲染器更换下保持稳定。

Conclusion: 该研究提出了一个完整的虚拟仿真训练框架，能够有效训练人形机器人的社交对话能力，特别在对话时机和融洽关系控制方面表现出色，为临床监督下的人形机器人试点奠定了基础。

Abstract: Testing humanoid robots with users is slow, causes wear, and limits iteration and diversity. Yet screening agents must master conversational timing, prosody, backchannels, and what to attend to in faces and speech for Depression and PTSD. Most simulators omit policy learning with nonverbal dynamics; many controllers chase task accuracy while underweighting trust, pacing, and rapport. We virtualise the humanoid as a conversational agent to train without hardware burden. Our agent-centred, simulation-first pipeline turns interview data into 276 Unreal Engine MetaHuman patients with synchronised speech, gaze/face, and head-torso poses, plus PHQ-8 and PCL-C flows. A perception-fusion-policy loop decides what and when to speak, when to backchannel, and how to avoid interruptions, under a safety shield. Training uses counterfactual replay (bounded nonverbal perturbations) and an uncertainty-aware turn manager that probes to reduce diagnostic ambiguity. Results are simulation-only; the humanoid is the transfer target. In comparing three controllers, a custom TD3 (Twin Delayed DDPG) outperformed PPO and CEM, achieving near-ceiling coverage with steadier pace at comparable rewards. Decision-quality analyses show negligible turn overlap, aligned cut timing, fewer clarification prompts, and shorter waits. Performance stays stable under modality dropout and a renderer swap, and rankings hold on a held-out patient split. Contributions: (1) an agent-centred simulator that turns interviews into 276 interactive patients with bounded nonverbal counterfactuals; (2) a safe learning loop that treats timing and rapport as first-class control variables; (3) a comparative study (TD3 vs PPO/CEM) with clear gains in completeness and social timing; and (4) ablations and robustness analyses explaining the gains and enabling clinician-supervised humanoid pilots.

</details>


### [31] [An Electrocardiogram Multi-task Benchmark with Comprehensive Evaluations and Insightful Findings](https://arxiv.org/abs/2512.08954)
*Yuhao Xu,Jiaying Lu,Sirui Ding,Defu Cao,Xiao Hu,Carl Yang*

Main category: cs.LG

TL;DR: 该研究评估了基础模型在ECG分析中的有效性，发现通用时间序列/ECG基础模型在ECG分析任务中能达到80%的顶级性能表现。


<details>
  <summary>Details</summary>
Motivation: 心电图（ECG）作为非侵入性心脏活动采集方法，在诊断心脏状况中广泛应用，但传统ECG分析需要领域专业知识，这限制了人工智能在医疗保健中的应用。虽然自监督学习和基础模型的发展使AI系统能够获取领域知识而不完全依赖人类专业知识，但缺乏对基础模型在ECG分析性能的全面评估。

Method: 研究通过比较语言/通用时间序列/ECG基础模型与时间序列深度学习模型来评估基础模型在ECG分析中的有效性。研究建立了公开的基准测试数据集和代码，进行了全面的实验评估。

Result: 实验结果显示，通用时间序列/ECG基础模型在ECG分析任务中能达到80%的顶级性能表现，证明了它们在ECG分析中的有效性。研究还提供了深入的分析和见解以及全面的实验结果。

Conclusion: 该研究强调了基础模型在推进生理波形分析方面的局限性和潜力，表明基础模型在ECG分析中具有实际应用价值，为医疗AI的发展提供了重要参考。

Abstract: In the process of patient diagnosis, non-invasive measurements are widely used due to their low risks and quick results. Electrocardiogram (ECG), as a non-invasive method to collect heart activities, is used to diagnose cardiac conditions. Analyzing the ECG typically requires domain expertise, which is a roadblock to applying artificial intelligence (AI) for healthcare. Through advances in self-supervised learning and foundation models, AI systems can now acquire and leverage domain knowledge without relying solely on human expertise. However, there is a lack of comprehensive analyses over the foundation models' performance on ECG. This study aims to answer the research question: "Are Foundation Models Useful for ECG Analysis?" To address it, we evaluate language/general time-series/ECG foundation models in comparison with time-series deep learning models. The experimental results show that general time-series/ECG foundation models achieve a top performance rate of 80%, indicating their effectiveness in ECG analysis. In-depth analyses and insights are provided along with comprehensive experimental results. This study highlights the limitations and potential of foundation models in advancing physiological waveform analysis. The data and code for this benchmark are publicly available at https://github.com/yuhaoxu99/ECGMultitasks-Benchmark.

</details>


### [32] [DW-KNN: A Transparent Local Classifier Integrating Distance Consistency and Neighbor Reliability](https://arxiv.org/abs/2512.08956)
*Kumarjit Pathak,Karthik K,Sachin Madan,Jitin Kapila*

Main category: cs.LG

TL;DR: DW-KNN是一种改进的KNN分类器，通过结合指数距离和邻居有效性双重加权，提高在异质特征空间中的预测可靠性，同时保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统KNN及其变体假设所有k个邻居同等可靠，这在异质特征空间中限制了预测的可靠性，需要更稳健的方法来处理噪声和误标记样本。

Method: 提出DW-KNN（双重加权KNN），整合指数距离加权和邻居有效性加权，实现实例级可解释性，抑制噪声或误标记样本，并降低超参数敏感性。

Result: 在9个数据集上评估，DW-KNN平均准确率达到0.8988，在6种方法中排名第2，与最佳集成KNN相差仅0.2%。交叉验证方差最低（0.0156），统计显著性测试显示优于紧凑性加权KNN（+4.09%）和核加权KNN（+1.13%）。

Conclusion: DW-KNN为复杂自适应方案提供了一个简单有效的替代方案，特别适用于需要可解释预测的高风险应用场景。

Abstract: K-Nearest Neighbors (KNN) is one of the most used ML classifiers. However, if we observe closely, standard distance-weighted KNN and relative variants assume all 'k' neighbors are equally reliable. In heterogeneous feature space, this becomes a limitation that hinders reliability in predicting true levels of the observation.
  We propose DW-KNN (Double Weighted KNN), a transparent and robust variant that integrates exponential distance with neighbor validity. This enables instance-level interpretability, suppresses noisy or mislabeled samples, and reduces hyperparameter sensitivity.
  Comprehensive evaluation on 9 data-sets helps to demonstrate that DW-KNN achieves 0.8988 accuracy on average. It ranks 2nd among six methods and within 0.2% of the best-performing Ensemble KNN. It also exhibits the lowest cross-validation variance (0.0156), indicating reliable prediction stability. Statistical significance test confirmed ($p < 0.001$) improvement over compactness weighted KNN (+4.09\%) and Kernel weighted KNN (+1.13\%). The method provides a simple yet effective alternative to complex adaptive schemes, particularly valuable for high-stakes applications requiring explainable predictions.

</details>


### [33] [LUMOS: Large User MOdels for User Behavior Prediction](https://arxiv.org/abs/2512.08957)
*Dhruv Nigam*

Main category: cs.LG

TL;DR: LUMOS是一个基于Transformer的架构，通过联合学习多个任务并使用原始用户活动数据，消除了任务特定模型和手动特征工程，解决了大规模用户行为预测的挑战。


<details>
  <summary>Details</summary>
Motivation: 在线B2C平台的大规模用户行为预测面临传统方法依赖任务特定模型和领域特定特征工程的挑战，这些方法耗时、计算成本高、需要领域专业知识且不可扩展。

Method: LUMOS采用基于Transformer的架构，引入新颖的交叉注意力机制，使预测能够基于未来已知事件（如节假日、促销等），并采用多模态标记化，将用户交易、事件上下文和静态用户人口统计属性通过专门的嵌入路径处理。

Result: 在包含250亿用户活动标记的2750亿用户活动数据集上，LUMOS在5个任务中相比传统任务特定模型表现更优：二元分类任务ROC-AUC平均提升0.025，回归任务MAPE降低4.6%。在线A/B测试验证了这些改进转化为可衡量的业务影响，日活跃用户增加3.15%。

Conclusion: LUMOS通过消除任务特定模型和手动特征工程，提供了一种可扩展的大规模用户行为预测解决方案，能够有效预测复杂行为模式，并在实际业务中产生显著积极影响。

Abstract: User behavior prediction at scale remains a critical challenge for online B2C platforms. Traditional approaches rely heavily on task-specific models and domain-specific feature engineering. This is time-consuming, computationally expensive, and requires domain expertise and therefore not scalable. We present LUMOS (Large User MOdel Series), a transformer-based architecture that eliminates task-specific models and manual feature engineering by learning multiple tasks jointly using only raw user activity data. LUMOS introduces a novel cross-attention mechanism that conditions predictions on future known events (e.g., holidays, sales, etc.), enabling the model to predict complex behaviour patterns like "how will upcoming holidays affect user engagement?" The architecture also employs multi-modal tokenization, combining user transactions, event context, and static user demographic attributes into rich representations processed through specialized embedding pathways.
  Through extensive experiments on a production dataset spanning 275 billion user activity tokens from 250 million users, we demonstrate that LUMOS achieves superior performance compared to traditional task-specific models. Across 5 tasks with established baselines, we achieve an average improvement of 0.025 in ROC-AUC for binary classification tasks and 4.6\% reduction in MAPE for regression tasks. Online A/B testing validates these improvements translate to measurable business impact with a 3.15\% increase in Daily Active Users.

</details>


### [34] [EEG-Bench: A Benchmark for EEG Foundation Models in Clinical Applications](https://arxiv.org/abs/2512.08959)
*Ard Kastrati,Josua Bürki,Jonas Lauer,Cheng Xuan,Raffaele Iaquinto,Roger Wattenhofer*

Main category: cs.LG

TL;DR: 提出了一个统一的基准测试框架，用于评估基于EEG的基础模型在临床诊断任务中的表现，涵盖11个诊断任务和14个公开EEG数据集。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏针对EEG基础模型在临床应用中的标准化评估框架，需要建立统一的基准来公平比较传统方法和现代基础模型的性能。

Method: 构建了一个统一的基准测试框架，包含11个临床诊断任务，使用14个公开EEG数据集，采用最小预处理和标准化评估协议，支持传统基线模型和现代基础模型的并行比较。

Result: 基础模型在某些场景下表现优异，但在临床分布偏移情况下，简单模型往往仍具有竞争力。所有准备的数据和代码都已公开发布，便于复现和扩展。

Conclusion: 该框架为EEG基础模型的临床评估提供了标准化基准，揭示了基础模型与简单模型在不同临床场景下的相对优势，促进了该领域的研究可复现性和进一步发展。

Abstract: We introduce a unified benchmarking framework focused on evaluating EEG-based foundation models in clinical applications. The benchmark spans 11 well-defined diagnostic tasks across 14 publicly available EEG datasets, including epilepsy, schizophrenia, Parkinson's disease, OCD, and mild traumatic brain injury. It features minimal preprocessing, standardized evaluation protocols, and enables side-by-side comparisons of classical baselines and modern foundation models. Our results show that while foundation models achieve strong performance in certain settings, simpler models often remain competitive, particularly under clinical distribution shifts. To facilitate reproducibility and adoption, we release all prepared data and code in an accessible and extensible format.

</details>


### [35] [Resolving Conflicts in Lifelong Learning via Aligning Updates in Subspaces](https://arxiv.org/abs/2512.08960)
*Yueer Zhou,Yichen Wu,Ying Wei*

Main category: cs.LG

TL;DR: PS-LoRA通过双正则化目标解决LoRA在持续学习中的灾难性遗忘问题，通过惩罚冲突方向和约束幅度偏差来保持参数稳定性，并采用基于幅度的合并策略整合适配器。


<details>
  <summary>Details</summary>
Motivation: LoRA在持续学习中存在灾难性遗忘问题，主要原因是新任务梯度与历史权重轨迹之间的对抗性方向更新。需要解决这种破坏性干扰以保持学习表示的稳定性。

Method: 提出PS-LoRA框架：1）使用双正则化目标，惩罚冲突方向并约束幅度偏差；2）采用基于幅度的合并策略，将顺序适配器整合为稳健表示而无需重新训练。

Result: 在NLP和视觉基准测试中，PS-LoRA优于最先进的方法，能够在高效适应新领域的同时保持学习表示的稳定性。

Conclusion: PS-LoRA通过解决优化子空间中的冲突更新，有效缓解了LoRA在持续学习中的灾难性遗忘问题，实现了参数稳定性和适应性之间的平衡。

Abstract: Low-Rank Adaptation (LoRA) enables efficient Continual Learning but often suffers from catastrophic forgetting due to destructive interference between tasks. Our analysis reveals that this degradation is primarily driven by antagonistic directional updates where new task gradients directly oppose the historical weight trajectory. To address this, we propose PS-LoRA (Parameter Stability LoRA), a framework designed to resolve conflicts by aligning updates within the optimization subspace. Our approach employs a dual-regularization objective that penalizes conflicting directions and constrains magnitude deviations to ensure consistency with prior knowledge. Additionally, we implement a magnitude-based merging strategy to consolidate sequential adapters into a robust representation without retraining. Experiments on NLP and Vision benchmarks show that PS-LoRA outperforms state-of-the-art methods by preserving the stability of learned representations while efficiently adapting to new domains.

</details>


### [36] [Financial Instruction Following Evaluation (FIFE)](https://arxiv.org/abs/2512.08965)
*Glenn Matlin,Siddharth,Anirudh JM,Aditya Shukla,Yahya Hassan,Sudheer Chava*

Main category: cs.LG

TL;DR: FIFE是一个用于评估语言模型在金融分析任务中遵循复杂指令能力的高难度基准，包含88个人工编写的提示和可验证约束系统，测试显示开源权重模型表现优于专有系统，但所有模型都难以完美满足复杂要求。


<details>
  <summary>Details</summary>
Motivation: 语言模型在处理复杂、相互依赖的指令方面存在困难，特别是在金融等高精度要求领域，需要开发专门的基准来评估模型在金融分析任务中的指令遵循能力。

Method: 开发FIFE基准，包含88个人工编写的金融分析提示，采用可链接、可验证的约束系统提供细粒度奖励信号，在零样本设置下评估53个模型（专有、开源权重、开源）。

Result: 性能层次清晰：顶级开源权重模型（严格76.1/宽松79.5）超越领先专有系统（严格65.9/宽松70.5），最佳开源模型显著落后（严格45.5/宽松48.9），但即使顶级模型也难以完全满足FIFE的复杂要求。

Conclusion: FIFE基准揭示了语言模型在金融分析任务中遵循复杂指令的局限性，开源数据集和代码将促进金融领域强化学习研究，为改进模型在关键领域的性能提供基础。

Abstract: Language Models (LMs) struggle with complex, interdependent instructions, particularly in high-stakes domains like finance where precision is critical. We introduce FIFE, a novel, high-difficulty benchmark designed to assess LM instruction-following capabilities for financial analysis tasks. FIFE comprises 88 human-authored prompts and employs a verification system with chainable, verifiable constraints for fine-grained reward signals. We evaluate 53 models (proprietary, open-weight, open-source) in a zero-shot setting. Our key findings reveal a clear performance hierarchy: the top open-weight model (76.1 strict / 79.5 loose) surpasses the leading proprietary system (65.9 strict / 70.5 loose), while the best open-source models lag significantly (45.5 strict / 48.9 loose). However, even top-performing models struggle with FIFE's complex requirements, failing to achieve perfect compliance. We release our dataset and code as an open-source resource to promote research in Reinforcement Learning for the financial domain.

</details>


### [37] [CluCERT: Certifying LLM Robustness via Clustering-Guided Denoising Smoothing](https://arxiv.org/abs/2512.08967)
*Zixia Wang,Gaojie Jin,Jia Hu,Ronghui Mu*

Main category: cs.LG

TL;DR: CluCERT：通过聚类引导的去噪平滑来认证LLM鲁棒性的新框架，相比现有方法提供更紧的鲁棒性边界和更高的计算效率


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然能力强大，但仍容易受到对抗性攻击，即使是保留语义的同义词替换也可能导致错误预测。现有认证方法存在两个关键局限：1) 由于缺乏对扰动输出的语义验证导致鲁棒性边界松散；2) 重复采样导致计算成本高

Method: 提出CluCERT框架，通过聚类引导的去噪平滑来认证LLM鲁棒性。具体包括：1) 语义聚类过滤器减少噪声样本并保留有意义的扰动；2) 精炼模块提取核心语义；3) 快速同义词替换策略加速去噪过程

Result: 在各种下游任务和越狱防御场景中的实验结果表明，该方法在鲁棒性边界和计算效率方面均优于现有认证方法

Conclusion: CluCERT通过语义聚类过滤和高效去噪机制，成功解决了现有LLM鲁棒性认证方法的局限性，提供了更紧的认证边界和更高的计算效率

Abstract: Recent advancements in Large Language Models (LLMs) have led to their widespread adoption in daily applications. Despite their impressive capabilities, they remain vulnerable to adversarial attacks, as even minor meaning-preserving changes such as synonym substitutions can lead to incorrect predictions. As a result, certifying the robustness of LLMs against such adversarial prompts is of vital importance. Existing approaches focused on word deletion or simple denoising strategies to achieve robustness certification. However, these methods face two critical limitations: (1) they yield loose robustness bounds due to the lack of semantic validation for perturbed outputs and (2) they suffer from high computational costs due to repeated sampling. To address these limitations, we propose CluCERT, a novel framework for certifying LLM robustness via clustering-guided denoising smoothing. Specifically, to achieve tighter certified bounds, we introduce a semantic clustering filter that reduces noisy samples and retains meaningful perturbations, supported by theoretical analysis. Furthermore, we enhance computational efficiency through two mechanisms: a refine module that extracts core semantics, and a fast synonym substitution strategy that accelerates the denoising process. Finally, we conduct extensive experiments on various downstream tasks and jailbreak defense scenarios. Experimental results demonstrate that our method outperforms existing certified approaches in both robustness bounds and computational efficiency.

</details>


### [38] [StructuredDNA: A Bio-Physical Framework for Energy-Aware Transformer Routing](https://arxiv.org/abs/2512.08968)
*Mustapha Hamdi*

Main category: cs.LG

TL;DR: StructuredDNA是一种基于生物物理能量最小化的稀疏Transformer路由框架，通过语义能量最小化动态选择专家，显著降低计算能耗，在专业和开放领域基准测试中均表现出优异的能量效率和语义稳定性。


<details>
  <summary>Details</summary>
Motivation: 随着大规模计算模型的快速发展，能源和计算成本急剧增加。受生物系统中结构和功能从低能量配置中涌现的启发，需要开发能量感知的稀疏架构框架来降低计算成本。

Method: 提出StructuredDNA稀疏架构框架，用基于语义能量最小化的生物物理能量引导路由层替代密集的Mixture-of-Experts路由。输入被动态分组为语义密码子，通过最小化结合内聚性、不确定性和计算成本的全局能量函数来选择单个专家。

Result: 在BioASQ基准测试（K=50）中，实现了97.7%的能量利用密度降低和0.998的语义稳定性指数。在WikiText-103上展示了语义缩放定律，通过扩展到2048个专家粒度，在开放领域中保持超过99%的能量效率。

Conclusion: StructuredDNA建立了生物物理原理与Transformer稀疏专家路由之间的明确联系，为未来能量感知、模块化和可扩展的计算系统提供了稳健的领域无关范式，指出了扩展到更大模型、数据集和硬件平台的方向。

Abstract: The rapid scaling of large computational models has led to a critical increase in energy and compute costs. Inspired by biological systems where structure and function emerge from low-energy configurations, we introduce StructuredDNA, a sparse architecture framework for modular, energy-aware Transformer routing. StructuredDNA replaces dense Mixture-of-Experts routing with a bio-physical, energy-guided routing layer based on semantic energy minimization. Inputs are dynamically grouped into semantic codons, and routing selects a single expert by minimizing a global energy functional that combines cohesion, uncertainty, and computational cost.
  We validate StructuredDNA on both specialized (BioASQ) and open-domain benchmarks (WikiText-103). On BioASQ (K = 50), we achieve a 97.7% reduction in Energy Utilization Density (EUD) and a Semantic Stability Index (SSI) of 0.998. We further demonstrate a Semantic Scaling Law on WikiText-103, showing that the architecture generalizes to open domains by scaling expert granularity (K = 2048) while maintaining more than 99% energy efficiency. StructuredDNA thus establishes a robust, domain-agnostic paradigm for future sparse computational frameworks.
  StructuredDNA provides an explicit link between bio-physical principles and sparse expert routing in Transformer architectures, and points toward future energy-aware, modular, and scalable computational systems. We discuss limitations of this proof-of-concept study and outline directions for scaling the approach to larger models, datasets, and hardware platforms. The StructuredDNA implementation is available at https://github.com/InnoDeep-repos/StructuredDNA .

</details>


### [39] [Peek-a-Boo Reasoning: Contrastive Region Masking in MLLMs](https://arxiv.org/abs/2512.08976)
*Isha Chaturvedi,Anjana Nair,Yushen Li,Adhitya Rajendra Kumar,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma*

Main category: cs.LG

TL;DR: CRM是一种无需训练的诊断方法，通过对比性区域掩码揭示多模态大语言模型在思维链推理中对特定视觉区域的依赖关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于最终答案或注意力图，无法提供因果性、步骤级别的归因，需要一种能够评估多模态模型推理忠实性的诊断工具。

Method: CRM通过系统性地掩码标注的视觉区域，对比掩码与未掩码情况下的推理轨迹，分析模型在每个推理步骤中对特定视觉区域的依赖。

Result: 在VisArgs等数据集上，CRM揭示了不同的失败模式：一些模型保持推理结构但在证据缺失时产生幻觉，另一些模型紧密依赖视觉线索但在扰动下崩溃。

Conclusion: CRM将视觉基准从答案正确性评估转变为推理忠实性诊断，强调需要评估多模态模型的推理稳健性和保真度，而不仅仅是性能。

Abstract: We introduce Contrastive Region Masking (CRM), a training free diagnostic that reveals how multimodal large language models (MLLMs) depend on specific visual regions at each step of chain-of-thought (CoT) reasoning. Unlike prior approaches limited to final answers or attention maps, CRM provides causal, step-level attri- bution by systematically masking annotated regions and contrasting the resulting reasoning traces with unmasked baselines. Applied to datasets such as VisArgs, CRM reveals distinct failure modes: some models preserve reasoning structure, but hallucinate when evidence is missing, while others ground tightly to visual cues yet collapse under perturbations. By shifting the evaluation from correctness of an- swers to faithfulness of reasoning, CRM reframes visual benchmarks as diagnostic tools, highlighting the need for multimodal evaluation frameworks that measure not just performance, but also robustness and fidelity of reasoning.

</details>


### [40] [Improving Multi-Class Calibration through Normalization-Aware Isotonic Techniques](https://arxiv.org/abs/2512.09054)
*Alon Arad,Saharon Rosset*

Main category: cs.LG

TL;DR: 本文提出了两种新的多类校准方法：NA-FIR（归一化感知保序回归）和SCIR（累积双变量保序回归），通过显式考虑概率归一化来改进多类概率预测的校准性能。


<details>
  <summary>Details</summary>
Motivation: 多类监督学习任务需要准确可靠的概率预测，良好校准的模型能支持理性决策。虽然保序回归在二元校准中有效，但通过一对多扩展到多类问题时效果不如参数方法，限制了实际应用。

Method: 提出了两种新的保序归一化感知技术：1) NA-FIR：将归一化直接纳入优化过程；2) SCIR：将问题建模为累积双变量保序回归。两种方法都基于实践者期望的自然直观假设。

Result: 在多种文本和图像分类数据集及不同模型架构上的实证评估表明，该方法在负对数似然（NLL）和期望校准误差（ECE）指标上持续改进。

Conclusion: 提出的保序归一化感知方法有效解决了多类校准问题，通过显式考虑概率归一化约束，超越了传统一对多校准方法，在多类概率预测校准方面取得了显著改进。

Abstract: Accurate and reliable probability predictions are essential for multi-class supervised learning tasks, where well-calibrated models enable rational decision-making. While isotonic regression has proven effective for binary calibration, its extension to multi-class problems via one-vs-rest calibration produced suboptimal results when compared to parametric methods, limiting its practical adoption. In this work, we propose novel isotonic normalization-aware techniques for multiclass calibration, grounded in natural and intuitive assumptions expected by practitioners. Unlike prior approaches, our methods inherently account for probability normalization by either incorporating normalization directly into the optimization process (NA-FIR) or modeling the problem as a cumulative bivariate isotonic regression (SCIR). Empirical evaluation on a variety of text and image classification datasets across different model architectures reveals that our approach consistently improves negative log-likelihood (NLL) and expected calibration error (ECE) metrics.

</details>


### [41] [A Diffusion-Based Framework for High-Resolution Precipitation Forecasting over CONUS](https://arxiv.org/abs/2512.09059)
*Marina Vicens-Miquel,Amy McGovern,Aaron J. Hill,Efi Foufoula-Georgiou,Clement Guilloteau,Samuel S. P. Shen*

Main category: cs.LG

TL;DR: 本研究提出基于扩散的深度学习框架，比较三种残差预测策略：纯数据驱动（MRMS）、纯数值预报修正（HRRR）和混合模型，在1公里分辨率上实现1-12小时降水预报，显著优于HRRR基准。


<details>
  <summary>Details</summary>
Motivation: 准确的降水预报对水文气象风险管理至关重要，特别是预测可能导致山洪和基础设施损坏的极端降雨。本研究旨在通过系统比较不同数据源对降水预报技能的贡献，提升深度学习降水预报的预测能力、可靠性和区域适用性。

Method: 引入基于扩散的深度学习框架，在统一设置下比较三种残差预测策略：1）纯数据驱动模型（仅使用MRMS历史观测）；2）纯数值预报修正模型（仅使用HRRR预报）；3）混合模型（整合MRMS和选定的HRRR预报变量）。采用1公里空间分辨率，从1小时直接预测扩展到12小时自回归滚动预测，并针对残差学习设置进行校准的不确定性量化。

Result: 在所有预报时效上，深度学习框架在像素级和空间统计指标上均一致优于HRRR基准。混合模型在最短预报时效表现最佳，而HRRR修正模型在较长预报时效优于其他模型，能保持高技能至12小时。这些改进对应急准备至关重要，适度的预报时效增加可以改善决策制定。

Conclusion: 本研究通过系统比较不同数据源的贡献，推进了基于深度学习的降水预报，显著提升了预测技能、可靠性和区域适用性，特别是在较长预报时效上的改进对应急管理决策具有重要意义。

Abstract: Accurate precipitation forecasting is essential for hydrometeorological risk management, especially for anticipating extreme rainfall that can lead to flash flooding and infrastructure damage. This study introduces a diffusion-based deep learning (DL) framework that systematically compares three residual prediction strategies differing only in their input sources: (1) a fully data-driven model using only past observations from the Multi-Radar Multi-Sensor (MRMS) system, (2) a corrective model using only forecasts from the High-Resolution Rapid Refresh (HRRR) numerical weather prediction system, and (3) a hybrid model integrating both MRMS and selected HRRR forecast variables. By evaluating these approaches under a unified setup, we provide a clearer understanding of how each data source contributes to predictive skill over the Continental United States (CONUS). Forecasts are produced at 1-km spatial resolution, beginning with direct 1-hour predictions and extending to 12 hours using autoregressive rollouts. Performance is evaluated using both CONUS-wide and region-specific metrics that assess overall performance and skill at extreme rainfall thresholds. Across all lead times, our DL framework consistently outperforms the HRRR baseline in pixel-wise and spatiostatistical metrics. The hybrid model performs best at the shortest lead time, while the HRRR-corrective model outperforms others at longer lead times, maintaining high skill through 12 hours. To assess reliability, we incorporate calibrated uncertainty quantification tailored to the residual learning setup. These gains, particularly at longer lead times, are critical for emergency preparedness, where modest increases in forecast horizon can improve decision-making. This work advances DL-based precipitation forecasting by enhancing predictive skill, reliability, and applicability across regions.

</details>


### [42] [Modular Deep-Learning-Based Early Warning System for Deadly Heatwave Prediction](https://arxiv.org/abs/2512.09074)
*Shangqing Xu,Zhiyuan Zhao,Megha Sharma,José María Martín-Olalla,Alexander Rodríguez,Gregory A. Wellenius,B. Aditya Prakash*

Main category: cs.LG

TL;DR: DeepTherm是一个模块化的致命热浪早期预警系统，无需热相关死亡率历史数据，通过深度学习分离基线死亡率来预测致命热浪


<details>
  <summary>Details</summary>
Motivation: 城市严重热浪对公共健康构成重大威胁，需要建立早期预警策略。但预测即将到来的致命热浪面临挑战，包括难以定义和估计热相关死亡率，以及早期预警系统对数据可用性、时空鲁棒性和决策成本的要求

Method: 提出DeepTherm模块化早期预警系统，利用深度学习灵活性，采用双预测管道，从全因死亡率中分离出无热浪和其他不规则事件时的基线死亡率

Result: 在西班牙真实数据上评估显示，DeepTherm在不同地区、时间段和人群群体中表现出一致、鲁棒和准确的性能，同时允许在漏报和误报之间进行权衡

Conclusion: DeepTherm能够在不依赖热相关死亡率历史数据的情况下有效预测致命热浪，为城市热浪早期预警提供了可行的解决方案

Abstract: Severe heatwaves in urban areas significantly threaten public health, calling for establishing early warning strategies. Despite predicting occurrence of heatwaves and attributing historical mortality, predicting an incoming deadly heatwave remains a challenge due to the difficulty in defining and estimating heat-related mortality. Furthermore, establishing an early warning system imposes additional requirements, including data availability, spatial and temporal robustness, and decision costs. To address these challenges, we propose DeepTherm, a modular early warning system for deadly heatwave prediction without requiring heat-related mortality history. By highlighting the flexibility of deep learning, DeepTherm employs a dual-prediction pipeline, disentangling baseline mortality in the absence of heatwaves and other irregular events from all-cause mortality. We evaluated DeepTherm on real-world data across Spain. Results demonstrate consistent, robust, and accurate performance across diverse regions, time periods, and population groups while allowing trade-off between missed alarms and false alarms.

</details>


### [43] [Beyond the Hype: Comparing Lightweight and Deep Learning Models for Air Quality Forecasting](https://arxiv.org/abs/2512.09076)
*Moazzam Umer Gondal,Hamad ul Qudous,Asma Ahmad Farhan*

Main category: cs.LG

TL;DR: 该研究比较了轻量级加法模型（Facebook Prophet和NeuralProphet）与复杂深度学习模型在北京市PM2.5和PM10污染物预测中的表现，发现Facebook Prophet在准确性和可解释性方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 城市空气污染的准确预测对公共健康保护和政策制定至关重要。虽然深度学习和混合方法在研究中占主导地位，但其复杂性和有限的可解释性阻碍了实际应用。本研究旨在探索轻量级加法模型是否能在污染物预测中提供有竞争力的表现。

Method: 使用北京市多年污染物和气象数据，采用系统特征选择（相关性、互信息、mRMR）、防泄漏缩放和按时间顺序的数据划分。训练Facebook Prophet和NeuralProphet模型，并引入污染物和前体物作为回归变量。作为对比，还实现了两个机器学习基线模型（LSTM、LightGBM）和一个传统统计模型（SARIMAX）。

Result: Facebook Prophet在7天保留测试集上表现最佳，对两种污染物的测试R²均超过0.94，优于NeuralProphet、SARIMAX和基于学习的基线模型。这表明轻量级加法模型在准确性和可解释性方面具有竞争力。

Conclusion: 可解释的加法模型在污染物预测中仍然具有竞争力，能够在准确性、透明度和部署便利性之间提供实用的平衡，为实际应用提供了有吸引力的替代方案。

Abstract: Accurate forecasting of urban air pollution is essential for protecting public health and guiding mitigation policies. While Deep Learning (DL) and hybrid pipelines dominate recent research, their complexity and limited interpretability hinder operational use. This study investigates whether lightweight additive models -- Facebook Prophet (FBP) and NeuralProphet (NP) -- can deliver competitive forecasts for particulate matter (PM$_{2.5}$, PM$_{10}$) in Beijing, China. Using multi-year pollutant and meteorological data, we applied systematic feature selection (correlation, mutual information, mRMR), leakage-safe scaling, and chronological data splits. Both models were trained with pollutant and precursor regressors, with NP additionally leveraging lagged dependencies. For context, two machine learning baselines (LSTM, LightGBM) and one traditional statistical model (SARIMAX) were also implemented. Performance was evaluated on a 7-day holdout using MAE, RMSE, and $R^2$. Results show that FBP consistently outperformed NP, SARIMAX, and the learning-based baselines, achieving test $R^2$ above 0.94 for both pollutants. These findings demonstrate that interpretable additive models remain competitive with both traditional and complex approaches, offering a practical balance of accuracy, transparency, and ease of deployment.

</details>


### [44] [Towards Optimal Valve Prescription for Transcatheter Aortic Valve Replacement (TAVR) Surgery: A Machine Learning Approach](https://arxiv.org/abs/2512.09198)
*Phevos Paschalidis,Vasiliki Stoumpou,Lisa Everest,Yu Ma,Talhat Azemi,Jawad Haider,Steven Zweibel,Eleftherios M. Protopapas,Jeff Mather,Maciej Tysarowski,George E. Sarris,Robert C. Hagberg,Howard L. Haronian,Dimitris Bertsimas*

Main category: cs.LG

TL;DR: 开发数据驱动的临床决策工具，为经导管主动脉瓣置换术（TAVR）选择最优瓣膜类型，以降低永久起搏器植入风险，在美希混合数据集中验证有效。


<details>
  <summary>Details</summary>
Motivation: TAVR已成为治疗严重主动脉瓣狭窄的微创方法，但不同经导管心脏瓣膜（THV）的选择缺乏明确指南，永久起搏器植入（PPI）是主要术后并发症，需要个性化瓣膜选择策略来降低风险。

Method: 整合美国和希腊患者数据，结合人口统计学、CT扫描和超声心动图三种数据源，采用叶级分析利用人群异质性，避免基于不确定反事实风险估计的基准测试，开发个性化处方模型。

Result: 最终处方模型在美国内部人群中降低PPI率26%，在希腊外部验证队列中降低16%，相比当前标准治疗有显著改善。

Conclusion: 这是首个统一的、个性化的TAVR中THV选择处方策略，通过数据驱动方法有效降低永久起搏器植入风险，具有临床实用价值。

Abstract: Transcatheter Aortic Valve Replacement (TAVR) has emerged as a minimally invasive treatment option for patients with severe aortic stenosis, a life-threatening cardiovascular condition. Multiple transcatheter heart valves (THV) have been approved for use in TAVR, but current guidelines regarding valve type prescription remain an active topic of debate. We propose a data-driven clinical support tool to identify the optimal valve type with the objective of minimizing the risk of permanent pacemaker implantation (PPI), a predominant postoperative complication. We synthesize a novel dataset that combines U.S. and Greek patient populations and integrates three distinct data sources (patient demographics, computed tomography scans, echocardiograms) while harmonizing differences in each country's record system. We introduce a leaf-level analysis to leverage population heterogeneity and avoid benchmarking against uncertain counterfactual risk estimates. The final prescriptive model shows a reduction in PPI rates of 26% and 16% compared with the current standard of care in our internal U.S. population and external Greek validation cohort, respectively. To the best of our knowledge, this work represents the first unified, personalized prescription strategy for THV selection in TAVR.

</details>


### [45] [LLMs for Analog Circuit Design Continuum (ACDC)](https://arxiv.org/abs/2512.09199)
*Yasaman Esfandiari,Jocelyn Rego,Austin Meyer,Jonathan Gallagher,Mia Levy*

Main category: cs.LG

TL;DR: 该研究探讨了大型语言模型在模拟电路设计中的可靠性和鲁棒性，发现模型对数据格式敏感、生成设计不稳定、对未见电路配置泛化能力有限等问题。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在自然语言任务中表现出色，但在需要领域专业知识、物理约束和结构化表示的工程领域（特别是模拟电路设计）中的可靠性和实用性尚未得到充分探索，限制了其在真实世界工程应用中的实际价值。

Method: 研究调查了不同数据表示对模型行为的影响，比较了小型模型（如T5、GPT-2）与大型基础模型（如Mistral-7B、GPT-oss-20B）在不同训练条件下的表现，重点关注人类参与循环的AI辅助设计场景。

Result: 研究结果揭示了关键可靠性挑战：模型对数据格式敏感、生成的设计不稳定、对未见电路配置的泛化能力有限。这些发现表明当前LLMs在复杂工程任务中作为增强人类能力工具的局限性。

Conclusion: 该研究为LLMs在结构化、真实世界应用中作为可靠、可部署工具的潜力和限制提供了早期证据，为设计面向复杂工程任务的基础模型提供了重要见解。

Abstract: Large Language Models (LLMs) and transformer architectures have shown impressive reasoning and generation capabilities across diverse natural language tasks. However, their reliability and robustness in real-world engineering domains remain largely unexplored, limiting their practical utility in human-centric workflows. In this work, we investigate the applicability and consistency of LLMs for analog circuit design -- a task requiring domain-specific reasoning, adherence to physical constraints, and structured representations -- focusing on AI-assisted design where humans remain in the loop. We study how different data representations influence model behavior and compare smaller models (e.g., T5, GPT-2) with larger foundation models (e.g., Mistral-7B, GPT-oss-20B) under varying training conditions. Our results highlight key reliability challenges, including sensitivity to data format, instability in generated designs, and limited generalization to unseen circuit configurations. These findings provide early evidence on the limits and potential of LLMs as tools to enhance human capabilities in complex engineering tasks, offering insights into designing reliable, deployable foundation models for structured, real-world applications.

</details>


### [46] [Contrastive Learning for Semi-Supervised Deep Regression with Generalized Ordinal Rankings from Spectral Seriation](https://arxiv.org/abs/2512.09267)
*Ce Wang,Weihang Dai,Hanru Bai,Xiaomeng Li*

Main category: cs.LG

TL;DR: 该论文提出了一种用于半监督回归的对比学习方法，通过构建特征相似度矩阵并利用谱排序算法恢复未标记样本的序数关系，减少对昂贵标注的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法高度依赖标签信息来恢复特征的序数关系，限制了在半监督回归中的应用。需要扩展对比回归方法以利用未标记数据，减少对昂贵标注的依赖。

Method: 1. 构建包含标记和未标记样本的特征相似度矩阵；2. 使用谱排序算法恢复未标记样本的序数排名；3. 利用标记样本提供正则化指导；4. 使用动态规划算法选择鲁棒特征；5. 将恢复的序数关系用于未标记样本的对比学习。

Result: 在多个数据集上的实验验证表明，该方法超越了现有的最先进半监督深度回归方法，提供了理论保证和实证验证。

Conclusion: 该方法成功扩展了对比回归到半监督设置，通过利用未标记数据提高特征表示能力，实现了更鲁棒的回归结果，代码已开源。

Abstract: Contrastive learning methods enforce label distance relationships in feature space to improve representation capability for regression models. However, these methods highly depend on label information to correctly recover ordinal relationships of features, limiting their applications to semi-supervised regression. In this work, we extend contrastive regression methods to allow unlabeled data to be used in the semi-supervised setting, thereby reducing the dependence on costly annotations. Particularly we construct the feature similarity matrix with both labeled and unlabeled samples in a mini-batch to reflect inter-sample relationships, and an accurate ordinal ranking of involved unlabeled samples can be recovered through spectral seriation algorithms if the level of error is within certain bounds. The introduction of labeled samples above provides regularization of the ordinal ranking with guidance from the ground-truth label information, making the ranking more reliable. To reduce feature perturbations, we further utilize the dynamic programming algorithm to select robust features for the matrix construction. The recovered ordinal relationship is then used for contrastive learning on unlabeled samples, and we thus allow more data to be used for feature representation learning, thereby achieving more robust results. The ordinal rankings can also be used to supervise predictions on unlabeled samples, serving as an additional training signal. We provide theoretical guarantees and empirical verification through experiments on various datasets, demonstrating that our method can surpass existing state-of-the-art semi-supervised deep regression methods. Our code have been released on https://github.com/xmed-lab/CLSS.

</details>


### [47] [Self-Supervised Learning with Gaussian Processes](https://arxiv.org/abs/2512.09322)
*Yunshan Duan,Sinead Williamson*

Main category: cs.LG

TL;DR: 提出GPSSL方法，利用高斯过程进行自监督学习，解决传统方法需要显式正样本对和缺乏不确定性量化的问题。


<details>
  <summary>Details</summary>
Motivation: 传统自监督学习方法需要生成相似观测对，这在某些数据类型中很困难，且缺乏不确定性量化，在样本外预测中表现不佳。

Method: 提出高斯过程自监督学习（GPSSL），在表示学习上施加高斯过程先验，通过最小化损失函数获得广义贝叶斯后验，利用GP协方差函数自然拉近相似单元的表示。

Result: GPSSL与核PCA和VICReg相关，但能提供后验不确定性并传播到下游任务。在多个数据集上的分类和回归任务中，GPSSL在准确性、不确定性量化和误差控制方面优于传统方法。

Conclusion: GPSSL为自监督学习提供了一种不需要显式正样本对且能进行不确定性量化的有效方法，在多种下游任务中表现优异。

Abstract: Self supervised learning (SSL) is a machine learning paradigm where models learn to understand the underlying structure of data without explicit supervision from labeled samples. The acquired representations from SSL have demonstrated useful for many downstream tasks including clustering, and linear classification, etc. To ensure smoothness of the representation space, most SSL methods rely on the ability to generate pairs of observations that are similar to a given instance. However, generating these pairs may be challenging for many types of data. Moreover, these methods lack consideration of uncertainty quantification and can perform poorly in out-of-sample prediction settings. To address these limitations, we propose Gaussian process self supervised learning (GPSSL), a novel approach that utilizes Gaussian processes (GP) models on representation learning. GP priors are imposed on the representations, and we obtain a generalized Bayesian posterior minimizing a loss function that encourages informative representations. The covariance function inherent in GPs naturally pulls representations of similar units together, serving as an alternative to using explicitly defined positive samples. We show that GPSSL is closely related to both kernel PCA and VICReg, a popular neural network-based SSL method, but unlike both allows for posterior uncertainties that can be propagated to downstream tasks. Experiments on various datasets, considering classification and regression tasks, demonstrate that GPSSL outperforms traditional methods in terms of accuracy, uncertainty quantification, and error control.

</details>


### [48] [Self Distillation Fine-Tuning of Protein Language Models Improves Versatility in Protein Design](https://arxiv.org/abs/2512.09329)
*Amin Tavakoli,Raswanth Murugan,Ozan Gokdemir,Arvind Ramanathan,Frances Arnold,Anima Anandkumar*

Main category: cs.LG

TL;DR: 提出了一种简单通用的蛋白质语言模型快速监督微调方法，通过轻量级筛选管道构建高质量训练数据，无需昂贵实验数据集，能生成更稳定、功能更好的酶蛋白序列


<details>
  <summary>Details</summary>
Motivation: 蛋白质序列建模中监督微调方法缺乏系统性，高质量标注数据获取困难，现有方法依赖昂贵的预编译实验数据集，需要更高效、通用的蛋白质语言模型微调方案

Method: 利用蛋白质语言模型自身，结合轻量级筛选管道和领域特定过滤器构建高质量训练数据，通过监督微调提升序列生成质量，方法对PLM和蛋白质系统都保持通用性

Result: 在色氨酸合酶酶家族上应用基因组规模PLM（GenSLM），监督微调后的模型生成序列不仅更具新颖性，而且在目标设计约束和涌现蛋白质性质指标上都显示出改进特性

Conclusion: 该方法提供了一种简单有效的蛋白质语言模型快速监督微调方案，能够生成更稳定、功能更好的酶蛋白序列，同时扩展了对蛋白质序列空间的探索，超越了天然变体

Abstract: Supervised fine-tuning (SFT) is a standard approach for adapting large language models to specialized domains, yet its application to protein sequence modeling and protein language models (PLMs) remains ad hoc. This is in part because high-quality annotated data are far more difficult to obtain for proteins than for natural language. We present a simple and general recipe for fast SFT of PLMs, designed to improve the fidelity, reliability, and novelty of generated protein sequences. Unlike existing approaches that require costly precompiled experimental datasets for SFT, our method leverages the PLM itself, integrating a lightweight curation pipeline with domain-specific filters to construct high-quality training data. These filters can independently refine a PLM's output and identify candidates for in vitro evaluation; when combined with SFT, they enable PLMs to generate more stable and functional enzymes, while expanding exploration into protein sequence space beyond natural variants. Although our approach is agnostic to both the choice of protein language model (PLM) and the protein system, we demonstrate its effectiveness with a genome-scale PLM (GenSLM) applied to the tryptophan synthase enzyme family. The supervised fine-tuned model generates sequences that are not only more novel but also display improved characteristics across both targeted design constraints and emergent protein property measures.

</details>


### [49] [Branching Strategies Based on Subgraph GNNs: A Study on Theoretical Promise versus Practical Reality](https://arxiv.org/abs/2512.09355)
*Junru Zhou,Yicheng Wang,Pan Li*

Main category: cs.LG

TL;DR: 该论文研究了子图GNN在MILP分支选择中的应用，理论上证明节点锚定子图GNN（表达能力低于3-WL）足以近似强分支评分，但实证发现其计算开销过大导致实际性能不如MPNN和启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现有GNN方法在MILP分支选择中存在表达能力和计算效率的权衡：MPNN效率高但表达能力不足，高阶GNN表达能力强但计算代价过高。需要寻找理论表达能力和实际计算效率之间的平衡点。

Method: 采用节点锚定子图GNN作为理论中间方案，理论上证明其表达能力（低于3-WL）足以近似强分支评分，并在四个基准数据集上进行广泛的实证评估，比较MPNN、启发式方法和子图GNN的性能。

Result: 理论分析表明节点锚定子图GNN足以近似强分支评分，但实证结果显示：尽管子图GNN理论上提供更优的分支决策，其O(n)复杂度开销导致显著的内存瓶颈和较慢的求解时间，实际性能不如MPNN和启发式方法。

Conclusion: 对于MILP分支选择，当前表达性GNN的计算成本超过了决策质量的收益，未来研究需要关注保持效率的表达性提升方法。

Abstract: Graph Neural Networks (GNNs) have emerged as a promising approach for ``learning to branch'' in Mixed-Integer Linear Programming (MILP). While standard Message-Passing GNNs (MPNNs) are efficient, they theoretically lack the expressive power to fully represent MILP structures. Conversely, higher-order GNNs (like 2-FGNNs) are expressive but computationally prohibitive. In this work, we investigate Subgraph GNNs as a theoretical middle ground. Crucially, while previous work [Chen et al., 2025] demonstrated that GNNs with 3-WL expressive power can approximate Strong Branching, we prove a sharper result: node-anchored Subgraph GNNs whose expressive power is strictly lower than 3-WL [Zhang et al., 2023] are sufficient to approximate Strong Branching scores. However, our extensive empirical evaluation on four benchmark datasets reveals a stark contrast between theory and practice. While node-anchored Subgraph GNNs theoretically offer superior branching decisions, their $O(n)$ complexity overhead results in significant memory bottlenecks and slower solving times than MPNNs and heuristics. Our results indicate that for MILP branching, the computational cost of expressive GNNs currently outweighs their gains in decision quality, suggesting that future research must focus on efficiency-preserving expressivity.

</details>


### [50] [A Granular Framework for Construction Material Price Forecasting: Econometric and Machine-Learning Approaches](https://arxiv.org/abs/2512.09360)
*Boge Lyu,Qianye Yin,Iris Denise Tommelein,Hanyang Liu,Karnamohit Ranka,Karthik Yeluripati,Junzhe Shi*

Main category: cs.LG

TL;DR: 该研究开发了一个基于CSI MasterFormat的建筑材料价格预测框架，通过整合原材料价格、商品指数和宏观经济指标等解释变量，显著提升了预测精度，其中LSTM模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 建筑材料的持续价格波动对成本估算、预算编制和项目交付构成重大风险，迫切需要更精细和可扩展的预测方法。

Method: 研究以CSI MasterFormat为目标数据结构，开发预测框架，支持六位数章节级别的预测。整合了原材料价格、商品指数和宏观经济指标等解释变量，评估了LSTM、ARIMA、VECM和Chronos-Bolt四种时间序列模型在基础配置（仅使用CSI数据）和扩展版本（加入解释变量）下的表现。

Result: 纳入解释变量显著提升了所有模型的预测性能。LSTM模型表现最佳，RMSE值低至1.390，MAPE值为0.957，相比传统统计时间序列模型ARIMA提升了高达59%。验证了框架在多个CSI分部中的可扩展性，并以第06分部（木材、塑料和复合材料）作为详细演示案例。

Conclusion: 该研究提供了一个稳健的方法论，使业主和承包商能够改进预算实践，在确定性水平上实现更可靠的成本估算。

Abstract: The persistent volatility of construction material prices poses significant risks to cost estimation, budgeting, and project delivery, underscoring the urgent need for granular and scalable forecasting methods. This study develops a forecasting framework that leverages the Construction Specifications Institute (CSI) MasterFormat as the target data structure, enabling predictions at the six-digit section level and supporting detailed cost projections across a wide spectrum of building materials. To enhance predictive accuracy, the framework integrates explanatory variables such as raw material prices, commodity indexes, and macroeconomic indicators. Four time-series models, Long Short-Term Memory (LSTM), Autoregressive Integrated Moving Average (ARIMA), Vector Error Correction Model (VECM), and Chronos-Bolt, were evaluated under both baseline configurations (using CSI data only) and extended versions with explanatory variables. Results demonstrate that incorporating explanatory variables significantly improves predictive performance across all models. Among the tested approaches, the LSTM model consistently achieved the highest accuracy, with RMSE values as low as 1.390 and MAPE values of 0.957, representing improvements of up to 59\% over the traditional statistical time-series model, ARIMA. Validation across multiple CSI divisions confirmed the framework's scalability, while Division 06 (Wood, Plastics, and Composites) is presented in detail as a demonstration case. This research offers a robust methodology that enables owners and contractors to improve budgeting practices and achieve more reliable cost estimation at the Definitive level.

</details>


### [51] [KGOT: Unified Knowledge Graph and Optimal Transport Pseudo-Labeling for Molecule-Protein Interaction Prediction](https://arxiv.org/abs/2512.09365)
*Jiayu Qin,Zhengquan Luo,Guy Tadmor,Changyou Chen,David Zeevi,Zhiqiang Xu*

Main category: cs.LG

TL;DR: 该论文提出了一种基于最优传输的生物信息学框架，通过整合多种生物数据源（分子、蛋白质、基因、通路等）并生成高质量伪标签，显著提升了分子-蛋白质相互作用预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有分子-蛋白质相互作用（MPI）预测模型面临两大挑战：1）标记数据稀缺，可用数据集仅捕获了生物相关相互作用的一小部分；2）大多数方法仅依赖分子和蛋白质特征，忽略了基因、代谢通路和功能注释等更广泛的生物背景信息。

Method: 首先整合多种生物数据集（包括分子、蛋白质、基因和通路水平的相互作用），然后开发基于最优传输的方法，利用已知相互作用的底层分布来指导标签分配，为未标记的分子-蛋白质对生成高质量的伪标签。

Result: 在多个MPI数据集（包括虚拟筛选任务和蛋白质检索任务）上评估，相比最先进方法在预测准确性和对未见相互作用的零样本能力方面都有显著提升。

Conclusion: 该框架不仅改进了MPI预测，还为利用多样化生物数据源解决传统上受限于单模态或双模态学习的问题提供了新范式，为计算生物学和药物发现的未来发展铺平了道路。

Abstract: Predicting molecule-protein interactions (MPIs) is a fundamental task in computational biology, with crucial applications in drug discovery and molecular function annotation. However, existing MPI models face two major challenges. First, the scarcity of labeled molecule-protein pairs significantly limits model performance, as available datasets capture only a small fraction of biological relevant interactions. Second, most methods rely solely on molecular and protein features, ignoring broader biological context such as genes, metabolic pathways, and functional annotations that could provide essential complementary information. To address these limitations, our framework first aggregates diverse biological datasets, including molecular, protein, genes and pathway-level interactions, and then develop an optimal transport-based approach to generate high-quality pseudo-labels for unlabeled molecule-protein pairs, leveraging the underlying distribution of known interactions to guide label assignment. By treating pseudo-labeling as a mechanism for bridging disparate biological modalities, our approach enables the effective use of heterogeneous data to enhance MPI prediction. We evaluate our framework on multiple MPI datasets including virtual screening tasks and protein retrieval tasks, demonstrating substantial improvements over state-of-the-art methods in prediction accuracies and zero shot ability across unseen interactions. Beyond MPI prediction, our approach provides a new paradigm for leveraging diverse biological data sources to tackle problems traditionally constrained by single- or bi-modal learning, paving the way for future advances in computational biology and drug discovery.

</details>


### [52] [CFLight: Enhancing Safety with Traffic Signal Control through Counterfactual Learning](https://arxiv.org/abs/2512.09368)
*Mingyuan Li,Chunyu Liu,Zhuojun Li,Xiao Liu,Guangsheng Yu,Bo Du,Jun Shen,Qiang Wu*

Main category: cs.LG

TL;DR: 提出CFLight框架，通过反事实学习增强交通信号控制中的安全性，在减少碰撞的同时提升整体交通性能


<details>
  <summary>Details</summary>
Motivation: 交通信号控制中强化学习方法通常优先考虑驾驶效率而忽视安全性，且缺乏可解释性，需要平衡安全与效率并提高方法透明度

Method: 提出基于反事实学习的CFLight框架，构建新的结构因果模型预测不同动作的结果，集成反事实模块与额外"X"模块促进安全强化学习实践

Result: 在真实世界和合成数据集上的实验表明，CFLight相比传统强化学习方法和近期安全强化学习模型，能减少碰撞并提升整体交通性能

Conclusion: CFLight提供了一个通用且安全的强化学习框架，通过近零碰撞控制策略显著提升交叉口安全性，并具有扩展到其他领域的潜力

Abstract: Traffic accidents result in millions of injuries and fatalities globally, with a significant number occurring at intersections each year. Traffic Signal Control (TSC) is an effective strategy for enhancing safety at these urban junctures. Despite the growing popularity of Reinforcement Learning (RL) methods in optimizing TSC, these methods often prioritize driving efficiency over safety, thus failing to address the critical balance between these two aspects. Additionally, these methods usually need more interpretability. CounterFactual (CF) learning is a promising approach for various causal analysis fields. In this study, we introduce a novel framework to improve RL for safety aspects in TSC. This framework introduces a novel method based on CF learning to address the question: ``What if, when an unsafe event occurs, we backtrack to perform alternative actions, and will this unsafe event still occur in the subsequent period?'' To answer this question, we propose a new structure causal model to predict the result after executing different actions, and we propose a new CF module that integrates with additional ``X'' modules to promote safe RL practices. Our new algorithm, CFLight, which is derived from this framework, effectively tackles challenging safety events and significantly improves safety at intersections through a near-zero collision control strategy. Through extensive numerical experiments on both real-world and synthetic datasets, we demonstrate that CFLight reduces collisions and improves overall traffic performance compared to conventional RL methods and the recent safe RL model. Moreover, our method represents a generalized and safe framework for RL methods, opening possibilities for applications in other domains. The data and code are available in the github https://github.com/MJLee00/CFLight-Enhancing-Safety-with-Traffic-Signal-Control-through-Counterfactual-Learning.

</details>


### [53] [Towards Resilient Transportation: A Conditional Transformer for Accident-Informed Traffic Forecasting](https://arxiv.org/abs/2512.09398)
*Hongjun Wang,Jiawei Yong,Jiawei Wang,Shintaro Fukushima,Renhe Jiang*

Main category: cs.LG

TL;DR: 提出了ConFormer框架，整合交通事故和法规数据，通过图传播和引导归一化层动态调整时空节点关系，在东京和加州数据集上超越现有最佳模型STAEFormer。


<details>
  <summary>Details</summary>
Motivation: 交通预测面临外部因素（如交通事故、法规）复杂影响的挑战，现有模型因数据整合有限而忽视这些因素，限制了预测准确性。

Method: 提出了两个包含交通事故和法规数据的东京和加州交通数据集，并设计了ConFormer（条件Transformer）框架，整合图传播与引导归一化层，动态调整时空节点关系。

Result: ConFormer在预测性能和效率上均超越当前最佳模型STAEFormer，计算成本更低、参数需求更少，在多个指标上持续优于主流时空基线模型。

Conclusion: ConFormer通过有效整合外部因素数据和动态调整时空关系，显著提升了交通预测准确性，具有推动交通预测研究发展的潜力。

Abstract: Traffic prediction remains a key challenge in spatio-temporal data mining, despite progress in deep learning. Accurate forecasting is hindered by the complex influence of external factors such as traffic accidents and regulations, often overlooked by existing models due to limited data integration. To address these limitations, we present two enriched traffic datasets from Tokyo and California, incorporating traffic accident and regulation data. Leveraging these datasets, we propose ConFormer (Conditional Transformer), a novel framework that integrates graph propagation with guided normalization layer. This design dynamically adjusts spatial and temporal node relationships based on historical patterns, enhancing predictive accuracy. Our model surpasses the state-of-the-art STAEFormer in both predictive performance and efficiency, achieving lower computational costs and reduced parameter demands. Extensive evaluations demonstrate that ConFormer consistently outperforms mainstream spatio-temporal baselines across multiple metrics, underscoring its potential to advance traffic prediction research.

</details>


### [54] [Are Hypervectors Enough? Single-Call LLM Reasoning over Knowledge Graphs](https://arxiv.org/abs/2512.09369)
*Yezi Liu,William Youngwoo Chung,Hanning Chen,Calvin Yeung,Mohsen Imani*

Main category: cs.LG

TL;DR: PathHD：基于超维度计算的轻量级知识图谱推理框架，用单次LLM调用替代神经路径评分，实现高效、可解释的KG-LLM推理


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的LLM推理方法依赖重型神经编码器或重复LLM调用，导致高延迟、高GPU成本和不透明的决策，阻碍了可信赖、可扩展的部署

Method: 提出PathHD框架：1）使用超维度计算将关系路径编码为块对角GHRR超向量；2）通过块状余弦相似度和Top-K剪枝对候选进行排序；3）执行一次性LLM裁决生成最终答案并引用支持路径

Result: 在WebQSP、CWQ和GrailQA数据集上：1）达到与强神经基线相当或更好的Hits@1，每查询仅需一次LLM调用；2）端到端延迟降低40-60%，GPU内存减少3-5倍；3）提供忠实、基于路径的推理依据，改善错误诊断和可控性

Conclusion: 精心设计的超维度计算表示提供了高效的KG-LLM推理实用基础，在准确性、效率和可解释性之间实现了有利的权衡

Abstract: Recent advances in large language models (LLMs) have enabled strong reasoning over both structured and unstructured knowledge. When grounded on knowledge graphs (KGs), however, prevailing pipelines rely on heavy neural encoders to embed and score symbolic paths or on repeated LLM calls to rank candidates, leading to high latency, GPU cost, and opaque decisions that hinder faithful, scalable deployment. We propose PathHD, a lightweight and encoder-free KG reasoning framework that replaces neural path scoring with hyperdimensional computing (HDC) and uses only a single LLM call per query. PathHD encodes relation paths into block-diagonal GHRR hypervectors, ranks candidates with blockwise cosine similarity and Top-K pruning, and then performs a one-shot LLM adjudication to produce the final answer together with cited supporting paths. Technically, PathHD is built on three ingredients: (i) an order-aware, non-commutative binding operator for path composition, (ii) a calibrated similarity for robust hypervector-based retrieval, and (iii) a one-shot adjudication step that preserves interpretability while eliminating per-path LLM scoring. On WebQSP, CWQ, and the GrailQA split, PathHD (i) attains comparable or better Hits@1 than strong neural baselines while using one LLM call per query; (ii) reduces end-to-end latency by $40-60\%$ and GPU memory by $3-5\times$ thanks to encoder-free retrieval; and (iii) delivers faithful, path-grounded rationales that improve error diagnosis and controllability. These results indicate that carefully designed HDC representations provide a practical substrate for efficient KG-LLM reasoning, offering a favorable accuracy-efficiency-interpretability trade-off.

</details>


### [55] [Rates and architectures for learning geometrically non-trivial operators](https://arxiv.org/abs/2512.09376)
*T. Mitchell Roddenberry,Leo Tzou,Ivan Dokmanić,Maarten V. de Hoop,Richard G. Baraniuk*

Main category: cs.LG

TL;DR: 该论文扩展了科学机器学习的学习理论，将双纤维化变换（包括广义Radon变换和测地线射线变换）纳入研究范围，证明了这类算子不受维度诅咒影响，误差衰减速度比训练样本数的任何固定幂次更快。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习理论主要针对椭圆算子等简单几何情况，但科学机器学习常涉及波传播、对流、流体动力学等具有奇异性传播的问题。需要扩展理论以涵盖更广泛的几何积分算子。

Method: 将学习理论扩展到双纤维化变换这类几何积分算子，包括广义Radon变换和测地线射线变换。研究基于水平集方法的交叉注意力架构，该架构显式编码变换的几何结构。

Result: 证明双纤维化变换类算子不受维度诅咒影响：误差以超代数速度衰减（比训练样本数倒数的任何固定幂次更快）。基于水平集方法的交叉注意力架构具有普适性、稳定性，并能从极少训练样本中学习双纤维化变换。

Conclusion: 该研究扩展了科学机器学习中算子学习的理论框架，为处理具有奇异性传播的问题提供了理论基础，并展示了特定架构在几何积分算子学习中的优越性能。

Abstract: Deep learning methods have proven capable of recovering operators between high-dimensional spaces, such as solution maps of PDEs and similar objects in mathematical physics, from very few training samples. This phenomenon of data-efficiency has been proven for certain classes of elliptic operators with simple geometry, i.e., operators that do not change the domain of the function or propagate singularities. However, scientific machine learning is commonly used for problems that do involve the propagation of singularities in a priori unknown ways, such as waves, advection, and fluid dynamics. In light of this, we expand the learning theory to include double fibration transforms--geometric integral operators that include generalized Radon and geodesic ray transforms. We prove that this class of operators does not suffer from the curse of dimensionality: the error decays superalgebraically, that is, faster than any fixed power of the reciprocal of the number of training samples. Furthermore, we investigate architectures that explicitly encode the geometry of these transforms, demonstrating that an architecture reminiscent of cross-attention based on levelset methods yields a parameterization that is universal, stable, and learns double fibration transforms from very few training examples. Our results contribute to a rapidly-growing line of theoretical work on learning operators for scientific machine learning.

</details>


### [56] [Representation Invariance and Allocation: When Subgroup Balance Matters](https://arxiv.org/abs/2512.09496)
*Anissa Alloula,Charles Jones,Zuzanna Wakefield-Skorniewska,Francesco Quinzan,Bartłomiej Papież*

Main category: cs.LG

TL;DR: 研究发现，在预训练模型微调中，子群性能对数据平衡的敏感性取决于预训练模型潜在空间中子群的分离程度，而非简单的数据平衡假设。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为平衡训练数据中的子群表示可以优化模型性能，但近期实证结果与此相矛盾：在某些情况下，不平衡的数据分布反而改善了子群性能，而在其他情况下，即使训练数据中完全缺失某个子群，其性能也不受影响。这种矛盾促使研究者系统研究子群分配问题。

Method: 研究在四个视觉和语言模型上进行系统实验，通过改变训练数据组成来表征子群性能对数据平衡的敏感性。提出了潜在分离假说，认为部分微调模型对子群表示的依赖程度取决于预训练模型潜在空间中子群的分离程度。对该假说进行了形式化、理论分析，并通过实验验证。

Result: 研究发现子群性能对数据平衡的敏感性确实与预训练模型潜在空间中子群的分离程度相关。当子群在潜在空间中高度分离时，模型性能对数据平衡更敏感；当子群在潜在空间中混合良好时，模型性能对数据平衡不敏感。这一发现挑战了传统的数据平衡假设。

Conclusion: 研究提出了潜在分离假说，为理解子群性能与数据平衡之间的关系提供了新的理论框架。该发现对基础模型微调具有实际应用价值，表明通过定量分析潜在子群分离程度，可以指导数据收集和平衡决策，而不是盲目追求数据平衡。

Abstract: Unequal representation of demographic groups in training data poses challenges to model generalisation across populations. Standard practice assumes that balancing subgroup representation optimises performance. However, recent empirical results contradict this assumption: in some cases, imbalanced data distributions actually improve subgroup performance, while in others, subgroup performance remains unaffected by the absence of an entire subgroup during training. We conduct a systematic study of subgroup allocation across four vision and language models, varying training data composition to characterise the sensitivity of subgroup performance to data balance. We propose the latent separation hypothesis, which states that a partially fine-tuned model's dependence on subgroup representation is determined by the degree of separation between subgroups in the latent space of the pre-trained model. We formalise this hypothesis, provide theoretical analysis, and validate it empirically. Finally, we present a practical application to foundation model fine-tuning, demonstrating that quantitative analysis of latent subgroup separation can inform data collection and balancing decisions.

</details>


### [57] [Federated Distillation Assisted Vehicle Edge Caching Scheme Based on Lightweight DDPM](https://arxiv.org/abs/2512.09378)
*Xun Li,Qiong Wu,Pingyi Fan,Kezhi Wang,Wen Chen,Khaled B. Letaief*

Main category: cs.LG

TL;DR: 提出基于轻量级去噪扩散概率模型和联邦蒸馏的车辆边缘缓存方案，解决传统联邦学习的通信开销大和车辆移动导致的训练失败问题。


<details>
  <summary>Details</summary>
Motivation: 车辆边缘缓存能显著降低车辆用户访问内容的延迟，但需要准确预测用户兴趣内容同时保护隐私。传统联邦学习虽然能保护隐私，但存在通信开销大和车辆移动导致训练失败的问题。

Method: 提出基于轻量级去噪扩散概率模型（LDPM）的联邦蒸馏辅助车辆边缘缓存方案，通过联邦蒸馏减少模型传输频率，降低通信开销，并适应车辆移动性。

Result: 仿真结果表明，所提方案对车辆速度变化具有良好鲁棒性，显著降低通信开销，提高缓存命中率。

Conclusion: 提出的基于LDPM的联邦蒸馏辅助车辆边缘缓存方案能有效解决传统联邦学习在车辆边缘缓存中的通信开销和移动性问题，提高系统性能。

Abstract: Vehicle edge caching is a promising technology that can significantly reduce the latency for vehicle users (VUs) to access content by pre-caching user-interested content at edge nodes. It is crucial to accurately predict the content that VUs are interested in without exposing their privacy. Traditional federated learning (FL) can protect user privacy by sharing models rather than raw data. However, the training of FL requires frequent model transmission, which can result in significant communication overhead. Additionally, vehicles may leave the road side unit (RSU) coverage area before training is completed, leading to training failures. To address these issues, in this letter, we propose a federated distillation-assisted vehicle edge caching scheme based on lightweight denoising diffusion probabilistic model (LDPM). The simulation results demonstrate that the proposed vehicle edge caching scheme has good robustness to variations in vehicle speed, significantly reducing communication overhead and improving cache hit percentage.

</details>


### [58] [Stanford Sleep Bench: Evaluating Polysomnography Pre-training Methods for Sleep Foundation Models](https://arxiv.org/abs/2512.09591)
*Magnus Ruud Kjaer,Rahul Thapa,Gauri Ganjoo,Hyatt Moore,Poul Joergen Jennum,Brandon M. Westover,James Zou,Emmanuel Mignot,Bryan He,Andreas Brink-Kjaer*

Main category: cs.LG

TL;DR: 斯坦福睡眠基准是一个大规模多导睡眠图数据集，包含17,467条记录和13个临床疾病预测任务，用于系统评估自监督表示学习方法在睡眠分析中的表现。


<details>
  <summary>Details</summary>
Motivation: 多导睡眠图产生大量多模态临床数据，为利用自监督表示学习预训练基础模型提供了机会。但目前睡眠基础模型发展面临两个关键限制：缺乏共享数据集和基准，以及缺乏对自监督学习方法在睡眠相关任务上的系统评估。

Method: 引入斯坦福睡眠基准数据集，包含17,467条记录（超过163,000小时），来自主要睡眠诊所，包括13个临床疾病预测任务以及睡眠分期、呼吸暂停诊断、年龄估计等经典任务。系统评估多种自监督预训练方法在下游任务上的表现。

Result: 多种预训练方法在睡眠分期、呼吸暂停诊断和年龄估计任务上表现相当。但对于死亡率和疾病预测，对比学习方法显著优于其他方法，且在预训练期间收敛更快。

Conclusion: 斯坦福睡眠基准填补了睡眠研究中的数据和方法评估空白，对比学习在临床预测任务中表现突出。将发布数据集、预训练模型权重、训练管道和评估代码以促进可重复性和睡眠研究进展。

Abstract: Polysomnography (PSG), the gold standard test for sleep analysis, generates vast amounts of multimodal clinical data, presenting an opportunity to leverage self-supervised representation learning (SSRL) for pre-training foundation models to enhance sleep analysis. However, progress in sleep foundation models is hindered by two key limitations: (1) the lack of a shared dataset and benchmark with diverse tasks for training and evaluation, and (2) the absence of a systematic evaluation of SSRL approaches across sleep-related tasks. To address these gaps, we introduce Stanford Sleep Bench, a large-scale PSG dataset comprising 17,467 recordings totaling over 163,000 hours from a major sleep clinic, including 13 clinical disease prediction tasks alongside canonical sleep-related tasks such as sleep staging, apnea diagnosis, and age estimation. We systematically evaluate SSRL pre-training methods on Stanford Sleep Bench, assessing downstream performance across four tasks: sleep staging, apnea diagnosis, age estimation, and disease and mortality prediction. Our results show that multiple pretraining methods achieve comparable performance for sleep staging, apnea diagnosis, and age estimation. However, for mortality and disease prediction, contrastive learning significantly outperforms other approaches while also converging faster during pretraining. To facilitate reproducibility and advance sleep research, we will release Stanford Sleep Bench along with pretrained model weights, training pipelines, and evaluation code.

</details>


### [59] [Cauchy-Schwarz Fairness Regularizer](https://arxiv.org/abs/2512.09467)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: 论文提出了一种基于柯西-施瓦茨散度的公平性正则化器，通过惩罚敏感群体间预测分布的差异来提升机器学习模型的群体公平性，相比现有方法具有更紧的泛化边界和更好的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有公平性正则化器基于不同的距离度量和设计选择，导致其行为难以推理且在不同任务上性能不一致。需要探究什么特性构成一个好的公平性正则化器，并设计满足理想特性的正则化方法。

Method: 将现有方法分为三类：跨敏感群体匹配预测统计量、对齐潜在表示、直接最小化预测与敏感属性间的依赖性。基于理想特性分析，提出柯西-施瓦茨公平性正则化器，惩罚敏感群体条件下预测分布间的经验CS散度。该方法采用分布无关的核基估计器，可扩展到多个敏感属性。

Result: 在四个表格基准和一个图像数据集上的实验表明，CS正则化器在保持竞争性准确率的同时，一致改进了人口统计均等和机会均等指标。相比先前正则化器，在超参数设置下实现了更稳定的效用-公平性权衡。

Conclusion: 柯西-施瓦茨散度作为公平性正则化器具有理论优势，包括更紧的泛化边界、对尺度差异的鲁棒性以及处理任意预测分布的能力。该方法为机器学习中的群体公平性提供了一种有效且稳定的解决方案。

Abstract: Group fairness in machine learning is often enforced by adding a regularizer that reduces the dependence between model predictions and sensitive attributes. However, existing regularizers are built on heterogeneous distance measures and design choices, which makes their behavior hard to reason about and their performance inconsistent across tasks. This raises a basic question: what properties make a good fairness regularizer? We address this question by first organizing existing in-process methods into three families: (i) matching prediction statistics across sensitive groups, (ii) aligning latent representations, and (iii) directly minimizing dependence between predictions and sensitive attributes. Through this lens, we identify desirable properties of the underlying distance measure, including tight generalization bounds, robustness to scale differences, and the ability to handle arbitrary prediction distributions. Motivated by these properties, we propose a Cauchy-Schwarz (CS) fairness regularizer that penalizes the empirical CS divergence between prediction distributions conditioned on sensitive groups. Under a Gaussian comparison, we show that CS divergence yields a tighter bound than Kullback-Leibler divergence, Maximum Mean Discrepancy, and the mean disparity used in Demographic Parity, and we discuss how these advantages translate to a distribution-free, kernel-based estimator that naturally extends to multiple sensitive attributes. Extensive experiments on four tabular benchmarks and one image dataset demonstrate that the proposed CS regularizer consistently improves Demographic Parity and Equal Opportunity metrics while maintaining competitive accuracy, and achieves a more stable utility-fairness trade-off across hyperparameter settings compared to prior regularizers.

</details>


### [60] [Circuits, Features, and Heuristics in Molecular Transformers](https://arxiv.org/abs/2512.09757)
*Kristof Varadi,Mark Marosi,Peter Antal*

Main category: cs.LG

TL;DR: 该论文对训练在药物类小分子上的自回归Transformer进行机制分析，揭示了模型在不同抽象层次捕捉分子表示规则的计算结构


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer能生成有效且多样的化学结构，但人们对这些模型如何捕捉分子表示规则的机制知之甚少，需要深入理解其计算结构

Method: 使用稀疏自编码器(SAEs)提取与化学相关激活模式相关的特征字典，对自回归Transformer进行多层次的机制分析

Result: 识别出与低层次语法解析和更抽象的化学有效性约束一致的计算模式，发现机制洞察可以转化为各种实际场景中的预测性能

Conclusion: 通过机制分析揭示了Transformer捕捉分子表示规则的计算结构，为理解化学AI模型提供了新的视角，并展示了机制洞察在实际应用中的价值

Abstract: Transformers generate valid and diverse chemical structures, but little is known about the mechanisms that enable these models to capture the rules of molecular representation. We present a mechanistic analysis of autoregressive transformers trained on drug-like small molecules to reveal the computational structure underlying their capabilities across multiple levels of abstraction. We identify computational patterns consistent with low-level syntactic parsing and more abstract chemical validity constraints. Using sparse autoencoders (SAEs), we extract feature dictionaries associated with chemically relevant activation patterns. We validate our findings on downstream tasks and find that mechanistic insights can translate to predictive performance in various practical settings.

</details>


### [61] [Contextual Dynamic Pricing with Heterogeneous Buyers](https://arxiv.org/abs/2512.09513)
*Thodoris Lykouris,Sloan Nietert,Princewill Okoroafor,Chara Podimata,Julian Zimmert*

Main category: cs.LG

TL;DR: 该论文研究了具有异质买家群体的上下文动态定价问题，卖家根据可观测的d维上下文重复定价，接收二元购买反馈，买家估值类型来自未知的有限支持分布，提出了基于乐观后验采样的算法，实现了接近最优的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多假设买家是同质的，但现实中买家群体通常是异质的，具有不同的估值类型。本文旨在解决具有异质买家群体的上下文动态定价问题，其中买家的估值类型来自未知的有限支持分布，这是对传统同质买家假设的重要扩展。

Method: 提出了基于乐观后验采样的上下文定价算法，利用贝叶斯方法处理未知的买家类型分布。对于非上下文情况，设计了方差感知的缩放算法，能够根据买家类型分布的方差特性进行优化。

Result: 上下文定价算法实现了$\widetilde{O}(K_{\star}\sqrt{dT})$的遗憾界，在d和T维度上达到接近最优（对数因子内）。非上下文情况下，方差感知缩放算法在$K_{\star}$依赖上达到最优。

Conclusion: 本文首次系统研究了具有异质买家群体的上下文动态定价问题，提出的算法在理论和实际性能上都表现出色，为处理现实世界中复杂的买家异质性提供了有效的解决方案。

Abstract: We initiate the study of contextual dynamic pricing with a heterogeneous population of buyers, where a seller repeatedly posts prices (over $T$ rounds) that depend on the observable $d$-dimensional context and receives binary purchase feedback. Unlike prior work assuming homogeneous buyer types, in our setting the buyer's valuation type is drawn from an unknown distribution with finite support size $K_{\star}$. We develop a contextual pricing algorithm based on optimistic posterior sampling with regret $\widetilde{O}(K_{\star}\sqrt{dT})$, which we prove to be tight in $d$ and $T$ up to logarithmic terms. Finally, we refine our analysis for the non-contextual pricing case, proposing a variance-aware zooming algorithm that achieves the optimal dependence on $K_{\star}$.

</details>


### [62] [Provably Learning from Modern Language Models via Low Logit Rank](https://arxiv.org/abs/2512.09892)
*Noah Golowich,Allen Liu,Abhishek Shetty*

Main category: cs.LG

TL;DR: 论文提出了一种基于低对数秩假设的现代语言模型学习算法，通过查询学习模型实现对近似低对数秩语言模型的高效学习。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型虽然复杂，但经验观察发现它们都具有近似低对数秩的特性。这种结构可能为算法学习提供可处理的抽象，从而获得可证明的学习保证。

Method: 采用查询学习模型，通过对数查询（logit queries）来反映常见API的访问模式。开发了高效算法来学习任何近似低对数秩模型。

Result: 提出了一个高效算法，能够从查询中学习任何近似低对数秩模型。这是第一个为可能捕捉现代语言模型特征的生成模型提供端到端学习保证的结果。

Conclusion: 低对数秩结构不仅反映了现代语言模型的实证行为，而且可以算法化地利用来获得可证明的学习保证，为理解语言模型的学习提供了理论基础。

Abstract: While modern language models and their inner workings are incredibly complex, recent work (Golowich, Liu & Shetty; 2025) has proposed a simple and potentially tractable abstraction for them through the observation that empirically, these language models all seem to have approximately low logit rank. Roughly, this means that a matrix formed by the model's log probabilities of various tokens conditioned on certain sequences of tokens is well approximated by a low rank matrix.
  In this paper, our focus is on understanding how this structure can be exploited algorithmically for obtaining provable learning guarantees. Since low logit rank models can encode hard-to-learn distributions such as noisy parities, we study a query learning model with logit queries that reflects the access model for common APIs. Our main result is an efficient algorithm for learning any approximately low logit rank model from queries. We emphasize that our structural assumption closely reflects the behavior that is empirically observed in modern language models. Thus, our result gives what we believe is the first end-to-end learning guarantee for a generative model that plausibly captures modern language models.

</details>


### [63] [QuanvNeXt: An end-to-end quanvolutional neural network for EEG-based detection of major depressive disorder](https://arxiv.org/abs/2512.09517)
*Nabil Anan Orka,Ehtashamul Haque,Maftahul Jannat,Md Abdul Awal,Mohammad Ali Moni*

Main category: cs.LG

TL;DR: QuanvNeXt是一种用于基于EEG的抑郁症诊断的端到端全量子卷积模型，通过创新的Cross Residual块减少特征同质性并增强跨特征关系，在两个开源数据集上取得了93.1%的平均准确率和97.2%的平均AUC-ROC，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效可靠的基于EEG的抑郁症诊断模型，解决现有方法在特征同质性和跨特征关系方面的不足，同时保持参数效率。

Method: 提出QuanvNeXt端到端全量子卷积模型，引入新颖的Cross Residual块来减少特征同质性并增强跨特征关系，同时保持参数效率。模型在两个开源EEG数据集上进行评估，并进行不确定性分析和可解释性AI分析。

Result: 在两个开源数据集上平均准确率达到93.1%，平均AUC-ROC达到97.2%，优于InceptionTime等现有基线方法。不确定性分析显示即使在最高扰动（ε=0.1）下，ECE分数仍保持较低水平。可解释性AI分析证实模型能有效识别和学习区分健康对照和重度抑郁症的频谱时间模式。

Conclusion: QuanvNeXt为基于EEG的抑郁症诊断建立了一种高效可靠的方法，通过创新的Cross Residual块在保持参数效率的同时提高了诊断性能，并具有良好的校准性和可解释性。

Abstract: This study presents QuanvNeXt, an end-to-end fully quanvolutional model for EEG-based depression diagnosis. QuanvNeXt incorporates a novel Cross Residual block, which reduces feature homogeneity and strengthens cross-feature relationships while retaining parameter efficiency. We evaluated QuanvNeXt on two open-source datasets, where it achieved an average accuracy of 93.1% and an average AUC-ROC of 97.2%, outperforming state-of-the-art baselines such as InceptionTime (91.7% accuracy, 95.9% AUC-ROC). An uncertainty analysis across Gaussian noise levels demonstrated well-calibrated predictions, with ECE scores remaining low (0.0436, Dataset 1) to moderate (0.1159, Dataset 2) even at the highest perturbation (ε = 0.1). Additionally, a post-hoc explainable AI analysis confirmed that QuanvNeXt effectively identifies and learns spectrotemporal patterns that distinguish between healthy controls and major depressive disorder. Overall, QuanvNeXt establishes an efficient and reliable approach for EEG-based depression diagnosis.

</details>


### [64] [Latent-Autoregressive GP-VAE Language Model](https://arxiv.org/abs/2512.09535)
*Yves Ruffenach*

Main category: cs.LG

TL;DR: 提出了一种基于高斯过程的完全潜在自回归方案，将其集成到变分自编码器中，将序列动态从观测空间转移到连续潜在空间，同时通过非自回归解码器保持语言生成的并行性。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型中时间结构是否可以通过潜在空间的概率几何来支持，而不是完全依赖显式的神经操作。将序列动态转移到连续潜在空间，同时保持语言生成的并行性。

Method: 提出完全潜在自回归方案，包含因果高斯过程先验、结构化摊销后验和基于正则化ELBO的训练协议。将序列动态从观测空间转移到连续潜在空间，使用非自回归解码器进行并行语言生成。

Result: 在概念验证框架下的实证评估表明，模型可以稳定训练，序列和并行采样变体表现出一致的行为。结果表明语言模型中的部分时间结构可以通过潜在空间的概率几何来支持。

Conclusion: 语言模型中的时间结构可以部分由潜在空间的概率几何支持，而不是完全依赖显式的神经操作。这种方法为序列建模提供了新的视角，将序列动态与生成过程分离。

Abstract: We investigate a fully Latent AutoRegressive scheme based on a Gaussian Process (GP) integrated into a Variational Autoencoder (VAE). In this setting, sequential dynamics are transferred from the observation space to a continuous latent space, while linguistic generation remains parallel through a non-autoregressive decoder. We present a complete methodological formulation, including a causal GP prior, a structured amortized posterior, and a training protocol based on a regularized ELBO. Empirical evaluation, conducted within a deliberately constrained proof-of-concept (POC) framework, shows that the model can be trained stably and that the sequential and parallel sampling variants exhibit consistent behavior. Overall, the results suggest that part of the temporal structure in a language model can be supported by the probabilistic geometry of the latent space rather than by explicit neural operations.

</details>


### [65] [FALCON: Few-step Accurate Likelihoods for Continuous Flows](https://arxiv.org/abs/2512.09914)
*Danyal Rehman,Tara Akhound-Sadegh,Artem Gazizov,Yoshua Bengio,Alexander Tong*

Main category: cs.LG

TL;DR: FALCON方法通过混合训练目标实现可逆性，使连续流模型能够用极少步骤进行采样，同时保持足够准确的似然计算，比现有方法快两个数量级。


<details>
  <summary>Details</summary>
Motivation: 热力学平衡中分子状态的可扩展采样是统计物理学的长期挑战。现有Boltzmann生成器使用连续归一化流(CNFs)，但似然计算成本极高，每个样本需要数千次函数评估，严重限制了其应用。

Method: 提出FALCON方法，通过引入混合训练目标来鼓励可逆性，使连续流模型能够在极少步骤内进行采样，同时保持足够准确的似然计算用于重要性采样。

Result: FALCON在分子Boltzmann采样方面优于最先进的归一化流模型，比同等性能的CNF模型快两个数量级。

Conclusion: FALCON方法解决了连续流模型采样效率低的问题，通过混合训练实现可逆性，显著提高了分子状态采样的计算效率。

Abstract: Scalable sampling of molecular states in thermodynamic equilibrium is a long-standing challenge in statistical physics. Boltzmann Generators tackle this problem by pairing a generative model, capable of exact likelihood computation, with importance sampling to obtain consistent samples under the target distribution. Current Boltzmann Generators primarily use continuous normalizing flows (CNFs) trained with flow matching for efficient training of powerful models. However, likelihood calculation for these models is extremely costly, requiring thousands of function evaluations per sample, severely limiting their adoption. In this work, we propose Few-step Accurate Likelihoods for Continuous Flows (FALCON), a method which allows for few-step sampling with a likelihood accurate enough for importance sampling applications by introducing a hybrid training objective that encourages invertibility. We show FALCON outperforms state-of-the-art normalizing flow models for molecular Boltzmann sampling and is two orders of magnitude faster than the equivalently performing CNF model.

</details>


### [66] [Semantic-Aware Cooperative Communication and Computation Framework in Vehicular Networks](https://arxiv.org/abs/2512.09621)
*Jingbo Zhang,Maoxin Ji,Qiong Wu,Pingyi Fan,Kezhi Wang,Wen Chen*

Main category: cs.LG

TL;DR: 本文提出了一种用于车联网的三方协作语义通信框架，通过V2I和V2V通信实现语义任务卸载，使用MAPPO-PDN算法优化语义符号数量，线性规划解决卸载比例，在高速公路场景下性能优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 车联网中结合语义通信和车辆边缘计算能提供高效的任务处理范式。在高速公路场景下，需要设计有效的任务卸载机制来优化任务延迟和语义符号数量，提高系统性能。

Method: 提出三方协作语义通信框架，支持车辆用户通过V2I和V2V通信进行语义任务卸载。将MINLP问题分解为两个子问题：1）使用基于参数分布噪声的多智能体近端策略优化方法优化语义符号数量；2）使用线性规划解决卸载比例问题。

Result: 仿真结果表明，该方案在性能上优于其他对比算法，能够有效优化任务延迟和语义符号数量，提升车联网系统的整体效率。

Conclusion: 提出的TCSC框架结合MAPPO-PDN算法和线性规划，为高速公路场景下的车联网提供了高效的语义任务卸载解决方案，显著提升了系统性能。

Abstract: Semantic Communication (SC) combined with Vehicular edge computing (VEC) provides an efficient edge task processing paradigm for Internet of Vehicles (IoV). Focusing on highway scenarios, this paper proposes a Tripartite Cooperative Semantic Communication (TCSC) framework, which enables Vehicle Users (VUs) to perform semantic task offloading via Vehicle-to-Infrastructure (V2I) and Vehicle-to-Vehicle (V2V) communications. Considering task latency and the number of semantic symbols, the framework constructs a Mixed-Integer Nonlinear Programming (MINLP) problem, which is transformed into two subproblems. First, we innovatively propose a multi-agent proximal policy optimization task offloading optimization method based on parametric distribution noise (MAPPO-PDN) to solve the optimization problem of the number of semantic symbols; second, linear programming (LP) is used to solve offloading ratio. Simulations show that performance of this scheme is superior to that of other algorithms.

</details>


### [67] [Membership and Dataset Inference Attacks on Large Audio Generative Models](https://arxiv.org/abs/2512.09654)
*Jakub Proboszcz,Paweł Kochanski,Karol Korszun,Donato Crisostomi,Giorgio Strano,Emanuele Rodolà,Kamil Deja,Jan Dubinski*

Main category: cs.LG

TL;DR: 该研究探讨了在生成式音频模型中通过成员推断攻击和数据集推断来验证艺术家作品是否被用于训练，发现成员推断在规模上效果有限，但数据集推断在音频领域有效，为版权保护提供了实用机制。


<details>
  <summary>Details</summary>
Motivation: 随着生成式音频模型（基于扩散和自回归架构）在质量和表现力上的快速发展，引发了紧迫的版权问题。这些模型通常在大量艺术和商业作品上进行训练，需要可靠的方法来验证艺术家的材料是否被包含在训练数据中，从而为版权持有者提供保护内容的手段。

Method: 研究调查了在开源生成式音频模型上通过成员推断攻击（MIA）进行验证的可行性，该方法试图确定特定音频样本是否属于训练集的一部分。同时，基于文本和视觉领域的先前工作，重点关注数据集推断（DI），该方法聚合多个样本的成员证据。

Result: 实证结果显示，成员推断在规模上效果有限，因为对于在大型多样化数据集上训练的模型，每个样本的成员信号很弱。然而，数据集推断在音频领域是成功的，提供了更实用的机制来评估艺术家的作品是否对模型训练有贡献。

Conclusion: 数据集推断是在大型音频生成模型时代进行版权保护和数据集问责的有前景方向，为艺术家和媒体所有者提供了验证其作品是否被用于模型训练的有效工具。

Abstract: Generative audio models, based on diffusion and autoregressive architectures, have advanced rapidly in both quality and expressiveness. This progress, however, raises pressing copyright concerns, as such models are often trained on vast corpora of artistic and commercial works. A central question is whether one can reliably verify if an artist's material was included in training, thereby providing a means for copyright holders to protect their content. In this work, we investigate the feasibility of such verification through membership inference attacks (MIA) on open-source generative audio models, which attempt to determine whether a specific audio sample was part of the training set. Our empirical results show that membership inference alone is of limited effectiveness at scale, as the per-sample membership signal is weak for models trained on large and diverse datasets. However, artists and media owners typically hold collections of works rather than isolated samples. Building on prior work in text and vision domains, in this work we focus on dataset inference (DI), which aggregates diverse membership evidence across multiple samples. We find that DI is successful in the audio domain, offering a more practical mechanism for assessing whether an artist's works contributed to model training. Our results suggest DI as a promising direction for copyright protection and dataset accountability in the era of large audio generative models.

</details>


### [68] [A data-driven approach to linking design features with manufacturing process data for sustainable product development](https://arxiv.org/abs/2512.09690)
*Jiahang Li,Lucas Cazzonelli,Jacqueline Höllig,Markus Doellken,Sven Matthiesen*

Main category: cs.LG

TL;DR: 提出了一种数据驱动的方法来映射和分析设计特征与制造过程数据之间的关系，通过机器学习模型提供自动化设计改进建议，支持可持续产品开发。


<details>
  <summary>Details</summary>
Motivation: 工业物联网技术使得制造过程数据能够自动实时收集，为数据驱动的产品开发提供了新机会。当前的数据驱动方法通常局限于特定领域（如设计或制造），缺乏对设计特征与制造过程数据整合的探索。由于设计决策显著影响制造结果（如错误率、能耗和处理时间），这种整合的缺失限制了数据驱动产品设计改进的潜力。

Method: 开发了一个全面的系统架构来确保连续的数据收集和整合。建立了设计特征与制造过程数据之间的关联，以此为基础开发机器学习模型，实现自动化设计改进建议。通过将制造过程数据与可持续性指标整合，支持可持续产品开发。

Result: 该方法能够有效映射和分析设计特征与制造过程数据之间的关系，通过机器学习模型提供自动化设计改进建议，为可持续产品开发开辟了新的可能性。

Conclusion: 提出的数据驱动方法成功整合了设计特征与制造过程数据，通过机器学习模型实现了自动化设计改进，为数据驱动的可持续产品开发提供了有效框架。

Abstract: The growing adoption of Industrial Internet of Things (IIoT) technologies enables automated, real-time collection of manufacturing process data, unlocking new opportunities for data-driven product development. Current data-driven methods are generally applied within specific domains, such as design or manufacturing, with limited exploration of integrating design features and manufacturing process data. Since design decisions significantly affect manufacturing outcomes, such as error rates, energy consumption, and processing times, the lack of such integration restricts the potential for data-driven product design improvements. This paper presents a data-driven approach to mapping and analyzing the relationship between design features and manufacturing process data. A comprehensive system architecture is developed to ensure continuous data collection and integration. The linkage between design features and manufacturing process data serves as the basis for developing a machine learning model that enables automated design improvement suggestions. By integrating manufacturing process data with sustainability metrics, this approach opens new possibilities for sustainable product development.

</details>


### [69] [Mixture of Lookup Key-Value Experts](https://arxiv.org/abs/2512.09723)
*Zongcheng Wang*

Main category: cs.LG

TL;DR: MoLKV模型通过上下文感知的专家选择机制改进MoLE，在小型评估中显著降低验证损失


<details>
  <summary>Details</summary>
Motivation: MoLE模型虽然适合资源受限设备，但其仅基于输入ID的上下文无关专家选择机制可能限制模型性能

Method: 提出MoLKV模型，将每个专家构建为键值对，通过输入派生的查询与当前序列缓存的键值专家交互，生成上下文感知的专家输出

Result: 实验结果显示MoLKV在小型评估中实现了显著更低的验证损失

Conclusion: MoLKV通过上下文感知机制有效缓解了MoLE的局限性，提升了模型性能

Abstract: Recent research has developed several LLM architectures suitable for inference on end-user devices, such as the Mixture of Lookup Experts (MoLE)~\parencite{jie_mixture_2025}. A key feature of MoLE is that each token id is associated with a dedicated group of experts. For a given input, only the experts corresponding to the input token id will be activated. Since the communication overhead of loading this small number of activated experts into RAM during inference is negligible, expert parameters can be offloaded to storage, making MoLE suitable for resource-constrained devices. However, MoLE's context-independent expert selection mechanism, based solely on input ids, may limit model performance. To address this, we propose the \textbf{M}ixture \textbf{o}f \textbf{L}ookup \textbf{K}ey-\textbf{V}alue Experts (\textbf{MoLKV}) model. In MoLKV, each expert is structured as a key-value pair. For a given input, the input-derived query interacts with the cached key-value experts from the current sequence, generating a context-aware expert output. This context-aware mechanism alleviates the limitation of MoLE, and experimental results demonstrate that MoLKV achieves significantly lower validation loss in small-scale evaluations.

</details>


### [70] [Knowledge Diversion for Efficient Morphology Control and Policy Transfer](https://arxiv.org/abs/2512.09796)
*Fu Feng,Ruixiao Shi,Yucheng Xie,Jianlu Shen,Jing Wang,Xin Geng*

Main category: cs.LG

TL;DR: DivMorph提出了一种模块化训练范式，通过知识分流学习可分解的控制器，实现跨形态和跨任务的通用策略学习，显著提升样本效率和减小模型规模。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的通用形态控制方法存在两个主要问题：1）计算成本高，部署开销大；2）跨任务泛化能力有限，每个新任务都需要从头训练。需要一种既能高效部署又能支持跨任务迁移的解决方案。

Method: DivMorph采用模块化训练范式，通过知识分流学习可分解控制器。首先通过SVD将随机初始化的Transformer权重分解为因子单元，然后使用动态软门控根据任务和形态嵌入调制这些单元，将其分离为共享的"learngenes"和特定于形态及任务的"tailors"，实现知识解耦。通过选择性激活相关组件，支持可扩展和高效的政策部署。

Result: 实验表明DivMorph达到了最先进的性能：在跨任务迁移方面，相比直接微调实现了3倍的样本效率提升；在单智能体部署方面，模型规模减少了17倍。

Conclusion: DivMorph通过知识解耦和模块化设计，有效解决了通用形态控制中的计算成本和跨任务泛化问题，为可扩展和高效的策略部署提供了新思路。

Abstract: Universal morphology control aims to learn a universal policy that generalizes across heterogeneous agent morphologies, with Transformer-based controllers emerging as a popular choice. However, such architectures incur substantial computational costs, resulting in high deployment overhead, and existing methods exhibit limited cross-task generalization, necessitating training from scratch for each new task. To this end, we propose \textbf{DivMorph}, a modular training paradigm that leverages knowledge diversion to learn decomposable controllers. DivMorph factorizes randomly initialized Transformer weights into factor units via SVD prior to training and employs dynamic soft gating to modulate these units based on task and morphology embeddings, separating them into shared \textit{learngenes} and morphology- and task-specific \textit{tailors}, thereby achieving knowledge disentanglement. By selectively activating relevant components, DivMorph enables scalable and efficient policy deployment while supporting effective policy transfer to novel tasks. Extensive experiments demonstrate that DivMorph achieves state-of-the-art performance, achieving a 3$\times$ improvement in sample efficiency over direct finetuning for cross-task transfer and a 17$\times$ reduction in model size for single-agent deployment.

</details>


### [71] [Ariel-ML: Computing Parallelization with Embedded Rust for Neural Networks on Heterogeneous Multi-core Microcontrollers](https://arxiv.org/abs/2512.09800)
*Zhaolan Huang,Kaspar Schleiser,Gyungmin Myung,Emmanuel Baccelli*

Main category: cs.LG

TL;DR: Ariel-ML：首个用于多核MCU的Rust嵌入式TinyML平台，自动并行化推理计算，支持多种32位微控制器架构


<details>
  <summary>Details</summary>
Motivation: 随着低功耗MCU从单核向多核架构演进，以及Rust在嵌入式领域的兴起，同时TinyML模型在边缘AI应用中的部署日益增多，但目前缺乏能够自动在多核MCU上并行化推理计算的Rust嵌入式软件平台

Method: 设计并实现了Ariel-ML工具包，结合通用TinyML流水线和嵌入式Rust软件平台，能够充分利用多种32位微控制器家族（Arm Cortex-M、RISC-V、ESP-32）的多核能力

Result: Ariel-ML在推理延迟方面优于现有技术，与使用嵌入式C/C++的现有工具包相比，实现了相当的内存占用，并开源了完整实现代码

Conclusion: Ariel-ML填补了Rust嵌入式软件平台在多核MCU上自动并行化TinyML模型推理的空白，为TinyML实践者和资源受限的嵌入式Rust开发者提供了有用基础

Abstract: Low-power microcontroller (MCU) hardware is currently evolving from single-core architectures to predominantly multi-core architectures. In parallel, new embedded software building blocks are more and more written in Rust, while C/C++ dominance fades in this domain. On the other hand, small artificial neural networks (ANN) of various kinds are increasingly deployed in edge AI use cases, thus deployed and executed directly on low-power MCUs. In this context, both incremental improvements and novel innovative services will have to be continuously retrofitted using ANNs execution in software embedded on sensing/actuating systems already deployed in the field. However, there was so far no Rust embedded software platform automating parallelization for inference computation on multi-core MCUs executing arbitrary TinyML models. This paper thus fills this gap by introducing Ariel-ML, a novel toolkit we designed combining a generic TinyML pipeline and an embedded Rust software platform which can take full advantage of multi-core capabilities of various 32bit microcontroller families (Arm Cortex-M, RISC-V, ESP-32). We published the full open source code of its implementation, which we used to benchmark its capabilities using a zoo of various TinyML models. We show that Ariel-ML outperforms prior art in terms of inference latency as expected, and we show that, compared to pre-existing toolkits using embedded C/C++, Ariel-ML achieves comparable memory footprints. Ariel-ML thus provides a useful basis for TinyML practitioners and resource-constrained embedded Rust developers.

</details>


### [72] [Incorporating Fairness in Neighborhood Graphs for Fair Spectral Clustering](https://arxiv.org/abs/2512.09810)
*Adithya K Moorthy,V Vijaya Saradhi,Bhanu Prasad*

Main category: cs.LG

TL;DR: 该论文提出了构建公平k近邻图和公平ε邻域图的新方法，通过在图的构建阶段就加入公平性约束，确保敏感特征在局部图结构中的比例代表性，从而改善谱聚类的公平性结果。


<details>
  <summary>Details</summary>
Motivation: 传统图聚类方法（如谱聚类）在图构建阶段可能存在偏见，导致某些群体在图中代表性不足。常用的kNN和ε邻域图构建方法会传播基于边缘的差异影响，导致聚类结果偏向某些敏感群体。现有研究在公平谱聚类的预处理阶段存在重要空白。

Method: 提出了两种公平图构建方法：1）公平k近邻图构建，在邻域选择步骤中主动强制执行人口统计均等；2）公平ε邻域图构建，在局部图结构中纳入敏感特征的比例代表性，同时保持几何一致性。这些方法在图的形成阶段就融入公平性约束。

Result: 在三个合成数据集、七个真实世界表格数据集和三个真实世界图像数据集上的实验证明，提出的公平图构建方法在图形聚类任务中超越了当前基线方法。通过确保每个节点的邻域中都有每个敏感群体的代表性，实现了更公平的谱聚类结果。

Conclusion: 图构建中的拓扑公平性对于实现公平聚类结果至关重要。通过在预处理阶段构建公平的图结构，可以在不改变聚类算法本身的情况下实现更公平的谱聚类结果。这项工作填补了公平无监督学习中的重要空白，展示了图构建阶段的拓扑公平性如何自然地促进更公平的聚类结果。

Abstract: Graph clustering plays a pivotal role in unsupervised learning methods like spectral clustering, yet traditional methods for graph clustering often perpetuate bias through unfair graph constructions that may underrepresent some groups. The current research introduces novel approaches for constructing fair k-nearest neighbor (kNN) and fair epsilon-neighborhood graphs that proactively enforce demographic parity during graph formation. By incorporating fairness constraints at the earliest stage of neighborhood selection steps, our approaches incorporate proportional representation of sensitive features into the local graph structure while maintaining geometric consistency.Our work addresses a critical gap in pre-processing for fair spectral clustering, demonstrating that topological fairness in graph construction is essential for achieving equitable clustering outcomes. Widely used graph construction methods like kNN and epsilon-neighborhood graphs propagate edge based disparate impact on sensitive groups, leading to biased clustering results. Providing representation of each sensitive group in the neighborhood of every node leads to fairer spectral clustering results because the topological features of the graph naturally reflect equitable group ratios. This research fills an essential shortcoming in fair unsupervised learning, by illustrating how topological fairness in graph construction inherently facilitates fairer spectral clustering results without the need for changes to the clustering algorithm itself. Thorough experiments on three synthetic datasets, seven real-world tabular datasets, and three real-world image datasets prove that our fair graph construction methods surpass the current baselines in graph clustering tasks.

</details>


### [73] [Conformal Bandits: Bringing statistical validity and reward efficiency to the small-gap regime](https://arxiv.org/abs/2512.09850)
*Simone Cuonzo,Nina Deliu*

Main category: cs.LG

TL;DR: 将Conformal Prediction整合到bandit问题中，为顺序决策提供有限时间统计保证，在收益差距小的场景下优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统bandit策略（如Thompson Sampling和UCB）通常依赖分布假设或渐近保证，主要关注regret而忽视统计特性，在收益差距小的场景下表现不佳

Method: 提出Conformal Bandits框架，将Conformal Prediction整合到bandit决策中，结合隐马尔可夫模型捕捉金融市场机制转换行为

Result: 在模拟研究和投资组合分配应用中，该框架在小差距场景下regret表现优于传统UCB策略，同时实现名义覆盖保证，保持风险调整后的regret效率收益

Conclusion: Conformal Bandits成功将regret最小化的决策潜力与有限时间统计保证相结合，在收益差距小的实际应用中具有显著优势

Abstract: We introduce Conformal Bandits, a novel framework integrating Conformal Prediction (CP) into bandit problems, a classic paradigm for sequential decision-making under uncertainty. Traditional regret-minimisation bandit strategies like Thompson Sampling and Upper Confidence Bound (UCB) typically rely on distributional assumptions or asymptotic guarantees; further, they remain largely focused on regret, neglecting their statistical properties. We address this gap. Through the adoption of CP, we bridge the regret-minimising potential of a decision-making bandit policy with statistical guarantees in the form of finite-time prediction coverage.
  We demonstrate the potential of it Conformal Bandits through simulation studies and an application to portfolio allocation, a typical small-gap regime, where differences in arm rewards are far too small for classical policies to achieve optimal regret bounds in finite sample. Motivated by this, we showcase our framework's practical advantage in terms of regret in small-gap settings, as well as its added value in achieving nominal coverage guarantees where classical UCB policies fail. Focusing on our application of interest, we further illustrate how integrating hidden Markov models to capture the regime-switching behaviour of financial markets, enhances the exploration-exploitation trade-off, and translates into higher risk-adjusted regret efficiency returns, while preserving coverage guarantees.

</details>


### [74] [HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression](https://arxiv.org/abs/2512.09886)
*Gustavo Coelho Haase,Paulo Henrique Dourado da Silva*

Main category: cs.LG

TL;DR: HPM-KD是一个知识蒸馏框架，通过集成六个协同组件解决了传统KD方法的四个关键限制：超参数敏感性、师生容量差距、多教师协调不足和计算资源低效使用。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法存在四个关键问题：1) 对超参数敏感需要大量手动调优；2) 从大教师模型到小学生模型时存在容量差距；3) 多教师场景下协调不足；4) 计算资源使用效率低下。这些限制阻碍了KD在实际应用中的广泛采用。

Method: HPM-KD框架集成了六个协同组件：1) 基于元学习的自适应配置管理器，消除手动超参数调优；2) 具有自动确定中间模型的渐进蒸馏链；3) 学习动态样本权重的注意力加权多教师集成；4) 适应训练过程中温度变化的元学习温度调度器；5) 具有智能负载均衡的并行处理流水线；6) 用于跨实验重用的共享优化内存。

Result: 在CIFAR-10、CIFAR-100和表格数据集上的实验表明：HPM-KD实现了10-15倍的压缩，同时保持85%的准确率保留；消除了手动调优需求；通过并行化减少了30-40%的训练时间。消融研究确认了每个组件的独立贡献（0.10-0.98个百分点）。

Conclusion: HPM-KD是一个全面的知识蒸馏框架，通过集成多个创新组件有效解决了传统KD方法的限制，实现了高效的模型压缩和性能保持，同时显著减少了训练时间和人工调优需求。该框架已作为开源DeepBridge库的一部分提供。

Abstract: Knowledge Distillation (KD) has emerged as a promising technique for model compression but faces critical limitations: (1) sensitivity to hyperparameters requiring extensive manual tuning, (2) capacity gap when distilling from very large teachers to small students, (3) suboptimal coordination in multi-teacher scenarios, and (4) inefficient use of computational resources. We present \textbf{HPM-KD}, a framework that integrates six synergistic components: (i) Adaptive Configuration Manager via meta-learning that eliminates manual hyperparameter tuning, (ii) Progressive Distillation Chain with automatically determined intermediate models, (iii) Attention-Weighted Multi-Teacher Ensemble that learns dynamic per-sample weights, (iv) Meta-Learned Temperature Scheduler that adapts temperature throughout training, (v) Parallel Processing Pipeline with intelligent load balancing, and (vi) Shared Optimization Memory for cross-experiment reuse. Experiments on CIFAR-10, CIFAR-100, and tabular datasets demonstrate that HPM-KD: achieves 10x-15x compression while maintaining 85% accuracy retention, eliminates the need for manual tuning, and reduces training time by 30-40% via parallelization. Ablation studies confirm independent contribution of each component (0.10-0.98 pp). HPM-KD is available as part of the open-source DeepBridge library.

</details>


### [75] [Closing the Train-Test Gap in World Models for Gradient-Based Planning](https://arxiv.org/abs/2512.09929)
*Arjun Parthasarathy,Nimit Kalra,Rohun Agrawal,Yann LeCun,Oumayma Bounou,Pavel Izmailov,Micah Goldblum*

Main category: cs.LG

TL;DR: 提出改进世界模型训练方法，通过缩小训练与测试差距，实现高效梯度规划，在10%时间预算内达到或超越传统CEM方法性能


<details>
  <summary>Details</summary>
Motivation: 世界模型结合模型预测控制可在离线专家轨迹数据集上训练，实现广泛规划任务泛化。梯度规划相比传统MPC更高效，但性能落后于其他方法。研究发现世界模型训练时使用下一状态预测目标，但测试时用于估计动作序列，存在训练-测试差距。

Method: 提出训练时数据合成技术，缩小训练与测试差距，改进现有世界模型的梯度规划能力。通过合成与规划任务更相关的训练数据，使世界模型更适合梯度优化。

Result: 在多种物体操作和导航任务中，该方法在10%的时间预算内达到或超越传统无梯度交叉熵方法（CEM）的性能。

Conclusion: 通过缩小训练与测试差距的数据合成技术，可以显著改进世界模型的梯度规划性能，在保持计算效率的同时达到或超越传统规划方法。

Abstract: World models paired with model predictive control (MPC) can be trained offline on large-scale datasets of expert trajectories and enable generalization to a wide range of planning tasks at inference time. Compared to traditional MPC procedures, which rely on slow search algorithms or on iteratively solving optimization problems exactly, gradient-based planning offers a computationally efficient alternative. However, the performance of gradient-based planning has thus far lagged behind that of other approaches. In this paper, we propose improved methods for training world models that enable efficient gradient-based planning. We begin with the observation that although a world model is trained on a next-state prediction objective, it is used at test-time to instead estimate a sequence of actions. The goal of our work is to close this train-test gap. To that end, we propose train-time data synthesis techniques that enable significantly improved gradient-based planning with existing world models. At test time, our approach outperforms or matches the classical gradient-free cross-entropy method (CEM) across a variety of object manipulation and navigation tasks in 10% of the time budget.

</details>
