<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 69]
- [cs.HC](#cs.HC) [Total: 12]
- [cs.AI](#cs.AI) [Total: 11]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Physics-Informed Machine Learning for Steel Development: A Computational Framework and CCT Diagram Modelling](https://arxiv.org/abs/2512.03050)
*Peter Hedström,Victor Lamelas Cubero,Jón Sigurdsson,Viktor Österberg,Satish Kolli,Joakim Odqvist,Ziyong Hou,Wangzhong Mu,Viswanadh Gowtham Arigela*

Main category: cs.LG

TL;DR: 该研究开发了一个结合物理洞察与机器学习的计算框架，用于预测钢的连续冷却转变(CCT)图，在4100个图的数据集上训练，能在5秒内生成完整CCT图，相分类F1分数超过88%，相变温度回归MAE低于20°C（贝氏体除外为27°C）。


<details>
  <summary>Details</summary>
Motivation: 虽然机器学习在材料科学中已用于新化合物发现和制造过程优化，但将其应用于钢铁等复杂工业材料仍面临挑战。主要障碍在于准确捕捉化学成分、工艺参数与微观结构/性能之间的复杂关系。需要开发结合物理洞察的ML框架来建立准确的CCT模型。

Method: 引入一个结合物理洞察与机器学习的计算框架，开发了物理信息化的连续冷却转变(CCT)模型。该模型在4100个CCT图的数据集上进行训练，通过整合物理知识来提高预测准确性。

Result: 模型表现出高计算效率，生成包含100条冷却曲线的完整CCT图仅需不到5秒。在合金钢中展现出强泛化能力：所有相的相分类F1分数均超过88%；相变温度回归的平均绝对误差(MAE)除贝氏体为27°C外，其他相均低于20°C。

Conclusion: 该框架可扩展为通用数字孪生平台，用于热处理过程。通过与补充模拟工具和针对性实验的集成，将进一步支持加速材料设计工作流程，为复杂工业材料提供有效的ML解决方案。

Abstract: Machine learning (ML) has emerged as a powerful tool for accelerating the computational design and production of materials. In materials science, ML has primarily supported large-scale discovery of novel compounds using first-principles data and digital twin applications for optimizing manufacturing processes. However, applying general-purpose ML frameworks to complex industrial materials such as steel remains a challenge. A key obstacle is accurately capturing the intricate relationship between chemical composition, processing parameters, and the resulting microstructure and properties. To address this, we introduce a computational framework that combines physical insights with ML to develop a physics-informed continuous cooling transformation (CCT) model for steels. Our model, trained on a dataset of 4,100 diagrams, is validated against literature and experimental data. It demonstrates high computational efficiency, generating complete CCT diagrams with 100 cooling curves in under 5 seconds. It also shows strong generalizability across alloy steels, achieving phase classification F1 scores above 88% for all phases. For phase transition temperature regression, it attains mean absolute errors (MAE) below 20 °C across all phases except bainite, which shows a slightly higher MAE of 27 °C. This framework can be extended with additional generic and customized ML models to establish a universal digital twin platform for heat treatment. Integration with complementary simulation tools and targeted experiments will further support accelerated materials design workflows.

</details>


### [2] [Energy-Efficient Federated Learning via Adaptive Encoder Freezing for MRI-to-CT Conversion: A Green AI-Guided Research](https://arxiv.org/abs/2512.03054)
*Ciro Benito Raggio,Lucia Migliorelli,Nils Skupien,Mathias Krohmer Zabaleta,Oliver Blanck,Francesco Cicone,Giuseppe Lucio Cascini,Paolo Zaffino,Maria Francesca Spadea*

Main category: cs.LG

TL;DR: 提出一种面向绿色AI的自适应层冻结策略，用于联邦学习中的MRI-to-CT转换任务，在保持模型性能的同时减少23%的训练时间、能耗和碳排放。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然能促进医疗健康领域的平等，但其高资源需求排除了计算基础设施有限的机构，加剧了医疗不平等。需要开发节能的联邦学习方法，使更多机构能够参与。

Method: 提出自适应层冻结策略：基于轮次间编码器权重的相对差异监控，选择性冻结编码器权重；采用基于耐心的机制，仅在更新持续保持最小时才进行冻结；使用CodeCarbon库跟踪能耗和碳排放。

Result: 相比未冻结的对照方法，训练时间、总能耗和CO2eq排放减少达23%；MRI-to-CT转换性能基本保持，MAE仅有小幅变化；5种架构中3种无统计显著差异，2种有统计显著改善。

Conclusion: 该方法在保持临床性能的同时实现了气候、社会和经济的可持续性，为促进AI医疗中的隐私、公平和正义提供了新的联邦学习评估框架基础。

Abstract: Federated Learning (FL) holds the potential to advance equality in health by enabling diverse institutions to collaboratively train deep learning (DL) models, even with limited data. However, the significant resource requirements of FL often exclude centres with limited computational infrastructure, further widening existing healthcare disparities. To address this issue, we propose a Green AI-oriented adaptive layer-freezing strategy designed to reduce energy consumption and computational load while maintaining model performance. We tested our approach using different federated architectures for Magnetic Resonance Imaging (MRI)-to-Computed Tomography (CT) conversion. The proposed adaptive strategy optimises the federated training by selectively freezing the encoder weights based on the monitored relative difference of the encoder weights from round to round. A patience-based mechanism ensures that freezing only occurs when updates remain consistently minimal. The energy consumption and CO2eq emissions of the federation were tracked using the CodeCarbon library. Compared to equivalent non-frozen counterparts, our approach reduced training time, total energy consumption and CO2eq emissions by up to 23%. At the same time, the MRI-to-CT conversion performance was maintained, with only small variations in the Mean Absolute Error (MAE). Notably, for three out of the five evaluated architectures, no statistically significant differences were observed, while two architectures exhibited statistically significant improvements. Our work aligns with a research paradigm that promotes DL-based frameworks meeting clinical requirements while ensuring climatic, social, and economic sustainability. It lays the groundwork for novel FL evaluation frameworks, advancing privacy, equity and, more broadly, justice in AI-driven healthcare.

</details>


### [3] [Delta Sampling: Data-Free Knowledge Transfer Across Diffusion Models](https://arxiv.org/abs/2512.03056)
*Zhidong Gao,Zimeng Pan,Yuhang Yao,Chenyue Xie,Wei Wei*

Main category: cs.LG

TL;DR: Delta Sampling (DS) 是一种无需原始训练数据的推理时方法，通过利用模型预测的差异（delta）在不同架构的基础模型间实现知识迁移。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型的适配组件（如LoRA、LyCORIS、ControlNet）与特定基础模型紧密耦合，当基础模型升级（如从SD 1.x到2.x）时难以重用，因为模型参数和架构发生重大变化。

Method: Delta Sampling (DS) 完全在推理时操作，利用模型预测的差异（delta）：即基础模型在适配前后的预测差异。然后将这个delta用于指导新基础模型的去噪过程。

Result: 在不同SD版本上的评估表明，DS在不同采样策略下都能在创建期望效果（如视觉风格、语义概念和结构）方面实现一致的改进。

Conclusion: DS是一种有效的即插即用机制，可用于基于扩散的图像合成中的知识迁移，无需访问原始训练数据。

Abstract: Diffusion models like Stable Diffusion (SD) drive a vibrant open-source ecosystem including fully fine-tuned checkpoints and parameter-efficient adapters such as LoRA, LyCORIS, and ControlNet. However, these adaptation components are tightly coupled to a specific base model, making them difficult to reuse when the base model is upgraded (e.g., from SD 1.x to 2.x) due to substantial changes in model parameters and architecture. In this work, we propose Delta Sampling (DS), a novel method that enables knowledge transfer across base models with different architectures, without requiring access to the original training data. DS operates entirely at inference time by leveraging the delta: the difference in model predictions before and after the adaptation of a base model. This delta is then used to guide the denoising process of a new base model. We evaluate DS across various SD versions, demonstrating that DS achieves consistent improvements in creating desired effects (e.g., visual styles, semantic concepts, and structures) under different sampling strategies. These results highlight DS as an effective, plug-and-play mechanism for knowledge transfer in diffusion-based image synthesis. Code:~ https://github.com/Zhidong-Gao/DeltaSampling

</details>


### [4] [Dynamical Properties of Tokens in Self-Attention and Effects of Positional Encoding](https://arxiv.org/abs/2512.03058)
*Duy-Tung Pham,An The Nguyen,Viet-Hoang Tran,Nhan-Phu Chung,Xin T. Tong,Tan M. Nguyen,Thieu N. Vo*

Main category: cs.LG

TL;DR: 该论文研究预训练Transformer模型中token的动态特性，分析其连续时间极限下的动力系统，表征token随时间的收敛或发散行为，并提出改进Transformer架构的简单方法。


<details>
  <summary>Details</summary>
Motivation: 研究预训练Transformer模型中token的动态特性，理解token在模型中的运动规律，探索如何利用这些动态特性来改进Transformer模型的性能。

Method: 分析预训练模型的连续时间极限动力系统，表征token的渐近行为（收敛或发散），研究绝对位置编码和旋转位置编码对动态机制的影响，并提出减轻收敛行为的架构改进方法。

Result: 提供了基于模型参数的充分条件来识别token收敛到零或发散到无穷的情况，发现收敛场景对模型性能有负面影响，提出了针对绝对和旋转位置编码的Transformer架构改进方法。

Conclusion: 该研究为改进Transformer模型提供了理论基础和设计原则，通过理解token的动态特性可以设计更好的Transformer架构，特别是针对不同位置编码方案的优化。

Abstract: This paper investigates the dynamical properties of tokens in pre-trained Transformer models and explores their application to improving Transformers. To this end, we analyze the dynamical system governing the continuous-time limit of the pre-trained model and characterize the asymptotic behavior of its solutions. Specifically, we characterize when tokens move closer to or farther from one another over time, depending on the model parameters. We provide sufficient conditions, based on these parameters, to identify scenarios where tokens either converge to zero or diverge to infinity. Unlike prior works, our conditions are broader in scope and more applicable to real-world models. Furthermore, we investigate how different forms of positional encoding -- specifically absolute and rotary -- affect these dynamical regimes. Empirical evidence reveals that the convergence scenario adversely impacts model performance. Motivated by these insights, we propose simple refinements to Transformer architectures that mitigate convergence behavior in models with absolute or rotary positional encoding. These findings support theoretical foundations and design principles for improving Transformer models.

</details>


### [5] [Safe and Sustainable Electric Bus Charging Scheduling with Constrained Hierarchical DRL](https://arxiv.org/abs/2512.03059)
*Jiaju Qi,Lei Lei,Thorsteinn Jonsson,Dusit Niyato*

Main category: cs.LG

TL;DR: 本文提出了一种安全的分层深度强化学习框架，用于解决多源不确定性下的电动公交车充电调度问题，通过结合拉格朗日松弛的DAC-MAPPO-Lagrangian算法，在成本最小化和安全合规性方面优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 电动公交车与光伏等可再生能源的整合是促进可持续低碳公共交通的有前景方法，但在实际条件下，光伏发电、动态电价、可变行程时间和有限充电基础设施等多源不确定性使得优化充电调度以最小化运营成本同时确保电池不耗尽的安全运行具有挑战性。

Method: 将问题建模为带选项的约束马尔可夫决策过程，提出新颖的DAC-MAPPO-Lagrangian分层深度强化学习算法。高层采用集中式PPO-Lagrangian算法学习安全充电器分配策略，低层采用MAPPO-Lagrangian在集中训练分散执行范式下学习分散充电功率决策。

Result: 基于真实数据的广泛实验表明，所提方法在成本最小化和安全合规性方面均优于现有基线方法，同时保持了快速的收敛速度。

Conclusion: 提出的安全分层深度强化学习框架有效解决了多源不确定性下的电动公交车充电调度问题，为可持续公共交通系统提供了可行的优化解决方案。

Abstract: The integration of Electric Buses (EBs) with renewable energy sources such as photovoltaic (PV) panels is a promising approach to promote sustainable and low-carbon public transportation. However, optimizing EB charging schedules to minimize operational costs while ensuring safe operation without battery depletion remains challenging - especially under real-world conditions, where uncertainties in PV generation, dynamic electricity prices, variable travel times, and limited charging infrastructure must be accounted for. In this paper, we propose a safe Hierarchical Deep Reinforcement Learning (HDRL) framework for solving the EB Charging Scheduling Problem (EBCSP) under multi-source uncertainties. We formulate the problem as a Constrained Markov Decision Process (CMDP) with options to enable temporally abstract decision-making. We develop a novel HDRL algorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization Lagrangian (DAC-MAPPO-Lagrangian), which integrates Lagrangian relaxation into the Double Actor-Critic (DAC) framework. At the high level, we adopt a centralized PPO-Lagrangian algorithm to learn safe charger allocation policies. At the low level, we incorporate MAPPO-Lagrangian to learn decentralized charging power decisions under the Centralized Training and Decentralized Execution (CTDE) paradigm. Extensive experiments with real-world data demonstrate that the proposed approach outperforms existing baselines in both cost minimization and safety compliance, while maintaining fast convergence speed.

</details>


### [6] [A Large Scale Heterogeneous Treatment Effect Estimation Framework and Its Applications of Users' Journey at Snap](https://arxiv.org/abs/2512.03060)
*Jing Pan,Li Shi,Paul Lo*

Main category: cs.LG

TL;DR: 大规模工业框架利用Snapchat数亿用户实验数据估计异质性处理效应，通过跨实验整合发现潜在用户特征，实现稳定的大规模处理效应估计


<details>
  <summary>Details</summary>
Motivation: 传统方法假设处理效应对所有用户相同，但实际中用户对广告等干预的反应存在异质性，需要能够识别不同用户群体差异效应的框架

Method: 构建大规模工业框架，包括实验选择、基础学习器设计和增量训练等核心组件，利用数百个实验的数据整合分析

Result: 框架成功识别了用户对广告的影响性和敏感性等潜在特征，基于影响性分数的在线A/B测试显示关键业务指标提升超过典型显著水平的六倍

Conclusion: 该框架能够在大规模工业环境中有效估计异质性处理效应，发现传统方法无法测量的用户特征，为个性化广告投放等应用提供有力支持

Abstract: Heterogeneous Treatment Effect (HTE) and Conditional Average Treatment Effect (CATE) models relax the assumption that treatment effects are the same for every user. We present a large scale industrial framework for estimating HTE using experimental data from hundreds of millions of Snapchat users. By combining results across many experiments, the framework uncovers latent user characteristics that were previously unmeasurable and produces stable treatment effect estimates at scale.
  We describe the core components that enabled this system, including experiment selection, base learner design, and incremental training. We also highlight two applications: user influenceability to ads and user sensitivity to ads. An online A/B test using influenceability scores for targeting showed an improvement on key business metrics that is more than six times larger than what is typically considered significant.

</details>


### [7] [Globally optimized SVD compression of LLMs via Fermi-function-based rank selection and gauge fixing](https://arxiv.org/abs/2512.03062)
*Roman Rausch,David Jansen,Sukhbinder Singh,Román Orús*

Main category: cs.LG

TL;DR: 该论文提出了两种基于物理启发的改进方法，用于提升基于SVD的LLM压缩效果：FermiGrad算法通过费米函数将离散的奇异值截断转化为连续优化，确定全局最优的层间秩；PivGa则利用参数化中的规范自由度对低秩因子进行无损压缩。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)对计算资源需求极高，基于奇异值分解(SVD)的低秩分解是LLM压缩的有前景方法，但面临层间秩选择和参数冗余消除等实际挑战。

Method: 提出了两种物理启发的改进：1) FermiGrad算法，通过费米函数将离散的奇异值截断松弛为连续优化问题，使用梯度下降确定全局最优的层间秩；2) PivGa方法，利用低秩因子参数化中的内在规范自由度，对低秩因子进行无损压缩。

Result: 论文提出的两种方法改进了基于SVD的LLM压缩，FermiGrad解决了层间秩选择问题，PivGa消除了参数冗余，实现了更高效的模型压缩。

Conclusion: 通过结合FermiGrad的全局秩优化和PivGa的无损压缩，为LLM的SVD压缩提供了更实用和高效的解决方案，降低了计算资源需求。

Abstract: Large Language Models (LLMs) are very demanding in terms of their computational resources. Low-rank decompositions of LLM weights, e.g. via Singular Value Decomposition (SVD), is a promising approach for LLM compression, but presents several practical hurdles, e.g. selecting appropriate layer-wise ranks and getting rid of its parameter redundancy. In this work, we present two physics-inspired improvements to SVD LLM compression: (1) \textbf{FermiGrad}, a gradient-descent algorithm that determines globally optimal layer-wise ranks by relaxing the discrete singular-value truncation into a continuous optimization using the Fermi function; (2) \textbf{PivGa}, an additional \textit{lossless} compression of the low-rank factors that exploits the intrinsic gauge freedom in their parametrization.

</details>


### [8] [Hierarchical clustering of complex energy systems using pretopology](https://arxiv.org/abs/2512.03069)
*Loup-Noe Levy,Jeremie Bosom,Guillaume Guerard,Soufian Ben Amor,Marc Bui,Hai Tran*

Main category: cs.LG

TL;DR: 本文提出使用预拓扑学建模建筑能耗分布，开发多准则层次分类算法，通过Python库实现，用于大规模建筑能耗管理的自动化推荐系统。


<details>
  <summary>Details</summary>
Motivation: 针对大规模分布式建筑能耗管理的需求，传统逐栋建筑深度审计方法耗时耗力且需要大量专业人员，需要开发自动化方法来建立有效的能耗管理推荐系统。

Method: 使用预拓扑学建模建筑能耗分布，开发基于预拓扑空间特性的多准则层次分类算法，并实现为Python库。使用三种数据集进行评估：二维空间生成点集、生成时间序列和法国能源公司400个真实建筑能耗时间序列。

Result: 在点数据集上，算法能根据空间位置和大小参数识别点簇；在生成时间序列上，使用皮尔逊相关系数能完美识别时间序列簇（调整兰德指数为1）。

Conclusion: 预拓扑学方法结合多准则层次分类算法能有效建模和分类大规模建筑能耗分布，为建筑能耗管理的自动化推荐系统提供可行解决方案。

Abstract: This article attempts answering the following problematic: How to model and classify energy consumption profiles over a large distributed territory to optimize the management of buildings' consumption?
  Doing case-by-case in depth auditing of thousands of buildings would require a massive amount of time and money as well as a significant number of qualified people. Thus, an automated method must be developed to establish a relevant and effective recommendations system.
  To answer this problematic, pretopology is used to model the sites' consumption profiles and a multi-criterion hierarchical classification algorithm, using the properties of pretopological space, has been developed in a Python library.
  To evaluate the results, three data sets are used: A generated set of dots of various sizes in a 2D space, a generated set of time series and a set of consumption time series of 400 real consumption sites from a French Energy company.
  On the point data set, the algorithm is able to identify the clusters of points using their position in space and their size as parameter. On the generated time series, the algorithm is able to identify the time series clusters using Pearson's correlation with an Adjusted Rand Index (ARI) of 1.

</details>


### [9] [Mixed Data Clustering Survey and Challenges](https://arxiv.org/abs/2512.03070)
*Guillaume Guerard,Sonia Djebali*

Main category: cs.LG

TL;DR: 本文提出了一种基于预拓扑空间的混合数据聚类方法，旨在解决大数据背景下数值和分类变量混合数据集的聚类挑战，并与传统数值聚类算法和现有预拓扑方法进行了性能对比。


<details>
  <summary>Details</summary>
Motivation: 大数据时代带来了数据量、速度和多样性的空前增长，混合数据聚类成为关键挑战。传统聚类方法通常针对同质数据集设计，难以有效处理数值和分类变量混合的复杂数据，需要专门针对混合数据环境的创新方法。

Method: 提出了一种基于预拓扑空间的聚类方法。预拓扑空间为处理混合数据类型提供了数学框架，能够更好地捕捉数据间的复杂关系。该方法特别适合处理大数据背景下的混合数据聚类问题。

Result: 通过与传统数值聚类算法和现有预拓扑方法进行基准测试，评估了所提方法的性能和有效性。测试结果表明该方法在大数据范式下具有较好的聚类效果。

Conclusion: 基于预拓扑空间的聚类方法为混合数据聚类提供了有效的解决方案，能够应对大数据背景下数值和分类变量混合的复杂聚类挑战，具有实际应用价值。

Abstract: The advent of the big data paradigm has transformed how industries manage and analyze information, ushering in an era of unprecedented data volume, velocity, and variety. Within this landscape, mixed-data clustering has become a critical challenge, requiring innovative methods that can effectively exploit heterogeneous data types, including numerical and categorical variables. Traditional clustering techniques, typically designed for homogeneous datasets, often struggle to capture the additional complexity introduced by mixed data, underscoring the need for approaches specifically tailored to this setting. Hierarchical and explainable algorithms are particularly valuable in this context, as they provide structured, interpretable clustering results that support informed decision-making. This paper introduces a clustering method grounded in pretopological spaces. In addition, benchmarking against classical numerical clustering algorithms and existing pretopological approaches yields insights into the performance and effectiveness of the proposed method within the big data paradigm.

</details>


### [10] [PretopoMD: Pretopology-based Mixed Data Hierarchical Clustering](https://arxiv.org/abs/2512.03071)
*Loup-Noe Levy,Guillaume Guerard,Sonia Djebali,Soufian Ben Amor*

Main category: cs.LG

TL;DR: 提出基于预拓扑的新算法，无需降维即可聚类混合数据，使用析取范式构建可定制逻辑规则和可调超参数，支持用户定义层次聚类，在保持数据完整性的同时实现准确可解释的聚类结果。


<details>
  <summary>Details</summary>
Motivation: 解决混合数据聚类中的挑战，避免传统降维技术导致的信息损失，提升聚类结果的可解释性，克服聚类数据可解释性问题。

Method: 基于预拓扑的算法，利用析取范式构建可定制的逻辑规则和可调超参数，支持用户定义的层次聚类构建，直接从原始数据中划分聚类而不需要降维。

Result: 通过层次树状图分析和比较聚类指标，该方法表现出优越性能，能够准确且可解释地从原始数据中划分聚类，保持数据完整性，实证结果突显了算法在构建有意义的聚类方面的鲁棒性。

Conclusion: 该工作的新颖性在于摆脱传统降维技术，创新性地使用逻辑规则增强聚类形成和清晰度，为混合数据聚类领域做出了重要贡献，特别是在可解释性方面取得了进展。

Abstract: This article presents a novel pretopology-based algorithm designed to address the challenges of clustering mixed data without the need for dimensionality reduction. Leveraging Disjunctive Normal Form, our approach formulates customizable logical rules and adjustable hyperparameters that allow for user-defined hierarchical cluster construction and facilitate tailored solutions for heterogeneous datasets. Through hierarchical dendrogram analysis and comparative clustering metrics, our method demonstrates superior performance by accurately and interpretably delineating clusters directly from raw data, thus preserving data integrity. Empirical findings highlight the algorithm's robustness in constructing meaningful clusters and reveal its potential in overcoming issues related to clustered data explainability. The novelty of this work lies in its departure from traditional dimensionality reduction techniques and its innovative use of logical rules that enhance both cluster formation and clarity, thereby contributing a significant advancement to the discourse on clustering mixed data.

</details>


### [11] [Risk-Entropic Flow Matching](https://arxiv.org/abs/2512.03078)
*Vahid R. Ramezani,Benjamin Englard*

Main category: cs.LG

TL;DR: 论文提出将倾斜（熵）风险应用于流匹配，通过log-exponential变换改进标准平方损失，更好地捕捉数据流形的几何结构和少数分支信息。


<details>
  <summary>Details</summary>
Motivation: 标准流匹配使用均方误差损失，将所有到达同一时空点的速度目标压缩为单一条件均值，忽略了高阶条件信息（方差、偏度、多模态），这些信息编码了数据流形的精细几何结构和少数分支。

Method: 将标准风险敏感（log-exponential）变换应用于条件流匹配损失，得到的倾斜风险损失是有意义的条件熵流匹配目标的上界。通过小阶展开，得到两个可解释的一阶修正：流匹配残差的协方差预处理，以及偏好不对称或稀有分支的偏尾项。

Result: 在专门设计用于探测模糊性和尾部的合成数据上，风险敏感损失在统计指标上优于标准整流流匹配，并能更忠实地恢复几何结构。

Conclusion: 倾斜风险损失为流匹配提供了一种自然框架，通过强调罕见或高损失事件，同时保持可优化性，能够更好地捕捉数据流形的几何复杂性。

Abstract: Tilted (entropic) risk, obtained by applying a log-exponential transform to a base loss, is a well established tool in statistics and machine learning for emphasizing rare or high loss events while retaining a tractable optimization problem. In this work, our aim is to interpret its structure for Flow Matching (FM). FM learns a velocity field that transports samples from a simple source distribution to data by integrating an ODE. In rectified FM, training pairs are obtained by linearly interpolating between a source sample and a data sample, and a neural velocity field is trained to predict the straight line displacement using a mean squared error loss. This squared loss collapses all velocity targets that reach the same space-time point into a single conditional mean, thereby ignoring higher order conditional information (variance, skewness, multi-modality) that encodes fine geometric structure about the data manifold and minority branches. We apply the standard risk-sensitive (log-exponential) transform to the conditional FM loss and show that the resulting tilted risk loss is a natural upper-bound on a meaningful conditional entropic FM objective defined at each space-time point. Furthermore, we show that a small order expansion of the gradient of this conditional entropic objective yields two interpretable first order corrections: covariance preconditioning of the FM residual, and a skew tail term that favors asymmetric or rare branches. On synthetic data designed to probe ambiguity and tails, the resulting risk-sensitive loss improves statistical metrics and recovers geometric structure more faithfully than standard rectified FM.

</details>


### [12] [ALARM: Automated MLLM-Based Anomaly Detection in Complex-EnviRonment Monitoring with Uncertainty Quantification](https://arxiv.org/abs/2512.03101)
*Congjing Zhang,Feng Lin,Xinyi Zhao,Pei Guo,Wei Li,Lin Chen,Chaoyue Zhao,Shuai Huang*

Main category: cs.LG

TL;DR: ALARM是一个基于多模态大语言模型的视觉异常检测框架，集成了不确定性量化技术，通过推理链、自反思和模型集成等方法提升在复杂环境中的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，视觉异常往往具有高度上下文依赖性和模糊性，因此基于多模态大语言模型的视觉异常检测系统需要具备不确定性量化能力才能成功部署。

Method: ALARM框架将不确定性量化与质量保证技术（推理链、自反思、MLLM集成）相结合，基于严格的概率推理流程和计算过程设计。

Result: 在真实世界的智能家居基准数据和伤口图像分类数据上进行广泛实证评估，显示ALARM具有优越性能，并在不同领域具有通用适用性，可实现可靠决策。

Conclusion: ALARM框架通过集成不确定性量化技术，为基于多模态大语言模型的视觉异常检测提供了鲁棒且准确的解决方案，适用于复杂环境中的可靠决策。

Abstract: The advance of Large Language Models (LLMs) has greatly stimulated research interest in developing multi-modal LLM (MLLM)-based visual anomaly detection (VAD) algorithms that can be deployed in complex environments. The challenge is that in these complex environments, the anomalies are sometimes highly contextual and also ambiguous, and thereby, uncertainty quantification (UQ) is a crucial capacity for an MLLM-based VAD system to succeed. In this paper, we introduce our UQ-supported MLLM-based VAD framework called ALARM. ALARM integrates UQ with quality-assurance techniques like reasoning chain, self-reflection, and MLLM ensemble for robust and accurate performance and is designed based on a rigorous probabilistic inference pipeline and computational process. Extensive empirical evaluations are conducted using the real-world smart-home benchmark data and wound image classification data, which shows ALARM's superior performance and its generic applicability across different domains for reliable decision-making.

</details>


### [13] [Detecting AI Hallucinations in Finance: An Information-Theoretic Method Cuts Hallucination Rate by 92%](https://arxiv.org/abs/2512.03107)
*Mainak Singha*

Main category: cs.LG

TL;DR: ECLIPSE框架通过结合语义熵估计和困惑度分解来检测LLM幻觉，将幻觉视为模型语义熵与可用证据容量之间的不匹配


<details>
  <summary>Details</summary>
Motivation: 大型语言模型会产生流畅但缺乏支持的答案（幻觉），限制了在高风险领域的安全部署。需要一种机制来检测和缓解这种幻觉问题。

Method: 提出ECLIPSE框架，将幻觉视为模型语义熵与可用证据容量之间的不匹配。结合多样本聚类的熵估计和新的困惑度分解方法，测量模型如何使用检索到的证据。

Result: 在受控金融问答数据集上，ECLIPSE在GPT-3.5-turbo上实现了0.89的ROC AUC和0.90的平均精度，显著优于仅使用语义熵的基线（AUC 0.50）。在Claude-3-Haiku上的消融实验显示AUC降至0.59，系数幅度下降95%，表明ECLIPSE依赖于校准的token级不确定性。

Conclusion: ECLIPSE是一个有效的幻觉检测机制，其效果依赖于校准的token级不确定性，证据利用特征是检测幻觉的关键。这是一个受控机制研究，未来需要在更多领域和自然发生的幻觉上进行验证。

Abstract: Large language models (LLMs) produce fluent but unsupported answers - hallucinations - limiting safe deployment in high-stakes domains. We propose ECLIPSE, a framework that treats hallucination as a mismatch between a model's semantic entropy and the capacity of available evidence. We combine entropy estimation via multi-sample clustering with a novel perplexity decomposition that measures how models use retrieved evidence. We prove that under mild conditions, the resulting entropy-capacity objective is strictly convex with a unique stable optimum. We evaluate on a controlled financial question answering dataset with GPT-3.5-turbo (n=200 balanced samples with synthetic hallucinations), where ECLIPSE achieves ROC AUC of 0.89 and average precision of 0.90, substantially outperforming a semantic entropy-only baseline (AUC 0.50). A controlled ablation with Claude-3-Haiku, which lacks token-level log probabilities, shows AUC dropping to 0.59 with coefficient magnitudes decreasing by 95% - demonstrating that ECLIPSE is a logprob-native mechanism whose effectiveness depends on calibrated token-level uncertainties. The perplexity decomposition features exhibit the largest learned coefficients, confirming that evidence utilization is central to hallucination detection. We position this work as a controlled mechanism study; broader validation across domains and naturally occurring hallucinations remains future work.

</details>


### [14] [E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing](https://arxiv.org/abs/2512.03109)
*Shuvom Sadhuka,Drew Prinster,Clara Fannjiang,Gabriele Scalia,Aviv Regev,Hanchen Wang*

Main category: cs.LG

TL;DR: e-valuator：将任意黑盒验证器评分转换为具有可证明错误警报率控制的决策规则的方法，用于评估智能体轨迹的成功与否


<details>
  <summary>Details</summary>
Motivation: 现有智能体AI系统的验证器（如LLM评判器和过程奖励模型）虽然能提供启发式评分，但缺乏正确性保证，无法可靠判断智能体是否会产生成功输出

Method: 将区分成功轨迹与失败轨迹的问题构建为序列假设检验问题，基于e-过程工具开发序列假设检验，使统计有效性在智能体轨迹的每一步都保持有效，支持在线监控

Result: 在六个数据集和三种智能体上，e-valuator相比其他策略具有更强的统计功效和更好的错误警报率控制，还能快速终止问题轨迹以节省token

Conclusion: e-valuator提供了一个轻量级、模型无关的框架，将验证器启发式方法转换为具有统计保证的决策规则，使智能体系统部署更加可靠

Abstract: Agentic AI systems execute a sequence of actions, such as reasoning steps or tool calls, in response to a user prompt. To evaluate the success of their trajectories, researchers have developed verifiers, such as LLM judges and process-reward models, to score the quality of each action in an agent's trajectory. Although these heuristic scores can be informative, there are no guarantees of correctness when used to decide whether an agent will yield a successful output. Here, we introduce e-valuator, a method to convert any black-box verifier score into a decision rule with provable control of false alarm rates. We frame the problem of distinguishing successful trajectories (that is, a sequence of actions that will lead to a correct response to the user's prompt) and unsuccessful trajectories as a sequential hypothesis testing problem. E-valuator builds on tools from e-processes to develop a sequential hypothesis test that remains statistically valid at every step of an agent's trajectory, enabling online monitoring of agents over arbitrarily long sequences of actions. Empirically, we demonstrate that e-valuator provides greater statistical power and better false alarm rate control than other strategies across six datasets and three agents. We additionally show that e-valuator can be used for to quickly terminate problematic trajectories and save tokens. Together, e-valuator provides a lightweight, model-agnostic framework that converts verifier heuristics into decisions rules with statistical guarantees, enabling the deployment of more reliable agentic systems.

</details>


### [15] [Beyond Additivity: Sparse Isotonic Shapley Regression toward Nonlinear Explainability](https://arxiv.org/abs/2512.03112)
*Jialai She*

Main category: cs.LG

TL;DR: SISR框架统一解决Shapley值的两个核心问题：通过单调变换恢复可加性，同时施加L0稀疏约束实现高效高维解释。


<details>
  <summary>Details</summary>
Motivation: 传统Shapley值面临两个主要挑战：1) 假设可加性，但现实中的收益函数常违反此假设（非高斯分布、重尾、特征依赖等），导致归因失真；2) 在高维中通过后处理阈值实现稀疏解释成本过高且不一致。

Method: 提出稀疏等渗Shapley回归(SISR)：同时学习单调变换恢复可加性，并施加L0稀疏约束。优化算法使用相邻池化违反者进行等渗回归，归一化硬阈值进行支持选择，具有实现简便和全局收敛保证。

Result: SISR能在多种场景下恢复真实变换，在高噪声下实现强支持恢复。首次证明无关特征和特征间依赖可导致真实收益函数显著偏离线性。在回归、逻辑回归和树集成实验中，SISR稳定归因，正确过滤无关特征，而标准Shapley值出现严重排序和符号失真。

Conclusion: SISR通过统一非线性变换估计和稀疏性追求，推进了非线性可解释性前沿，提供了理论坚实且实用的归因框架。

Abstract: Shapley values, a gold standard for feature attribution in Explainable AI, face two primary challenges. First, the canonical Shapley framework assumes that the worth function is additive, yet real-world payoff constructions--driven by non-Gaussian distributions, heavy tails, feature dependence, or domain-specific loss scales--often violate this assumption, leading to distorted attributions. Secondly, achieving sparse explanations in high dimensions by computing dense Shapley values and then applying ad hoc thresholding is prohibitively costly and risks inconsistency. We introduce Sparse Isotonic Shapley Regression (SISR), a unified nonlinear explanation framework. SISR simultaneously learns a monotonic transformation to restore additivity--obviating the need for a closed-form specification--and enforces an L0 sparsity constraint on the Shapley vector, enhancing computational efficiency in large feature spaces. Its optimization algorithm leverages Pool-Adjacent-Violators for efficient isotonic regression and normalized hard-thresholding for support selection, yielding implementation ease and global convergence guarantees. Analysis shows that SISR recovers the true transformation in a wide range of scenarios and achieves strong support recovery even in high noise. Moreover, we are the first to demonstrate that irrelevant features and inter-feature dependencies can induce a true payoff transformation that deviates substantially from linearity. Experiments in regression, logistic regression, and tree ensembles demonstrate that SISR stabilizes attributions across payoff schemes, correctly filters irrelevant features while standard Shapley values suffer severe rank and sign distortions. By unifying nonlinear transformation estimation with sparsity pursuit, SISR advances the frontier of nonlinear explainability, providing a theoretically grounded and practical attribution framework.

</details>


### [16] [Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models](https://arxiv.org/abs/2512.03125)
*Xiwen Wei,Mustafa Munir,Radu Marculescu*

Main category: cs.LG

TL;DR: 论文提出MoDE架构解决统一多模态生成模型中的灾难性遗忘问题，特别是跨模态遗忘现象


<details>
  <summary>Details</summary>
Motivation: 统一多模态生成模型在持续学习新任务时面临严重的灾难性遗忘问题，包括模态内遗忘和跨模态遗忘。跨模态遗忘现象在现有研究中尚未得到充分探索，需要理论解释和解决方案。

Method: 提出模态解耦专家（MoDE）架构：1）通过隔离模态特定更新来缓解梯度冲突；2）利用知识蒸馏防止灾难性遗忘并保留预训练能力；3）显式解耦模态以防止干扰

Result: 在多样化基准测试中，MoDE显著缓解了跨模态和模态内遗忘，在统一多模态生成设置中优于先前的持续学习基线方法

Conclusion: MoDE提供了一种轻量级、可扩展的解决方案，有效解决了统一多模态生成模型中的持续学习挑战，特别是跨模态遗忘问题，为多模态持续学习提供了新的研究方向

Abstract: Unified Multimodal Generative Models (UMGMs) unify visual understanding and image generation within a single autoregressive framework. However, their ability to continually learn new tasks is severely hindered by catastrophic forgetting, both within a modality (intra-modal) and across modalities (inter-modal). While intra-modal forgetting has been studied in prior continual learning (CL) work, inter-modal forgetting remains largely unexplored. In this paper, we identify and empirically validate this phenomenon in UMGMs and provide a theoretical explanation rooted in gradient conflict between modalities. To address both intra- and inter-modal forgetting, we propose Modality-Decoupled Experts (MoDE), a lightweight and scalable architecture that isolates modality-specific updates to mitigate the gradient conflict and leverages knowledge distillation to prevent catastrophic forgetting and preserve pre-trained capabilities. Unlike previous CL methods that remain modality-coupled and suffer from modality gradient conflict, MoDE explicitly decouples modalities to prevent interference. Experiments across diverse benchmarks demonstrate that MoDE significantly mitigates both inter- and intra-modal forgetting, outperforming prior CL baselines in unified multimodal generation settings. Codes will be publicly available: https://github.com/Christina200/MoDE-official.git

</details>


### [17] [Atomic Diffusion Models for Small Molecule Structure Elucidation from NMR Spectra](https://arxiv.org/abs/2512.03127)
*Ziyu Xiong,Yichi Zhang,Foyez Alauddin,Chu Xin Cheng,Joon Soo An,Mohammad R. Seyedsayamdost,Ellen D. Zhong*

Main category: cs.LG

TL;DR: ChefNMR是一个端到端框架，直接从1D NMR谱和化学式预测未知分子结构，使用原子扩散模型，在天然产物结构预测中达到超过65%的准确率。


<details>
  <summary>Details</summary>
Motivation: NMR谱解析是确定小分子结构的关键技术，但传统方法耗时且需要专业知识，限制了天然产物和临床治疗药物的发现效率。

Method: 将结构解析构建为条件生成问题，使用基于非等变transformer架构的原子扩散模型，并创建了包含111,000多个天然产物的模拟1D NMR谱数据集。

Result: ChefNMR在具有挑战性的天然产物化合物结构预测中达到了超过65%的准确率，超越了现有方法。

Conclusion: 该研究在自动化小分子结构解析方面迈出了重要一步，展示了深度学习在加速分子发现方面的潜力。

Abstract: Nuclear Magnetic Resonance (NMR) spectroscopy is a cornerstone technique for determining the structures of small molecules and is especially critical in the discovery of novel natural products and clinical therapeutics. Yet, interpreting NMR spectra remains a time-consuming, manual process requiring extensive domain expertise. We introduce ChefNMR (CHemical Elucidation From NMR), an end-to-end framework that directly predicts an unknown molecule's structure solely from its 1D NMR spectra and chemical formula. We frame structure elucidation as conditional generation from an atomic diffusion model built on a non-equivariant transformer architecture. To model the complex chemical groups found in natural products, we generated a dataset of simulated 1D NMR spectra for over 111,000 natural products. ChefNMR predicts the structures of challenging natural product compounds with an unsurpassed accuracy of over 65%. This work takes a significant step toward solving the grand challenge of automating small-molecule structure elucidation and highlights the potential of deep learning in accelerating molecular discovery. Code is available at https://github.com/ml-struct-bio/chefnmr.

</details>


### [18] [Contrastive Deep Learning for Variant Detection in Wastewater Genomic Sequencing](https://arxiv.org/abs/2512.03158)
*Adele Chinda,Richmond Azumah,Hemanth Demakethepalli Venkateswara*

Main category: cs.LG

TL;DR: 提出基于VQ-VAE的无监督病毒变异检测框架，用于废水基因组监测，无需参考基因组或变异标签，在SARS-CoV-2数据上取得高准确率。


<details>
  <summary>Details</summary>
Motivation: 废水基因组监测面临计算挑战：高测序噪声、低病毒覆盖率、片段化读取、缺乏变异标注。传统基于参考的变异检测方法难以处理新突变且计算资源需求大。

Method: 使用向量量化变分自编码器(VQ-VAE)从k-mer标记化序列中学习基因组模式的离散码本，无需参考基因组或变异标签。扩展基础架构：添加掩码重建预训练以增强对缺失数据的鲁棒性，以及对比学习以获得高判别性嵌入。

Result: 在约10万条SARS-CoV-2废水测序数据上，VQ-VAE达到99.52%的平均标记级准确率和56.33%的精确序列匹配率，同时保持19.73%的码本利用率。对比微调显著提升聚类性能：64维嵌入的轮廓系数提升35%，128维嵌入提升42%。

Conclusion: 该参考无关框架为基因组监测提供了可扩展、可解释的方法，可直接应用于公共卫生监测，解决了废水基因组监测中的计算挑战。

Abstract: Wastewater-based genomic surveillance has emerged as a powerful tool for population-level viral monitoring, offering comprehensive insights into circulating viral variants across entire communities. However, this approach faces significant computational challenges stemming from high sequencing noise, low viral coverage, fragmented reads, and the complete absence of labeled variant annotations. Traditional reference-based variant calling pipelines struggle with novel mutations and require extensive computational resources. We present a comprehensive framework for unsupervised viral variant detection using Vector-Quantized Variational Autoencoders (VQ-VAE) that learns discrete codebooks of genomic patterns from k-mer tokenized sequences without requiring reference genomes or variant labels. Our approach extends the base VQ-VAE architecture with masked reconstruction pretraining for robustness to missing data and contrastive learning for highly discriminative embeddings. Evaluated on SARS-CoV-2 wastewater sequencing data comprising approximately 100,000 reads, our VQ-VAE achieves 99.52% mean token-level accuracy and 56.33% exact sequence match rate while maintaining 19.73% codebook utilization (101 of 512 codes active), demonstrating efficient discrete representation learning. Contrastive fine-tuning with different projection dimensions yields substantial clustering improvements: 64-dimensional embeddings achieve +35% Silhouette score improvement (0.31 to 0.42), while 128-dimensional embeddings achieve +42% improvement (0.31 to 0.44), clearly demonstrating the impact of embedding dimensionality on variant discrimination capability. Our reference-free framework provides a scalable, interpretable approach to genomic surveillance with direct applications to public health monitoring.

</details>


### [19] [Plantain: Plan-Answer Interleaved Reasoning](https://arxiv.org/abs/2512.03176)
*Anthony Liang,Jonathan Berant,Adam Fisch,Abhimanyu Goyal,Kalpesh Krishna,Jacob Eisenstein*

Main category: cs.LG

TL;DR: 提出交错推理(IR)和Plantain方法，让语言模型在推理过程中交替输出中间结果，减少用户等待时间并提高任务成功率


<details>
  <summary>Details</summary>
Motivation: 传统语言模型采用"先思考后回答"的方式，在长时间推理过程中不给用户任何提示，导致用户无法及时纠正错误的推理前提，造成时间浪费和糟糕的用户体验。相比之下，人类对话中会进行轻量级的增量确认来确保双方理解一致。

Method: 提出交错推理(IR)方法，让模型在思考和生成最终答案之间交替输出中间响应。进一步提出Plantain方法，首先输出明确的逐步执行计划作为第一个中间响应，然后交替进行思考和回答，允许用户干预和提供早期反馈。

Result: 在多个具有挑战性的数学推理和编码基准测试中，Plantain方法相对于"先思考后回答"基线，在pass@1指标上提高了约6%，同时将首次响应时间减少了60%以上。

Conclusion: 交错推理方法能够显著改善语言模型的用户体验，减少感知延迟，同时提高任务成功率。Plantain的计划优先策略特别有效，允许用户早期干预，为后续推理步骤提供反馈。

Abstract: Reasoning models often spend a significant amount of time thinking before they generate a visible response. In the meantime, they do not give the user any hints as to whether their reasoning is on the right track, and do not give the user any recourse to stop and correct them if their reasoning is flawed. This creates a frustrating, but unfortunately common, experience: the user's time is wasted while the model reasons from a false premise that could have easily been corrected. In contrast, human speakers typically perform lightweight, incremental grounding acts to ensure that participants in the conversation are on the same page; here we ask if language models can learn to leverage a similar type of behavior? With this motivation, we propose interleaved reasoning (IR), in which the model alternates between thinking and surfacing intermediate responses, as an alternative to the standard "think-then-answer" approach. By providing useful information to the user earlier, IR reduces perceived latency, the time a user waits for an initial output, without compromising the quality of the final response. We further introduce a specialization of interleaved reasoning, Plantain (Plan-Thought-Answer Interleaving), where the first intermediate response is an explicit, step-by-step plan for executing the task. This plan-first strategy allows for user intervention and early feedback for subsequent reasoning steps. We demonstrate that Plantain yields an ~6% improvement in pass@1 across several challenging math reasoning and coding benchmarks, while reducing time-to-first-response by over 60% relative to think-then-answer baselines.

</details>


### [20] [Neighborhood density estimation using space-partitioning based hashing schemes](https://arxiv.org/abs/2512.03187)
*Aashi Jindal*

Main category: cs.LG

TL;DR: FiRE/FiRE.1是用于单细胞RNA测序数据中罕见细胞亚群检测的草图算法，Enhash是用于流数据概念漂移检测的快速集成学习器


<details>
  <summary>Details</summary>
Motivation: 解决大规模单细胞RNA测序数据中罕见细胞亚群的快速检测问题，以及流数据中概念漂移的高效检测需求

Method: FiRE/FiRE.1采用草图算法进行异常检测；Enhash使用投影哈希的集成学习方法检测概念漂移

Result: FiRE/FiRE.1在检测罕见细胞亚群方面优于现有技术；Enhash在各种漂移类型中在时间和准确性方面都具有竞争力

Conclusion: 提出的两种方法分别在单细胞RNA测序异常检测和流数据概念漂移检测方面表现出色，具有实际应用价值

Abstract: This work introduces FiRE/FiRE.1, a novel sketching-based algorithm for anomaly detection to quickly identify rare cell sub-populations in large-scale single-cell RNA sequencing data. This method demonstrated superior performance against state-of-the-art techniques. Furthermore, the thesis proposes Enhash, a fast and resource-efficient ensemble learner that uses projection hashing to detect concept drift in streaming data, proving highly competitive in time and accuracy across various drift types.

</details>


### [21] [Scaling Internal-State Policy-Gradient Methods for POMDPs](https://arxiv.org/abs/2512.03204)
*Douglas Aberdeen,Jonathan Baxter*

Main category: cs.LG

TL;DR: 本文提出了几种改进算法，用于在无限时域设置中学习具有记忆的策略，包括已知环境模型时的直接学习和通过模拟学习的方法。


<details>
  <summary>Details</summary>
Motivation: 策略梯度方法在部分可观测环境中学习行动机制方面受到关注，但在需要记忆的情况下效果不佳。本文旨在改进学习具有记忆策略的算法。

Method: 开发了多种改进算法：当环境模型已知时直接学习策略，否则通过模拟学习。在大型POMDPs（包括噪声机器人导航和多智能体问题）上进行比较。

Result: 算法在大型POMDPs上进行了比较测试，包括噪声机器人导航和多智能体问题。

Conclusion: 提出了改进的学习具有记忆策略的算法，为部分可观测环境中的策略学习提供了更有效的解决方案。

Abstract: Policy-gradient methods have received increased attention recently as a mechanism for learning to act in partially observable environments. They have shown promise for problems admitting memoryless policies but have been less successful when memory is required. In this paper we develop several improved algorithms for learning policies with memory in an infinite-horizon setting -- directly when a known model of the environment is available, and via simulation otherwise. We compare these algorithms on some large POMDPs, including noisy robot navigation and multi-agent problems.

</details>


### [22] [SPARK: Stepwise Process-Aware Rewards for Reference-Free Reinforcement Learning](https://arxiv.org/abs/2512.03244)
*Salman Rahman,Sruthi Gorantla,Arpit Gupta,Swastik Roy,Nanyun Peng,Yang Liu*

Main category: cs.LG

TL;DR: SPARK是一个三阶段框架，通过生成模型产生多样解，验证模型评估这些解，然后使用验证输出作为合成训练数据来微调生成式过程奖励模型，最终用于强化学习训练，在数学推理任务上超越了基于真实结果的监督方法。


<details>
  <summary>Details</summary>
Motivation: 过程奖励模型（PRMs）虽然能提供密集的步骤级反馈，但由于需要昂贵的步骤级标注或真实参考而应用受限。研究者希望开发一种无需真实参考的强化学习方法，能够在缺乏可验证答案或可访问真实数据的领域中取得更好效果。

Method: SPARK采用三阶段框架：1）生成模型产生多样解，验证模型通过并行扩展（自一致性）和序列扩展（元批判）进行评估；2）使用验证输出作为合成训练数据微调生成式过程奖励模型；3）将生成式PRM与思维链验证（PRM-CoT）结合作为强化学习的奖励模型，并引入格式约束防止奖励攻击。

Result: 在ProcessBench上达到67.5 F1分数，优于参考引导训练的66.4和GPT-4o的61.9。在六个数学推理基准测试中，使用Qwen2.5-Math-7B达到47.4%平均准确率，超越了基于真实结果的RLVR方法的43.9%。

Conclusion: SPARK框架实现了无需真实参考的强化学习训练，其性能超过了基于真实结果的方法，为缺乏可验证答案或可访问真实数据的领域开辟了新的可能性。

Abstract: Process reward models (PRMs) that provide dense, step-level feedback have shown promise for reinforcement learning, yet their adoption remains limited by the need for expensive step-level annotations or ground truth references. We propose SPARK: a three-stage framework where in the first stage a generator model produces diverse solutions and a verifier model evaluates them using parallel scaling (self-consistency) and sequential scaling (meta-critique). In the second stage, we use these verification outputs as synthetic training data to fine-tune generative process reward models, which subsequently serve as reward signals during training. We show that aggregating multiple independent verifications at the step level produces training data for process reward models that surpass ground-truth outcome supervision, achieving 67.5 F1 on ProcessBench (a benchmark for identifying erroneous steps in mathematical reasoning) compared to 66.4 for reference-guided training and 61.9 for GPT-4o. In the final stage, we apply our generative PRM with chain-of-thought verification (PRM-CoT) as the reward model in RL experiments on mathematical reasoning, and introduce format constraints to prevent reward hacking. Using Qwen2.5-Math-7B, we achieve 47.4% average accuracy across six mathematical reasoning benchmarks, outperforming ground-truth-based RLVR (43.9%). Our work enables reference-free RL training that exceeds ground-truth methods, opening new possibilities for domains lacking verifiable answers or accessible ground truth.

</details>


### [23] [Perch 2.0 transfers 'whale' to underwater tasks](https://arxiv.org/abs/2512.03219)
*Andrea Burns,Lauren Harrell,Bart van Merriënboer,Vincent Dumoulin,Jenny Hamer,Tom Denton*

Main category: cs.LG

TL;DR: Perch 2.0作为生物声学基础模型，在海洋哺乳动物音频任务上通过少样本迁移学习表现出色，优于其他预训练模型。


<details>
  <summary>Details</summary>
Motivation: 尽管Perch 2.0在训练数据中几乎不包含海洋哺乳动物音频或类别，但研究希望评估其在海洋哺乳动物和水下音频任务上的少样本迁移学习能力，以验证其作为基础模型的泛化性能。

Method: 使用Perch 2.0生成的嵌入进行线性探测（linear probing），与其他预训练生物声学模型（包括Perch 1.0、SurfPerch、AVES-bio、BirdAVES、Birdnet V2.3等）在少样本迁移学习任务上进行比较。

Result: Perch 2.0的嵌入在少样本迁移学习中表现出持续的高性能，在大多数任务上优于其他嵌入模型，特别是在海洋哺乳动物分类任务中。

Conclusion: Perch 2.0是开发海洋哺乳动物分类线性分类器的推荐选择，特别是在只有少量标注样本的情况下，其嵌入表现出卓越的迁移学习能力。

Abstract: Perch 2.0 is a supervised bioacoustics foundation model pretrained on 14,597 species, including birds, mammals, amphibians, and insects, and has state-of-the-art performance on multiple benchmarks. Given that Perch 2.0 includes almost no marine mammal audio or classes in the training data, we evaluate Perch 2.0 performance on marine mammal and underwater audio tasks through few-shot transfer learning. We perform linear probing with the embeddings generated from this foundation model and compare performance to other pretrained bioacoustics models. In particular, we compare Perch 2.0 with previous multispecies whale, Perch 1.0, SurfPerch, AVES-bio, BirdAVES, and Birdnet V2.3 models, which have open-source tools for transfer-learning and agile modeling. We show that the embeddings from the Perch 2.0 model have consistently high performance for few-shot transfer learning, generally outperforming alternative embedding models on the majority of tasks, and thus is recommended when developing new linear classifiers for marine mammal classification with few labeled examples.

</details>


### [24] [Adaptive Regime-Switching Forecasts with Distribution-Free Uncertainty: Deep Switching State-Space Models Meet Conformal Prediction](https://arxiv.org/abs/2512.03298)
*Echo Diyun LU,Charles Findling,Marianne Clausel,Alessandro Leite,Wei Gong,Pierric Kersaudy*

Main category: cs.LG

TL;DR: 该研究将深度切换状态空间模型与自适应共形推理结合，为非平稳时间序列提供具有有限样本保证的预测区间，并在多种基准模型上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 时间序列中的体制转换经常破坏平稳性，使得校准的不确定性估计与点预测精度同样重要。需要为体制切换预测提供分布无关的不确定性量化方法。

Method: 将深度切换状态空间模型与自适应共形推理（ACI）及其聚合变体（AgACI）相结合。引入统一的共形包装器，可应用于S4、MC-Dropout GRU、稀疏高斯过程和变点局部模型等强序列基线，在非平稳性和模型误设下提供具有有限样本边际保证的在线预测区间。

Result: 在合成和真实数据集上，共形化预测器实现了接近名义水平的覆盖度，具有竞争力的准确性，并且通常提高了区间效率。

Conclusion: 通过结合深度切换模型与自适应共形推理，能够为体制切换时间序列预测提供具有统计保证的不确定性量化，在非平稳环境下保持可靠的覆盖性能。

Abstract: Regime transitions routinely break stationarity in time series, making calibrated uncertainty as important as point accuracy. We study distribution-free uncertainty for regime-switching forecasting by coupling Deep Switching State Space Models with Adaptive Conformal Inference (ACI) and its aggregated variant (AgACI). We also introduce a unified conformal wrapper that sits atop strong sequence baselines including S4, MC-Dropout GRU, sparse Gaussian processes, and a change-point local model to produce online predictive bands with finite-sample marginal guarantees under nonstationarity and model misspecification. Across synthetic and real datasets, conformalized forecasters achieve near-nominal coverage with competitive accuracy and generally improved band efficiency.

</details>


### [25] [Too Late to Recall: Explaining the Two-Hop Problem in Multimodal Knowledge Retrieval](https://arxiv.org/abs/2512.03276)
*Constantin Venhoff,Ashkan Khakzar,Sonia Joseph,Philip Torr,Neel Nanda*

Main category: cs.LG

TL;DR: 视觉语言模型（VLM）在事实回忆任务上表现不如其基础LLM，主要原因是VLM需要先形成实体表示（第一跳），再基于这些表示回忆事实知识（第二跳）。研究发现性能下降的VLM在计算过程中太晚解析实体表示，无法有效复用LLM已有的事实回忆机制。


<details>
  <summary>Details</summary>
Motivation: 许多视觉语言模型在事实回忆任务上表现不如其基础的大语言模型，这引发了一个问题：多模态微调在将LLM现有机制扩展到视觉输入方面效果如何？研究旨在理解VLM为何在事实回忆上表现不佳，并探索其根本原因。

Method: 对14个不同架构（LLaVA、Native、Cross-Attention）、规模（7B-124B参数）和训练设置的VLM进行基准测试，比较它们与其原始LLM主干模型在事实回忆任务上的表现。使用归因修补、激活修补和探测技术分析高/低性能退化模型，研究VLM如何使用LLM的事实回忆电路。

Result: 14个模型中有11个表现出事实回忆性能退化。研究发现性能下降的VLM在计算过程中太晚解析实体表示，无法有效复用LLM已有的事实回忆机制；而高性能VLM能早期解析实体表示。通过两种方法可以恢复性能：1）将LLM主干中的实体表示修补到VLM中；2）使用思维链推理提示。

Conclusion: 早期实体解析的速度对VLM能否有效使用预存LLM机制至关重要。机制分析可以解释和揭示多模态对齐中的系统性失败，为改进VLM设计提供了重要见解。

Abstract: Training vision language models (VLMs) aims to align visual representations from a vision encoder with the textual representations of a pretrained large language model (LLM). However, many VLMs exhibit reduced factual recall performance compared to their LLM backbones, raising the question of how effective multimodal fine-tuning is at extending existing mechanisms within the LLM to visual inputs. We argue that factual recall based on visual inputs requires VLMs to solve a two-hop problem: (1) forming entity representations from visual inputs, and (2) recalling associated factual knowledge based on these entity representations. By benchmarking 14 VLMs with various architectures (LLaVA, Native, Cross-Attention), sizes (7B-124B parameters), and training setups on factual recall tasks against their original LLM backbone models, we find that 11 of 14 models exhibit factual recall degradation. We select three models with high and two models with low performance degradation, and use attribution patching, activation patching, and probing to show that degraded VLMs struggle to use the existing factual recall circuit of their LLM backbone, because they resolve the first hop too late in the computation. In contrast, high-performing VLMs resolve entity representations early enough to reuse the existing factual recall mechanism. Finally, we demonstrate two methods to recover performance: patching entity representations from the LLM backbone into the VLM, and prompting with chain-of-thought reasoning. Our results highlight that the speed of early entity resolution critically determines how effective VLMs are in using preexisting LLM mechanisms. More broadly, our work illustrates how mechanistic analysis can explain and unveil systematic failures in multimodal alignment.

</details>


### [26] [HydroDCM: Hydrological Domain-Conditioned Modulation for Cross-Reservoir Inflow Prediction](https://arxiv.org/abs/2512.03300)
*Pengfei Hu,Fan Ming,Xiaoxue Han,Chang Lu,Yue Ning,Dan Lu*

Main category: cs.LG

TL;DR: HydroDCM：一个用于跨水库流量预测的可扩展域泛化框架，通过空间元数据构建伪域标签指导对抗学习，在推理时通过轻量级条件层适应目标水库特征。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在水库流量预测中表现良好，但在不同水库间应用时性能下降，存在域偏移问题。传统域泛化方法难以处理水文系统中每个水库具有独特流量模式、空间元数据间接但重要影响的多域水文系统。

Method: 提出HydroDCM框架：1）利用水库空间元数据构建伪域标签，指导对抗学习提取不变时间特征；2）推理时通过轻量级条件层，结合目标水库元数据自适应调整特征，平衡域不变性与位置特异性适应。

Result: 在科罗拉多河上游流域30个真实水库上的实验表明，该方法在多域条件下显著优于最先进的域泛化基线方法，同时保持计算效率。

Conclusion: HydroDCM通过结合空间元数据指导的对抗学习和轻量级条件适应，有效解决了水文系统中多域泛化问题，为跨水库流量预测提供了可扩展且高效的解决方案。

Abstract: Deep learning models have shown promise in reservoir inflow prediction, yet their performance often deteriorates when applied to different reservoirs due to distributional differences, referred to as the domain shift problem. Domain generalization (DG) solutions aim to address this issue by extracting domain-invariant representations that mitigate errors in unseen domains. However, in hydrological settings, each reservoir exhibits unique inflow patterns, while some metadata beyond observations like spatial information exerts indirect but significant influence. This mismatch limits the applicability of conventional DG techniques to many-domain hydrological systems. To overcome these challenges, we propose HydroDCM, a scalable DG framework for cross-reservoir inflow forecasting. Spatial metadata of reservoirs is used to construct pseudo-domain labels that guide adversarial learning of invariant temporal features. During inference, HydroDCM adapts these features through light-weight conditioning layers informed by the target reservoir's metadata, reconciling DG's invariance with location-specific adaptation. Experiment results on 30 real-world reservoirs in the Upper Colorado River Basin demonstrate that our method substantially outperforms state-of-the-art DG baselines under many-domain conditions and remains computationally efficient.

</details>


### [27] [Robust Tabular Foundation Models](https://arxiv.org/abs/2512.03307)
*Matthew Peroni,Franck Le,Vadim Sheinin*

Main category: cs.LG

TL;DR: RTFM提出了一种针对表格基础模型的对抗训练框架，通过参数化生成器分布来强调对模型具有挑战性的数据集，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 表格基础模型（TFMs）在结构化数据上展现出超越传统ML方法的潜力，但现有研究主要关注设计高质量的先验生成器来提升预训练性能。作者发现参数化生成器分布可以实现对抗鲁棒性视角，通过强调对模型具有挑战性的数据集来改进模型。

Method: 提出RTFM（Robust Tabular Foundation Models）框架：1）引入最优性差距度量，计算TFM性能与XGBoost、CatBoost、Random Forests等强基线最佳可达性能之间的差异；2）基于此进行模型无关的对抗训练，在训练过程中调整生成器以强调对模型具有挑战性的数据集。

Result: 在TabPFN V2分类器上应用RTFM，相比原始TabPFN和其他基线算法，平均归一化AUC提升高达6%，且仅需不到10万个额外的合成数据集。

Conclusion: RTFM展示了仅使用合成数据进行针对性对抗训练和微调TFMs的新方向，为表格基础模型的优化提供了有前景的方法。

Abstract: The development of tabular foundation models (TFMs) has accelerated in recent years, showing strong potential to outperform traditional ML methods for structured data. A key finding is that TFMs can be pretrained entirely on synthetic datasets, opening opportunities to design data generators that encourage desirable model properties. Prior work has mainly focused on crafting high-quality priors over generators to improve overall pretraining performance. Our insight is that parameterizing the generator distribution enables an adversarial robustness perspective: during training, we can adapt the generator to emphasize datasets that are particularly challenging for the model. We formalize this by introducing an optimality gap measure, given by the difference between TFM performance and the best achievable performance as estimated by strong baselines such as XGBoost, CatBoost, and Random Forests. Building on this idea, we propose Robust Tabular Foundation Models (RTFM), a model-agnostic adversarial training framework. Applied to the TabPFN V2 classifier, RTFM improves benchmark performance, with up to a 6% increase in mean normalized AUC over the original TabPFN and other baseline algorithms, while requiring less than 100k additional synthetic datasets. These results highlight a promising new direction for targeted adversarial training and fine-tuning of TFMs using synthetic data alone.

</details>


### [28] [Multi-Frequency Federated Learning for Human Activity Recognition Using Head-Worn Sensors](https://arxiv.org/abs/2512.03287)
*Dario Fenoglio,Mohan Li,Davide Casnici,Matias Laporte,Shkurta Gashi,Silvia Santini,Martin Gjoreski,Marc Langheinrich*

Main category: cs.LG

TL;DR: 提出多频联邦学习用于头戴设备活动识别，解决隐私问题和设备采样频率差异


<details>
  <summary>Details</summary>
Motivation: 传统人类活动识别依赖集中式用户数据，存在隐私问题；不同设备采样频率差异大，需要跨设备联合学习

Method: 采用多频联邦学习方法，支持隐私保护机器学习，实现不同采样频率设备间的联合模型学习

Result: 在两个数据集上相比频率特定方法有改进，表明多频联邦学习在头戴设备活动识别任务中具有前景

Conclusion: 多频联邦学习为头戴设备活动识别提供隐私保护和跨频率设备协同学习的有效解决方案

Abstract: Human Activity Recognition (HAR) benefits various application domains, including health and elderly care. Traditional HAR involves constructing pipelines reliant on centralized user data, which can pose privacy concerns as they necessitate the uploading of user data to a centralized server. This work proposes multi-frequency Federated Learning (FL) to enable: (1) privacy-aware ML; (2) joint ML model learning across devices with varying sampling frequency. We focus on head-worn devices (e.g., earbuds and smart glasses), a relatively unexplored domain compared to traditional smartwatch- or smartphone-based HAR. Results have shown improvements on two datasets against frequency-specific approaches, indicating a promising future in the multi-frequency FL-HAR task. The proposed network's implementation is publicly available for further research and development.

</details>


### [29] [Single-Round Scalable Analytic Federated Learning](https://arxiv.org/abs/2512.03336)
*Alan T. L. Bacellar,Mustafa Munir,Felipe M. G. França,Priscila M. V. Lima,Radu Marculescu,Lizy K. John*

Main category: cs.LG

TL;DR: SAFLe框架通过引入结构化头部和稀疏分组嵌入，实现了非线性表达能力，同时保持了单轮通信优势，在联邦学习中取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临两大挑战：高通信开销和非IID数据下的性能崩溃。现有的分析方法（AFL）虽然提供单轮、数据分布不变的解决方案，但仅限于线性模型。而非线性方法（如DeepAFL）虽然恢复了准确性，却牺牲了单轮通信的优势。

Method: 提出SAFLe框架，通过引入结构化头部（包含分桶特征）和稀疏分组嵌入来实现可扩展的非线性表达能力。关键创新是证明这种非线性架构在数学上等价于高维线性回归，从而能够使用AFL的单次、不变聚合定律进行求解。

Result: SAFLe在联邦视觉任务中建立了新的最先进水平，在所有基准测试中显著优于线性AFL和多轮DeepAFL的准确性，同时保持了高效的单轮通信特性。

Conclusion: SAFLe打破了联邦学习中非线性表达能力和单轮通信之间的权衡，提供了一个高效、可扩展的解决方案，为联邦视觉应用开辟了新途径。

Abstract: Federated Learning (FL) is plagued by two key challenges: high communication overhead and performance collapse on heterogeneous (non-IID) data. Analytic FL (AFL) provides a single-round, data distribution invariant solution, but is limited to linear models. Subsequent non-linear approaches, like DeepAFL, regain accuracy but sacrifice the single-round benefit. In this work, we break this trade-off. We propose SAFLe, a framework that achieves scalable non-linear expressivity by introducing a structured head of bucketed features and sparse, grouped embeddings. We prove this non-linear architecture is mathematically equivalent to a high-dimensional linear regression. This key equivalence allows SAFLe to be solved with AFL's single-shot, invariant aggregation law. Empirically, SAFLe establishes a new state-of-the-art for analytic FL, significantly outperforming both linear AFL and multi-round DeepAFL in accuracy across all benchmarks, demonstrating a highly efficient and scalable solution for federated vision.

</details>


### [30] [Better World Models Can Lead to Better Post-Training Performance](https://arxiv.org/abs/2512.03400)
*Prakhar Gupta,Henry Conklin,Sarah-Jane Leslie,Andrew Lee*

Main category: cs.LG

TL;DR: 该研究探讨了显式世界建模目标如何影响Transformer在不同训练阶段的内部表示和下游能力，使用2x2x2魔方作为测试平台，发现显式世界建模能产生更线性可解码和因果可控的状态表示，并提升强化学习后训练的效果。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解显式世界建模目标如何影响Transformer的内部表示和下游能力，特别是在序列规划任务中，探索世界模型质量对强化学习后训练性能的影响。

Method: 使用2x2x2魔方作为测试环境，比较标准下一个令牌预测与两种显式世界建模策略：(i)状态预测预训练和(ii)状态预测+下一个令牌联合目标。使用Group Relative Policy Optimization (GRPO)进行后训练，通过线性探针和因果干预评估表示质量。

Result: 显式世界建模产生更线性可解码和因果可控的状态表示。更重要的是，改进的状态表示能显著提升GRPO的性能增益，特别是在更难的魔方状态上。状态表示的锐化能提高序列规划任务后训练的有效性。

Conclusion: 显式世界建模目标能改善Transformer的状态表示质量，这些改进的表示能有效提升强化学习后训练在序列规划任务中的性能，特别是在复杂状态下的表现。

Abstract: In this work we study how explicit world-modeling objectives affect the internal representations and downstream capability of Transformers across different training stages. We use a controlled 2x2x2 Rubik's Cube and ask: (1) how does explicitly pretraining a world model affect the model's latent representations, and (2) how does world-model quality affect the model's performance after reinforcement learning post-training? We compare standard next-token prediction to two explicit world-modeling strategies -- (i) state-prediction pretraining and (ii) a joint state-prediction + next-token objective -- and assess task performance after Group Relative Policy Optimization (GRPO) is applied as post-training. We evaluate the representation quality with linear probes and causal interventions. We find that explicit world-modeling yields more linearly decodable and causally steerable state representations. More importantly, we find that improved state representations lead to higher gains for GRPO, especially on harder cube states. Our results indicate that sharpening state representations can improve the effectiveness of post-training for sequence-planning tasks.

</details>


### [31] [Breaking Determinism: Stochastic Modeling for Reliable Off-Policy Evaluation in Ad Auctions](https://arxiv.org/abs/2512.03354)
*Hongseon Yeom,Jaeyoul Shin,Soojin Min,Jeongmin Yoon,Seunghak Yu,Dongyeop Kang*

Main category: cs.LG

TL;DR: 提出首个用于确定性广告拍卖的离策略评估框架，通过重新利用出价景观模型来近似倾向得分，使SNIPS等稳定估计器能够用于反事实评估，显著减少在线A/B测试的成本和风险。


<details>
  <summary>Details</summary>
Motivation: 在线A/B测试消耗大量工程资源且存在收入损失风险，而传统离策略评估方法在确定性拍卖环境中不适用，因为最高出价者获胜的机制导致非获胜广告的曝光概率为零。

Method: 重新利用出价景观模型来近似倾向得分，推导出稳健的近似倾向得分，使自归一化逆倾向评分等稳定估计器能够用于确定性拍卖的反事实评估。

Result: 在AuctionNet模拟基准和大型工业平台2周在线A/B测试中验证，方法显示与在线结果显著一致，点击率预测的MDA达到92%，显著优于参数基线。

Conclusion: 贡献了首个实用且经过验证的确定性拍卖环境可靠离策略评估框架，为昂贵且风险高的在线实验提供了高效替代方案。

Abstract: Online A/B testing, the gold standard for evaluating new advertising policies, consumes substantial engineering resources and risks significant revenue loss from deploying underperforming variations. This motivates the use of Off-Policy Evaluation (OPE) for rapid, offline assessment. However, applying OPE to ad auctions is fundamentally more challenging than in domains like recommender systems, where stochastic policies are common. In online ad auctions, it is common for the highest-bidding ad to win the impression, resulting in a deterministic, winner-takes-all setting. This results in zero probability of exposure for non-winning ads, rendering standard OPE estimators inapplicable. We introduce the first principled framework for OPE in deterministic auctions by repurposing the bid landscape model to approximate the propensity score. This model allows us to derive robust approximate propensity scores, enabling the use of stable estimators like Self-Normalized Inverse Propensity Scoring (SNIPS) for counterfactual evaluation. We validate our approach on the AuctionNet simulation benchmark and against 2-weeks online A/B test from a large-scale industrial platform. Our method shows remarkable alignment with online results, achieving a 92\% Mean Directional Accuracy (MDA) in CTR prediction, significantly outperforming the parametric baseline. MDA is the most critical metric for guiding deployment decisions, as it reflects the ability to correctly predict whether a new model will improve or harm performance. This work contributes the first practical and validated framework for reliable OPE in deterministic auction environments, offering an efficient alternative to costly and risky online experiments.

</details>


### [32] [The promising potential of vision language models for the generation of textual weather forecasts](https://arxiv.org/abs/2512.03623)
*Edward C. C. Steele,Dinesh Mane,Emilio Monti,Luis Orus,Rebecca Chantrill-Cheyette,Matthew Couch,Kirstine I. Dale,Simon Eaton,Govindarajan Rangarajan,Amir Majlesi,Steven Ramsdale,Michael Sharpe,Craig Smith,Jonathan Smith,Rebecca Yates,Holly Ellis,Charles Ewen*

Main category: cs.LG

TL;DR: 使用视觉语言模型从视频编码的网格天气数据直接生成航运预报文本，探索多模态基础模型在气象产品服务中的新应用


<details>
  <summary>Details</summary>
Motivation: 尽管多模态基础模型具有巨大潜力，但在气象产品和服务生成方面的应用仍处于起步阶段。为了加速该领域的应用和采纳，研究者探索将视觉语言模型应用于直接从天气数据生成航运预报文本

Method: 采用视觉语言模型，将视频编码的网格天气数据作为输入，直接生成航运预报文本内容

Result: 早期结果显示，该方法在提高生产效率和促进服务创新方面展现出有前景的可扩展技术机会

Conclusion: 这项研究为天气企业及其他领域展示了多模态基础模型在增强生产效率和推动服务创新方面的潜力

Abstract: Despite the promising capability of multimodal foundation models, their application to the generation of meteorological products and services remains nascent. To accelerate aspiration and adoption, we explore the novel use of a vision language model for writing the iconic Shipping Forecast text directly from video-encoded gridded weather data. These early results demonstrate promising scalable technological opportunities for enhancing production efficiency and service innovation within the weather enterprise and beyond.

</details>


### [33] [Dynamically Scaled Activation Steering](https://arxiv.org/abs/2512.03661)
*Alex Ferrando,Xavier Suau,Jordi Gonzàlez,Pau Rodriguez*

Main category: cs.LG

TL;DR: DSAS是一种动态缩放激活引导框架，通过自适应调节现有引导方法的强度，只在检测到不良行为时进行干预，在毒性缓解和效用保持之间实现更好的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有激活引导方法对所有输入统一应用干预，在不必要引导时会降低模型性能。需要一种方法能够区分何时需要引导以及如何引导。

Method: DSAS将"何时引导"与"如何引导"解耦，通过计算上下文相关的缩放因子，自适应调节现有引导方法在不同层和输入上的强度。可以端到端联合优化引导函数。

Result: DSAS与现有引导方法结合时，在毒性缓解和效用保持的帕累托前沿上表现更好。在文本到图像扩散模型中也能有效调节特定概念，同时计算开销最小且提高可解释性。

Conclusion: DSAS是一种方法无关的动态缩放激活引导框架，通过自适应调节引导强度，在保持模型效用的同时更有效地缓解不良行为，具有广泛适用性和实用性。

Abstract: Activation steering has emerged as a powerful method for guiding the behavior of generative models towards desired outcomes such as toxicity mitigation. However, most existing methods apply interventions uniformly across all inputs, degrading model performance when steering is unnecessary. We introduce Dynamically Scaled Activation Steering (DSAS), a method-agnostic steering framework that decouples when to steer from how to steer. DSAS adaptively modulates the strength of existing steering transformations across layers and inputs, intervening strongly only when undesired behavior is detected. At generation time, DSAS computes context-dependent scaling factors that selectively adjust the strength of any steering method. We also show how DSAS can be jointly optimized end-to-end together with the steering function. When combined with existing steering methods, DSAS consistently improves the Pareto front with respect to steering alone, achieving a better trade-off between toxicity mitigation and utility preservation. We further demonstrate DSAS's generality by applying it to a text-to-image diffusion model, showing how adaptive steering allows the modulation of specific concepts. Finally, DSAS introduces minimal computational overhead while improving interpretability, pinpointing which tokens require steering and by how much.

</details>


### [34] [Tuning-Free Structured Sparse Recovery of Multiple Measurement Vectors using Implicit Regularization](https://arxiv.org/abs/2512.03393)
*Lakshmi Jayalal,Sheetal Kalyani*

Main category: cs.LG

TL;DR: 提出一种基于隐式正则化的免调参框架，用于多测量向量（MMV）中的联合稀疏信号恢复，无需先验知识或参数调整。


<details>
  <summary>Details</summary>
Motivation: 传统MMV方法如M-OMP和M-FOCUSS需要仔细的参数调整或对信号稀疏度和噪声方差的先验知识，这在实际应用中存在局限性。

Method: 通过过参数化引入隐式正则化，将估计矩阵重新参数化为因子，分离共享的行支持与个体向量条目。对标准最小二乘目标应用梯度下降，优化动态自然促进期望的行稀疏结构。

Result: 理论证明：在足够小且平衡的初始化下，优化动态呈现"动量效应"，使真实支持中的行范数比其他行增长更快，确保解轨迹收敛到理想的行稀疏解。实验结果表明，该方法无需先验信息或调参即可达到与现有方法相当的性能。

Conclusion: 提出了一种免调参的MMV稀疏恢复框架，通过隐式正则化自动实现行稀疏性，克服了传统方法对参数调整和先验知识的依赖。

Abstract: Recovering jointly sparse signals in the multiple measurement vectors (MMV) setting is a fundamental problem in machine learning, but traditional methods like multiple measurement vectors orthogonal matching pursuit (M-OMP) and multiple measurement vectors FOCal Underdetermined System Solver (M-FOCUSS) often require careful parameter tuning or prior knowledge of the sparsity of the signal and/or noise variance. We introduce a novel tuning-free framework that leverages Implicit Regularization (IR) from overparameterization to overcome this limitation. Our approach reparameterizes the estimation matrix into factors that decouple the shared row-support from individual vector entries. We show that the optimization dynamics inherently promote the desired row-sparse structure by applying gradient descent to a standard least-squares objective on these factors. We prove that with a sufficiently small and balanced initialization, the optimization dynamics exhibit a "momentum-like" effect, causing the norms of rows in the true support to grow significantly faster than others. This formally guarantees that the solution trajectory converges towards an idealized row-sparse solution. Additionally, empirical results demonstrate that our approach achieves performance comparable to established methods without requiring any prior information or tuning.

</details>


### [35] [DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training](https://arxiv.org/abs/2512.03847)
*Dingwei Zhu,Zhiheng Xi,Shihan Dou,Yuhui Wang,Sixian Li,Junjie Ye,Honglin Guo,Shichun Liu,Chenhao Huang,Yajie Yang,Junlin Shang,Senjie Jin,Ming Zhang,Jiazheng Zhang,Caishuang Huang,Yunke Zhang,Demei Yan,Yuran Wang,Tao Gui*

Main category: cs.LG

TL;DR: DVPO：结合条件风险理论和分布价值建模的新RL框架，用于LLM后训练，在噪声监督下平衡鲁棒性和泛化性


<details>
  <summary>Details</summary>
Motivation: 现实世界部署中常遇到噪声或不完整的监督信号，现有方法（如RFQI、CQL、PPO、GRPO）要么忽视泛化性，要么产生过于保守的策略，导致在不同实际场景中表现不均

Method: DVPO结合条件风险理论与分布价值建模，学习token级别的价值分布以提供细粒度监督，并应用非对称风险正则化来塑造分布尾部：收缩下尾以抑制噪声负偏差，扩展上尾以保持探索多样性

Result: 在多轮对话、数学推理和科学问答的广泛实验中，DVPO在噪声监督下始终优于PPO、GRPO和基于鲁棒Bellman的PPO

Conclusion: DVPO展示了在现实世界LLM后训练中的潜力，能更好地平衡鲁棒性和泛化性

Abstract: Reinforcement learning (RL) has shown strong performance in LLM post-training, but real-world deployment often involves noisy or incomplete supervision. In such settings, complex and unreliable supervision signals can destabilize training and harm generalization. While existing approaches such as worst-case optimization (e.g., RFQI, CQL) and mean-based methods (e.g., PPO, GRPO) can improve stability, they often overlook generalization and may produce overly conservative policies, leading to uneven performance across diverse real scenarios. To this end, we introduce DVPO (Distributional Value Modeling with Risk-aware Policy Optimization), a new RL framework that combines conditional risk theory with distributional value modeling to better balance robustness and generalization. DVPO learns token-level value distributions to provide fine-grained supervision, and applies an asymmetric risk regularization to shape the distribution tails: it contracts the lower tail to dampen noisy negative deviations, while expanding the upper tail to preserve exploratory diversity. Across extensive experiments and analysis in multi-turn dialogue, math reasoning, and scientific QA, DVPO consistently outperforms PPO, GRPO, and robust Bellman-based PPO under noisy supervision, showing its potential for LLM post-training in the real-world.

</details>


### [36] [Hyperdimensional Computing for Sustainable Manufacturing: An Initial Assessment](https://arxiv.org/abs/2512.03864)
*Danny Hoang,Anandkumar Patel,Ruimen Chen,Rajiv Malhotra,Farhad Imani*

Main category: cs.LG

TL;DR: 该研究比较了智能加工中几何质量预测的AI模型能耗，引入超维计算(HDC)作为替代方案，在保持精度的同时大幅降低能耗和计算时间。


<details>
  <summary>Details</summary>
Motivation: 智能制造虽能提高效率和降低能耗，但AI模型的高能耗可能抵消这些优势。需要寻找既能保持预测精度又能大幅降低能耗的AI方法。

Method: 使用原位传感预测智能加工中的几何质量，比较常见AI模型的能耗、精度和速度。引入超维计算(HDC)作为替代方案，并与传统模型进行对比分析。

Result: HDC达到与传统模型相当的精度，同时大幅降低能耗：训练能耗降低200倍，推理能耗降低175-1000倍。训练时间减少200倍，推理时间减少300-600倍。

Conclusion: 超维计算(HDC)在保持预测精度的同时，显著降低了能耗和计算时间，展示了其在节能智能制造中的巨大潜力。

Abstract: Smart manufacturing can significantly improve efficiency and reduce energy consumption, yet the energy demands of AI models may offset these gains. This study utilizes in-situ sensing-based prediction of geometric quality in smart machining to compare the energy consumption, accuracy, and speed of common AI models. HyperDimensional Computing (HDC) is introduced as an alternative, achieving accuracy comparable to conventional models while drastically reducing energy consumption, 200$\times$ for training and 175 to 1000$\times$ for inference. Furthermore, HDC reduces training times by 200$\times$ and inference times by 300 to 600$\times$, showcasing its potential for energy-efficient smart manufacturing.

</details>


### [37] [Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning](https://arxiv.org/abs/2512.03973)
*Franki Nguimatsia Tiofack,Théotime Le Hellard,Fabian Schramm,Nicolas Perrin-Gilbert,Justin Carpentier*

Main category: cs.LG

TL;DR: GFP通过结合多步流匹配策略和蒸馏的单步演员，使用加权行为克隆专注于复制数据集中的高价值动作，而不是盲目模仿所有状态-动作对，在离线强化学习中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习中传统的行为正则化方法存在缺陷，它们无法区分高价值和低价值动作，对所有状态-动作对都进行相同的正则化处理，这限制了策略的性能提升。

Method: 提出引导流策略(GFP)，将多步流匹配策略与蒸馏的单步演员耦合。演员通过加权行为克隆指导流策略专注于复制数据集中的高价值动作，而流策略则约束演员保持与数据集最佳转换对齐的同时最大化批评者价值。

Result: GFP在OGBench、Minari和D4RL基准测试的144个状态和像素任务中实现了最先进的性能，特别是在次优数据集和挑战性任务上取得了显著提升。

Conclusion: GFP通过演员和流策略之间的相互引导机制，有效地区分并专注于高价值动作，克服了传统行为正则化的局限性，为离线强化学习提供了更有效的解决方案。

Abstract: Offline reinforcement learning often relies on behavior regularization that enforces policies to remain close to the dataset distribution. However, such approaches fail to distinguish between high-value and low-value actions in their regularization components. We introduce Guided Flow Policy (GFP), which couples a multi-step flow-matching policy with a distilled one-step actor. The actor directs the flow policy through weighted behavior cloning to focus on cloning high-value actions from the dataset rather than indiscriminately imitating all state-action pairs. In turn, the flow policy constrains the actor to remain aligned with the dataset's best transitions while maximizing the critic. This mutual guidance enables GFP to achieve state-of-the-art performance across 144 state and pixel-based tasks from the OGBench, Minari, and D4RL benchmarks, with substantial gains on suboptimal datasets and challenging tasks. Webpage: https://simple-robotics.github.io/publications/guided-flow-policy/

</details>


### [38] [GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test](https://arxiv.org/abs/2512.03428)
*Ziyi Ding,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: 提出GaussDetect-LiNGAM方法，通过利用前向模型噪声高斯性与反向模型残差独立性之间的等价性，避免显式高斯性检验，提升双变量因果发现的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统LiNGAM方法依赖显式高斯性检验，但这些检验在样本有限时脆弱且敏感。需要更鲁棒的方法来避免高斯性检验的局限性，提高因果发现的可靠性。

Method: 基于理论证明：在LiNGAM假设（线性、无环、外生性）下，前向模型噪声的高斯性等价于反向模型中回归变量与残差的独立性。利用这一等价性，用鲁棒的核基独立性检验替代脆弱的高斯性检验。

Result: 实验验证了理论等价性，GaussDetect-LiNGAM在不同噪声类型和样本量下保持高一致性，同时减少了每个决策所需的检验次数（TPD），提高了效率。

Conclusion: 该方法通过避免显式高斯性检验，增强了LiNGAM的效率和实际应用性，使因果推断在现实场景中更易用和可靠。

Abstract: We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.

</details>


### [39] [MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking](https://arxiv.org/abs/2512.04044)
*Yizhou Zhao,Zhiwei Steven Wu,Adam Block*

Main category: cs.LG

TL;DR: MarkTune是一种基于理论原理的在线策略微调框架，通过将GaussMark水印信号作为奖励，同时正则化防止文本质量下降，显著改善了开放权重语言模型的水印质量-可检测性权衡。


<details>
  <summary>Details</summary>
Motivation: 开放权重语言模型对水印技术提出了严峻挑战，因为一旦模型权重公开，就无法强制执行推理时干预。现有的开放权重模型水印技术（如GaussMark）通常需要对模型权重进行微小修改，但这会导致检测能力有限或生成质量明显下降。

Method: MarkTune是一个理论上有原则的在线策略微调框架，将GaussMark信号作为奖励，同时通过正则化防止文本质量下降。该方法在模型的表示空间中进行更精细的、水印感知的权重更新，同时保持生成质量。

Result: MarkTune将GaussMark的质量-可检测性边界推近到接近推理时水印的水平，对改写和微调攻击保持鲁棒性，并表现出强大的泛化能力：在一个数据集上微调的模型在未见数据集上仍保持显著的水印检测能力。

Conclusion: MarkTune作为一种通用策略，能够在开放权重语言模型中嵌入鲁棒、高质量的水印，解决了开放权重模型水印技术的关键挑战。

Abstract: Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.

</details>


### [40] [Grokked Models are Better Unlearners](https://arxiv.org/abs/2512.03437)
*Yuanbang Liang,Yang Li*

Main category: cs.LG

TL;DR: 研究发现，在模型完成"顿悟"（grokking）阶段后进行机器学习遗忘，比在早期训练阶段进行遗忘更高效、更稳定，且对保留数据的影响更小。


<details>
  <summary>Details</summary>
Motivation: 探索"顿悟"（延迟泛化）现象是否有助于机器学习遗忘任务，即在不完全重新训练的情况下移除特定数据的影响。

Method: 比较在顿悟前后应用标准遗忘方法的效果，在视觉任务（CNN/ResNet在CIFAR、SVHN、ImageNet）和语言任务（Transformer在TOFU风格设置）上进行实验。

Result: 从顿悟后检查点开始遗忘：(1) 遗忘效率更高（达到目标遗忘水平所需更新更少）；(2) 附带损害更小（保留数据和测试性能下降更少）；(3) 不同随机种子下更新更稳定。

Conclusion: 顿悟后模型学习到更模块化的表示，减少了遗忘子集和保留子集之间的梯度对齐，有利于选择性遗忘。这为改进现有遗忘方法提供了实用方案。

Abstract: Grokking-delayed generalization that emerges well after a model has fit the training data-has been linked to robustness and representation quality. We ask whether this training regime also helps with machine unlearning, i.e., removing the influence of specified data without full retraining. We compare applying standard unlearning methods before versus after the grokking transition across vision (CNNs/ResNets on CIFAR, SVHN, and ImageNet) and language (a transformer on a TOFU-style setup). Starting from grokked checkpoints consistently yields (i) more efficient forgetting (fewer updates to reach a target forget level), (ii) less collateral damage (smaller drops on retained and test performance), and (iii) more stable updates across seeds, relative to early-stopped counterparts under identical unlearning algorithms. Analyses of features and curvature further suggest that post-grokking models learn more modular representations with reduced gradient alignment between forget and retain subsets, which facilitates selective forgetting. Our results highlight when a model is trained (pre- vs. post-grokking) as an orthogonal lever to how unlearning is performed, providing a practical recipe to improve existing unlearning methods without altering their algorithms.

</details>


### [41] [Fare Comparison App of Uber, Ola and Rapido](https://arxiv.org/abs/2512.04065)
*Ashlesha Gopinath Sawant,Sahil S. Jadhav,Vidhan R. Jain,Shriraj S. Jagtap,Prachi Jadhav,Soham Jadhav,Ichha Raina*

Main category: cs.LG

TL;DR: 开发了一个网约车比价Web应用，通过API获取Ola、Uber、Rapido的实时价格，为用户提供最优出行选择


<details>
  <summary>Details</summary>
Motivation: 用户在选择网约车服务时面临困难，难以在价格和时间效率之间做出最优选择，需要透明化的比价工具来提升出行体验

Method: 构建Web应用程序，使用Python后端通过API获取不同网约车平台的实时价格数据，利用Android Studio模拟器、Appium等技术进行数据采集和位置比较

Result: 成功开发了能够实时比较Ola、Uber、Rapido价格的比价系统，为用户提供最优出行选择建议

Conclusion: 该项目提高了网约车服务的透明度，增强了用户出行效率和体验，解决了API数据获取、模拟器使用等技术挑战

Abstract: In todays increasing world, it is very important to have good hailing services like Ola, Uber, and Rapido as it is very essential for our daily transportation. Users often face difficulties in choosing the most appropriate and efficient ride that would lead to both cost-effective and would take us to our destination in less time. This project provides you with the web application that helps you to select the most beneficial ride for you by providing users with the fare comparison between Ola, Uber, Rapido for the destination entered by the user. The backend is use to fetch the data, providing users with the fare comparison for the ride and finally providing with the best option using Python. This research paper also addresses the problem and challenges faced in accessing the data using APIs, Android Studios emulator, Appium and location comparison. Thus, the aim of the project is to provide transparency to the users in ride-hailing services and increase efficiency and provide users with better experience.

</details>


### [42] [Multi-Modal Opinion Integration for Financial Sentiment Analysis using Cross-Modal Attention](https://arxiv.org/abs/2512.03464)
*Yujing Liu,Chen Yang*

Main category: cs.LG

TL;DR: 提出用于金融情感分析的端到端深度学习框架，整合时效性和流行性两种意见模态，通过跨模态注意力机制提升分类准确率至83.5%


<details>
  <summary>Details</summary>
Motivation: 现有金融情感分析方法难以有效整合多样化的意见模态，无法捕捉模态间的细粒度交互。时效性意见（近期市场更新）和流行性意见（趋势性集体情感）代表不同的信息渠道，需要专门设计的方法来整合

Method: 1. 使用BERT（Chinese-wwm-ext）进行特征嵌入；2. 提出金融多头交叉注意力（FMHCA）结构促进两种意见模态间的信息交换；3. 通过Transformer层优化处理特征；4. 使用多模态因子双线性池化进行特征融合；5. 分类为负面、中性和正面情感

Result: 在涵盖837家公司的综合数据集上，该方法达到83.5%的准确率，显著优于BERT+Transformer等基线方法21个百分点

Conclusion: 该框架通过专门设计的跨模态注意力机制有效整合金融意见的不同模态，显著提升情感分析性能，有助于支持更准确的金融决策和风险管理

Abstract: In recent years, financial sentiment analysis of public opinion has become increasingly important for market forecasting and risk assessment. However, existing methods often struggle to effectively integrate diverse opinion modalities and capture fine-grained interactions across them. This paper proposes an end-to-end deep learning framework that integrates two distinct modalities of financial opinions: recency modality (timely opinions) and popularity modality (trending opinions), through a novel cross-modal attention mechanism specifically designed for financial sentiment analysis. While both modalities consist of textual data, they represent fundamentally different information channels: recency-driven market updates versus popularity-driven collective sentiment. Our model first uses BERT (Chinese-wwm-ext) for feature embedding and then employs our proposed Financial Multi-Head Cross-Attention (FMHCA) structure to facilitate information exchange between these distinct opinion modalities. The processed features are optimized through a transformer layer and fused using multimodal factored bilinear pooling for classification into negative, neutral, and positive sentiment. Extensive experiments on a comprehensive dataset covering 837 companies demonstrate that our approach achieves an accuracy of 83.5%, significantly outperforming baselines including BERT+Transformer by 21 percent. These results highlight the potential of our framework to support more accurate financial decision-making and risk management.

</details>


### [43] [Bayesian Event-Based Model for Disease Subtype and Stage Inference](https://arxiv.org/abs/2512.03467)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: 本文提出了一种新的贝叶斯事件模型BEBMS，在疾病亚型推断任务中显著优于现有方法SuStaIn，并在阿尔茨海默病数据上得到更符合科学共识的结果。


<details>
  <summary>Details</summary>
Motivation: 慢性疾病在不同患者中的进展方式存在差异，通常存在少量亚型。现有方法SuStaIn虽然广泛应用，但其鲁棒性需要评估。本文旨在开发更稳健的贝叶斯方法并评估其性能。

Method: 开发了基于贝叶斯的事件模型BEBMS，通过合成数据实验（包含不同程度的模型误设）与SuStaIn进行比较，评估排序、分期和亚型分配任务的性能。最后在真实阿尔茨海默病数据集上应用两种方法。

Result: BEBMS在排序、分期和亚型分配任务上显著优于SuStaIn。在阿尔茨海默病数据上，BEBMS的结果更符合该疾病进展的科学共识。

Conclusion: BEBMS作为SuStaIn的贝叶斯改进版本，在疾病亚型推断任务中表现出更强的鲁棒性和准确性，为疾病进展建模提供了更可靠的工具。

Abstract: Chronic diseases often progress differently across patients. Rather than randomly varying, there are typically a small number of subtypes for how a disease progresses across patients. To capture this structured heterogeneity, the Subtype and Stage Inference Event-Based Model (SuStaIn) estimates the number of subtypes, the order of disease progression for each subtype, and assigns each patient to a subtype from primarily cross-sectional data. It has been widely applied to uncover the subtypes of many diseases and inform our understanding of them. But how robust is its performance? In this paper, we develop a principled Bayesian subtype variant of the event-based model (BEBMS) and compare its performance to SuStaIn in a variety of synthetic data experiments with varied levels of model misspecification. BEBMS substantially outperforms SuStaIn across ordering, staging, and subtype assignment tasks. Further, we apply BEBMS and SuStaIn to a real-world Alzheimer's data set. We find BEBMS has results that are more consistent with the scientific consensus of Alzheimer's disease progression than SuStaIn.

</details>


### [44] [Joint Progression Modeling (JPM): A Probabilistic Framework for Mixed-Pathology Progression](https://arxiv.org/abs/2512.03475)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: JPM是一个概率框架，用于从横断面数据推断混合神经退行性疾病的联合进展，将单病轨迹视为部分排序并构建联合进展先验，相比传统单病EBM提高了排序准确性。


<details>
  <summary>Details</summary>
Motivation: 传统事件模型假设个体只有单一疾病，但神经退行性疾病中混合病理很常见，需要能够处理多种疾病同时进展的模型。

Method: 提出联合进展模型(JPM)，将单病轨迹视为部分排序，构建联合进展先验。研究了四种变体：Pairwise、Bradley-Terry、Plackett-Luce和Mallows，分析了校准性、分离性和锐度三个特性。

Result: 所有变体都具有校准性，分离性接近完美；锐度因变体而异，可通过输入部分排序的简单特征预测。在合成实验中，JPM比传统SA-EBM基线提高约21%的排序准确性。在NACC数据中，Mallows变体和SA-EBM的结果与AD和VaD混合病理进展的文献更一致。

Conclusion: JPM为从横断面数据推断混合神经退行性疾病进展提供了一个有效框架，相比传统单病模型显著提高了准确性，并且能够产生与现有文献一致的生物学合理结果。

Abstract: Event-based models (EBMs) infer disease progression from cross-sectional data, and standard EBMs assume a single underlying disease per individual. In contrast, mixed pathologies are common in neurodegeneration. We introduce the Joint Progression Model (JPM), a probabilistic framework that treats single-disease trajectories as partial rankings and builds a prior over joint progressions. We study several JPM variants (Pairwise, Bradley-Terry, Plackett-Luce, and Mallows) and analyze three properties: (i) calibration -- whether lower model energy predicts smaller distance to the ground truth ordering; (ii) separation -- the degree to which sampled rankings are distinguishable from random permutations; and (iii) sharpness -- the stability of sampled aggregate rankings. All variants are calibrated, and all achieve near-perfect separation; sharpness varies by variant and is well-predicted by simple features of the input partial rankings (number and length of rankings, conflict, and overlap). In synthetic experiments, JPM improves ordering accuracy by roughly 21 percent over a strong EBM baseline (SA-EBM) that treats the joint disease as a single condition. Finally, using NACC, we find that the Mallows variant of JPM and the baseline model (SA-EBM) have results that are more consistent with prior literature on the possible disease progression of the mixed pathology of AD and VaD.

</details>


### [45] [Adaptive sampling using variational autoencoder and reinforcement learning](https://arxiv.org/abs/2512.03525)
*Adil Rasheed,Mikael Aleksander Jansen Shahly,Muhammad Faisal Aftab*

Main category: cs.LG

TL;DR: 提出自适应稀疏感知框架，结合变分自编码器先验与强化学习进行序列测量选择，优于传统压缩感知、最优传感器布置和生成模型方法


<details>
  <summary>Details</summary>
Motivation: 传统压缩感知使用通用基和随机测量，效率和质量有限；最优传感器布置基于历史数据但使用固定线性基，无法适应非线性或样本特异性变化；生成模型压缩感知使用深度生成先验但仍采用次优随机采样

Method: 提出自适应稀疏感知框架，将变分自编码器先验与强化学习耦合，通过强化学习序列选择测量点，利用变分自编码器提供生成先验

Result: 实验表明该方法在稀疏测量重建方面优于压缩感知、最优传感器布置和生成模型重建方法

Conclusion: 自适应稀疏感知框架通过结合变分自编码器先验和强化学习，实现了更有效的序列测量选择和高质量重建

Abstract: Compressed sensing enables sparse sampling but relies on generic bases and random measurements, limiting efficiency and reconstruction quality. Optimal sensor placement uses historcal data to design tailored sampling patterns, yet its fixed, linear bases cannot adapt to nonlinear or sample-specific variations. Generative model-based compressed sensing improves reconstruction using deep generative priors but still employs suboptimal random sampling. We propose an adaptive sparse sensing framework that couples a variational autoencoder prior with reinforcement learning to select measurements sequentially. Experiments show that this approach outperforms CS, OSP, and Generative model-based reconstruction from sparse measurements.

</details>


### [46] [Parameter-Efficient Augment Plugin for Class-Incremental Learning](https://arxiv.org/abs/2512.03537)
*Zhiming Xu,Baile Xu,Jian Zhao,Furao Shen,Suorong Yang*

Main category: cs.LG

TL;DR: DLC是一种用于类增量学习的插件扩展范式，通过部署额外的LoRA组件来增强基础模型，在仅增加少量参数的情况下显著提升准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的类增量学习方法存在遗忘问题或稳定性-可塑性困境，而扩展方法虽然能获得更高准确率，但通常需要显著增加参数数量。需要一种高效且参数友好的增量学习方案。

Method: 提出DLC（Deployment of extra LoRA Components）插件扩展范式：将基于重放或蒸馏训练的特征提取器作为基础模型，为每个任务使用低秩适应（LoRA）向基础模型的深层注入任务特定残差。推理时聚合带任务特定残差的表示进行分类预测，并引入轻量级加权单元来缓解非目标LoRA插件的干扰。

Result: 在ImageNet-100上，仅使用标准ResNet-18 4%的参数，DLC模型实现了8%的准确率显著提升，表现出卓越的效率。在固定内存预算下能够超越最先进方法。

Conclusion: DLC作为一种即插即用的增强方法，能够高效扩展基础方法，在类增量学习中实现高准确率和参数效率的良好平衡，为解决遗忘问题和稳定性-可塑性困境提供了有效方案。

Abstract: Existing class-incremental learning (CIL) approaches based on replay or knowledge distillation are often constrained by forgetting or the stability-plasticity dilemma. Some expansion-based approaches could achieve higher accuracy. However, they always require significant parameter increases. In this paper, we propose a plugin extension paradigm termed the Deployment of extra LoRA Components (DLC) for non-pre-trained CIL scenarios.We treat the feature extractor trained through replay or distillation as a base model with rich knowledge. For each task, we use Low-Rank Adaptation (LoRA) to inject task-specific residuals into the base model's deep layers. During inference, representations with task-specific residuals are aggregated to produce classification predictions. To mitigate interference from non-target LoRA plugins, we introduce a lightweight weighting unit. This unit learns to assign importance scores to different LoRA-tuned representations. Like downloadable contents in software, our method serves as a plug-and-play enhancement that efficiently extends the base methods. Remarkably, on the large-scale ImageNet-100, with merely 4 % of the parameters of a standard ResNet-18, our DLC model achieves a significant 8 % improvement in accuracy, demonstrating exceptional efficiency. Moreover, it could surpass state-of-the-art methods under the fixed memory budget.

</details>


### [47] [Towards Irreversible Machine Unlearning for Diffusion Models](https://arxiv.org/abs/2512.03564)
*Xun Yuan,Zilong Zhao,Jiayu Li,Aryan Pasikhani,Prosanta Gope,Biplab Sikdar*

Main category: cs.LG

TL;DR: 本文提出了一种针对扩散模型遗忘学习的重新学习攻击（DiMRA），能够逆转基于微调的遗忘方法，并提出了基于记忆的扩散模型遗忘方法（DiMUM）来增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成合成图像方面表现出色，但存在安全、隐私和版权问题，需要遗忘学习技术来让模型忘记特定训练数据。然而，现有的基于微调的遗忘方法存在安全漏洞，容易被攻击者逆转。

Method: 1. 提出DiMRA攻击：在不知道遗忘元素的情况下，通过在辅助数据集上优化已遗忘的扩散模型来逆转遗忘过程；2. 提出DiMUM防御方法：通过记忆替代数据或特征来替换目标遗忘数据，而不是简单地遗忘。

Result: 实验证明DiMRA能够有效逆转最先进的基于微调的扩散模型遗忘方法，揭示了现有技术的脆弱性。DiMUM在保持扩散模型生成性能的同时，显著增强了对抗DiMRA攻击的鲁棒性。

Conclusion: 基于微调的扩散模型遗忘方法存在安全漏洞，容易被重新学习攻击逆转。提出的DiMUM方法通过记忆替代内容而非简单遗忘，提供了更鲁棒的解决方案，为扩散模型的安全应用提供了重要保障。

Abstract: Diffusion models are renowned for their state-of-the-art performance in generating synthetic images. However, concerns related to safety, privacy, and copyright highlight the need for machine unlearning, which can make diffusion models forget specific training data and prevent the generation of sensitive or unwanted content. Current machine unlearning methods for diffusion models are primarily designed for conditional diffusion models and focus on unlearning specific data classes or features. Among these methods, finetuning-based machine unlearning methods are recognized for their efficiency and effectiveness, which update the parameters of pre-trained diffusion models by minimizing carefully designed loss functions. However, in this paper, we propose a novel attack named Diffusion Model Relearning Attack (DiMRA), which can reverse the finetuning-based machine unlearning methods, posing a significant vulnerability of this kind of technique. Without prior knowledge of the unlearning elements, DiMRA optimizes the unlearned diffusion model on an auxiliary dataset to reverse the unlearning, enabling the model to regenerate previously unlearned elements. To mitigate this vulnerability, we propose a novel machine unlearning method for diffusion models, termed as Diffusion Model Unlearning by Memorization (DiMUM). Unlike traditional methods that focus on forgetting, DiMUM memorizes alternative data or features to replace targeted unlearning data or features in order to prevent generating such elements. In our experiments, we demonstrate the effectiveness of DiMRA in reversing state-of-the-art finetuning-based machine unlearning methods for diffusion models, highlighting the need for more robust solutions. We extensively evaluate DiMUM, demonstrating its superior ability to preserve the generative performance of diffusion models while enhancing robustness against DiMRA.

</details>


### [48] [Optimal Transportation and Alignment Between Gaussian Measures](https://arxiv.org/abs/2512.03579)
*Sanjit Dandapanthula,Aleksandr Podkopaev,Shiva Prasad Kasiviswanathan,Aaditya Ramdas,Ziv Goldfeld*

Main category: cs.LG

TL;DR: 本文为高斯分布下的最优传输和Gromov-Wasserstein对齐提供了全面的理论框架和闭式解，解决了文献中的多个空白问题，并应用于知识蒸馏和异构聚类任务。


<details>
  <summary>Details</summary>
Motivation: 最优传输和Gromov-Wasserstein对齐在数据科学和机器学习中广泛用于比较、转换和聚合异构数据集，但由于计算成本高，大规模应用通常依赖于高斯分布和二次成本的闭式解。本文旨在填补文献中的空白，扩展这些框架的适用性。

Method: 1. 针对可分离希尔伯特空间上非中心高斯分布的内积GW对齐，给出了闭式表达式（需通过酉算子的二次优化）；2. 当至少一个高斯分布为中心时，提供完全闭式解；3. 为中心高斯分布提供IGW重心解析解；4. 将具有成对二次成本的高斯多边际OT简化为可处理的优化问题，并提出使用秩缺陷约束的高效算法。

Result: 1. 解决了非中心高斯分布IGW对齐的开放问题，提供了闭式表达式和紧致的解析上下界；2. 为中心情况提供了完全闭式解；3. 为中心高斯分布提供了IGW重心的解析解；4. 实现了高斯多边际OT的高效算法；5. 在合成和真实数据集上成功应用于知识蒸馏和异构聚类任务。

Conclusion: 本文为高斯分布下的OT和GW对齐提供了全面的理论框架，填补了文献中的关键空白，扩展了这些几何框架的适用性，并通过实际应用验证了其效用，为大规模数据科学应用提供了理论基础和实用工具。

Abstract: Optimal transport (OT) and Gromov-Wasserstein (GW) alignment provide interpretable geometric frameworks for comparing, transforming, and aggregating heterogeneous datasets -- tasks ubiquitous in data science and machine learning. Because these frameworks are computationally expensive, large-scale applications often rely on closed-form solutions for Gaussian distributions under quadratic cost. This work provides a comprehensive treatment of Gaussian, quadratic cost OT and inner product GW (IGW) alignment, closing several gaps in the literature to broaden applicability. First, we treat the open problem of IGW alignment between uncentered Gaussians on separable Hilbert spaces by giving a closed-form expression up to a quadratic optimization over unitary operators, for which we derive tight analytic upper and lower bounds. If at least one Gaussian measure is centered, the solution reduces to a fully closed-form expression, which we further extend to an analytic solution for the IGW barycenter between centered Gaussians. We also present a reduction of Gaussian multimarginal OT with pairwise quadratic costs to a tractable optimization problem and provide an efficient algorithm to solve it using a rank-deficiency constraint. To demonstrate utility, we apply our results to knowledge distillation and heterogeneous clustering on synthetic and real-world datasets.

</details>


### [49] [Federated Learning and Trajectory Compression for Enhanced AIS Coverage](https://arxiv.org/abs/2512.03584)
*Thomas Gräupl,Andreas Reisenbauer,Marcel Hecko,Anil Rasouli,Anita Graser,Melitta Dragaschnig,Axel Weissenfeld,Gilles Dejaegere,Mahmoud Sakr*

Main category: cs.LG

TL;DR: VesselEdge系统利用联邦学习和带宽受限轨迹压缩技术，通过扩展AIS覆盖范围来增强海上态势感知能力，将船舶转变为移动传感器，实现实时异常检测和低带宽下的高效数据传输。


<details>
  <summary>Details</summary>
Motivation: 海上态势感知依赖于AIS数据，但现有系统存在覆盖范围有限、数据传输带宽受限等问题，需要一种能够扩展AIS覆盖、实现实时异常检测并适应低带宽环境的新型解决方案。

Method: 系统采用联邦学习框架（M3fed模型）和带宽受限轨迹压缩算法（BWC-DR-A算法），将船舶转变为移动传感器，优先传输异常数据，实现分布式学习和高效数据传输。

Result: 初步结果显示VesselEdge系统能有效提高AIS覆盖范围和海上态势感知能力，在历史数据测试中表现出良好的性能。

Conclusion: VesselEdge系统通过结合联邦学习和轨迹压缩技术，成功扩展了海上AIS覆盖范围，增强了实时异常检测能力，为低带宽环境下的海上态势感知提供了有效解决方案。

Abstract: This paper presents the VesselEdge system, which leverages federated learning and bandwidth-constrained trajectory compression to enhance maritime situational awareness by extending AIS coverage. VesselEdge transforms vessels into mobile sensors, enabling real-time anomaly detection and efficient data transmission over low-bandwidth connections. The system integrates the M3fed model for federated learning and the BWC-DR-A algorithm for trajectory compression, prioritizing anomalous data. Preliminary results demonstrate the effectiveness of VesselEdge in improving AIS coverage and situational awareness using historical data.

</details>


### [50] [Observation-driven correction of numerical weather prediction for marine winds](https://arxiv.org/abs/2512.03606)
*Matteo Peduto,Qidong Yang,Jonathan Giezendanner,Devis Tuia,Sherrie Wang*

Main category: cs.LG

TL;DR: 该论文提出了一种基于Transformer的深度学习架构，通过同化最新的现场观测数据来修正全球天气预报系统(GFS)的输出，从而改进海洋风速预测。


<details>
  <summary>Details</summary>
Motivation: 准确的海洋风速预测对于安全航行、船舶路线规划和能源运营至关重要，但由于海洋观测数据稀疏、异构且时间变化大，预测仍然具有挑战性。现有数值天气预报模型存在系统性误差，需要有效的后处理方法进行修正。

Method: 将风速预测重新定义为观测信息驱动的全球数值天气预报模型修正问题。提出基于Transformer的深度学习架构：1) 通过掩码和基于集合的注意力机制处理不规则和时间变化的观测集；2) 通过交叉注意力将预测条件化于最近的观测-预报对；3) 使用循环时间嵌入和坐标感知的位置表示，实现任意空间坐标的单次推理。模型能够处理多种观测平台数据。

Result: 在大西洋区域使用ICOADS观测数据评估，模型在所有48小时预报时效内都降低了GFS 10米风速的RMSE：1小时预报时效改善45%，48小时预报时效改善13%。空间分析显示在海岸线和航运路线等观测最丰富的区域改进最显著。模型能够同时生成站点特定预测和流域尺度网格化产品。

Conclusion: 该研究展示了一种实用、低延迟的后处理方法，通过学习修正系统性预报误差来补充数值天气预报。基于token化的架构能够自然适应异构观测平台，为海洋风速预测提供了有效的修正方案。

Abstract: Accurate marine wind forecasts are essential for safe navigation, ship routing, and energy operations, yet they remain challenging because observations over the ocean are sparse, heterogeneous, and temporally variable. We reformulate wind forecasting as observation-informed correction of a global numerical weather prediction (NWP) model. Rather than forecasting winds directly, we learn local correction patterns by assimilating the latest in-situ observations to adjust the Global Forecast System (GFS) output. We propose a transformer-based deep learning architecture that (i) handles irregular and time-varying observation sets through masking and set-based attention mechanisms, (ii) conditions predictions on recent observation-forecast pairs via cross-attention, and (iii) employs cyclical time embeddings and coordinate-aware location representations to enable single-pass inference at arbitrary spatial coordinates. We evaluate our model over the Atlantic Ocean using observations from the International Comprehensive Ocean-Atmosphere Data Set (ICOADS) as reference. The model reduces GFS 10-meter wind RMSE at all lead times up to 48 hours, achieving 45% improvement at 1-hour lead time and 13% improvement at 48-hour lead time. Spatial analyses reveal the most persistent improvements along coastlines and shipping routes, where observations are most abundant. The tokenized architecture naturally accommodates heterogeneous observing platforms (ships, buoys, tide gauges, and coastal stations) and produces both site-specific predictions and basin-scale gridded products in a single forward pass. These results demonstrate a practical, low-latency post-processing approach that complements NWP by learning to correct systematic forecast errors.

</details>


### [51] [Cyclical Temporal Encoding and Hybrid Deep Ensembles for Multistep Energy Forecasting](https://arxiv.org/abs/2512.03656)
*Salim Khazem,Houssam Kanso*

Main category: cs.LG

TL;DR: 该论文提出了一种统一的深度学习框架，结合循环时间编码和混合LSTM-CNN架构，用于提高多步能源预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 准确的电力消费预测对于需求管理和智能电网运营至关重要。现有方法在捕捉长期季节性效应和短期局部模式方面存在局限，需要更有效的预测框架。

Method: 1. 使用正弦余弦编码系统性地转换基于日历的属性，以保留周期结构；2. 通过相关性分析评估预测相关性；3. 采用由LSTM、CNN和专门针对每个预测范围的MLP回归器元学习器组成的集成模型；4. 使用一年全国消费数据集进行实验研究。

Result: 在所有七个预测范围内都取得了持续改进，混合模型实现了比单个架构和先前方法更低的RMSE和MAE。消融分析显示循环编码和日历特征对性能有显著贡献。

Conclusion: 结合循环时间表示与互补的深度学习结构具有明显优势。这是首个在统一短期能源预测框架中联合评估时间编码、日历特征和混合集成架构的工作。

Abstract: Accurate electricity consumption forecasting is essential for demand management and smart grid operations. This paper introduces a unified deep learning framework that integrates cyclical temporal encoding with hybrid LSTM-CNN architectures to enhance multistep energy forecasting. We systematically transform calendar-based attributes using sine cosine encodings to preserve periodic structure and evaluate their predictive relevance through correlation analysis. To exploit both long-term seasonal effects and short-term local patterns, we employ an ensemble model composed of an LSTM, a CNN, and a meta-learner of MLP regressors specialized for each forecast horizon. Using a one year national consumption dataset, we conduct an extensive experimental study including ablation analyses with and without cyclical encodings and calendar features and comparisons with established baselines from the literature. Results demonstrate consistent improvements across all seven forecast horizons, with our hybrid model achieving lower RMSE and MAE than individual architectures and prior methods. These findings confirm the benefit of combining cyclical temporal representations with complementary deep learning structures. To our knowledge, this is the first work to jointly evaluate temporal encodings, calendar-based features, and hybrid ensemble architectures within a unified short-term energy forecasting framework.

</details>


### [52] [Feature-aware Modulation for Learning from Temporal Tabular Data](https://arxiv.org/abs/2512.03678)
*Hao-Run Cai,Han-Jia Ye*

Main category: cs.LG

TL;DR: 该论文提出了一种特征感知的时间调制机制来处理表格数据中的时间分布偏移问题，通过调节特征的统计特性来平衡模型的泛化能力和适应性。


<details>
  <summary>Details</summary>
Motivation: 表格机器学习在实际部署中面临时间分布偏移的挑战，静态模型假设固定映射但缺乏适应性，而自适应模型可能过度拟合瞬时模式，需要在鲁棒性和适应性之间找到平衡。

Method: 提出特征感知的时间调制机制，通过将特征表示条件化于时间上下文来调节特征的统计属性（如尺度和偏度），从而对齐不同时间阶段的特征语义。

Result: 基准评估验证了该方法在处理表格数据时间偏移方面的有效性，实现了轻量级但强大的适应能力。

Conclusion: 通过调节特征统计特性来对齐跨时间特征语义的方法，能够有效平衡泛化性和适应性，为处理表格数据中的时间分布偏移提供了有效解决方案。

Abstract: While tabular machine learning has achieved remarkable success, temporal distribution shifts pose significant challenges in real-world deployment, as the relationships between features and labels continuously evolve. Static models assume fixed mappings to ensure generalization, whereas adaptive models may overfit to transient patterns, creating a dilemma between robustness and adaptability. In this paper, we analyze key factors essential for constructing an effective dynamic mapping for temporal tabular data. We discover that evolving feature semantics-particularly objective and subjective meanings-introduce concept drift over time. Crucially, we identify that feature transformation strategies are able to mitigate discrepancies in feature representations across temporal stages. Motivated by these insights, we propose a feature-aware temporal modulation mechanism that conditions feature representations on temporal context, modulating statistical properties such as scale and skewness. By aligning feature semantics across time, our approach achieves a lightweight yet powerful adaptation, effectively balancing generalizability and adaptability. Benchmark evaluations validate the effectiveness of our method in handling temporal shifts in tabular data.

</details>


### [53] [Unlocking the Invisible Urban Traffic Dynamics under Extreme Weather: A New Physics-Constrained Hamiltonian Learning Algorithm](https://arxiv.org/abs/2512.03744)
*Xuhui Lin,Qiuchen Lu*

Main category: cs.LG

TL;DR: 提出了一种基于物理约束的哈密顿学习算法，通过"结构不可逆性检测"和"能量景观重建"来识别交通系统的隐藏结构损伤，解决了传统表面指标无法检测"虚假恢复"的问题。


<details>
  <summary>Details</summary>
Motivation: 当前城市交通系统韧性评估方法依赖表面恢复指标，无法检测隐藏的结构损伤，导致无法区分真正的恢复和"虚假恢复"（流量指标正常化但系统动力学永久退化）。

Method: 开发了物理约束的哈密顿学习算法，结合结构不可逆性检测和能量景观重建，提取低维状态表示，通过物理约束优化识别准哈密顿结构，并通过能量景观比较量化结构变化。

Result: 对伦敦2021年极端降雨事件的分析表明，虽然表面指标完全恢复，但该算法检测到64.8%的结构损伤被传统监测方法遗漏。

Conclusion: 该框架为主动结构风险评估提供了工具，使基础设施投资能够基于真实的系统健康状况而非误导性的表面指标。

Abstract: Urban transportation systems face increasing resilience challenges from extreme weather events, but current assessment methods rely on surface-level recovery indicators that miss hidden structural damage. Existing approaches cannot distinguish between true recovery and "false recovery," where traffic metrics normalize, but the underlying system dynamics permanently degrade. To address this, a new physics-constrained Hamiltonian learning algorithm combining "structural irreversibility detection" and "energy landscape reconstruction" has been developed. Our approach extracts low-dimensional state representations, identifies quasi-Hamiltonian structures through physics-constrained optimization, and quantifies structural changes via energy landscape comparison. Analysis of London's extreme rainfall in 2021 demonstrates that while surface indicators were fully recovered, our algorithm detected 64.8\% structural damage missed by traditional monitoring. Our framework provides tools for proactive structural risk assessment, enabling infrastructure investments based on true system health rather than misleading surface metrics.

</details>


### [54] [Universally Converging Representations of Matter Across Scientific Foundation Models](https://arxiv.org/abs/2512.03750)
*Sathya Edamadaka,Soojung Yang,Ju Li,Rafael Gómez-Bombarelli*

Main category: cs.LG

TL;DR: 研究发现近60个科学模型（涵盖字符串、图、3D原子和蛋白质模态）在化学系统中表现出高度对齐的表示学习，表明基础模型学习物理现实的共同底层表示，但当前模型仍受训练数据和归纳偏置限制。


<details>
  <summary>Details</summary>
Motivation: 理解不同模态和架构的机器学习模型是否学习相似的内部物质表示，这对于构建能够可靠泛化到训练域之外的科学基础模型至关重要。尽管在语言和视觉领域已观察到表示收敛，但在科学领域尚未系统探索。

Method: 分析了近60个科学模型的表示学习，涵盖字符串、图、3D原子和蛋白质等不同模态。研究了在不同数据集上训练的模型对小分子的表示相似性，以及机器学习原子间势能在表示空间中的收敛情况。

Result: 1. 不同模型在化学系统中表现出高度对齐的表示学习；2. 在不同数据集上训练的模型对小分子有高度相似的表示；3. 机器学习原子间势能随着性能提升在表示空间中收敛；4. 发现两种不同的模型状态：在类似训练输入时，高性能模型紧密对齐，弱模型在表示空间中发散到局部次优解；在完全不同结构时，几乎所有模型都坍缩到低信息表示。

Conclusion: 科学基础模型学习物理现实的共同底层表示，但当前模型仍受训练数据和归纳偏置限制，尚未编码真正通用的结构。表示对齐可作为科学基础模型通用性的定量基准，用于追踪物质通用表示的出现，并选择在模态、物质域和科学任务间转移最好的模型。

Abstract: Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.

</details>


### [55] [Deep Unfolding: Recent Developments, Theory, and Design Guidelines](https://arxiv.org/abs/2512.03768)
*Nir Shlezinger,Santiago Segarra,Yi Zhang,Dvir Avrahami,Zohar Davidov,Tirza Routtenberg,Yonina C. Eldar*

Main category: cs.LG

TL;DR: 深度展开（Deep Unfolding）是一种将迭代优化算法转化为结构化、可训练的机器学习架构的框架，旨在融合经典优化方法的理论保证与机器学习的数据驱动能力。


<details>
  <summary>Details</summary>
Motivation: 经典迭代优化算法虽然具有可解释性和理论保证，但通常依赖替代目标、需要仔细的超参数调优且计算延迟较大；而机器学习虽然具有强大的数据驱动建模能力，但缺乏优化驱动推理所需的结构、透明度和效率。深度展开旨在弥合这两种范式之间的差距。

Method: 深度展开通过系统地将迭代优化算法转化为结构化、可训练的机器学习架构来实现。文章介绍了四种代表性的设计范式，并讨论了由其迭代性质产生的独特训练方案。

Result: 文章综述了深度展开的理论进展，包括收敛性和泛化保证的建立，并提供了比较性的定性和实证研究，说明了深度展开在复杂性、可解释性和鲁棒性方面的相对权衡。

Conclusion: 深度展开为信号处理中的优化方法提供了一个有前景的框架，它融合了经典优化算法的理论优势与机器学习的数据驱动能力，为优化驱动的推理提供了新的可能性。

Abstract: Optimization methods play a central role in signal processing, serving as the mathematical foundation for inference, estimation, and control. While classical iterative optimization algorithms provide interpretability and theoretical guarantees, they often rely on surrogate objectives, require careful hyperparameter tuning, and exhibit substantial computational latency. Conversely, machine learning (ML ) offers powerful data-driven modeling capabilities but lacks the structure, transparency, and efficiency needed for optimization-driven inference. Deep unfolding has recently emerged as a compelling framework that bridges these two paradigms by systematically transforming iterative optimization algorithms into structured, trainable ML architectures. This article provides a tutorial-style overview of deep unfolding, presenting a unified perspective of methodologies for converting optimization solvers into ML models and highlighting their conceptual, theoretical, and practical implications. We review the foundations of optimization for inference and for learning, introduce four representative design paradigms for deep unfolding, and discuss the distinctive training schemes that arise from their iterative nature. Furthermore, we survey recent theoretical advances that establish convergence and generalization guarantees for unfolded optimizers, and provide comparative qualitative and empirical studies illustrating their relative trade-offs in complexity, interpretability, and robustness.

</details>


### [56] [Forensic Activity Classification Using Digital Traces from iPhones: A Machine Learning-based Approach](https://arxiv.org/abs/2512.03786)
*Conor McCarthy,Jan Peter van Zandwijk,Marcel Worring,Zeno Geradts*

Main category: cs.LG

TL;DR: 基于智能手机和智能手表传感器数据，开发机器学习方法将数字痕迹转化为不同身体活动的似然比，用于法医调查中的活动识别和重建。


<details>
  <summary>Details</summary>
Motivation: 智能手机和智能手表在日常生活中的普及提供了丰富的用户行为信息，其内置运动传感器产生的数字痕迹为法医调查人员了解个人身体活动提供了机会。

Method: 提出基于机器学习的方法，将数字痕迹转化为不同身体活动的似然比（LRs），使用包含四种不同iPhone设备数据和19种活动标签的新数据集NFI_FARED进行评估，并将方法扩展到同时分析多个活动（或活动组）并创建活动时间线。

Result: 在171个可能的活动中，该方法能够为167个活动配对生成有用的似然比系统，表明该方法在区分不同身体活动方面具有良好效果。

Conclusion: 该方法能够有效利用智能手机传感器数据进行法医调查中的活动识别，公开的数据集和代码将促进该领域的进一步研究，特别是在法医调查的早期和后期阶段提供活动时间线分析支持。

Abstract: Smartphones and smartwatches are ever-present in daily life, and provide a rich source of information on their users' behaviour. In particular, digital traces derived from the phone's embedded movement sensors present an opportunity for a forensic investigator to gain insight into a person's physical activities. In this work, we present a machine learning-based approach to translate digital traces into likelihood ratios (LRs) for different types of physical activities. Evaluating on a new dataset, NFI\_FARED, which contains digital traces from four different types of iPhones labelled with 19 activities, it was found that our approach could produce useful LR systems to distinguish 167 out of a possible 171 activity pairings. The same approach was extended to analyse likelihoods for multiple activities (or groups of activities) simultaneously and create activity timelines to aid in both the early and latter stages of forensic investigations. The dataset and all code required to replicate the results have also been made public to encourage further research on this topic.

</details>


### [57] [Adaptive Identification and Modeling of Clinical Pathways with Process Mining](https://arxiv.org/abs/2512.03787)
*Francesco Vitale,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 提出基于过程挖掘的两阶段临床路径建模方法，利用一致性检查扩展临床路径知识库，在COVID-19并发症数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 临床路径是标准化的医疗计划，但基于临床指南和领域专家知识的手工建模困难，难以反映不同疾病变异或组合的实际最佳实践。

Method: 两阶段建模方法：第一阶段收集特定疾病的历史数据，构建过程模型；第二阶段将新数据与参考模型进行一致性检查，根据检查结果扩展知识库，为新的变异或疾病组合创建更具体的模型。

Result: 在Synthea基准数据集（模拟SARS-CoV-2感染及COVID-19并发症）上验证，方法能以95.62%的AUC精度扩展临床路径知识库，同时保持67.11%的弧度简洁性。

Conclusion: 该方法能够有效扩展临床路径知识库，为不同疾病变异和组合提供更精确的标准化治疗方案，提高医疗质量并优化资源使用。

Abstract: Clinical pathways are specialized healthcare plans that model patient treatment procedures. They are developed to provide criteria-based progression and standardize patient treatment, thereby improving care, reducing resource use, and accelerating patient recovery. However, manual modeling of these pathways based on clinical guidelines and domain expertise is difficult and may not reflect the actual best practices for different variations or combinations of diseases. We propose a two-phase modeling method using process mining, which extends the knowledge base of clinical pathways by leveraging conformance checking diagnostics. In the first phase, historical data of a given disease is collected to capture treatment in the form of a process model. In the second phase, new data is compared against the reference model to verify conformance. Based on the conformance checking results, the knowledge base can be expanded with more specific models tailored to new variants or disease combinations. We demonstrate our approach using Synthea, a benchmark dataset simulating patient treatments for SARS-CoV-2 infections with varying COVID-19 complications. The results show that our method enables expanding the knowledge base of clinical pathways with sufficient precision, peaking to 95.62% AUC while maintaining an arc-degree simplicity of 67.11%.

</details>


### [58] [EfficientECG: Cross-Attention with Feature Fusion for Efficient Electrocardiogram Classification](https://arxiv.org/abs/2512.03804)
*Hanhui Deng,Xinglin Li,Jie Luo,Zhanpeng Jin,Di Wu*

Main category: cs.LG

TL;DR: 该论文提出了一种基于深度学习的ECG诊断模型，包括轻量级分类模型EfficientECG和跨注意力特征融合模型，旨在提高心电图分析的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 心电图是诊断心脏异常的重要信号，但现有ECG模型误诊率高。作者希望通过深度学习技术自动提取ECG特征，构建准确快速的诊断模型，减轻医疗工作者的负担。

Method: 1. 基于EfficientNet设计EfficientECG模型，用于处理高频长序列多导联ECG数据；2. 提出跨注意力特征融合模型，整合多导联ECG数据与多特征（如性别、年龄）。

Result: 在代表性ECG数据集上的评估表明，该模型在精度、多特征融合和轻量化方面优于现有最先进方法。

Conclusion: 提出的深度学习方法能够有效管理和分析ECG数据，构建准确快速的诊断模型，为心电图分析提供了新的技术方案。

Abstract: Electrocardiogram is a useful diagnostic signal that can detect cardiac abnormalities by measuring the electrical activity generated by the heart. Due to its rapid, non-invasive, and richly informative characteristics, ECG has many emerging applications. In this paper, we study novel deep learning technologies to effectively manage and analyse ECG data, with the aim of building a diagnostic model, accurately and quickly, that can substantially reduce the burden on medical workers. Unlike the existing ECG models that exhibit a high misdiagnosis rate, our deep learning approaches can automatically extract the features of ECG data through end-to-end training. Specifically, we first devise EfficientECG, an accurate and lightweight classification model for ECG analysis based on the existing EfficientNet model, which can effectively handle high-frequency long-sequence ECG data with various leading types. On top of that, we next propose a cross-attention-based feature fusion model of EfficientECG for analysing multi-lead ECG data with multiple features (e.g., gender and age). Our evaluations on representative ECG datasets validate the superiority of our model against state-of-the-art works in terms of high precision, multi-feature fusion, and lightweights.

</details>


### [59] [Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+($λ$,$λ$))-GA](https://arxiv.org/abs/2512.03805)
*Tai Nguyen,Phong Le,André Biedenkapp,Carola Doerr,Nguyen Dang*

Main category: cs.LG

TL;DR: 本文系统研究了深度强化学习在动态算法配置中的应用，针对(1+(λ,λ))-GA算法的种群规模参数控制问题，揭示了DDQN和PPO算法的两大挑战：可扩展性下降和学习不稳定性，并提出了自适应奖励偏移机制等解决方案。


<details>
  <summary>Details</summary>
Motivation: 动态算法配置(DAC)旨在为参数化优化算法高效识别控制策略。虽然已有研究利用强化学习的鲁棒性来解决算法配置的优化挑战，但将RL应用于DAC仍然困难且需要大量领域专业知识。本文旨在通过系统分析深度RL算法在DAC中的表现，揭示其根本挑战并提供解决方案。

Method: 研究采用系统分析方法，通过控制(1+(λ,λ))-GA算法在OneMax实例上的种群规模参数，深入分析DDQN和PPO两种深度强化学习算法。针对发现的挑战，提出了自适应奖励偏移机制来解决探索不足问题，并采用无折扣学习解决规划视野覆盖问题。同时分析了PPO的超参数依赖性。

Result: 研究发现DDQN和PPO在DAC中存在两大根本挑战：可扩展性下降和学习不稳定性。这些问题主要源于探索不足和规划视野覆盖不足。自适应奖励偏移机制有效解决了探索问题，无需实例特定的超参数调优。无折扣学习解决了DDQN的规划视野覆盖问题，而PPO则面临基本方差问题。配备自适应奖励偏移策略的DDQN达到了与理论推导策略相当的性能，样本效率大幅提升，比先前DAC方法优越数个数量级。

Conclusion: 深度强化学习在动态算法配置中面临可扩展性和稳定性挑战，但通过针对性的解决方案可以有效克服。自适应奖励偏移机制和无折扣学习是有效的改进策略，使得DDQN在DAC中表现出色，为RL在算法配置领域的应用提供了重要见解。

Abstract: Dynamic Algorithm Configuration (DAC) studies the efficient identification of control policies for parameterized optimization algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges in algorithm configuration. However, applying RL to DAC is challenging and often requires extensive domain expertise. We conduct a comprehensive study of deep-RL algorithms in DAC through a systematic analysis of controlling the population size parameter of the (1+($λ$,$λ$))-GA on OneMax instances. Our investigation of DDQN and PPO reveals two fundamental challenges that limit their effectiveness in DAC: scalability degradation and learning instability. We trace these issues to two primary causes: under-exploration and planning horizon coverage, each of which can be effectively addressed through targeted solutions. To address under-exploration, we introduce an adaptive reward shifting mechanism that leverages reward distribution statistics to enhance DDQN agent exploration, eliminating the need for instance-specific hyperparameter tuning and ensuring consistent effectiveness across different problem scales. In dealing with the planning horizon coverage problem, we demonstrate that undiscounted learning effectively resolves it in DDQN, while PPO faces fundamental variance issues that necessitate alternative algorithmic designs. We further analyze the hyperparameter dependencies of PPO, showing that while hyperparameter optimization enhances learning stability, it consistently falls short in identifying effective policies across various configurations. Finally, we demonstrate that DDQN equipped with our adaptive reward shifting strategy achieves performance comparable to theoretically derived policies with vastly improved sample efficiency, outperforming prior DAC approaches by several orders of magnitude.

</details>


### [60] [Log Probability Tracking of LLM APIs](https://arxiv.org/abs/2512.03816)
*Timothée Chauvin,Erwan Le Merrer,François Taïani,Gilles Tredan*

Main category: cs.LG

TL;DR: 提出了一种基于logprobs统计测试的低成本LLM API持续监控方法，比现有方法敏感1000倍且更便宜


<details>
  <summary>Details</summary>
Motivation: 现有LLM API审计方法成本过高，无法定期监控广泛可用的LLM API，导致模型更新在实践中基本未被监控，影响下游应用的可靠性和研究的可复现性

Method: 利用LLM对数概率(logprobs)的非确定性特征，基于每个token对数概率的平均值应用简单统计测试，仅需请求单个token输出

Result: 该方法能够检测到小至一次微调步骤的模型变化，比现有方法更敏感，同时成本降低1000倍

Conclusion: 基于logprobs的统计测试为LLM API的持续监控提供了一种成本效益高的解决方案，并引入了TinyChange基准来衡量审计方法对小规模现实模型变化的敏感性

Abstract: When using an LLM through an API provider, users expect the served model to remain consistent over time, a property crucial for the reliability of downstream applications and the reproducibility of research. Existing audit methods are too costly to apply at regular time intervals to the wide range of available LLM APIs. This means that model updates are left largely unmonitored in practice. In this work, we show that while LLM log probabilities (logprobs) are usually non-deterministic, they can still be used as the basis for cost-effective continuous monitoring of LLM APIs. We apply a simple statistical test based on the average value of each token logprob, requesting only a single token of output. This is enough to detect changes as small as one step of fine-tuning, making this approach more sensitive than existing methods while being 1,000x cheaper. We introduce the TinyChange benchmark as a way to measure the sensitivity of audit methods in the context of small, realistic model changes.

</details>


### [61] [Probabilistic Foundations of Fuzzy Simplicial Sets for Nonlinear Dimensionality Reduction](https://arxiv.org/abs/2512.03899)
*Janis Keck,Lukas Silvester Barth,Fatemeh,Fahimi,Parvaneh Joharinad,Jürgen Jost*

Main category: cs.LG

TL;DR: 该论文为模糊单纯形集提供了一个概率框架，将其解释为单纯形集上概率测度的边际分布，为UMAP等降维方法提供了统一的理论基础。


<details>
  <summary>Details</summary>
Motivation: 模糊单纯形集在降维和流形学习中变得越来越重要（特别是在UMAP中），但现有的代数拓扑定义缺乏清晰的概率解释，脱离了这些领域常用的理论框架。

Method: 提出了一个概率框架，将模糊单纯形集解释为单纯形集上概率测度的边际分布。具体展示了UMAP的模糊权重源于一个生成模型，该模型在随机尺度上采样Vietoris-Rips滤过，产生成对距离的累积分布函数。

Result: 该框架将模糊单纯形集连接到面偏序集上的概率模型，阐明了Kullback-Leibler散度与模糊交叉熵之间的关系，并通过底层单纯形集的布尔运算恢复了标准的t-范数和t-余范数。

Conclusion: 这个概率视角为模糊单纯形集提供了统一的概率理论基础，阐明了UMAP在该框架中的作用，并使得能够系统性地推导出新的降维方法，论文还通过使用Čech滤过和三重采样的UMAP泛化示例进行了说明。

Abstract: Fuzzy simplicial sets have become an object of interest in dimensionality reduction and manifold learning, most prominently through their role in UMAP. However, their definition through tools from algebraic topology without a clear probabilistic interpretation detaches them from commonly used theoretical frameworks in those areas. In this work we introduce a framework that explains fuzzy simplicial sets as marginals of probability measures on simplicial sets. In particular, this perspective shows that the fuzzy weights of UMAP arise from a generative model that samples Vietoris-Rips filtrations at random scales, yielding cumulative distribution functions of pairwise distances. More generally, the framework connects fuzzy simplicial sets to probabilistic models on the face poset, clarifies the relation between Kullback-Leibler divergence and fuzzy cross-entropy in this setting, and recovers standard t-norms and t-conorms via Boolean operations on the underlying simplicial sets. We then show how new embedding methods may be derived from this framework and illustrate this on an example where we generalize UMAP using Čech filtrations with triplet sampling. In summary, this probabilistic viewpoint provides a unified probabilistic theoretical foundation for fuzzy simplicial sets, clarifies the role of UMAP within this framework, and enables the systematic derivation of new dimensionality reduction methods.

</details>


### [62] [Density-Informed VAE (DiVAE): Reliable Log-Prior Probability via Density Alignment Regularization](https://arxiv.org/abs/2512.03928)
*Michele Alessi,Alessio Ansuini,Alex Rodriguez*

Main category: cs.LG

TL;DR: DiVAE是一种轻量级的数据驱动正则化方法，通过将VAE的对数先验概率与数据估计的对数密度对齐，改进潜在空间与数据空间密度结构的匹配。


<details>
  <summary>Details</summary>
Motivation: 标准VAE将潜在变量匹配到简单先验分布，忽略了数据空间中的密度结构。这导致潜在空间不能很好地反映数据分布特征，影响模型的可解释性和OOD检测性能。

Method: DiVAE通过向ELBO添加一个鲁棒的、精度加权的惩罚项，鼓励编码器根据数据空间密度按比例分配后验质量，并在先验可学习时推动先验向高密度区域移动。

Result: 在合成数据集上，DiVAE改善了潜在对数密度与真实分布的匹配、提高了先验覆盖度、改进了OOD不确定性校准。在MNIST上，DiVAE改善了先验与外部密度估计的对齐，提供了更好的可解释性，并提高了可学习先验的OOD检测性能。

Conclusion: DiVAE是一种计算开销可忽略的有效正则化方法，能够显著改善VAE的分布对齐、先验覆盖和OOD检测性能，同时增强模型的可解释性。

Abstract: We introduce Density-Informed VAE (DiVAE), a lightweight, data-driven regularizer that aligns the VAE log-prior probability $\log p_Z(z)$ with a log-density estimated from data. Standard VAEs match latents to a simple prior, overlooking density structure in the data-space. DiVAE encourages the encoder to allocate posterior mass in proportion to data-space density and, when the prior is learnable, nudges the prior toward high-density regions. This is realized by adding a robust, precision-weighted penalty to the ELBO, incurring negligible computational overhead. On synthetic datasets, DiVAE (i) improves distributional alignment of latent log-densities to its ground truth counterpart, (ii) improves prior coverage, and (iii) yields better OOD uncertainty calibration. On MNIST, DiVAE improves alignment of the prior with external estimates of the density, providing better interpretability, and improves OOD detection for learnable priors.

</details>


### [63] [Technical Report on Text Dataset Distillation](https://arxiv.org/abs/2512.03967)
*Keith Ando Ogawa,Bruno Lopes Yamamoto,Lucas Lauton de Alcantara,Victor Zacarias,Edson Bollis,Lucas Pellicer,Rosimeire Pereira Costa,Anna Helena Reali Costa,Artur Jordao*

Main category: cs.LG

TL;DR: 本文综述了文本数据集蒸馏领域的发展历程，从最初借鉴视觉领域方法到形成独立研究方向，涵盖transformer模型应用、离散文本生成、大规模模型扩展等里程碑，并指出该领域在基准标准化、文本离散性处理、复杂任务应对和实际应用方面仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 文本数据集蒸馏领域虽然已有一定发展，但与视觉领域相比研究较少，且面临文本模态的特殊挑战。本文旨在系统回顾该领域的发展历程，梳理不同蒸馏策略、关键贡献和普遍挑战，为未来研究提供参考。

Method: 本文采用文献综述方法，系统梳理文本数据集蒸馏领域的发展脉络，分析从视觉领域方法移植到形成独立研究分支的转变过程，重点关注transformer模型应用、离散文本生成、大规模模型扩展等关键技术进展。

Result: 识别了文本数据集蒸馏领域的多个重要里程碑：transformer模型的应用、离散合成文本的生成、以及扩展到超过10亿参数的仅解码器模型。同时指出了该领域仍处于成熟阶段，在基准标准化、文本离散性处理、复杂任务应对和实际应用展示等方面存在改进空间。

Conclusion: 文本数据集蒸馏已从视觉领域的简单移植发展为独立研究方向，取得了显著进展但仍面临诸多挑战。未来需要在基准标准化、离散文本处理、复杂任务适应和实际应用验证等方面继续探索，推动该领域向更成熟的方向发展。

Abstract: In the vision domain, dataset distillation arises as a technique to condense a large dataset into a smaller synthetic one that exhibits a similar result in the training process. While image data presents an extensive literature of distillation methods, text dataset distillation has fewer works in comparison. Text dataset distillation initially grew as an adaptation of efforts from the vision universe, as the particularities of the modality became clear obstacles, it rose into a separate branch of research. Several milestones mark the development of this area, such as the introduction of methods that use transformer models, the generation of discrete synthetic text, and the scaling to decoder-only models with over 1B parameters. Despite major advances in modern approaches, the field remains in a maturing phase, with room for improvement on benchmarking standardization, approaches to overcome the discrete nature of text, handling complex tasks, and providing explicit examples of real-world applications. In this report, we review past and recent advances in dataset distillation for text, highlighting different distillation strategies, key contributions, and general challenges.

</details>


### [64] [Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs](https://arxiv.org/abs/2512.03994)
*Oren Rachmil,Roy Betser,Itay Gershon,Omer Hofman,Nitay Yakoby,Yuval Meron,Idan Yankelev,Asaf Shabtai,Yuval Elovici,Roman Vainshtein*

Main category: cs.LG

TL;DR: 提出一种无需训练的高效方法，将政策违规检测视为分布外检测问题，通过白化技术处理隐藏激活，使用欧几里得范数作为合规分数，在政策基准上达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在敏感领域（法律、金融、医疗）的部署，组织需要可靠机制检测内部政策违规，现有方法如护栏系统局限于安全领域，LLM-as-a-judge和微调方法延迟高且缺乏可解释性。

Method: 将政策违规检测视为分布外检测问题，采用白化技术对模型隐藏激活进行线性变换（去相关和标准化），在变换空间中使用欧几里得范数作为合规分数，仅需政策文本和少量示例样本。

Result: 在具有挑战性的政策基准测试中，该方法取得了最先进的结果，超越了现有护栏系统和微调推理模型，为组织提供了实用且统计基础的政策感知监督框架。

Conclusion: 该方法为组织提供了轻量级、易部署的政策违规检测方案，无需训练且高效，推动了可部署AI治理的进展。

Abstract: Aligning proprietary large language models (LLMs) with internal organizational policies has become an urgent priority as organizations increasingly deploy LLMs in sensitive domains such as legal support, finance, and medical services. Beyond generic safety filters, enterprises require reliable mechanisms to detect policy violations within their regulatory and operational frameworks, where breaches can trigger legal and reputational risks. Existing content moderation frameworks, such as guardrails, remain largely confined to the safety domain and lack the robustness to capture nuanced organizational policies. LLM-as-a-judge and fine-tuning approaches, though flexible, introduce significant latency and lack interpretability. To address these limitations, we propose a training-free and efficient method that treats policy violation detection as an out-of-distribution (OOD) detection problem. Inspired by whitening techniques, we apply a linear transformation to decorrelate the model's hidden activations and standardize them to zero mean and unit variance, yielding near-identity covariance matrix. In this transformed space, we use the Euclidean norm as a compliance score to detect policy violations. The method requires only the policy text and a small number of illustrative samples, which makes it light-weight and easily deployable. On a challenging policy benchmark, our approach achieves state-of-the-art results, surpassing both existing guardrails and fine-tuned reasoning models. This work provides organizations with a practical and statistically grounded framework for policy-aware oversight of LLMs, advancing the broader goal of deployable AI governance. Code is available at: https://tinyurl.com/policy-violation-detection

</details>


### [65] [Physics-Embedded Gaussian Process for Traffic State Estimation](https://arxiv.org/abs/2512.04004)
*Yanlin Chen,Kehua Chen,Yinhai Wang*

Main category: cs.LG

TL;DR: 提出PEGP框架，将交通流物理模型嵌入高斯过程中，解决低渗透率稀疏观测下的交通状态估计问题，相比传统方法有更好的泛化性和不确定性校准。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：纯数据驱动方法缺乏物理解释且在稀疏数据下泛化性差；物理模型难以整合不确定性和捕捉真实交通复杂性；现有物理嵌入方法依赖惩罚调优且缺乏不确定性校准，对模型误设敏感。

Method: 提出物理嵌入高斯过程(PEGP)框架，设计两种基于经典交通流模型的多输出核函数，通过线性化微分算子的显式应用构建，将领域知识与数据驱动方法结合。

Result: 在HighD和NGSIM数据集上的实验显示，PEGP相比非物理基线方法有持续改进。PEGP-ARZ在稀疏观测下更可靠，PEGP-LWR在密集观测下误差更低。消融研究表明PEGP-ARZ残差与物理更一致且产生可校准、可解释的不确定性，而PEGP-LWR残差更正交且产生几乎恒定的方差场。

Conclusion: PEGP框架成功结合了物理先验和不确定性量化，能为交通状态估计提供可靠支持，解决了现有方法的局限性。

Abstract: Traffic state estimation (TSE) becomes challenging when probe-vehicle penetration is low and observations are spatially sparse. Pure data-driven methods lack physical explanations and have poor generalization when observed data is sparse. In contrast, physical models have difficulty integrating uncertainties and capturing the real complexity of traffic. To bridge this gap, recent studies have explored combining them by embedding physical structure into Gaussian process. These approaches typically introduce the governing equations as soft constraints through pseudo-observations, enabling the integration of model structure within a variational framework. However, these methods rely heavily on penalty tuning and lack principled uncertainty calibration, which makes them sensitive to model mis-specification. In this work, we address these limitations by presenting a novel Physics-Embedded Gaussian Process (PEGP), designed to integrate domain knowledge with data-driven methods in traffic state estimation. Specifically, we design two multi-output kernels informed by classic traffic flow models, constructed via the explicit application of the linearized differential operator. Experiments on HighD, NGSIM show consistent improvements over non-physics baselines. PEGP-ARZ proves more reliable under sparse observation, while PEGP-LWR achieves lower errors with denser observation. Ablation study further reveals that PEGP-ARZ residuals align closely with physics and yield calibrated, interpretable uncertainty, whereas PEGP-LWR residuals are more orthogonal and produce nearly constant variance fields. This PEGP framework combines physical priors, uncertainty quantification, which can provide reliable support for TSE.

</details>


### [66] [Efficient Public Verification of Private ML via Regularization](https://arxiv.org/abs/2512.04008)
*Zoë Ruha Bell,Anvith Thudi,Olive Franzese-McLaughlin,Nicolas Papernot,Shafi Goldwasser*

Main category: cs.LG

TL;DR: 提出首个差分隐私算法，其隐私验证成本远低于训练成本，在DP-SCO问题上实现了接近最优的隐私-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 当前差分隐私算法的验证成本与训练成本相当，数据提供者和公众缺乏高效验证模型是否满足DP保证的方法，需要降低验证成本。

Method: 通过私有化最小化一系列正则化目标，仅使用标准DP组合边界，在DP-SCO问题中实现接近最优的隐私-效用权衡。

Result: 获得了接近最优的隐私-效用权衡，且验证成本远低于训练成本，显著减少了大型数据集上的验证开销。

Conclusion: 这是首个在DP-SCO中实现接近最优隐私-效用权衡且验证成本显著低于训练成本的算法，为差分隐私验证提供了更高效的方法。

Abstract: Training with differential privacy (DP) provides a guarantee to members in a dataset that they cannot be identified by users of the released model. However, those data providers, and, in general, the public, lack methods to efficiently verify that models trained on their data satisfy DP guarantees. The amount of compute needed to verify DP guarantees for current algorithms scales with the amount of compute required to train the model. In this paper we design the first DP algorithm with near optimal privacy-utility trade-offs but whose DP guarantees can be verified cheaper than training. We focus on DP stochastic convex optimization (DP-SCO), where optimal privacy-utility trade-offs are known. Here we show we can obtain tight privacy-utility trade-offs by privately minimizing a series of regularized objectives and only using the standard DP composition bound. Crucially, this method can be verified with much less compute than training. This leads to the first known DP-SCO algorithm with near optimal privacy-utility whose DP verification scales better than training cost, significantly reducing verification costs on large datasets.

</details>


### [67] [Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions](https://arxiv.org/abs/2512.04034)
*Hong Yang,Devroop Kar,Qi Yu,Alex Ororbia,Travis Desell*

Main category: cs.LG

TL;DR: 该论文从信息论角度解释了为什么在单域数据集上训练的模型会出现OOD检测灾难性失败，提出了"域特征崩溃"理论，并通过域过滤方法验证了该理论。


<details>
  <summary>Details</summary>
Motivation: 解释为什么当前最先进的OOD检测方法在单域数据集训练时会表现出灾难性失败现象，从理论层面理解这一经验观察到的难题。

Method: 1. 从信息论角度分析，证明单域监督学习会导致域特征崩溃（I(x_d; z)=0）；2. 使用Fano不等式量化实际场景中的部分崩溃；3. 引入Domain Bench基准测试；4. 通过域过滤方法（使用预训练表示）验证理论。

Result: 1. 理论证明单域训练会导致模型完全丢弃域特定信息；2. 在MNIST等数据集上OOD检测性能极差（仅53% FPR@95）；3. 域过滤方法能有效解决该问题，为理论提供了实证支持。

Conclusion: 单域监督学习存在根本性局限，会导致域特征崩溃，从而无法进行有效的OOD检测。该研究不仅解释了经验现象，还对迁移学习以及何时微调与冻结预训练模型具有更广泛的意义。

Abstract: Why do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse -- representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano's inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) > 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.

</details>


### [68] [Convergence for Discrete Parameter Updates](https://arxiv.org/abs/2512.04051)
*Paul Wilson,Fabio Zanasi,George Constantinides*

Main category: cs.LG

TL;DR: 提出一种离散更新规则的量化训练方法，避免对连续更新的离散化，为具有固有离散结构的模型提供高效训练新途径


<details>
  <summary>Details</summary>
Motivation: 现代深度学习模型需要巨大的计算资源，量化训练通过低比特整数表示训练组件来降低计算成本，但现有方法通常依赖于对实值更新的离散化

Method: 引入离散更新规则方法，避免对连续更新的量化设计，提出一般类离散方案的收敛保证，并以多项更新规则作为具体实例

Result: 建立了离散方案的收敛保证，并通过实证评估支持多项更新规则的有效性

Conclusion: 这种离散更新视角为高效训练开辟了新途径，特别适用于具有固有离散结构的模型

Abstract: Modern deep learning models require immense computational resources, motivating research into low-precision training. Quantised training addresses this by representing training components in low-bit integers, but typically relies on discretising real-valued updates. We introduce an alternative approach where the update rule itself is discrete, avoiding the quantisation of continuous updates by design. We establish convergence guarantees for a general class of such discrete schemes, and present a multinomial update rule as a concrete example, supported by empirical evaluation. This perspective opens new avenues for efficient training, particularly for models with inherently discrete structure.

</details>


### [69] [Eval Factsheets: A Structured Framework for Documenting AI Evaluations](https://arxiv.org/abs/2512.04062)
*Florian Bordes,Candace Ross,Justine T Kao,Evangelia Spiliopoulou,Adina Williams*

Main category: cs.LG

TL;DR: 提出Eval Factsheets框架，为AI系统评估方法提供结构化文档标准，解决当前评估方法缺乏系统文档化的问题


<details>
  <summary>Details</summary>
Motivation: 当前AI领域基准测试激增，但评估方法缺乏像数据集和模型那样的结构化文档框架（如Datasheets和Model Cards），导致可复现性、透明度和决策制定方面存在挑战

Method: 提出Eval Factsheets框架，通过五维分类法（上下文、范围、结构、方法、对齐）和基于问卷的方法，为评估方法提供结构化文档标准

Result: 通过多个基准测试的案例研究证明，Eval Factsheets能够有效捕捉从传统基准到LLM-as-judge等多样化评估范式，同时保持一致性和可比性

Conclusion: 希望Eval Factsheets能被纳入现有和新发布的评估框架中，从而提高评估的透明度和可复现性

Abstract: The rapid proliferation of benchmarks has created significant challenges in reproducibility, transparency, and informed decision-making. However, unlike datasets and models -- which benefit from structured documentation frameworks like Datasheets and Model Cards -- evaluation methodologies lack systematic documentation standards. We introduce Eval Factsheets, a structured, descriptive framework for documenting AI system evaluations through a comprehensive taxonomy and questionnaire-based approach. Our framework organizes evaluation characteristics across five fundamental dimensions: Context (Who made the evaluation and when?), Scope (What does it evaluate?), Structure (With what the evaluation is built?), Method (How does it work?) and Alignment (In what ways is it reliable/valid/robust?). We implement this taxonomy as a practical questionnaire spanning five sections with mandatory and recommended documentation elements. Through case studies on multiple benchmarks, we demonstrate that Eval Factsheets effectively captures diverse evaluation paradigms -- from traditional benchmarks to LLM-as-judge methodologies -- while maintaining consistency and comparability. We hope Eval Factsheets are incorporated into both existing and newly released evaluation frameworks and lead to more transparency and reproducibility.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [70] [Smartphone Vibrometric Force Estimation for Grip Related Strength Measurements](https://arxiv.org/abs/2512.03186)
*Colin Barry,Edward Jay Wang*

Main category: cs.HC

TL;DR: 利用智能手机内置振动马达和惯性测量单元，通过振动计量力估计技术测量握力相关力量，无需额外设备


<details>
  <summary>Details</summary>
Motivation: 握力是重要的临床生物标志物，但传统测量需要专门设备。本研究探索仅使用智能手机传感器进行握力评估的方法，以实现大规模、低负担的功能健康测量

Method: 使用Google Pixel 4手机，通过同步IMU数据和真实力量测量，在不同力量轨迹下进行数据采集。应用振动计量力估计技术：当手机振动时，施加的手指力量会调制高频加速度计和陀螺仪信号的振幅。训练岭回归模型进行绝对和相对力量预测

Result: 在15折留一验证中，绝对力量估计的平均绝对误差为1.88磅，相对力量估计的平均误差为10.1%。虽然测量的是捏力而非标准全手握力，但证明了仅使用设备传感器进行智能手机力量评估的可行性

Conclusion: 该方法展示了使用智能手机内置传感器进行力量评估的潜力，一旦完成主要智能手机型号的配置分析，可能实现大规模、低负担的功能健康测量

Abstract: Hand grip strength is a widely used clinical biomarker linked to mobility, frailty, surgical outcomes, and overall health. This work explores a novel, phone only approach for estimating grip related force using a smartphone's built in vibration motor and inertial measurement unit. When the phone vibrates, applied finger force modulates the amplitude of high frequency accelerometer and gyroscope signals through Vibrometric Force Estimation. We profiled a Google Pixel 4 using synchronized IMU data and ground truth force measurements across varied force trajectories, then trained ridge regression models for both absolute and relative force prediction. In 15 fold hold one out validation, absolute force estimation achieved a mean absolute error of 1.88 lbs, while relative force estimation achieved a mean error of 10.1%. Although the method captures pinch type force rather than standardized full hand HGS, the results demonstrate the feasibility of smartphone based strength assessment using only on device sensors. This approach may enable large scale, low burden functional health measurements once profiling is completed for major smartphone models.

</details>


### [71] [DAWZY: A New Addition to AI powered "Human in the Loop" Music Co-creation](https://arxiv.org/abs/2512.03289)
*Aaron C Elkins,Sanchit Singh,Adrian Kieback,Sawyer Blankenship,Uyiosa Philip Amadasun,Aman Chadha*

Main category: cs.HC

TL;DR: DAWZY是一个开源AI助手，通过自然语言（文本/语音/哼唱）控制REAPER数字音频工作站，将高级创意意图转化为可逆操作，减少用户学习复杂界面的时间。


<details>
  <summary>Details</summary>
Motivation: 传统DAW需要大量低层级操作，打断创作流程；现有AI音乐生成器多为一次性生成，缺乏迭代开发和人类参与的机会。需要一种能保持DAW作为创作中心，同时提供自然语言交互的解决方案。

Method: 使用基于LLM的代码生成技术，将自然语言请求转化为可执行脚本；采用Model Context Protocol工具进行实时状态查询、参数调整和AI节拍生成；通过状态刷新确保准确性，使用原子脚本和撤销功能保证安全性和可逆性。

Result: DAWZY在常见制作任务中表现可靠，用户评价在可用性、控制性、学习性、协作性和愉悦度等方面均为正面。

Conclusion: DAWZY成功地将自然语言交互引入DAW创作流程，通过LLM代码生成显著减少了用户学习复杂界面的时间，同时保持了DAW作为创作中心的核心地位，为音乐制作提供了更直观、高效的交互方式。

Abstract: Digital Audio Workstations (DAWs) offer fine control, but mapping high-level intent (e.g., "warm the vocals") to low-level edits breaks creative flow. Existing artificial intelligence (AI) music generators are typically one-shot, limiting opportunities for iterative development and human contribution. We present DAWZY, an open-source assistant that turns natural-language (text/voice/hum) requests into reversible actions in REAPER. DAWZY keeps the DAW as the creative hub with a minimal GUI and voice-first interface. DAWZY uses LLM-based code generation as a novel way to significantly reduce the time users spend familiarizing themselves with large interfaces, replacing hundreds of buttons and drop-downs with a chat box. DAWZY also uses three Model Context Protocol tools for live state queries, parameter adjustment, and AI beat generation. It maintains grounding by refreshing state before mutation and ensures safety and reversibility with atomic scripts and undo. In evaluations, DAWZY performed reliably on common production tasks and was rated positively by users across Usability, Control, Learning, Collaboration, and Enjoyment.

</details>


### [72] [Teacher, But Also Student: Challenges and Tech Needs of Adult Braille Learners with Sight](https://arxiv.org/abs/2512.03398)
*Quan Zhou,Cameron Cassidy,Alyson Yin,Stacy Branham*

Main category: cs.HC

TL;DR: 研究关注盲文教师作为成年学习者面临的挑战，包括缺乏持续接触、时间有限等问题，并提出设计机会来促进盲文读写能力。


<details>
  <summary>Details</summary>
Motivation: 盲文读写能力对盲人的独立性和生活质量至关重要，但识字率持续下降。虽然盲文教师在K-12融合课堂中扮演关键角色，但先前研究几乎完全集中在盲人青少年学生身上，对视力正常的成年教师如何学习盲文知之甚少。

Method: 采访了14名教育工作者，包括13名认证的视觉障碍学生教师和1名辅助教育工作者，这些人都作为成年人学习了盲文。

Result: 研究发现这些成年盲文学习者面临三个主要挑战：(1) 缺乏一致的盲文接触来巩固知识和技能；(2) 由于成年后的多重责任而练习时间有限；(3) 寻求既吸引人又高效的学习工具。

Conclusion: 研究关注了一个被忽视的盲文学习者群体，并确定了新的设计机会来促进盲文读写能力，为改善盲文教师培训和支持提供了方向。

Abstract: Braille literacy is critical for blind individuals' independence and quality of life, yet literacy rates continue to decline. Though braille instructors in integrated K-12 classrooms play a central role in literacy development in blind youth, prior research on braille learning almost exclusively focuses on blind adolescent students. As a result, we still know little about how sighted adult teachers learn braille. To address this, we interviewed 14 educators, including 13 certificated Teachers of Students with Visual Impairments (TVIs) and 1 paraeducator, who learned braille as adults. We found that they: (1) lack consistent braille exposure to reinforce knowledge and skill; (2) have limited time to practice due to myriad responsibilities of adulthood; and thus, (3) seek learning tools that are engaging and efficient. Our research draws attention to the needs of a group of braille learners who have been overlooked and identifies new design opportunities to facilitate braille literacy.

</details>


### [73] [Why Some Seek AI, Others Seek Therapists: Mental Health in the Age of Generative AI](https://arxiv.org/abs/2512.03406)
*Junsang Park,Sarah Brown,Sharon Lynn Chu*

Main category: cs.HC

TL;DR: 研究基于健康信念模型，比较了人们对生成式AI和人类治疗师的使用意愿，发现治疗师在情感、关系和个性化方面更受重视，而AI在可及性和经济性上有优势，但情感收益和个性化才是决定采用的关键因素。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能进入心理健康领域，需要了解人们如何在AI工具和人类治疗师之间进行权衡，以及影响他们选择决策的信念因素。

Method: 基于健康信念模型，在两个群体（大学生样本N=1155和全国代表性成人样本N=651）中，使用重复测量方差分析和LASSO回归分析信念因素对使用意愿的预测作用。

Result: 治疗师在情感、关系和个性化方面持续受到重视，而生成式AI在可及性和经济性方面更受青睐。但结构性优势本身不能预测采用，情感收益和个性化才是决定性因素。学生将AI视为补充，而全国成人样本将其视为替代品。隐私和可靠性担忧限制了AI的使用。

Conclusion: 研究将健康信念模型扩展到多模态情境，强调了设计值得信赖、情感共鸣的数字心理健康工具的重要性，并揭示了不同群体对AI心理健康服务的不同接受模式。

Abstract: As generative artificial intelligence (GAI) enters the mental health landscape, questions arise about how individuals weigh AI tools against human therapists. Drawing on the Health Belief Model (HBM), this study examined belief-based predictors of intention to use GAI and therapists across two populations: a university sample (N = 1,155) and a nationally representative adult sample (N = 651). Using repeated-measures ANOVA and LASSO regression, we found that therapists were consistently valued for emotional, relational, and personalization benefits, while GAI was favored for accessibility and affordability. Yet structural advantages alone did not predict adoption; emotional benefit and personalization emerged as decisive factors. Adoption patterns diverged across groups: students treated GAI as a complement, whereas national adults approached it as a substitute. Concerns about privacy and reliability constrained GAI use in both groups. These findings extend HBM to multi-modality contexts and highlight design implications for trustworthy, emotionally resonant digital mental health tools.

</details>


### [74] [CellScout: Visual Analytics for Mining Biomarkers in Cell State Discovery](https://arxiv.org/abs/2512.03485)
*Rui Sheng,Zelin Zang,Jiachen Wang,Yan Luo,Zixin Chen,Yan Zhou,Shaolun Ruan,Huamin Qu*

Main category: cs.HC

TL;DR: 开发了CellScout可视化分析系统，基于混合专家(MoE)机器学习算法，帮助生物学家发现细胞状态与生物标志物之间的关联关系，推进细胞状态发现


<details>
  <summary>Details</summary>
Motivation: 细胞状态发现对理解生物系统和改善医疗结果至关重要，但当前方法存在内在不一致性：生物学家通常通过降维可视化细胞，将视觉聚类视为不同状态，然后寻找独特生物标志物，这一假设常因聚类内部不一致而无效，导致试错过程且高度不确定

Method: 1. 基于混合专家(MoE)技术设计机器学习算法，识别细胞群体与生物标志物之间有意义的关联关系；2. 与生物学家合作开发可视化分析系统CellScout，帮助探索和优化这些关联关系

Result: 通过专家访谈验证系统有效性，并选择代表性案例展示其在发现新细胞状态方面的能力

Conclusion: CellScout系统能够有效帮助生物学家发现细胞状态与生物标志物之间的隐藏关联关系，推进细胞状态发现过程

Abstract: Cell state discovery is crucial for understanding biological systems and enhancing medical outcomes. A key aspect of this process is identifying distinct biomarkers that define specific cell states. However, difficulties arise from the co-discovery process of cell states and biomarkers: biologists often use dimensionality reduction to visualize cells in a two- dimensional space. Then they usually interpret visually clustered cells as distinct states, from which they seek to identify unique biomarkers. However, this assumption is often invalid due to internal inconsistencies in a cluster, making the process trial-and-error and highly uncertain. Therefore, biologists urgently need effective tools to help uncover the hidden association relationships between different cell populations and their potential biomarkers. To address this problem, we first designed a machine-learning algorithm based on the Mixture-of-Experts (MoE) technique to identify meaningful associations between cell populations and biomarkers. We further developed a visual analytics system, CellScout, in collaboration with biologists, to help them explore and refine these association relationships to advance cell state discovery. We validated our system through expert interviews, from which we further selected a representative case to demonstrate its effectiveness in discovering new cell states.

</details>


### [75] [EMINDS: Understanding User Behavior Progression for Mental Health Exploration on Social Media](https://arxiv.org/abs/2512.03495)
*Rui Sheng,Yifang Wang,Xingbo Wang,Shun Dai,Qingyu Guo,Tai-Quan Peng,Huamin Qu,Dongyu Liu*

Main category: cs.HC

TL;DR: EMINDS是一个可视化分析系统，用于分析在线心理健康社区用户行为阶段模式及其对心理健康状态的长期影响


<details>
  <summary>Details</summary>
Motivation: 心理健康是紧迫的社会问题，现有序列挖掘技术无法有效探索不同群体（如恢复或恶化群体）的行为进展，也无法追踪行为对心理健康状态的潜在长期影响

Method: 开发EMINDS可视化分析系统，基于新型自动挖掘管道提取不同的行为阶段，评估频繁阶段模式对心理健康状态的潜在影响，包括交互式可视化总结行为阶段含义和阶段模式演化，以及模式中心的桑基图揭示阶段模式对心理健康影响的上下文信息

Result: 通过两个案例研究和专家访谈评估了EMINDS的有效性和可用性，通过分析Reddit用户行为，研究了影响长期心理健康的潜在阶段模式

Conclusion: EMINDS系统能够帮助专家理解阶段模式前后序列的具体变化，为在线心理健康社区的行为分析和干预提供了有效的可视化分析工具

Abstract: Mental health is an urgent societal issue, and social scientists are increasingly turning to online mental health communities (OMHCs) to analyze user behavior data for early intervention. However, existing sequence mining techniques fall short of the urgent need to explore the behavior progression of different groups (e.g., recovery or deterioration groups) and track the potential long-term impact of behaviors on mental health status. To address this issue, we introduce EMINDS, a visual analytics system built on a novel automatic mining pipeline that extracts distinct behavior stages and assesses the potential impact of frequent stage patterns on mental health status over time. The system includes a set of interactive visualizations that summarize the meaning of each behavior stage and the evolution of different stage patterns. We feature a pattern-centric Sankey diagram to reveal contextual information about the impact of stage patterns on mental health, helping experts understand the specific changes in sequences before and after a stage pattern. We evaluated the effectiveness and usability of EMINDS through two case studies and expert interviews, which examined the potential stage patterns impacting long-term mental health by analyzing user behaviors on Reddit.

</details>


### [76] [Left shifting analysis of Human-Autonomous Team interactions to analyse risks of autonomy in high-stakes AI systems](https://arxiv.org/abs/2512.03519)
*Ben Larwood,Oliver J. Sutton,Callum Cockburn*

Main category: cs.HC

TL;DR: 论文提出一个框架，用于在系统生命周期早期分析人机协作中AI故障模式，以识别风险并提高系统鲁棒性，通过C2系统案例进行说明。


<details>
  <summary>Details</summary>
Motivation: 开发包含AI组件的高风险自主系统很复杂，错误后果可能灾难性，但难以规划所有操作场景。在人类操作员面临压力的短决策时间场景中，故障风险加剧。缺乏对AI故障模式的理解阻碍了AI在智能系统中的稳健应用，导致项目时间、风险和成本增加。

Method: 提出一个框架，基于LaMonica等人（2022）的人机团队建模，通过分析人机交互和探索每个方面的故障模式，系统性地识别整个操作领域中的人机交互风险。该方法应在系统的整个操作设计域范围内进行分析。

Result: 该框架能够早期表征人机协作在操作环境中出现的风险，通过理解涌现行为提高系统鲁棒性。以支持指挥与控制（C2）系统的AI助手为例进行了说明。

Conclusion: 系统工程的"左移"原则应包括AI故障案例分析作为系统生命周期设计阶段的一部分。提出的框架能够系统识别人机交互风险，提高高风险自主系统的稳健性。

Abstract: Developing high-stakes autonomous systems that include Artificial Intelligence (AI) components is complex; the consequences of errors can be catastrophic, yet it is challenging to plan for all operational cases. In stressful scenarios for the human operator, such as short decision-making timescales, the risk of failures is exacerbated. A lack of understanding of AI failure modes obstructs this and so blocks the robust implementation of applications of AI in smart systems. This prevents early risk identification, leading to increased time, risk and cost of projects.
  A key tenet of Systems Engineering and acquisition engineering is centred around a "left-shift" in test and evaluation activities to earlier in the system lifecycle, to allow for "accelerated delivery of [systems] that work". We argue it is therefore essential that this shift includes the analysis of AI failure cases as part of the design stages of the system life cycle. Our proposed framework enables the early characterisation of risks emerging from human-autonomy teaming (HAT) in operational contexts. The cornerstone of this is a new analysis of AI failure modes, built on the seminal modelling of human-autonomy teams laid out by LaMonica et al., 2022. Using the analysis of the interactions between human and autonomous systems and exploring the failure modes within each aspect, our approach provides a way to systematically identify human-AI interactions risks across the operational domain of the system of interest. The understanding of the emergent behaviour enables increased robustness of the system, for which the analysis should be undertaken over the whole scope of its operational design domain. This approach is illustrated through an example use case for an AI assistant supporting a Command & Control (C2) System.

</details>


### [77] [Synthetic Cognitive Walkthrough: Aligning Large Language Model Performance with Human Cognitive Walkthrough](https://arxiv.org/abs/2512.03568)
*Ruican Zhong,David W. McDonald,Gary Hsieh*

Main category: cs.HC

TL;DR: 研究探索大语言模型能否模拟人类在认知走查中的行为，发现LLMs能导航界面并提供合理推理，但行为与人类不同，通过额外提示可预测人类识别的失败点


<details>
  <summary>Details</summary>
Motivation: 传统认知走查等可用性测试成本高昂，而具备视觉推理和UI导航能力的大语言模型为自动化认知走查提供了机会

Method: 比较GPT-4和Gemini-2.5-pro大语言模型与人类参与者在认知走查中的表现，包括任务完成率、导航路径和失败点识别

Result: LLMs提示的认知走查比人类达到更高的任务完成率，遵循更优的导航路径，但识别出的潜在失败点较少；通过额外提示，LLMs能预测人类识别的失败点，使其表现与人类参与者对齐

Conclusion: 虽然LLMs不能完全复制人类行为，但可用于扩展可用性走查并提供UI洞察，作为传统可用性测试的有价值补充

Abstract: Conducting usability testing like cognitive walkthrough (CW) can be costly. Recent developments in large language models (LLMs), with visual reasoning and UI navigation capabilities, present opportunities to automate CW. We explored whether LLMs (GPT-4 and Gemini-2.5-pro) can simulate human behavior in CW by comparing their walkthroughs with human participants. While LLMs could navigate interfaces and provide reasonable rationales, their behavior differed from humans. LLM-prompted CW achieved higher task completion rates than humans and followed more optimal navigation paths, while identifying fewer potential failure points. However, follow-up studies demonstrated that with additional prompting, LLMs can predict human-identified failure points, aligning their performance with human participants. Our work highlights that while LLMs may not replicate human behaviors exactly, they can be leveraged for scaling usability walkthroughs and providing UI insights, offering a valuable complement to traditional usability testing.

</details>


### [78] [Head, posture, and full-body gestures in interactive communication](https://arxiv.org/abs/2512.03636)
*Ľuboš Hládek,Bernhard U. Seeber*

Main category: cs.HC

TL;DR: 研究探讨在噪音环境下全身动作对沟通的影响，发现噪音增加时手势更复杂、头部上下运动更明显，但头部运动在倾听时减少，手势-语音同步性基本不受影响。


<details>
  <summary>Details</summary>
Motivation: 当面对面交流因背景噪音或干扰者而变得困难时，视觉线索的作用变得尤为重要。以往研究主要关注头部或手部动作，本研究旨在探索在声学不利条件下全身动作的作用。

Method: 在虚拟声学环境中进行自由对话实验，使用新开发的标签系统描述对话动作，分析不同类型动作的频率，并评估手势-语音同步性以衡量手势质量。

Result: 更高噪音水平导致说话和倾听时手势复杂度增加，头部上下运动更明显，但倾听时的头部运动相对减少。同步性和峰值速度不受噪音影响，手势质量仅轻微变化。

Conclusion: 结果支持先前关于手势频率的发现，但手势-语音同步性变化有限。研究揭示了全身沟通模式，并说明了多模态适应沟通需求的方式。

Abstract: When face-to-face communication becomes effortful due to background noise or interfering talkers, the role of visual cues becomes increasingly important for communication success. While previous research has selectively examined head or hand movements, here we explore movements of the whole body in acoustically adverse conditions. We hypothesized that increasing background noise in conversations would lead to increased gesture frequency in hand, head, trunk, and leg movements typical of conversation. Increased use of hand movements should support the speaker's role, while increased head and trunk movements may help the listener. We conducted a free dyadic conversation experiment with normal-hearing participants (n=8) in a virtual acoustic environment. Conversational movements were described with a newly developed labeling system for typical conversational actions, and the frequency of individual types was analyzed. In addition, we analyzed gesture quality by assessing hand-speech synchrony, with the hypothesis that higher levels of background noise would lead to a loss of synchrony according to an interactive coupling model. Higher noise levels led to increased hand-gesture complexity during speaking and listening, more pronounced up-down head movements, and contrary to expectations, head movements during listening generally decreased relative to speaking. Synchrony and peak velocity were unaffected by noise, while gesture quality scaled only modestly. The results support previous findings regarding gesturing frequency, but we found only limited evidence for changes in speech-gesture synchrony. This work reveals communication patterns of the whole body and illustrates multimodal adaptation to communication demands.

</details>


### [79] [Sleep Modulation: The Challenge of Transitioning from Open Loop to Closed Loop](https://arxiv.org/abs/2512.03784)
*Guisong Liu,Jiansong Zhang,Yinpei Luo,Guoliang Wei,Shuqing Sun,Shiyang Deng,Pengfei Wei,Nanxi Chen*

Main category: cs.HC

TL;DR: 该论文综述了睡眠调节技术从开环向闭环系统的范式转变，分析了现有开环方法的局限性，并提出了构建有效睡眠闭环调节系统的关键挑战和解决方案。


<details>
  <summary>Details</summary>
Motivation: 睡眠障碍已成为全球性健康问题，需要有效且广泛可及的干预技术。非侵入性脑刺激作为安全无创的神经活动调节方法受到关注，但现有开环方法存在个体适应性和调节精度不足的问题，限制了临床转化和家庭环境大规模应用。

Method: 论文首先界定睡眠调节的基本范式，批判性分析开环方法的内在局限性，并正式概念化睡眠闭环调节。然后综合评述五种常用调节技术的研究，评估其在闭环框架中的整合潜力。最后识别构建有效睡眠闭环调节系统的三个主要挑战。

Result: 论文系统分析了睡眠调节技术的发展现状，指出了从开环向闭环系统转变的必要性。提出了构建睡眠闭环调节系统需要解决的三个核心挑战：传感器方案选择、监测模型设计和调节策略设计，并为每个挑战提供了潜在的解决方案。

Conclusion: 睡眠调节技术需要从依赖经验参数的开环范式转向能够实现个体适应和精确调节的闭环系统。通过解决传感器选择、监测模型和调节策略等关键挑战，可以推动睡眠调节技术的临床转化和家庭环境大规模部署，最终实现更有效的睡眠干预。

Abstract: Sleep disorders have emerged as a critical global health issue, highlighting the urgent need for effective and widely accessible intervention technologies. Non-invasive brain stimulation has garnered attention as it enables direct or indirect modulation of neural activity, thereby promoting sleep enhancement in a safe and unobtrusive manner. This class of approaches is collectively referred to as sleep modulation. To date, the majority of sleep modulation research relies on open-loop paradigms with empirically determined parameters, while achieving individual adaptation and modulation accuracy remains a distant objective. The paradigm-specific constraints inherent to open-loop designs represent a major obstacle to clinical translation and large-scale deployment in home environments. In this paper, we delineate fundamental paradigms of sleep modulation, critically examine the intrinsic limitations of open-loop approaches, and formally conceptualize sleep closed-loop modulation. We further provide a comprehensive synthesis of prior studies involving five commonly employed modulation techniques, evaluating their potential integration within a closed-loop framework. Finally, we identify three primary challenges in constructing an effective sleep closed-loop modulation system: sensor solution selection, monitoring model design, and modulation strategy design, while also proposing potential solutions. Collectively, this work aims to advance the paradigm shift of sleep modulation from open-loop toward closed-loop systems.

</details>


### [80] [Adhera: A Human-Centered Health Informatics Solution for Reducing Informal Caregiver Burden through Improved Medication Adherence](https://arxiv.org/abs/2512.03878)
*Zhiyin Zhou*

Main category: cs.HC

TL;DR: Adhera是一个面向照护者的健康信息系统，通过智能药盒和移动应用帮助管理药物依从性，减轻照护者负担


<details>
  <summary>Details</summary>
Motivation: 全球老年人口增长和医疗人力短缺导致对非正式照护者的依赖增加，药物管理是照护者最繁重且易出错的任务之一。现有数字健康技术大多只关注患者，忽视了照护者的信息和情感需求

Method: 采用混合方法研究设计，包括15次半结构化照护者访谈、65份问卷调查和5次药剂师咨询。基于CeHRes Roadmap 2.0和TBLD+C框架，结合照护者共同设计，开发了配备传感器的智能药盒和移动应用

Result: 研究识别出三个主要挑战：照护者对药物摄入不确定性的压力、与医疗专业人员沟通碎片化、对现有数字工具的不信任。初步评估表明Adhera提高了可视性，增强了照护者信心，简化了药物管理流程

Conclusion: Adhera展示了以人为本的设计和协作框架如何将技术创新与同理心驱动的照护相结合，为健康信息学领域做出贡献，通过技术解决方案减轻照护者负担并改善药物依从性

Abstract: The growing global population of older adults, combined with ongoing healthcare workforce shortages, has increased reliance on informal caregivers, including family members and friends who provide unpaid support to individuals with chronic illnesses. Among their daily responsibilities, medication management remains one of the most demanding and error-prone tasks. Non-adherence to prescribed regimens not only undermines patient outcomes but also intensifies caregiver stress, anxiety, and fatigue. Although digital health technologies have proliferated to address adherence, most solutions focus exclusively on patients and neglect the informational and emotional needs of caregivers. This paper introduces Adhera, a caregiver-inclusive health informatics system designed to support medication adherence while reducing caregiver burden. Using a mixed-methods research design that included fifteen semi-structured caregiver interviews, sixty-five survey responses, and five pharmacist consultations, this study identified three primary challenges: caregiver stress related to uncertainty about medication intake, fragmented communication with healthcare professionals, and distrust in existing digital tools. Informed by the CeHRes Roadmap 2.0 and the Triple Bottom Line by Design and Culture (TBLD+C) framework, as well as recent co-design studies involving caregivers, Adhera integrates a sensor-equipped smart pill organizer with a mobile companion application that records intake events, sends real-time reminders, and provides caregivers with synchronized adherence data. Preliminary evaluation suggests that Adhera enhances visibility, improves caregiver confidence, and streamlines medication routines. This study contributes to the field of health informatics by demonstrating how human-centered design and collaborative frameworks can align technical innovation with empathy-driven care.

</details>


### [81] [HEART-Watch: A multimodal physiological dataset from a Google Pixel Watch across different physical states](https://arxiv.org/abs/2512.03988)
*Jathushan Kaetheeswaran,Boyi Ma,Ali Abedi,Milad Lankarany,Shehroz Khan*

Main category: cs.HC

TL;DR: HEART-Watch是一个多模态生理数据集，包含来自40名健康成年人的同步手腕穿戴设备信号，旨在支持消费级智能手表心血管分析算法的开发和基准测试。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死亡原因，消费级智能手表为健康监测提供了新选择。然而，现有公开数据集缺乏人口多样性，可能导致算法开发偏差，需要更多样化的同步生物信号数据。

Method: 使用Google Pixel Watch 2收集40名健康成年人的同步心电图、光电容积描记图和加速度计信号，涵盖坐、站、走三种状态，并同步参考胸导联心电图，同时收集间歇性上臂血压测量数据。

Result: 创建了HEART-Watch数据集，包含来自多样化人群的多模态生理信号，支持未来心血管分析算法的开发和评估。

Conclusion: HEART-Watch数据集为开发适用于不同人群的消费级智能手表心血管监测算法提供了重要资源，有助于减少算法偏差并提高监测可靠性。

Abstract: Consumer-grade smartwatches offer a new personalized health monitoring option for general consumers globally as cardiovascular diseases continue to prevail as the leading cause of global mortality. The development and validation of reliable cardiovascular monitoring algorithms for these consumer-grade devices requires realistic biosignal data from diverse sets of participants. However, the availability of public consumer-grade smartwatch datasets with synchronized cardiovascular biosignals is limited, and existing datasets do not offer rich demographic diversity in their participant cohorts, leading to potentially biased algorithm development. This paper presents HEART-Watch, a multimodal physiological dataset collected from temporally synchronized wrist-worn Google Pixel Watch 2 electrocardiogram (ECG), photoplethysmography, and accelerometer signals from a diverse cohort of 40 healthy adults across three physical states - sitting, standing and walking with reference chest ECG. Intermittent upper arm blood pressure measurements and concurrent biosignals were collected as an additional biomarker for future research. The motivation, methodology, and initial analyses of results are presented. HEART-Watch is intended to support the development and benchmarking of robust algorithms for cardiovascular analyses on consumer-grade smartwatches across diverse populations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [82] [Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI](https://arxiv.org/abs/2512.03072)
*Hu Keyi*

Main category: cs.AI

TL;DR: 提出"权重计算主义"认知架构，基于逻辑原子和基本操作，通过可解释的权重计算模型实现AGI，强调可解释性、通用性和价值对齐。


<details>
  <summary>Details</summary>
Motivation: 当前AI范式作为"体验架构师"面临可解释性和价值对齐的根本挑战，需要一种新的认知架构来解决这些问题，为可信赖的AGI奠定基础。

Method: 引入"权重计算主义"认知架构，将认知分解为不可分割的逻辑原子和两个基本操作：指向和比较。决策通过可解释的权重计算模型（权重=收益*概率）形式化，所有值都可追溯到可审计的初始权重集。通过基于图算法的计算引擎和全局工作空间工作流实现。

Result: 该架构在未见过场景中实现了透明、类人推理和鲁棒学习，为构建可信赖和对齐的AGI建立了实践和理论基础。

Conclusion: 权重计算主义为AGI提供了一条可行的路径，通过原子分解实现了根本的可解释性、对新情境的内在通用性以及可追溯的价值对齐，为解决当前AI的核心挑战提供了新方向。

Abstract: Current AI paradigms, as "architects of experience," face fundamental challenges in explainability and value alignment. This paper introduces "Weight-Calculatism," a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.

</details>


### [83] [When Do Symbolic Solvers Enhance Reasoning in Large Language Models?](https://arxiv.org/abs/2512.03272)
*Zhiyuan He,Dingmin Wang*

Main category: cs.AI

TL;DR: 本文探讨了大型推理模型（LRMs）在复杂推理任务中生成长思维链（CoTs）时可能产生大量token开销的问题，研究了符号求解器集成方法何时能增强传统长CoT方法。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过生成长思维链在复杂推理任务上表现良好，但这种方法可能导致大量token开销，特别是当模型"过度思考"产生冗长推理链时，甚至可能导致错误答案。符号求解器集成方法利用LLMs的代码生成能力将推理任务转化为可执行代码，然后用符号求解器解决，这是一个有前景的方向。

Method: 研究采用符号求解器集成方法，探索传统长思维链何时能被符号求解器增强。通过实验分析不同问题类型（需要有限隐式推理但涉及充足搜索空间的问题）中符号求解器的效果。

Result: 实验结果显示：1）符号求解器集成方法仅在问题需要有限隐式推理但涉及充足搜索空间时有效；2）最新LLMs（如GPT-4o）在推理深度较浅的演绎问题上表现更好；3）符号求解器集成方法显著提高了LLMs在需要重复回溯的约束满足问题上的性能；4）当提供声明性示例时，即使是CodeLlama-13B也能在困难的斑马谜题上超越GPT-4o。

Conclusion: 符号求解器集成方法对特定类型的问题（需要有限隐式推理但涉及充足搜索空间的约束满足问题）特别有效，能够显著提升LLMs的性能。这种方法为减少大型推理模型的token开销和提高推理准确性提供了有前景的解决方案。

Abstract: Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models "overthink" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.

</details>


### [84] [Prior preferences in active inference agents: soft, hard, and goal shaping](https://arxiv.org/abs/2512.03293)
*Filippo Torresan,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 该研究比较了主动推理中四种偏好分布定义方式（硬目标vs软目标、有无目标塑造）在网格世界导航任务中的表现，发现目标塑造能提升性能但会牺牲对环境的探索学习。


<details>
  <summary>Details</summary>
Motivation: 主动推理使用期望自由能作为规划目标来平衡探索与利用，但文献中很少关注偏好分布如何定义以及不同定义方式对推理和学习的影响。本研究旨在填补这一空白。

Method: 研究者考虑了四种定义偏好分布的方式：硬目标vs软目标、有无目标塑造（中间目标）。在网格世界导航任务中比较了使用这四种偏好分布的智能体表现。

Result: 结果显示，目标塑造总体上能实现最佳性能（促进利用），但会牺牲对环境转移动态的学习（阻碍探索）。

Conclusion: 偏好分布的定义方式对主动推理智能体的性能有显著影响，目标塑造在提升利用性能的同时会减少探索，需要在两者之间权衡。

Abstract: Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).

</details>


### [85] [Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia](https://arxiv.org/abs/2512.03318)
*Chandler Smith,Marwa Abdulhai,Manfred Diaz,Marko Tesic,Rakshit S. Trivedi,Alexander Sasha Vezhnevets,Lewis Hammond,Jesse Clifton,Minsuk Chang,Edgar A. Duéñez-Guzmán,John P. Agapiou,Jayd Matyas,Danny Karmon,Akash Kundu,Aliaksei Korshuk,Ananya Ananya,Arrasy Rahman,Avinaash Anand Kulandaivel,Bain McHale,Beining Zhang,Buyantuev Alexander,Carlos Saith Rodriguez Rojas,Caroline Wang,Chetan Talele,Chenao Liu,Chichen Lin,Diana Riazi,Di Yang Shi,Emanuel Tewolde,Elizaveta Tennant,Fangwei Zhong,Fuyang Cui,Gang Zhao,Gema Parreño Piqueras,Hyeonggeun Yun,Ilya Makarov,Jiaxun Cui,Jebish Purbey,Jim Dilkes,Jord Nguyen,Lingyun Xiao,Luis Felipe Giraldo,Manuela Chacon-Chamorro,Manuel Sebastian Rios Beltran,Marta Emili García Segura,Mengmeng Wang,Mogtaba Alim,Nicanor Quijano,Nico Schiavone,Olivia Macmillan-Scott,Oswaldo Peña,Peter Stone,Ram Mohan Rao Kadiyala,Rolando Fernandez,Ruben Manrique,Sunjia Lu,Sheila A. McIlraith,Shamika Dhuri,Shuqing Shi,Siddhant Gupta,Sneheel Sarangi,Sriram Ganapathi Subramanian,Taehun Cha,Toryn Q. Klassen,Wenming Tu,Weijian Fan,Wu Ruiyang,Xue Feng,Yali Du,Yang Liu,Yiding Wang,Yipeng Kang,Yoonchang Sung,Yuxuan Chen,Zhaowei Zhang,Zhihan Wang,Zhiqiang Wu,Ziang Chen,Zilong Zheng,Zixia Jia,Ziyan Wang,Dylan Hadfield-Menell,Natasha Jaques,Tim Baarslag,Jose Hernandez-Orallo,Joel Z. Leibo*

Main category: cs.AI

TL;DR: 该论文提出了一种评估LLM智能体在零样本、混合动机环境中合作能力的方法，使用Concordia自然语言多智能体模拟环境，通过NeurIPS 2024竞赛发现当前智能体在需要说服和规范执行等场景中的合作泛化能力存在显著差距。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在社会互动方面展现出强大能力，并越来越多地部署在与人类和人工智能体互动的场景中。然而，现有评估方法无法衡量这些能力如何泛化到新的社会情境，特别是合作能力在混合动机环境中的表现。

Method: 引入Concordia自然语言多智能体模拟环境，通过评估智能体在零样本、混合动机环境中识别和利用互利机会的能力来测量一般合作智能。在NeurIPS 2024 Concordia竞赛中，测试智能体在从谈判到集体行动问题等多种场景中实现互利的能力。

Result: 研究发现当前智能体能力与实现可靠合作所需的稳健泛化之间存在显著差距，特别是在需要说服和规范执行的场景中。这表明LLM智能体在复杂社会互动中的合作能力仍有待提升。

Conclusion: 需要开发更好的方法来评估和提高LLM智能体在多样化社会情境中的合作能力，特别是在需要说服和规范执行的复杂场景中，以实现更可靠的社会互动。

Abstract: Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.

</details>


### [86] [Multi-Agent Reinforcement Learning with Communication-Constrained Priors](https://arxiv.org/abs/2512.03528)
*Guang Yang,Tianpei Yang,Jingwen Qiao,Yanqing Wu,Jing Huo,Xingguo Chen,Yang Gao*

Main category: cs.AI

TL;DR: 提出了一种通信受限的多智能体强化学习框架，通过区分有损和无损消息，将通信影响量化到全局奖励中，提高了在复杂动态环境中的可扩展性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在现实世界多智能体系统中，有损通信是普遍问题，现有通信方法由于可扩展性和鲁棒性有限，难以应用于复杂动态环境。

Method: 1) 提出通用通信约束模型统一描述不同场景的通信条件；2) 将其作为学习先验区分有损和无损消息；3) 使用双重互信息估计器解耦有损/无损消息对分布式决策的影响；4) 引入通信约束多智能体强化学习框架，将通信消息影响量化到全局奖励中。

Result: 在多个通信受限基准测试中验证了方法的有效性。

Conclusion: 提出的通信约束多智能体强化学习框架能够有效处理现实世界中的有损通信问题，提高了系统在复杂动态环境中的适应性和性能。

Abstract: Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.

</details>


### [87] [Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks](https://arxiv.org/abs/2512.03560)
*Gianni Molinari,Fabio Ciravegna*

Main category: cs.AI

TL;DR: RP-ReAct是一种新型多智能体架构，通过将战略规划与低级执行解耦，解决了企业级复杂任务中单智能体架构的轨迹不稳定性和小上下文窗口问题，在ToolQA基准测试中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前自主智能体在企业级复杂任务中存在两个主要局限：1）单智能体架构的单一规划-执行循环导致轨迹不稳定；2）为数据隐私使用本地开源模型时，较小的上下文窗口难以处理大型工具输出。

Method: 提出RP-ReAct多智能体方法，包含：1）Reasoner Planner Agent（RPA）负责子步骤规划，利用大型推理模型持续分析执行结果；2）一个或多个Proxy-Execution Agent（PEA）使用ReAct方法将子步骤转换为具体工具交互；3）在PEA中采用上下文保存策略，通过外部存储和按需访问管理大型工具输出。

Result: 在具有挑战性的多领域ToolQA基准测试中，使用六种不同的开源推理模型进行评估，RP-ReAct在性能、泛化能力和鲁棒性方面均优于现有最先进基线方法，在不同模型规模下表现出增强的稳定性和可靠性。

Conclusion: RP-ReAct通过解耦规划与执行的多智能体架构，结合上下文管理策略，为企业级可部署的智能体解决方案提供了有效途径，能够处理需要协调多个工具和处理多样化数据源的复杂任务。

Abstract: Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent architectures enforce a monolithic plan-execute loop, which directly causes trajectory instability. Second, the requirement to use local open-weight models for data privacy introduces smaller context windows leading to the rapid consumption of context from large tool outputs. To solve this problem we introduce RP-ReAct (Reasoner Planner-ReAct), a novel multi-agent approach that fundamentally decouples strategic planning from low-level execution to achieve superior reliability and efficiency. RP-ReAct consists of a Reasoner Planner Agent (RPA), responsible for planning each sub-step, continuously analysing the execution results using the strong reasoning capabilities of a Large Reasoning Model, and one or multiple Proxy-Execution Agent (PEA) that translates sub-steps into concrete tool interactions using a ReAct approach. Crucially, we incorporate a context-saving strategy within the PEA to mitigate context window overflow by managing large tool outputs via external storage and on-demand access. We evaluate RP-ReAct, on the challenging, multi-domain ToolQA benchmark using a diverse set of six open-weight reasoning models. Our empirical results show that RP-ReAct achieves superior performance and improved generalization ability over state-of-the-art baselines when addressing diverse complex tasks across the evaluated domains. Furthermore we establish the enhanced robustness and stability of our approach across different model scales, paving the way for effective and deployable agentic solutions for enterprises.

</details>


### [88] [EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths](https://arxiv.org/abs/2512.03571)
*Zhening Li,Armando Solar-Lezama,Yisong Yue,Stephan Zheng*

Main category: cs.AI

TL;DR: 本文提出PAN编程模型，通过分离智能体工作流逻辑和推理时策略，简化LLM智能体开发，并提供EnCompass框架实现


<details>
  <summary>Details</summary>
Motivation: 当前智能体编程方法通常将核心工作流逻辑和推理时策略（如树搜索）耦合在一起，导致开发复杂且难以灵活调整策略

Method: 提出"概率天使非确定性"（PAN）编程模型，分离工作流描述和推理策略；实现EnCompass框架，使用Python装饰器将智能体工作流程序编译为搜索空间

Result: 通过三个案例研究证明，该框架能让程序员快速提升智能体可靠性，轻松切换不同推理时策略，且只需少量额外编码

Conclusion: PAN模型和EnCompass框架有效解决了智能体编程中工作流与推理策略的耦合问题，简化了LLM智能体的开发和优化过程

Abstract: We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce "probabilistic angelic nondeterminism" ("PAN"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.

</details>


### [89] [DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization](https://arxiv.org/abs/2512.03607)
*Yusen Wu,Xiaotie Deng*

Main category: cs.AI

TL;DR: DeepRule是一个集成框架，用于零售品类和定价优化的自动化业务规则生成，通过三层次架构解决理论模型与现实经济复杂性之间的系统性错配问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有理论模型与现实经济复杂性之间的系统性错配问题，具体包括三个关键差距：数据模态不匹配（非结构化文本源阻碍准确客户画像）、动态特征纠缠（非线性价格弹性和时变属性建模困难）、以及多层级业务约束导致的运营不可行性。

Method: 采用三层次架构：1) 混合知识融合引擎，使用大语言模型深度语义解析非结构化文本，将分销商协议和销售评估转化为结构化特征；2) 基于博弈论的约束优化机制，通过双边效用函数动态协调供应链利益；3) 可解释决策蒸馏接口，利用LLM引导的符号回归优化定价策略和可审计业务规则。

Result: 在真实零售环境中验证框架，相比系统性B2C基线实现了更高的利润，同时确保运营可行性。

Conclusion: 建立了一个闭环管道，统一了非结构化知识注入、多智能体优化和可解释策略合成，为真实经济智能提供了系统化解决方案。

Abstract: This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.
  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.

</details>


### [90] [RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design](https://arxiv.org/abs/2512.03762)
*Jiawei Xu,Fengfeng Wei,Weineng Chen*

Main category: cs.AI

TL;DR: RoCo是一个基于多智能体角色协作的系统，通过四个专门化的LLM智能体（探索者、利用者、批评者、整合者）协同工作，自动设计高质量的启发式算法来解决组合优化问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的自动启发式设计研究通常只考虑单一角色，限制了启发式算法的多样性和质量。需要一种能够通过多角色协作来增强启发式设计多样性和质量的新方法。

Method: 提出RoCo多智能体角色协作系统，包含四个专门化的LLM智能体：探索者（创造性、多样性驱动）、利用者（保守性、效率导向）、批评者（评估进化步骤并提供反馈）、整合者（综合提案平衡创新与利用）。这些智能体通过结构化的多轮过程进行交互，包括反馈、精炼和精英突变，并受到短期和长期反思的指导。

Result: 在五个不同的组合优化问题上，在自盒和黑盒设置下进行评估。实验结果表明，RoCo在自盒和黑盒场景中都实现了优越性能，生成的启发式算法优于现有方法（包括ReEvo和HSEvo）。

Conclusion: 这种基于角色的协作范式为稳健且高性能的自动启发式设计建立了新标准，通过多角色协作显著提升了启发式设计的多样性和质量。

Abstract: Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.

</details>


### [91] [Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning](https://arxiv.org/abs/2512.03783)
*Dongchao Yang,Songxiang Liu,Disong Wang,Yuanyuan Wang,Guanglu Wan,Helen Meng*

Main category: cs.AI

TL;DR: 提出了Omni-AutoThink框架，通过自适应调整推理深度来解决现有Omni模型推理行为僵化的问题，包含自适应监督微调和自适应强化学习两个阶段，并在多模态基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有Omni模型在多模态感知和生成方面取得了进展，但推理行为仍然僵化，要么对简单问题过度推理，要么在需要推理时无法有效推理。需要一种能够根据任务难度动态调整推理深度的自适应推理框架。

Method: 提出Omni-AutoThink自适应推理框架，包含两个阶段：1）自适应监督微调阶段，使用大规模推理增强数据赋予Omni模型基本推理能力；2）自适应强化学习阶段，基于任务复杂度和奖励反馈优化推理行为。还构建了涵盖文本、文本-音频、文本-视觉、文本-音频-视觉模态的全面自适应推理基准。

Result: 实验结果表明，提出的框架相比之前的基线方法显著提高了自适应推理性能。所有基准数据和代码将公开释放。

Conclusion: Omni-AutoThink通过自适应调整推理深度有效解决了Omni模型推理行为僵化的问题，在多模态自适应推理任务上表现出色，为多模态智能系统提供了更灵活的推理能力。

Abstract: Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.

</details>


### [92] [Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol](https://arxiv.org/abs/2512.03955)
*Niklas Jobs,Luis Miguel Vieira da Silva,Jayanth Somashekaraiah,Maximilian Weigand,David Kube,Felix Gehlhoff*

Main category: cs.AI

TL;DR: 该研究为基于LLM的工业自动化智能体创建了一个标准化的基准测试框架，包含可执行的仿真环境和标准工具接口，用于系统评估不同智能体架构的规划与执行能力。


<details>
  <summary>Details</summary>
Motivation: 工业自动化需要能够适应变化任务和环境的灵活控制策略，基于大语言模型（LLMs）的智能体具有自适应规划和执行的潜力，但缺乏用于系统比较的标准基准测试。

Method: 引入一个包含可执行仿真环境的基准测试，基于Blocksworld问题提供五个复杂度类别。通过集成模型上下文协议（MCP）作为标准化工具接口，使不同智能体架构能够无需特定实现修改即可连接和评估。

Result: 通过单智能体实现展示了基准测试的适用性，建立了用于比较基于LLM的规划与执行方法的量化指标。

Conclusion: 该基准测试框架为系统评估和比较基于LLM的工业自动化智能体提供了标准化平台，促进了自适应规划与执行方法的研究和发展。

Abstract: Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.

</details>
