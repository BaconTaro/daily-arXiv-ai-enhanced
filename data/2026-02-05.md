<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]
- [cs.HC](#cs.HC) [Total: 26]
- [cs.LG](#cs.LG) [Total: 89]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Knowledge Model Prompting Increases LLM Performance on Planning Tasks](https://arxiv.org/abs/2602.03900)
*Erik Goh,John Kos,Ashok Goel*

Main category: cs.AI

TL;DR: TMK框架显著提升LLM在规划任务中的推理能力，特别是在符号化任务上表现突出，准确率从31.5%提升至97.3%


<details>
  <summary>Details</summary>
Motivation: LLM在推理和规划任务上存在不足，现有提示技术如CoT也受到质疑。研究探索认知科学中的TMK框架是否能改善LLM的推理能力，因其能捕捉因果、目的论和层次化推理结构，并提供明确的任务分解机制

Method: 使用Task-Method-Knowledge框架构建提示，在PlanBench基准的Blocksworld领域进行实验，测试TMK结构化提示是否能帮助语言模型更好地将复杂规划问题分解为可管理的子任务

Result: TMK提示显著提升推理模型性能，在PlanBench的随机Blocksworld任务上准确率从31.5%提升至97.3%，实现了语义近似与符号操作之间的桥梁

Conclusion: TMK不仅作为上下文，更是一种引导机制，使推理模型从默认的语言模式转向形式化的代码执行路径，有效提升LLM在符号化规划任务中的表现

Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into question. Borrowing from the domain of cognitive and educational science, this paper investigates whether the Task-Method-Knowledge (TMK) framework can improve LLM reasoning capabilities beyond its previously demonstrated success in educational applications. The TMK framework's unique ability to capture causal, teleological, and hierarchical reasoning structures, combined with its explicit task decomposition mechanisms, makes it particularly well-suited for addressing language model reasoning deficiencies, and unlike other hierarchical frameworks such as HTN and BDI, TMK provides explicit representations of not just what to do and how to do it, but also why actions are taken. The study evaluates TMK by experimenting on the PlanBench benchmark, focusing on the Blocksworld domain to test for reasoning and planning capabilities, examining whether TMK-structured prompting can help language models better decompose complex planning problems into manageable sub-tasks. Results also highlight significant performance inversion in reasoning models. TMK prompting enables the reasoning model to achieve up to an accuracy of 97.3\% on opaque, symbolic tasks (Random versions of Blocksworld in PlanBench) where it previously failed (31.5\%), suggesting the potential to bridge the gap between semantic approximation and symbolic manipulation. Our findings suggest that TMK functions not merely as context, but also as a mechanism that steers reasoning models away from their default linguistic modes to engage formal, code-execution pathways in the context of the experiments.

</details>


### [2] [Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation](https://arxiv.org/abs/2602.03950)
*Aditya Basarkar,Benyamin Tabarsi,Tiffany Barnes,Dongkuan,Xu*

Main category: cs.AI

TL;DR: IIPC是一种迭代改进的程序构造方法，通过结合程序执行反馈和LLM的思维链能力，提升数学推理的准确性和可修正性。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体LLM系统在数学推理中缺乏可靠可修正的推理过程表示，要么采用僵化的顺序流程无法修正早期错误，要么依赖启发式自我评估可能无法识别和修复错误。此外，程序化上下文可能分散语言模型的注意力并降低准确性。

Method: IIPC（迭代改进的程序构造）方法迭代地精炼程序化推理链，将程序执行反馈与基础LLM的原生思维链能力相结合，以保持高层次上下文关注。

Result: IIPC在多个基础LLM上的大多数推理基准测试中超越了竞争方法。

Conclusion: IIPC通过迭代精炼程序化推理链并结合执行反馈与思维链能力，显著提升了数学推理的可靠性和准确性，所有代码和实现均已开源。

Abstract: Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although recent advances in multi-agent LLM-based systems have enhanced their mathematical reasoning capabilities, they still lack a reliably revisable representation of the reasoning process. Existing agents either operate in rigid sequential pipelines that cannot correct earlier steps or rely on heuristic self-evaluation that can fail to identify and fix errors. In addition, programmatic context can distract language models and degrade accuracy. To address these gaps, we introduce Iteratively Improved Program Construction (IIPC), a reasoning method that iteratively refines programmatic reasoning chains and combines execution feedback with the native Chain-of-thought abilities of the base LLM to maintain high-level contextual focus. IIPC surpasses competing approaches in the majority of reasoning benchmarks on multiple base LLMs. All code and implementations are released as open source.

</details>


### [3] [AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent](https://arxiv.org/abs/2602.03955)
*Yinyi Luo,Yiqiao Jin,Weichen Yu,Mengqi Zhang,Srijan Kumar,Xiaoxiao Li,Weijie Xu,Xin Chen,Jindong Wang*

Main category: cs.AI

TL;DR: AgentArk框架将多智能体系统的动态蒸馏到单个模型的权重中，将显式的测试时交互转化为隐式的模型能力，使单个智能体具备多智能体系统的智能同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型多智能体系统通过迭代辩论实现了优越的推理性能，但实际部署受到高计算成本和错误传播的限制。

Method: 提出了AgentArk框架，研究了三种分层蒸馏策略：推理增强微调、基于轨迹的增强和过程感知蒸馏，将多智能体动态蒸馏到单个模型的权重中。

Result: 蒸馏后的模型保持单个智能体的效率，同时展现出多智能体的强大推理和自我纠正性能，在多样化推理任务中表现出增强的鲁棒性和泛化能力。

Conclusion: 通过将计算负担从推理转移到训练，AgentArk为高效、鲁棒的多智能体开发提供了新思路，有望推动未来研究。

Abstract: While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights of a single model, effectively transforming explicit test-time interactions into implicit model capabilities. This equips a single agent with the intelligence of multi-agent systems while remaining computationally efficient. Specifically, we investigate three hierarchical distillation strategies across various models, tasks, scaling, and scenarios: reasoning-enhanced fine-tuning; trajectory-based augmentation; and process-aware distillation. By shifting the burden of computation from inference to training, the distilled models preserve the efficiency of one agent while exhibiting strong reasoning and self-correction performance of multiple agents. They further demonstrate enhanced robustness and generalization across diverse reasoning tasks. We hope this work can shed light on future research on efficient and robust multi-agent development. Our code is at https://github.com/AIFrontierLab/AgentArk.

</details>


### [4] [Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure](https://arxiv.org/abs/2602.03975)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 提出了一种状态级选择性验证框架，在验证成本受限的情况下，通过确定性可行性门控、预验证排序和自适应分配验证调用，显著减少验证次数同时提高推理准确性。


<details>
  <summary>Details</summary>
Motivation: 测试时计算已成为大语言模型推理进展的主要驱动力，但越来越受到昂贵验证的瓶颈制约。在许多推理系统中，大量验证调用被浪费在冗余或无希望的中间假设上。研究在验证成本受限设置下的推理问题，探讨如何在不同中间状态间分配验证努力。

Method: 提出了状态级选择性验证框架，包含三个核心组件：(1) 结构化移动接口上的确定性可行性门控；(2) 结合学习状态距离和残差评分的预验证排序；(3) 基于局部不确定性的验证调用自适应分配。与解决方案级的最佳N选择或均匀中间验证不同，该方法将验证分配到最信息丰富的地方。

Result: 在MATH基准测试上，该方法比最佳N选择、多数投票和波束搜索获得更高的准确性，同时减少了44%的验证调用次数。

Conclusion: 通过智能分配验证资源到最信息丰富的中间状态，可以在验证成本受限的情况下显著提高推理系统的效率和准确性，为大规模语言模型推理提供了更高效的验证策略。

Abstract: Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant or unpromising intermediate hypotheses. We study reasoning under a \emph{verification-cost-limited} setting and ask how verification effort should be allocated across intermediate states. We propose a state-level selective verification framework that combines (i) deterministic feasibility gating over a structured move interface, (ii) pre-verification ranking using a hybrid of learned state-distance and residual scoring, and (iii) adaptive allocation of verifier calls based on local uncertainty. Unlike solution-level best-of-$N$ or uniform intermediate verification, our method distributes verification where it is most informative. On the \textsc{MATH} benchmark, our approach achieves higher accuracy than best-of-$N$, majority voting, and beam search while using 44\% fewer verifier calls.

</details>


### [5] [Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning](https://arxiv.org/abs/2602.03978)
*Zidi Xiong,Shan Chen,Himabindu Lakkaraju*

Main category: cs.AI

TL;DR: 研究发现：在强化学习可验证奖励（RLVR）训练中，思维链（CoT）的可监控性并非总是"免费获得"，而是高度依赖数据多样性和指令遵循数据；可监控性与模型能力正交，主要源于响应分布锐化和对提示的关注增强。


<details>
  <summary>Details</summary>
Motivation: 随着大型推理模型（LRMs）的广泛应用，对其思维链（CoT）轨迹进行安全审计变得至关重要。现有研究发现在强化学习可验证奖励（RLVR）早期阶段，可监控性（CoT忠实反映内部计算的程度）似乎可以"免费获得"，但这一现象需要系统验证。

Method: 通过跨模型家族和训练领域的系统评估，分析数据多样性、指令遵循数据在RLVR训练中的关键作用。采用机制分析，研究响应分布锐化（熵减少）和提示关注增强对可监控性的影响，并控制训练和评估难度来观察可监控性动态变化。

Result: 可监控性改进具有强烈数据依赖性，并非普遍现象。可监控性与推理能力正交，能力提升不意味着透明度增加。机制分析显示可监控性增益主要源于响应分布锐化和对提示的关注增强，而非对推理轨迹的因果依赖增强。

Conclusion: 研究提供了RLVR下可监控性如何出现的整体视角，明确了何时可能获得可监控性增益，何时不会。强调了数据多样性和指令遵循数据的关键作用，以及可监控性与模型能力的独立性。

Abstract: As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal computation--can appear as a "free gift" during the early stages of Reinforcement Learning with Verifiable Rewards (RLVR). We make this observation concrete through a systematic evaluation across model families and training domains. Our results show that this effect is not universal: monitorability improvements are strongly data-dependent. In particular, we demonstrate the critical role of data diversity and instruction-following data during RLVR training. We further show that monitorability is orthogonal to capability--improvements in reasoning performance do not imply increased transparency. Through mechanistic analysis, we attribute monitorability gains primarily to response distribution sharpening (entropy reduction) and increased attention to the prompt, rather than stronger causal reliance on reasoning traces. We also reveal how monitorability dynamics vary with controlled training and evaluation difficulty. Together, these findings provide a holistic view of how monitorability emerges under RLVR, clarifying when gains are likely to occur and when they are not.

</details>


### [6] [When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making](https://arxiv.org/abs/2602.04003)
*Shutong Fan,Lan Zhang,Xiaoyong Yuan*

Main category: cs.AI

TL;DR: 本文首次系统性地研究了对抗性解释攻击(AEAs)，即攻击者通过操纵LLM生成解释的框架来调节用户对错误输出的信任，揭示了AI与用户之间认知层的新攻击面。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统越来越多地在人类决策循环中运行，用户依赖模型推荐进行决策。LLM生成的流畅自然语言解释会影响用户对AI输出的感知和信任，这揭示了一个新的认知层攻击面：AI与其用户之间的通信渠道。目前大多数对抗性威胁针对模型的计算行为，而非依赖模型的用户。

Method: 引入对抗性解释攻击(AEAs)概念，通过信任校准差距（正确与错误输出在对抗性解释下的人类信任差异）来形式化这一行为威胁。进行受控实验(n=205)，系统性地改变解释框架的四个维度：推理模式、证据类型、沟通风格和呈现格式。

Result: 用户对对抗性和良性解释报告几乎相同的信任度，对抗性解释尽管是错误的，但仍保留了大部分良性信任。最脆弱的案例出现在AEAs类似专家沟通时，结合权威证据、中性语气和领域适当的推理。在困难任务、事实驱动领域以及教育程度较低、较年轻或高度信任AI的参与者中，脆弱性最高。

Conclusion: 这是首个将解释视为对抗性认知渠道并量化其对AI辅助决策中人类信任影响的系统性安全研究。研究表明，攻击者可以通过操纵解释框架来维持用户对错误输出的信任，揭示了AI系统在认知层面的新安全威胁。

Abstract: Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret and act on model recommendations. Large Language Models generate fluent natural-language explanations that shape how users perceive and trust AI outputs, revealing a new attack surface at the cognitive layer: the communication channel between AI and its users. We introduce adversarial explanation attacks (AEAs), where an attacker manipulates the framing of LLM-generated explanations to modulate human trust in incorrect outputs. We formalize this behavioral threat through the trust miscalibration gap, a metric that captures the difference in human trust between correct and incorrect outputs under adversarial explanations. By incorporating this gap, AEAs explore the daunting threats in which persuasive explanations reinforce users' trust in incorrect predictions. To characterize this threat, we conducted a controlled experiment (n = 205), systematically varying four dimensions of explanation framing: reasoning mode, evidence type, communication style, and presentation format. Our findings show that users report nearly identical trust for adversarial and benign explanations, with adversarial explanations preserving the vast majority of benign trust despite being incorrect. The most vulnerable cases arise when AEAs closely resemble expert communication, combining authoritative evidence, neutral tone, and domain-appropriate reasoning. Vulnerability is highest on hard tasks, in fact-driven domains, and among participants who are less formally educated, younger, or highly trusting of AI. This is the first systematic security study that treats explanations as an adversarial cognitive channel and quantifies their impact on human trust in AI-assisted decision making.

</details>


### [7] [Axiomatic Foundations of Counterfactual Explanations](https://arxiv.org/abs/2602.04028)
*Leila Amgoud,Martin Cooper*

Main category: cs.AI

TL;DR: 本文提出一个反事实解释的axiomatic框架，通过公理体系定义五种不同类型的反事实解释，包括局部和全局解释，并建立公理子集与解释器家族的一一对应关系。


<details>
  <summary>Details</summary>
Motivation: 当前反事实解释研究存在两个主要问题：1) 大多数解释器只关注单一类型的反事实；2) 主要局限于局部解释，缺乏对系统整体推理过程的全局解释。需要系统性地研究不同类型的反事实解释。

Method: 提出基于一组理想属性的公理化框架，证明不可能性定理（某些公理组合无法同时满足），建立表示定理，揭示五种不同类型的反事实解释与特定公理子集的一一对应关系。

Result: 框架识别出五种根本不同的反事实类型，包括局部和全局解释；将现有解释器纳入分类体系，形式化描述其行为，并分析生成此类解释的计算复杂性。

Conclusion: 该公理化框架为反事实解释提供了系统化理论基础，揭示了反事实解释的多样性，为开发更全面的解释方法奠定了理论基础，有助于提高对自主智能系统决策的信任。

Abstract: Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions could be altered. Despite the growing literature, most existing explainers focus on a single type of counterfactual and are restricted to local explanations, focusing on individual instances. There has been no systematic study of alternative counterfactual types, nor of global counterfactuals that shed light on a system's overall reasoning process.
  This paper addresses the two gaps by introducing an axiomatic framework built on a set of desirable properties for counterfactual explainers. It proves impossibility theorems showing that no single explainer can satisfy certain axiom combinations simultaneously, and fully characterizes all compatible sets. Representation theorems then establish five one-to-one correspondences between specific subsets of axioms and the families of explainers that satisfy them. Each family gives rise to a distinct type of counterfactual explanation, uncovering five fundamentally different types of counterfactuals. Some of these correspond to local explanations, while others capture global explanations. Finally, the framework situates existing explainers within this taxonomy, formally characterizes their behavior, and analyzes the computational complexity of generating such explanations.

</details>


### [8] [Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL](https://arxiv.org/abs/2602.04089)
*Xiaofeng Lin,Sirou Zhu,Yilei Chen,Mingyu Chen,Hejian Sang,Ioannis Paschalidis,Zhipeng Wang,Aldo Pacchiano,Xuezhou Zhang*

Main category: cs.AI

TL;DR: ORBIT框架通过元强化学习训练LLMs在上下文中从交互学习，使开源模型在未见环境中实现接近GPT-5.2的在线学习性能


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在需要在线交互获取信息、延迟反馈、平衡探索与利用的决策任务中表现不佳，无法可靠利用上下文交互经验

Method: 提出ORBIT框架：多任务、多回合的元强化学习框架，训练LLMs在上下文中从交互学习，无需权重更新

Result: 元训练后，相对较小的开源模型(Qwen3-14B)在完全未见环境中表现出显著改进的上下文在线学习能力，匹配GPT-5.2性能，大幅优于标准RL微调

Conclusion: 通过训练可以解决LLMs在在线决策任务中的局限性，模型规模扩展实验显示持续增益，表明学习型推理决策智能体有巨大发展空间

Abstract: Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction, feedback is delayed, and effective behavior requires balancing information collection and exploitation over time. While in-context learning enables adaptation without weight updates, existing LLMs often struggle to reliably leverage in-context interaction experience in such settings. In this work, we show that this limitation can be addressed through training. We introduce ORBIT, a multi-task, multi-episode meta-reinforcement learning framework that trains LLMs to learn from interaction in context. After meta-training, a relatively small open-source model (Qwen3-14B) demonstrates substantially improved in-context online learning on entirely unseen environments, matching the performance of GPT-5.2 and outperforming standard RL fine-tuning by a large margin. Scaling experiments further reveal consistent gains with model size, suggesting significant headroom for learn-at-inference-time decision-making agents. Code reproducing the results in the paper can be found at https://github.com/XiaofengLin7/ORBIT.

</details>


### [9] [Interfaze: The Future of AI is built on Task-Specific Small Models](https://arxiv.org/abs/2602.04101)
*Harsha Vardhan Khurdula,Vineet Agarwal,Yoeven D Khemlani*

Main category: cs.AI

TL;DR: Interfaze是一个将LLM应用视为上下文构建与执行问题的系统，通过异构DNN栈、小型语言模型、上下文构建层和动作层组合，而非单一大型模型，实现高效的多模态处理。


<details>
  <summary>Details</summary>
Motivation: 现代LLM应用不应仅依赖单一大型模型，而应通过构建和操作上下文来解决问题，将计算负担从昂贵的大型模型转移到小型模型和工具栈上。

Method: 系统包含三个核心层：(1) 异构DNN栈配对小语言模型作为感知模块，处理复杂PDF、图表、多语言ASR；(2) 上下文构建层爬取、索引、解析外部资源为结构化状态；(3) 动作层支持浏览、检索、代码执行和浏览器驱动。顶层控制器决定使用哪些小型模型和动作，并将精炼后的上下文转发给用户选择的LLM生成最终响应。

Result: Interfaze-Beta在多个基准测试中表现优异：MMLU-Pro 83.6%、MMLU 91.4%、GPQA-Diamond 81.3%、LiveCodeBench v5 57.8%、AIME-2025 90.0%，多模态任务上MMMU(val) 77.3%、AI2D 91.5%、ChartQA 90.9%、Common Voice v16 90.8%。大部分查询由小型模型和工具栈处理，大型LLM仅操作精炼后的上下文。

Conclusion: 通过将LLM应用重构为上下文构建与执行问题，Interfaze系统能够在保持竞争力的准确率的同时，将主要计算从昂贵的大型模型转移到小型模型和工具栈，实现了更高效、模块化的LLM应用架构。

Abstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OCR involving complex PDFs, charts and diagrams, and multilingual ASR with (ii) a context-construction layer that crawls, indexes, and parses external sources (web pages, code, PDFs) into compact structured state, and (iii) an action layer that can browse, retrieve, execute code in a sandbox, and drive a headless browser for dynamic web pages. A thin controller sits on top of this stack and exposes a single, OpenAI-style endpoint: it decides which small models and actions to run and always forwards the distilled context to a user-selected LLM that produces the final response.
  On this architecture, Interfaze-Beta achieves 83.6% on MMLU-Pro, 91.4% on MMLU, 81.3% on GPQA-Diamond, 57.8% on LiveCodeBench v5, and 90.0% on AIME-2025, along with strong multimodal scores on MMMU (val) (77.3%), AI2D (91.5%), ChartQA (90.9%), and Common Voice v16 (90.8%). We show that most queries are handled primarily by the small-model and tool stack, with the large LLM operating only on distilled context, yielding competitive accuracy while shifting the bulk of computation away from the most expensive and monolithic models.

</details>


### [10] [Steering LLMs via Scalable Interactive Oversight](https://arxiv.org/abs/2602.04210)
*Enyu Zhou,Zhiheng Xi,Long Ma,Zhihao Zhang,Shihan Dou,Zhikai Lei,Guoteng Wang,Rui Zheng,Hang Yan,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.AI

TL;DR: 论文提出可扩展交互监督框架，通过将复杂意图分解为可管理的决策树来增强人类监督能力，在网页开发任务中验证了非专家也能生成专家级产品需求文档，对齐度提升54%。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在复杂长时程任务（如氛围编程）中日益自动化，出现了监督缺口。模型擅长执行，但用户因领域专业知识不足、难以精确表达意图、无法可靠验证复杂输出而难以有效指导模型。这提出了可扩展监督的关键挑战：如何让人类在超越自身规范和验证能力的任务上负责任地引导AI系统。

Method: 提出可扩展交互监督框架，将复杂意图分解为递归的决策树，而不是依赖开放式提示。系统在每个节点收集低负担反馈，并递归聚合这些信号为精确的全局指导。在网页开发任务中验证，并展示该框架可通过强化学习仅使用在线用户反馈进行优化。

Result: 在网页开发任务中，该框架使非专家能够生成专家级产品需求文档，实现了54%的对齐度改进。关键的是，证明了该框架可以通过仅使用在线用户反馈的强化学习进行优化，为AI扩展时保持人类控制提供了实用路径。

Conclusion: 可扩展交互监督框架通过分解复杂意图为可管理决策树，有效解决了人类监督AI执行超越自身能力任务的挑战，为非专家提供专家级指导能力，并通过强化学习优化机制为AI规模化发展中的可控性提供了可行方案。

Abstract: As Large Language Models increasingly automate complex, long-horizon tasks such as \emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight, a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54\% improvement in alignment. Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback, offering a practical pathway for maintaining human control as AI scales.

</details>


### [11] [Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.04284)
*Yansong Ning,Jun Fang,Naiqiang Tan,Hao Liu*

Main category: cs.AI

TL;DR: Agent-Omit：一个训练框架，让LLM智能体能够自适应地省略冗余的思维和观察，在保持性能的同时提升效率


<details>
  <summary>Details</summary>
Motivation: 现有研究将整个交互轨迹同等对待，忽略了不同回合中思维必要性和观察效用的差异。需要让智能体能够自适应地省略冗余的思维和观察，以提高效率。

Method: 1. 合成少量冷启动数据（包括单回合和多回合省略场景）微调智能体；2. 提出省略感知的智能体强化学习方法，包含双重采样机制和定制的省略奖励；3. 理论上证明省略策略的偏差受KL散度上界约束。

Result: 在五个智能体基准测试中，Agent-Omit-8B模型性能与七个前沿LLM智能体相当，并且在七个高效LLM智能体方法中实现了最佳的有效性-效率权衡。

Conclusion: Agent-Omit框架能够有效提升LLM智能体的效率，通过自适应省略冗余思维和观察，在保持性能的同时显著减少计算开销。

Abstract: Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.

</details>


### [12] [Digital Twins & ZeroConf AI: Structuring Automated Intelligent Pipelines for Industrial Applications](https://arxiv.org/abs/2602.04385)
*Marco Picone,Fabio Turazza,Matteo Martinelli,Marco Mamei*

Main category: cs.AI

TL;DR: 本文提出了一种模块化、可互操作的解决方案，通过零配置AI管道将人工智能无缝集成到信息物理系统中，解决了工业领域AI/ML技术集成的碎片化挑战。


<details>
  <summary>Details</summary>
Motivation: 信息物理系统日益复杂，特别是在工业领域，物联网和工业物联网技术的碎片化（表现为不同的通信协议、数据格式和设备能力）在底层物理层和高级智能功能之间造成了巨大鸿沟。当前的数字孪生方法往往是孤立的、紧密耦合的，限制了AI功能的可扩展性和重用性。

Method: 提出了一种模块化和可互操作的解决方案，通过最小化配置和解耦数字孪生与AI组件的角色，实现AI管道无缝集成到信息物理系统中。引入了零配置AI管道概念，其中数字孪生负责数据管理和智能增强。

Result: 在微工厂场景中演示了该方法，展示了支持并发机器学习模型和动态数据处理的能力，有效加速了复杂工业环境中智能服务的部署。

Conclusion: 该解决方案通过零配置AI管道和数字孪生技术的结合，解决了信息物理系统中AI/ML集成的碎片化问题，提高了可扩展性、重用性和部署效率，为复杂工业环境中的智能服务提供了有效的技术路径。

Abstract: The increasing complexity of Cyber-Physical Systems (CPS), particularly in the industrial domain, has amplified the challenges associated with the effective integration of Artificial Intelligence (AI) and Machine Learning (ML) techniques. Fragmentation across IoT and IIoT technologies, manifested through diverse communication protocols, data formats and device capabilities, creates a substantial gap between low-level physical layers and high-level intelligent functionalities. Recently, Digital Twin (DT) technology has emerged as a promising solution, offering structured, interoperable and semantically rich digital representations of physical assets. Current approaches are often siloed and tightly coupled, limiting scalability and reuse of AI functionalities. This work proposes a modular and interoperable solution that enables seamless AI pipeline integration into CPS by minimizing configuration and decoupling the roles of DTs and AI components. We introduce the concept of Zero Configuration (ZeroConf) AI pipelines, where DTs orchestrate data management and intelligent augmentation. The approach is demonstrated in a MicroFactory scenario, showing support for concurrent ML models and dynamic data processing, effectively accelerating the deployment of intelligent services in complex industrial settings.

</details>


### [13] [From Competition to Collaboration: Designing Sustainable Mechanisms Between LLMs and Online Forums](https://arxiv.org/abs/2602.04572)
*Niv Fono,Yftah Ziser,Omer Ben-Porat*

Main category: cs.AI

TL;DR: 研究提出一个顺序交互框架来解决生成式AI系统与问答论坛之间的悖论关系：AI系统依赖论坛数据提升性能，却又将用户从论坛吸引走。通过数据驱动的模拟验证了激励错配问题，但显示双方仍能获得理想全信息场景下约一半的效用。


<details>
  <summary>Details</summary>
Motivation: 生成式AI系统面临一个悖论：它们依赖问答论坛产生的数据来提升性能，但同时又将用户从这些论坛吸引走。这种关系可能导致知识共享平台的可持续性危机，因此需要探索AI系统与人类知识平台之间的协作机制。

Method: 提出一个顺序交互框架，其中生成式AI系统向论坛提出问题，论坛可以选择发布其中一些问题。该框架捕捉了协作中的多个复杂性：非货币交换、信息不对称和激励错配。使用真实的Stack Exchange数据和常用LLM进行全面的数据驱动模拟来验证框架。

Result: 实证证明了激励错配问题的存在，但同时显示参与者能够达到理想全信息场景下大约一半的效用。这表明尽管存在激励不一致，但AI系统和人类知识平台之间仍有可能实现可持续的协作。

Conclusion: 研究结果强调了生成式AI系统与人类知识平台之间可持续协作的潜力，这种协作能够保持有效的知识共享。通过适当的框架设计，可以缓解AI系统对传统问答平台的负面影响，实现互利共赢。

Abstract: While Generative AI (GenAI) systems draw users away from (Q&A) forums, they also depend on the very data those forums produce to improve their performance. Addressing this paradox, we propose a framework of sequential interaction, in which a GenAI system proposes questions to a forum that can publish some of them. Our framework captures several intricacies of such a collaboration, including non-monetary exchanges, asymmetric information, and incentive misalignment. We bring the framework to life through comprehensive, data-driven simulations using real Stack Exchange data and commonly used LLMs. We demonstrate the incentive misalignment empirically, yet show that players can achieve roughly half of the utility in an ideal full-information scenario. Our results highlight the potential for sustainable collaboration that preserves effective knowledge sharing between AI systems and human knowledge platforms.

</details>


### [14] [Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration](https://arxiv.org/abs/2602.04575)
*Jiaheng Liu,Yuanxing Zhang,Shihao Li,Xinping Lei*

Main category: cs.AI

TL;DR: 论文提出Vibe AIGC新范式，通过多智能体工作流编排解决当前生成式AI的"意图-执行鸿沟"问题，将用户从提示工程师转变为提供高层"氛围"的指挥官。


<details>
  <summary>Details</summary>
Motivation: 当前生成式AI受模型中心范式主导，虽然视觉保真度显著提升，但存在"可用性天花板"问题，表现为意图-执行鸿沟——创作者的高层意图与当前单次生成模型的随机性、黑盒性质之间的根本差距。

Method: 受Vibe Coding启发，提出Vibe AIGC范式：通过智能体编排实现内容生成，构建分层多智能体工作流。用户作为指挥官提供"氛围"（包含审美偏好、功能逻辑等高层表示），中心化元规划器作为系统架构师，将"氛围"解构为可执行、可验证、自适应的智能体管道。

Result: 通过从随机推理转向逻辑编排，Vibe AIGC弥合了人类想象力与机器执行之间的鸿沟，将AI从脆弱的推理引擎转变为稳健的系统级工程伙伴。

Conclusion: 这一范式转变将重新定义人机协作经济，使复杂、长视野数字资产的创作民主化，为生成式AI开辟新的发展方向。

Abstract: For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the \textbf{Vibe AIGC}, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows.
  Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.

</details>


### [15] [WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.04634)
*Zelai Xu,Zhexuan Xu,Ruize Zhang,Chunyang Zhu,Shi Yu,Weilin Liu,Quanlu Zhang,Wenbo Ding,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: 论文提出WideSeek-R1多智能体框架，通过宽度扩展而非深度扩展来解决广泛信息检索任务，使用4B参数模型达到与671B单智能体模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 随着任务范围扩大，关键瓶颈从个体能力转向组织能力。现有多智能体系统依赖手工工作流程和轮转交互，无法有效并行化工作。

Method: 提出WideSeek-R1框架，采用领导智能体-子智能体架构，通过多智能体强化学习训练，利用共享LLM但隔离上下文和专用工具，在2万个广泛信息检索任务数据集上联合优化。

Result: WideSeek-R1-4B在WideSearch基准测试中达到40.0%的项目F1分数，与单智能体DeepSeek-R1-671B性能相当。随着并行子智能体数量增加，性能持续提升。

Conclusion: 宽度扩展是多智能体系统解决广泛信息检索任务的有效方法，WideSeek-R1框架展示了通过并行执行和可扩展编排实现高效任务处理的潜力。

Abstract: Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking. Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution. By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark, which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.

</details>


### [16] [Are AI Capabilities Increasing Exponentially? A Competing Hypothesis](https://arxiv.org/abs/2602.04836)
*Haosen Ge,Hamsa Bastani,Osbert Bastani*

Main category: cs.AI

TL;DR: 该论文反驳了METR报告中关于AI能力呈指数增长的结论，认为数据不支持指数增长，并提出了更复杂的模型表明拐点已过或即将到来


<details>
  <summary>Details</summary>
Motivation: 反驳METR报告中AI能力呈指数增长的观点，指出现有预测的脆弱性，强调需要更谨慎地评估AI发展轨迹

Method: 1. 对METR数据进行sigmoid曲线拟合，发现拐点已过；2. 提出将AI能力分解为基础能力和推理能力的复杂模型，分别评估改进速率

Result: 1. 数据不支持AI能力的指数增长；2. sigmoid拟合显示拐点已过；3. 复杂模型支持AI能力将在近期出现拐点的假设

Conclusion: 现有关于AI能力指数增长的预测是脆弱的，需要更复杂的建模方法来准确评估AI发展轨迹，拐点可能已经或即将到来

Abstract: Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.

</details>


### [17] [Fluid Representations in Reasoning Models](https://arxiv.org/abs/2602.04843)
*Dmitrii Kharlapenko,Alessandro Stolfo,Arthur Conmy,Mrinmaya Sachan,Zhijing Jin*

Main category: cs.AI

TL;DR: QwQ-32B模型通过推理过程逐步改进对抽象结构信息的内部表示，形成专注于结构而非具体动作名称的抽象编码，这种"流体推理表示"是推理模型性能提升的关键因素之一。


<details>
  <summary>Details</summary>
Motivation: 尽管推理语言模型在抽象问题上表现优异，但其内部机制如何实现这种优越性能仍然不明确。研究旨在揭示QwQ-32B模型处理抽象结构信息的具体机制。

Method: 在语义混淆的规划领域Mystery Blocksworld上，对QwQ-32B进行机制分析，包括观察推理过程中内部表示的变化，以及通过导向实验验证因果效应。

Result: 模型在推理过程中逐步改进对动作和概念的内部表示，形成专注于结构的抽象编码。注入成功轨迹中的精炼表示能提升准确性，而符号表示可以替代许多混淆编码且性能损失最小。

Conclusion: 推理模型性能的关键驱动因素之一是上下文中的标记表示精炼，即"流体推理表示"。这些适应性改进有助于问题解决，为理解推理语言模型的内部机制提供了新见解。

Abstract: Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural information. On Mystery Blocksworld - a semantically obfuscated planning domain - we find that QwQ-32B gradually improves its internal representation of actions and concepts during reasoning. The model develops abstract encodings that focus on structure rather than specific action names. Through steering experiments, we establish causal evidence that these adaptations improve problem solving: injecting refined representations from successful traces boosts accuracy, while symbolic representations can replace many obfuscated encodings with minimal performance loss. We find that one of the factors driving reasoning model performance is in-context refinement of token representations, which we dub Fluid Reasoning Representations.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [18] [WebAccessVL: Making an Accessible Web via Violation-Conditioned VLM](https://arxiv.org/abs/2602.03850)
*Amber Yijia Zheng,Jae Joong Lee,Bedrich Benes,Raymond A. Yeh*

Main category: cs.HC

TL;DR: 提出一个视觉语言模型，能够自动编辑网站HTML以解决WCAG2可访问性违规问题，通过HTML和渲染图像学习修正，效果优于商业LLM API。


<details>
  <summary>Details</summary>
Motivation: 网站可访问性对于残障用户至关重要，但手动修复WCAG2违规既耗时又昂贵。现有方法难以同时理解视觉渲染和HTML结构来有效修正可访问性问题。

Method: 将任务形式化为监督式图像条件程序合成，模型学习根据HTML及其渲染图像进行修正。收集WebAccessVL数据集，并提出违规条件VLM，额外基于WCAG2违规数量指导修正过程。

Result: 方法有效将每个网站的平均违规数量从5.34减少到0.44，优于Gemini和GPT-5等商业LLM API。感知研究证实编辑后的网站保持了原始视觉外观和内容。

Conclusion: 提出的视觉语言模型能够有效自动修复网站可访问性违规，在减少违规数量的同时保持网站原有外观，为可访问性自动化提供了有前景的解决方案。

Abstract: We present a vision-language model (VLM) that automatically edits website HTML to address Web Content Accessibility Guidelines 2 (WCAG2) violations. We formulate this as a supervised image-conditioned program synthesis task, where the model learns to correct HTML given the HTML and its rendering. We collected WebAccessVL, a new dataset with manually corrected accessibility violations, establishing paired training data. We then propose a violation-conditioned VLM that additionally conditions on the WCAG2 violation count to guide the correction process. Experiments demonstrate that our method effectively reduces the average number of violations from 5.34 to 0.44 per website, outperforming commercial LLM APIs (Gemini, GPT-5). A perceptual study confirms that our edited websites maintain the original visual appearance and content.

</details>


### [19] [Gamification-Based Learning Method for Hijaiyah Letters](https://arxiv.org/abs/2602.03851)
*Wisnu Uriawan,Denis Firmansyah,Devi Mulyana,Dika Haekal Firza Pratama,Adly Juliarta Lerian,Fajar Satria Wiguna*

Main category: cs.HC

TL;DR: 本研究设计并实施了一种基于游戏化的Hijaiyah字母学习创新方法，通过ADDIE框架开发，使用Unity 2D和Firebase构建，显著提高了学生的学习成绩和参与度。


<details>
  <summary>Details</summary>
Motivation: 传统基于重复记忆的Hijaiyah字母教学方法难以维持当代年轻学习者的学习兴趣，需要创新的教学方法来提高学习效果和参与度。

Method: 采用ADDIE框架（分析、设计、开发、实施、评估）系统开发游戏化学习方法，使用Unity 2D和Firebase技术实现，包含积分、徽章、排行榜、渐进关卡等游戏元素，以及视觉动画、基于tajwid的音频发音、互动字母描摹等多维度学习组件。

Result: 50名小学生参与实证评估，平均测试分数从42.8提高到88.6（提升107%，p < 0.001），效应量极大（Cohen's d = 4.87），用户参与度高（平均每日4.2次会话），满意度评分高（平均动机得分4.82/5）。

Conclusion: 游戏化方法不仅显著提高了Hijaiyah字母的认知学习效果，还培养了毅力、责任感和纪律性等伊斯兰价值观，成功将传统伊斯兰教学原则与现代数字学习技术相结合，为当代伊斯兰教育中的Hijaiyah识字发展创建了变革性、参与性和有意义的教育范式。

Abstract: The mastery of Hijaiyah letters is a crucial foundation for reading and comprehending the Quran, yet conventional pedagogical approaches based on repetitive memorization frequently struggle to maintain the engagement of young learners in contemporary educational contexts. This research presents the design and implementation of an innovative gamification-based methodology for Hijaiyah literacy acquisition, systematically developed through the ADDIE framework (Analysis, Design, Development, Implementation, Evaluation) to optimize student motivation, participation, and educational outcomes. The resulting technological solution, engineered using Unity 2D and Firebase, strategically incorporates game design elements such as points, badges, leaderboards, and progressive leveling, while integrating multifaceted learning components including visual animations, authentic tajwid-based audio pronunciation, and interactive letter tracing exercises to simultaneously develop cognitive recognition capabilities and fine motor skills. Empirical evaluation involving 50 elementary school participants revealed substantial quantitative improvements, with mean assessment scores increasing from 42.8 to 88.6 (107% improvement, p < 0.001), demonstrating an exceptionally large effect size (Cohen's d = 4.87), complemented by strong user engagement metrics (4.2 average daily sessions) and high satisfaction ratings (4.82 out of 5 mean motivation score). Beyond cognitive learning outcomes, the gamified approach effectively fostered intrinsic Islamic values such as perseverance, responsibility, and disciplined practice, thereby establishing an innovative educational paradigm that successfully integrates traditional Islamic pedagogical principles with modern digital learning technologies to create a transformative, engaging, and meaningful framework for Hijaiyah literacy development in contemporary Islamic education.

</details>


### [20] [On-Demand Lecture Watching System Using Various Actions of Student Characters to Maintain Concentration](https://arxiv.org/abs/2602.03853)
*Saizo Aoyagi,Ryoma Okazaki,Seishiro Hara,Fumiya Ikeda,Michiya Yamamoto*

Main category: cs.HC

TL;DR: 研究开发了使用裸眼3D显示器呈现3D虚拟教室的在线讲座观看系统，发现同时展示积极和消极行为的学生角色比仅展示积极行为更能帮助维持注意力。


<details>
  <summary>Details</summary>
Motivation: COVID-19疫情后在线讲座普及，但缺乏学生共同在场导致注意力不集中。先前研究表明3D角色配合适当行为可能改善注意力，但尚未找到有效的行为组合。

Method: 开发了使用裸眼3D显示器呈现3D虚拟教室的讲座观看系统，包含展示点头、记笔记、睡觉等行为的学生角色。实验设置两个条件：(1)仅积极行为；(2)同时包含积极和消极行为。

Result: 以姿势和记笔记行为为关键指标的分析表明，当学生角色同时展示积极和消极行为时，比仅展示积极行为更能帮助维持注意力。

Conclusion: 研究结果为按需讲座中维持学生注意力提供了有前景的策略，有助于开发更有效的在线教育系统。

Abstract: Since the COVID-19 pandemic, online lectures have spread rapidly and many students are satisfied with them. However, one challenge remains the loss of concentration due to the lack of students' copresence. Our previous work suggests that presenting 3D characters with appropriate actions has the potential to improve concentration in online lectures. Nevertheless, an effective combination of actions has not yet been identified. In this study, we developed a lecture watching system that presents a 3D virtual classroom using a naked-eye 3D display. The system includes student characters that show copresence with various actions such as nodding, notetaking, and sleeping. An evaluation experiment was conducted with two conditions; (1) student characters perform only positive actions and (2) both positive and negative actions. The results, analyzed using posture and notetaking behavior as key indicators, suggest that the system can help to maintain concentration when the student characters perform both positive and negative actions, rather than only positive ones. These findings provide promising strategies for maintaining student focus in on-demand lectures and contribute to the development of more effective online education systems.

</details>


### [21] [From Expectation To Experience: A Before And After Survey Of Public Opinion On Autonomous Cars In Saudi Arabia](https://arxiv.org/abs/2602.03854)
*Mona Alfayez,Ohoud Alharbi*

Main category: cs.HC

TL;DR: 该研究调查了沙特公民在接触自动驾驶技术前后的认知变化，以及人口统计学因素对自动驾驶接受度的影响，为政策制定提供参考。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车作为交通领域的变革性创新，在安全、可持续性和效率方面具有潜在优势。沙特阿拉伯的自动驾驶采用符合其"2030愿景"，通过利雅得自动驾驶地铁和自动驾驶汽车等项目推动智能交通。研究旨在了解沙特公民对自动驾驶的认知变化及其影响因素。

Method: 采用定量研究方法，调查沙特公民在接触自动驾驶技术前后的认知变化，分析年龄、性别、教育水平和驾驶习惯等人口统计学因素对自动驾驶接受度的影响。

Result: 研究发现信任、感知安全性和便利性是影响自动驾驶接受度的关键因素。研究结果为理解自动驾驶采用过程中的更广泛影响因素提供了见解。

Conclusion: 研究结果可为政策制定者和行业利益相关者提供策略参考，促进自动驾驶在沙特阿拉伯交通生态系统中的成功整合，支持沙特"2030愿景"的智能交通目标。

Abstract: Autonomous vehicles (AVs) are emerging as a transformative innovation in transportation, offering potential benefits in safety, sustainability, and efficiency. Saudi Arabian adoption of AVs aligns with Vision 2030, emphasizing smart mobility through initiatives such as the Riyadh Autonomous Metro and self-driving cars. This study explores Saudi citizens perceptions of AVs before and after exposure to these technologies and examines whether demographic factors age, gender, education level, and driving habits affect acceptance. Using quantitative methods, the findings provide insights into the broader influences shaping AV adoption, highlighting the importance of trust, perceived safety, and convenience. These results can inform policymakers and industry stakeholders on strategies to facilitate successful integration of AVs into Saudi Arabian transportation ecosystem.

</details>


### [22] [Futuring Social Assemblages: How Enmeshing AIs into Social Life Challenges the Individual and the Interpersonal](https://arxiv.org/abs/2602.03958)
*Lingqing Wang,Yingting Gao,Chidimma Lois Anyi,Ashok Goel*

Main category: cs.HC

TL;DR: 社交AI在缓解人际问题的同时，反而加剧了这些问题，并带来隐私危害和身份威胁，暴露了以用户为中心的设计范式的问题。


<details>
  <summary>Details</summary>
Motivation: 随着AI日益融入人类社交生活，形成人与AI共同塑造的变革性关系，迫切需要研究这些系统如何反过来塑造其用户。

Method: 采用三阶段设计研究，涉及24名参与者，探索社交AI与用户之间的动态关系。

Result: 研究发现三个关键矛盾：1)社交AI常常加剧它本应缓解的人际问题；2)为无意中参与AI中介社交互动的次要用户带来微妙的隐私危害；3)可能威胁主要用户的个人能动性和身份认同。

Conclusion: 这些矛盾暴露了以用户为中心范式的倾向性问题，即优先考虑即时用户体验而牺牲人际伦理和自我效能等核心人类价值。需要转向更具挑战性和关系性的设计视角，强调长期的社会和个人后果。

Abstract: Recent advances in AI are integrating AI into the fabric of human social life, creating transformative, co-shaping relationships between humans and AI. This trend makes it urgent to investigate how these systems, in turn, shape their users. We conducted a three-phase design study with 24 participants to explore this dynamic. Our findings reveal critical tensions: (1) social AI often exacerbates the very interpersonal problems it is designed to mitigate; (2) it introduces nuanced privacy harms for secondary users inadvertently involved in AI-mediated social interactions; and (3) it can threaten the primary user's personal agency and identity. We argue these tensions expose a problematic tendency in the user-centered paradigm, which often prioritizes immediate user experience at the expense of core human values like interpersonal ethics and self-efficacy. We call for a paradigm shift toward a more provocative and relational design perspective that foregrounds long-term social and personal consequences.

</details>


### [23] [After Talking with 1,000 Personas: Learning Preference-Aligned Proactive Assistants From Large-Scale Persona Interactions](https://arxiv.org/abs/2602.04000)
*Ziyi Xuan,Yiwen Wu,Zhaoyang Yan,Vinod Namboodiri,Yu Yang*

Main category: cs.HC

TL;DR: 提出了一种面向智能助手的群体到个体学习框架，通过大规模模拟学习用户偏好，在设备端通过轻量级激活引导实现个性化适配，无需模型重训练或云端更新。


<details>
  <summary>Details</summary>
Motivation: 智能助手主动行为时机不当或侵入性会导致用户失去信任并禁用功能。学习用户偏好困难，因为真实世界研究成本高、规模有限，且难以捕捉跨多会话的偏好变化。现有合成数据集在时间深度、多样性和多维偏好方面有限，且缺乏将群体洞察迁移到设备端个体的支持。

Method: 采用群体到个体学习框架：1）使用1000个多样化虚拟角色进行大规模交互模拟，学习用户在时间、自主性、沟通风格等维度上的偏好表达共享结构；2）在设备端通过基于简单交互反馈的轻量级激活引导进行个性化适配，无需模型重训练或云端更新。

Result: 通过1000个模拟角色的控制模拟和30名参与者的人类研究进行评估。结果显示：相比未调优和直接响应基线，在时机决策和感知交互质量方面有改进；设备端激活引导性能与基于人类反馈的强化学习相当；参与者报告随着助手在多会话中适配，满意度、信任度和舒适度更高。

Conclusion: 该框架能够在隐私和设备端约束下，通过大规模模拟学习群体偏好结构，再通过轻量级激活引导实现个性化适配，有效提升智能助手的主动行为时机和用户体验，为偏好对齐的主动助手提供了可行方案。

Abstract: Smart assistants increasingly act proactively, yet mistimed or intrusive behavior often causes users to lose trust and disable these features. Learning user preferences for proactive assistance is difficult because real-world studies are costly, limited in scale, and rarely capture how preferences change across multiple interaction sessions. Large language model based generative agents offer a way to simulate realistic interactions, but existing synthetic datasets remain limited in temporal depth, diverse personas, and multi-dimensional preferences. They also provide little support for transferring population-level insights to individual users under on-device constraints. We present a population-to-individual learning framework for preference-aligned proactive assistants that operates under on-device and privacy constraints. Our approach uses large-scale interaction simulation with 1,000 diverse personas to learn shared structure in how users express preferences across recurring dimensions such as timing, autonomy, and communication style, providing a strong cold start without relying on real user logs. The assistant then adapts to individual users on device through lightweight activation-based steering driven by simple interaction feedback, without model retraining or cloud-side updates. We evaluate the framework using controlled simulations with 1,000 simulated personas and a human-subject study with 30 participants. Results show improved timing decisions and perceived interaction quality over untuned and direct-response baselines, while on-device activation steering achieves performance comparable to reinforcement learning from human feedback. Participants also report higher satisfaction, trust, and comfort as the assistant adapts over multiple sessions of interactions.

</details>


### [24] [Understanding How Accessibility Practices Impact Teamwork in Mixed-Ability Teams that Collaborate Virtually](https://arxiv.org/abs/2602.04015)
*Crescentia Jung,Kexin Cheng,Sharon Heung,Malte F. Jung,Shiri Azenkot*

Main category: cs.HC

TL;DR: 虚拟协作中，混合能力团队的可访问性实践不仅提供残疾人访问权限，还深刻影响团队协作、参与度和凝聚力，同时带来共情与责任平衡等挑战。


<details>
  <summary>Details</summary>
Motivation: 研究虚拟协作中混合能力团队（包含残疾人和非残疾人）的可访问性实践如何影响团队协作的各个方面，如生产力、参与度和团队凝聚力，填补当前研究空白。

Method: 对18名参与者（12名残疾人，6名非残疾人）进行访谈，这些参与者均来自混合能力团队，通过定性研究方法收集数据。

Result: 可访问性实践不仅提供访问权限，还影响任务协调、关系维持和责任协商；同时带来共情与责任平衡的挑战；非残疾人将盟友关系视为学习过程和技能。

Conclusion: 应将可访问性实践重新定义为强大团队协作的基础，并提出团队实践建议和虚拟协作工具设计机会，以支持混合能力团队的有效协作。

Abstract: Virtual collaboration has transformed how people in mixed-ability teams, composed of disabled and non-disabled people, work together by offering greater flexibility. In these settings, accessibility practices, such as accommodations and inclusive norms, are essential for providing access to disabled people. However, we do not yet know how these practices shape broader facets of teamwork, such as productivity, participation, and camaraderie. To address this gap, we interviewed 18 participants (12 disabled, 6 non-disabled) who are part of mixed-ability teams. We found that beyond providing access, accessibility practices shaped how all participants coordinated tasks, sustained rapport, and negotiated responsibilities. Accessibility practices also introduced camaraderie challenges, such as balancing empathy and accountability. Non-disabled participants described allyship as a learning process and skill shaped by their disabled team members and team culture. Based on our findings, we present recommendations for team practices and design opportunities for virtual collaboration tools that reframe accessibility practices as a foundation for strong teamwork.

</details>


### [25] [Chaplains' Reflections on the Design and Usage of AI for Conversational Care](https://arxiv.org/abs/2602.04017)
*Joel Wester,Samuel Rhys Cox,Henning Pohl,Niels van Berkel*

Main category: cs.HC

TL;DR: 研究探讨牧师对AI聊天机器人在非临床情感支持中的看法，发现虽然部分牧师持谨慎乐观态度，但多数认为AI在倾听、连接、承载和需求方面存在局限，需要基于"调谐"概念设计更适合日常情感支持的聊天机器人。


<details>
  <summary>Details</summary>
Motivation: 当前对话式AI研究主要基于临床专业知识，侧重于诊断和干预，但日常情感支持需求大多发生在非临床环境中，需要不同的对话方法。研究者希望通过牧师（在个人危机、悲伤和反思中提供指导的专业人士）的视角，了解AI聊天机器人在非临床情感支持中的潜力和局限。

Method: 招募18名牧师参与构建AI聊天机器人，通过质性分析研究他们对AI聊天机器人的看法和参与体验，分析牧师如何理解他们的牧灵关怀职责以及AI聊天机器人在哪些方面存在不足。

Result: 虽然部分牧师对聊天机器人持谨慎乐观态度，但大多数认为聊天机器人在支持日常幸福感方面存在局限性。分析揭示了牧师如何看待他们的牧灵关怀职责以及AI聊天机器人的不足之处，主要围绕四个主题：倾听、连接、承载和需求。这些主题与"调谐"概念产生共鸣，调谐最近被强调为理解护理技术提供微妙体验的关系视角。

Conclusion: 研究为设计旨在支持非临床环境中幸福感的聊天机器人提供了视角，强调了基于"调谐"概念的重要性，以更好地满足日常情感支持需求，弥补当前AI系统在非临床关怀方面的不足。

Abstract: Despite growing recognition that responsible AI requires domain knowledge, current work on conversational AI primarily draws on clinical expertise that prioritises diagnosis and intervention. However, much of everyday emotional support needs occur in non-clinical contexts, and therefore requires different conversational approaches. We examine how chaplains, who guide individuals through personal crises, grief, and reflection, perceive and engage with conversational AI. We recruited eighteen chaplains to build AI chatbots. While some chaplains viewed chatbots with cautious optimism, the majority expressed limitations of chatbots' ability to support everyday well-being. Our analysis reveals how chaplains perceive their pastoral care duties and areas where AI chatbots fall short, along the themes of Listening, Connecting, Carrying, and Wanting. These themes resonate with the idea of attunement, recently highlighted as a relational lens for understanding the delicate experiences care technologies provide. This perspective informs chatbot design aimed at supporting well-being in non-clinical contexts.

</details>


### [26] [Exploring Emerging Norms of AI Disclosure in Programming Education](https://arxiv.org/abs/2602.04023)
*Runlong Ye,Oliver Huang,Jessica He,Michael Liut*

Main category: cs.HC

TL;DR: 该研究通过情景实验探讨了AI辅助下计算机科学学生的作者归属认知与披露偏好，发现AI协助程度和人工精修是主要影响因素，建议从声明式政策转向过程导向的归属机制。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模糊了计算教育中的作者界限，学生在使用AI协助时面临如何正确归属的不确定性。研究旨在探索这些新兴规范，了解学生如何看待AI辅助下的作者归属问题。

Method: 采用因子情景研究设计，对94名计算机科学学生进行了102个独特情景的实验，系统操纵了评估类型、AI自主性、学生活动、先验知识和人工精修努力五个因素。

Result: 研究发现：1）归属判断主要由不同水平的AI协助和人工精修驱动；2）学生对作者身份的认知显著预测其政策期望；3）学生更倾向于过程导向的披露方式而非简单的声明式政策。

Conclusion: 建议从声明式政策转向过程导向的归属机制，将披露转化为一种教学工具，促进学生批判性地参与AI生成内容，从而更好地适应AI辅助下的学术环境。

Abstract: Generative AI blurs the lines of authorship in computing education, creating uncertainty around how students should attribute AI assistance. To examine these emerging norms, we conducted a factorial vignette study with 94 computer science students across 102 unique scenarios, systematically manipulating assessment type, AI autonomy, student activity, prior knowledge, and human refinement effort. This paper details how these factors influence students' perceptions of ownership and disclosure preferences. Our findings indicate that attribution judgments are primarily driven by different levels of AI assistance and human refinement. We also found that students' perception of authorship significantly predicts their policy expectations. We conclude by proposing a shift from statement-style policies to process-oriented attribution, transforming disclosure into a pedagogical mechanism for fostering critical engagement with AI-generated content.

</details>


### [27] [From Crafting Text to Crafting Thought: Grounding AI Writing Support to Writing Center Pedagogy](https://arxiv.org/abs/2602.04047)
*Yijun Liu,John Gallagher,Sarah Sterman,Tal August*

Main category: cs.HC

TL;DR: 论文开发了AI写作反馈工具Writor，通过借鉴写作中心的教学理念，帮助学生在保留个人声音的同时获得反馈，而不直接生成文本。


<details>
  <summary>Details</summary>
Motivation: 随着AI写作工具从修正表面错误发展到与作者共同创作语言，新功能引发了对学生写作能力负面影响的担忧，如取代学生声音和削弱批判性思维能力。需要设计能支持而非取代学生写作过程的AI工具。

Method: 借鉴大学写作中心从修正错误到保护学生声音的转变经验，基于写作中心文献和10位写作导师访谈制定设计指南，开发原型工具Writor。Writor通过设定目标、提供平衡反馈和对话互动来帮助学生修改文本，但不直接生成文本。对30位写作教师、导师和AI研究人员进行专家评审。

Result: 专家评审评估了Writor的教学合理性、与写作中心教学法的契合度以及整合环境。研究结果为未来AI写作反馈系统提炼了设计启示，包括为对AI持怀疑态度的教育者设计信任机制。

Conclusion: AI写作反馈系统应借鉴写作中心的教学理念，通过支持性而非替代性的设计来保护学生声音和批判性思维，同时建立教育者对AI工具的信任。

Abstract: As AI writing tools evolve from fixing surface errors to creating language with writers, new capabilities raise concerns about negative impacts on student writers, such as replacing their voices and undermining critical thinking skills. To address these challenges, we look at a parallel transition in university writing centers from focusing on fixing errors to preserving student voices. We develop design guidelines informed by writing center literature and interviews with 10 writing tutors. We illustrate these guidelines in a prototype AI tool, Writor. Writor helps writers revise text by setting goals, providing balanced feedback, and engaging in conversations without generating text verbatim. We conducted an expert review with 30 writing instructors, tutors, and AI researchers on Writor to assess the pedagogical soundness, alignment with writing center pedagogy, and integration contexts. We distill our findings into design implications for future AI writing feedback systems, including designing for trust among AI-skeptical educators.

</details>


### [28] [Tinker Tales: Supporting Child-AI Collaboration through Co-Creative Storytelling with Educational Scaffolding](https://arxiv.org/abs/2602.04109)
*Nayoung Choi,Jiseung Hong,Peace Cyebukayire,Ikseon Choi,Jinho D. Choi*

Main category: cs.HC

TL;DR: Tinker Tales是一个支持儿童与AI协作创作故事的实体交互系统，通过叙事和社交情感支架促进儿童在故事创作中的主导权。


<details>
  <summary>Details</summary>
Motivation: 当前AI与儿童的互动研究主要集中在AI主导的教学场景，缺乏对儿童与AI共同创造性协作的探索。本研究旨在填补这一空白，探索儿童如何通过迭代共创与AI进行有意义的互动。

Method: 开发了Tinker Tales系统，包含物理故事板、嵌入NFC的玩具（代表角色、地点、物品和情感）以及协调儿童-AI交互的移动应用。儿童通过放置和移动故事元素，以及通过实体和语音交互与AI互动来塑造和精炼故事。进行了探索性用户研究，涉及10名儿童。

Result: 研究发现儿童将AI视为专注、响应迅速的协作伙伴，同时系统提供的支架支持了连贯的叙事精炼，且没有削弱儿童的主导权。

Conclusion: Tinker Tales系统成功支持了儿童与AI的协作创作，展示了在保持儿童主导权的同时，通过适当的支架设计可以促进有意义的儿童-AI共创体验。

Abstract: Artificial intelligence (AI) is increasingly framed as a collaborative partner in creative activities, yet children's interactions with AI have largely been studied in AI-led instructional settings rather than co-creative collaboration. This leaves open questions about how children can meaningfully engage with AI through iterative co-creation. We present Tinker Tales, a tangible storytelling system designed with narrative and social-emotional scaffolding to support child-AI collaboration. The system combines a physical storytelling board, NFC-embedded toys representing story elements (e.g., characters, places, items, and emotions), and a mobile app that mediates child-AI interaction. Children shape and refine stories by placing and moving story elements and interacting with the AI through tangible and voice-based interaction. We conducted an exploratory user study with 10 children to examine how they interacted with Tinker Tales. Our findings show that children treated the AI as an attentive, responsive collaborator, while scaffolding supported coherent narrative refinement without diminishing children's agency.

</details>


### [29] [Counting the Wait: Effects of Temporal Feedback on Downstream Task Performance and Perceived Wait-Time Experience during System-Imposed Delays](https://arxiv.org/abs/2602.04138)
*Felicia Fang-Yi Tan,Oded Nov*

Main category: cs.HC

TL;DR: 研究系统等待时间反馈模式对用户体验和任务表现的影响，发现剩余时间反馈会增加挫败感，无时间显示会延长感知等待时间，但这些体验差异不影响后续任务表现。


<details>
  <summary>Details</summary>
Motivation: 系统强加的等待时间会显著干扰数字工作流程，影响用户体验和任务表现。虽然已有HCI研究探讨时间反馈模式（如已过时间vs剩余时间）如何影响等待时间感知，但很少有研究调查这种反馈如何影响用户的下游任务表现以及整体情感和认知体验。

Method: 进行在线实验，425名参与者执行视觉推理任务时经历10秒、30秒或60秒的等待，分别使用剩余时间反馈、已过时间反馈或无时间显示三种条件。

Result: 时间反馈模式影响等待感知：剩余时间反馈相比已过时间反馈增加了挫败感，而无时间显示使等待感觉更长并增加了模糊性。值得注意的是，这些体验差异并未转化为等待后任务表现的差异。

Conclusion: 结合心理物理学和认知科学视角，讨论了在易延迟的数字系统中实施时间反馈的启示，强调虽然反馈模式影响主观体验，但不影响后续任务表现。

Abstract: System-imposed wait times can significantly disrupt digital workflows, affecting user experience and task performance. Prior HCI research has examined how temporal feedback, such as feedback mode (Elapsed-Time vs. Remaining-Time) shapes wait-time perception. However, few studies have investigated how such feedback influences users' downstream task performance, as well as overall affective and cognitive experience. To study these effects, we conducted an online experiment where 425 participants performing a visual reasoning task experienced a 10-, 30-, or 60-second wait with a Remaining-Time, Elapsed-Time, or No Time Display. Findings show that temporal feedback mode shapes how waiting is perceived: Remaining-Time feedback increased frustration relative to Elapsed-Time feedback, while No Time Display made waits feel longer and heightened ambiguity. Notably, these experiential differences did not translate into differences in post-wait task performance. Integrating psychophysical and cognitive science perspectives, we discuss implications for implementing temporal feedback in latency-prone digital systems.

</details>


### [30] [Paint by Odor: An Exploration of Odor Visualization through Large Language Model and Generative AI](https://arxiv.org/abs/2602.04159)
*Gang Yu,Yuchi Sun,Weining Yan,Xinyu Wang,Qi Lu*

Main category: cs.HC

TL;DR: Paint by Odor：利用生成式AI和大型语言模型将嗅觉感知转化为视觉图像的自动化管道，通过实验验证了语言描述和抽象风格对气味可视化的影响。


<details>
  <summary>Details</summary>
Motivation: 传统气味可视化主要依赖一维映射（如气味到颜色的关联）且需要大量人工设计，而生成式AI和LLMs为自动化气味可视化提供了新机遇。当前研究在连接嗅觉感知与生成工具以产生气味图像方面仍存在空白。

Method: 提出Paint by Odor管道，利用Gen AI和LLMs将嗅觉感知转化为丰富、具有美学吸引力的视觉表征。进行了两个实验：1）30名参与者闻真实气味并提供描述数据；2）28名参与者通过7个系统设计的提示评估560个生成的气味图像。

Result: 研究发现LLMs在产生嗅觉感知方面的能力（与人类反应比较），揭示了基于语言的描述和几种抽象风格对气味可视化的底层机制和影响。讨论了无需人类参与的自动化气味可视化的可能性。

Conclusion: 该研究填补了使用LLMs和Gen AI进行气味可视化的研究空白，为未来应用提供了有价值的设计见解和各种可能性。

Abstract: Odor visualization translates odor information and perception into visual outcomes and arouses the corresponding olfactory synesthesia, surpassing the spatial limitation that odors can only be perceived where they are present. Traditional odor visualization has typically relied on unidimensional mappings, such as odor-to-color associations, and has required extensive manual design efforts. However, the advent of generative AI (Gen AI) and large language models (LLMs) presents a new opportunity for automatic odor visualization. Nonetheless, gaps remain in bridging olfactory perception with generative tools to produce odor images. To address these gaps, this paper introduces Paint by Odor, a pipeline that leverages Gen AI and LLMs to transform olfactory perceptions into rich, aesthetically engaging visual representations. Two experiments were conducted, where 30 participants smelled real-world odors and provided descriptive data and 28 participants evaluated 560 generated odor images through seven systematically designed prompts. Our findings explored the capability of LLMs in producing olfactory perception by comparing it with human responses and revealed the underlying mechanisms and effects of language-based descriptions and several abstraction styles on odor visualization. Our work further discussed the possibility of automatic odor visualization without human participation. These explorations and results have bridged the research gap in odor visualization using LLMs and Gen AI, offering valuable design insights and various possibilities for future applications.

</details>


### [31] [Strategic Adaptation Under Contextual Change: Insights from a Dyadic Negotiation Testbed for AI Coaching Technologies](https://arxiv.org/abs/2602.04242)
*Mobasshira Akter Urmi,Raiyan Abdul Baten*

Main category: cs.HC

TL;DR: 研究人员开发了一种可重复的谈判测试平台，通过中程改变一方外部选择来评估战略适应能力，发现扰动导致谈判行为从合作转向竞争，这种转变预测了更差的关系体验。


<details>
  <summary>Details</summary>
Motivation: 战略适应是谈判训练的核心目标，也是AI教练系统的新兴方向，但难以评估，因为适应相关时刻在典型任务中不可预测地出现。

Method: 开发可重复的双边谈判测试平台，通过控制一方外部选择的中程变化作为可重复扰动来压力测试适应能力；进行六轮基于聊天的谈判研究（N=100）。

Result: 扰动可靠地重组了互动动态：整合（合作）与分配（立场）行为之间的转换减少，行为多样性变窄，互动倾向于更多分配策略；这种分配性漂移预测了更差的关系体验，适应模式对先前行为具有路径依赖性。

Conclusion: 建立了一个评估和比较AI教练系统战略适应过程的方法桥梁，识别了自适应互动支持的失败模式和设计目标。

Abstract: Strategic adaptation -- the ability to adjust interaction behavior in response to changing constraints and leverage -- is a central goal of negotiation training and an emerging target for AI coaching systems. However, adaptation is difficult to evaluate because adaptation-relevant moments arise unpredictably in typical tasks. We study a reusable dyadic negotiation testbed that employs a controlled midstream change in one party's outside alternative as a repeatable perturbation to stress-test adaptation. In a six-round chat-based negotiation study (N=100), the perturbation reliably reorganized interaction dynamics: transitions between integrative (cooperative) and distributive (positional) behaviors declined, behavioral diversity narrowed, and interactions drifted toward more distributive tactics. Critically, this distributive drift predicted worse relational experience net of objective outcomes, and adaptation patterns were path dependent on prior behavior. These results establish a methodological bridge for evaluating and comparing AI coaching systems on strategic adaptation as a process and identify failure modes and design targets for adaptive interaction support.

</details>


### [32] [A Multimodal fNIRS-EEG Dataset for Unilateral Limb Motor Imagery](https://arxiv.org/abs/2602.04299)
*Lufeng Feng,Baomin Xu,Haoran Zhang,Bihai Lin,Zuxuan Deng,Sidi Tao,Chenyu Liu,Shifan Jia,Li Duan,Ziyu Jia*

Main category: cs.HC

TL;DR: 该研究构建了MIND数据集，一个公开的多模态脑机接口数据集，同时记录脑电图(EEG)和功能性近红外光谱(fNIRS)，专注于右上肢四方向运动想象任务。


<details>
  <summary>Details</summary>
Motivation: 现有公开数据集主要关注左右肢二分类或四分类运动想象，主要利用半球偏侧化特征，缺乏同时记录EEG和fNIRS的单侧多方向运动想象数据集，而单侧运动想象在运动康复和外部设备精确控制中具有重要作用。

Method: 构建了MIND数据集，包含30名参与者（12名女性，18名男性；年龄19.0-25.0岁）的64通道EEG记录（1000Hz）和51通道fNIRS记录（47.62Hz），基于右上肢四方向运动想象范式。

Result: 分析了EEG频谱功率和血流动力学响应的时空特征，验证了混合fNIRS-EEG脑机接口在分类准确性方面的潜在优势。

Conclusion: 该数据集将促进神经影像分析和解码方法的评估与比较，为单侧多方向运动想象研究提供重要资源。

Abstract: Unilateral limb motor imagery (MI) plays an important role in upper-limb motor rehabilitation and precise control of external devices, and places higher demands on spatial resolution. However, most existing public datasets focus on binary- or four-class left-right limb paradigms that mainly exploit coarse hemispheric lateralization, and there is still a lack of multimodal datasets that simultaneously record EEG and fNIRS for unilateral multi-directional MI. To address this gap, we constructed MIND, a public motor imagery fNIRS-EEG dataset based on a four-class directional MI paradigm of the right upper limb. The dataset includes 64-channel EEG recordings (1000 Hz) and 51-channel fNIRS recordings (47.62 Hz) from 30 participants (12 females, 18 males; aged 19.0-25.0 years). We analyse the spatiotemporal characteristics of EEG spectral power and hemodynamic responses, and validate the potential advantages of hybrid fNIRS-EEG BCIs in terms of classification accuracy. We expect that this dataset will facilitate the evaluation and comparison of neuroimaging analysis and decoding methods.

</details>


### [33] [Normalizing Speed-accuracy Biases in 2D Pointing Tasks with Better Calculation of Effective Target Widths](https://arxiv.org/abs/2602.04432)
*Shota Yamanaka,I. Scott MacKenzie*

Main category: cs.HC

TL;DR: 比较了在2D Fitts定律评估中，使用单变量标准差与双变量标准差计算有效目标宽度(W_e)的效果，发现单变量方法在所有速度-准确度偏置条件下都产生更高的模型相关性和更稳定的吞吐量。


<details>
  <summary>Details</summary>
Motivation: ISO 9241-411推荐使用单变量标准差计算有效目标宽度进行2D目标选择的Fitts定律评估，但相关研究提出了使用双变量标准差的方法。然而，该提案仅在单一速度-准确度偏置条件下测试，评估有限。

Method: 在2D Fitts定律实验中比较了单变量和双变量技术，使用了三种速度-准确度偏置条件和346名众包工作者。还使用了随机抽样的参与者数据子集进行一致性验证。

Result: 使用单变量标准差计算W_e在所有偏置条件下都产生了更高的模型相关性，并在不同偏置间产生了更稳定的吞吐量。使用名义或有效振幅以及不同任务轴视角的影响微不足道。

Conclusion: 建议未来研究应使用单变量标准差计算W_e以进行公平的性能评估。单变量方法在2D Fitts定律评估中表现更优。

Abstract: For evaluations of 2D target selection using Fitts' law, ISO 9241-411 recommends using the effective target width (W_e) calculated using the univariate standard deviation of selection coordinates. Related research proposed using a bivariate standard deviation; however, the proposal was only tested using a single speed-accuracy bias condition, thus the assessment was limited. We compared the univariate and bivariate techniques in a 2D Fitts' law experiment using three speed-accuracy biases and 346 crowdworkers. Calculating W_e using the univariate standard deviation yielded higher model correlations across all bias conditions and produced more stable throughput among the biases. The findings were also consistent in cases using randomly sampled subsets of the participant data. We recommend that future research should calculate W_e using the univariate standard deviation for fair performance evaluations. Also, we found trivial effects when using nominal or effective amplitude and using different perspectives of the task axis.

</details>


### [34] [Can Theory-Informed Message Framing Drive Honest and Motivated Performance with Better Assessment Experiences in a Remote Assessment?](https://arxiv.org/abs/2602.04450)
*Suvadeep Mukherjee,Björn Rohles,Gabriele Lenzini,Pedro Cardoso-Leite*

Main category: cs.HC

TL;DR: 研究验证了基于心理学理论的45条信息干预能否在远程无监督评估中减少作弊，同时保持表现和体验。结果显示这些信息将完全作弊率降低42%，增加非作弊率19%，且不影响表现和体验。


<details>
  <summary>Details</summary>
Motivation: 当前远程无监督评估中的信息干预缺乏理论基础，仅关注作弊抑制而忽视表现和体验，且将作弊视为二元而非连续变量。需要基于心理学理论开发更有效的干预措施。

Method: 通过专家工作坊(N=5)基于自我决定、认知失调、社会规范和自我效能等理论的15个心理学概念开发了45条信息。在线参与者(N=1232)完成激励性字谜任务，被分为非作弊者(0%)、部分作弊者(1-99%)和完全作弊者(100%)。

Result: 概念信息将完全作弊发生率降低42%(33%到19%)，非作弊率增加19%(53%到63%)，对所有诚信组的参与者的表现和体验均无负面影响。不同理论概念的信息效果几乎相同，信息同时影响多个心理机制而非特定目标。

Conclusion: 诚信干预使用支持性动机而非规则强制可以减少作弊而不损害表现或体验。因果路径比现有理论预测更复杂，信息同时影响多个心理机制。

Abstract: Remote unproctored assessments increasingly use messaging interventions to reduce cheating, but existing approaches lack theoretical grounding, focus narrowly on cheating suppression while overlooking performance and experience, and treat cheating as binary rather than continuous. This study examines whether messages based on 15 psychological concepts from self-determination, cognitive dissonance, social norms, and self-efficacy theories can reduce cheating while preserving performance and experience. Through an expert workshop (N=5), we developed 45 theory-informed messages and tested them with online participants (N=1232) who completed an incentivized anagram task. Participants were classified as non-cheaters (0% items cheated), partial-cheaters (1-99% cheated), or full-cheaters (100% cheated). Results show that concept-based messages reduced full-cheating occurrence by 42% (33% to 19%), increased non-cheating by 19% (53% to 63%), with no negative effects on performance or experience across integrity groups. Surprisingly, messages grounded in different theoretical concepts produced virtually identical effects. Analyses of self-rated psychological mechanisms revealed that messages influenced multiple mechanisms simultaneously rather than their intended targets, though these mechanisms predicted behavior, performance, and experience. These findings show that causal pathways are more complex than current theories predict. Practically, integrity interventions using supportive motivation rather than rule enforcement can reduce cheating without impairing performance or experience.

</details>


### [35] [Robot-Assisted Group Tours for Blind People](https://arxiv.org/abs/2602.04458)
*Yaxin Hu,Masaki Kuribayashi,Allan Wang,Seita Kayukawa,Daisuke Sato,Bilge Mutlu,Hironobu Takagi,Chieko Asakawa*

Main category: cs.HC

TL;DR: 研究探索移动机器人如何支持盲人在混合视觉群体中的参与，通过博物馆导览场景进行实地研究


<details>
  <summary>Details</summary>
Motivation: 群体互动对社交功能至关重要，但盲人难以识别和解读视觉线索，使得参与群体活动成为重大挑战

Method: 1) 对盲人(n=5)和博物馆专家(n=5)进行访谈研究；2) 设计并原型化支持盲人参与群体导览的机器人系统；3) 在科学博物馆进行实地研究，盲人参与者(n=8)与导游和明眼人参与者(n=8)一起参加群体导览

Result: 研究发现：用户从机器人导航支持中获得安全感；对群体参与的担忧；获取环境信息的偏好。提出了支持盲人混合视觉群体参与的机器人系统设计建议

Conclusion: 移动机器人可以有效支持盲人在混合视觉群体中的参与，研究为未来支持盲人群体参与的机器人系统提供了设计指导

Abstract: Group interactions are essential to social functioning, yet effective engagement relies on the ability to recognize and interpret visual cues, making such engagement a significant challenge for blind people. In this paper, we investigate how a mobile robot can support group interactions for blind people. We used the scenario of a guided tour with mixed-visual groups involving blind and sighted visitors. Based on insights from an interview study with blind people (n=5) and museum experts (n=5), we designed and prototyped a robotic system that supported blind visitors to join group tours. We conducted a field study in a science museum where each blind participant (n=8) joined a group tour with one guide and two sighted participants (n=8). Findings indicated users' sense of safety from the robot's navigational support, concerns in the group participation, and preferences for obtaining environmental information. We present design implications for future robotic systems to support blind people's mixed-visual group participation.

</details>


### [36] [PersoPilot: An Adaptive AI-Copilot for Transparent Contextualized Persona Classification and Personalized Response Generation](https://arxiv.org/abs/2602.04540)
*Saleh Afzoon,Amin Beheshti,Usman Naseem*

Main category: cs.HC

TL;DR: PersoPilot是一个集成用户画像理解和上下文分析的AI助手，通过可解释的聊天界面为终端用户提供个性化服务，同时为分析师提供基于推理的标注助手和主动学习分类系统，实现精准的上下文感知个性化推荐。


<details>
  <summary>Details</summary>
Motivation: 现有系统通常将用户画像和上下文作为独立输入处理，限制了生成细致、自适应交互的能力。为了充分利用用户画像的潜力，需要将其与情境上下文结合，实现更精确、有意义的服务提供。

Method: 提出PersoPilot框架，包含两个主要组件：1) 为终端用户提供透明、可解释的聊天界面，支持自然语言偏好表达和个性化推荐；2) 为分析师提供基于推理的标注助手，集成主动学习驱动的分类过程，能够随着新标注数据自适应更新。

Result: PersoPilot通过反馈循环实现了有针对性的服务推荐和自适应个性化，弥合了原始画像数据与可操作的上下文感知洞察之间的差距。该框架适用于广泛的服务个性化场景。

Conclusion: PersoPilot通过集成用户画像理解和上下文分析，为终端用户和分析师提供了统一的解决方案，实现了更精确、自适应的个性化服务，解决了现有系统将画像与上下文分离处理的局限性。

Abstract: Understanding and classifying user personas is critical for delivering effective personalization. While persona information offers valuable insights, its full potential is realized only when contextualized, linking user characteristics with situational context to enable more precise and meaningful service provision. Existing systems often treat persona and context as separate inputs, limiting their ability to generate nuanced, adaptive interactions. To address this gap, we present PersoPilot, an agentic AI-Copilot that integrates persona understanding with contextual analysis to support both end users and analysts. End users interact through a transparent, explainable chat interface, where they can express preferences in natural language, request recommendations, and receive information tailored to their immediate task. On the analyst side, PersoPilot delivers a transparent, reasoning-powered labeling assistant, integrated with an active learning-driven classification process that adapts over time with new labeled data. This feedback loop enables targeted service recommendations and adaptive personalization, bridging the gap between raw persona data and actionable, context-aware insights. As an adaptable framework, PersoPilot is applicable to a broad range of service personalization scenarios.

</details>


### [37] [AI in Education Beyond Learning Outcomes: Cognition, Agency, Emotion, and Ethics](https://arxiv.org/abs/2602.04598)
*Lucile Favero,Juan Antonio Pérez-Ortiz,Tanja Käser,Nuria Oliver*

Main category: cs.HC

TL;DR: AI教育应用需警惕认知卸载、主体性削弱、情感疏离和伦理监控等相互强化的风险，这些可能损害批判思维、自主性和公民参与能力。关键在于如何设计和管理AI以支持学习同时保障教育的社会公民目标。


<details>
  <summary>Details</summary>
Motivation: AI在教育中快速普及，但无批判性的采用可能产生超出个人学习成果的意外危害，影响更广泛的社会目标。需要系统分析AI教育应用的社会影响。

Method: 采用整合性框架分析AI教育的社会影响，包含四个相互关联的维度：认知、主体性、情感福祉和伦理。综合教育、认知科学、心理学和伦理学的研究证据。

Result: AI驱动的认知卸载、学习者主体性削弱、情感疏离和监控导向实践会相互强化，可能损害批判思维、智力自主性、情感韧性和信任，这些能力对有效学习和民主参与都至关重要。

Conclusion: 核心挑战不是AI是否应用于教育，而是如何设计和治理AI系统，使其支持学习的同时保障教育的社会和公民目的。需要教学对齐、伦理基础和以人为本的AI系统。

Abstract: Artificial intelligence (AI) is rapidly being integrated into educational contexts, promising personalized support and increased efficiency. However, growing evidence suggests that the uncritical adoption of AI may produce unintended harms that extend beyond individual learning outcomes to affect broader societal goals. This paper examines the societal implications of AI in education through an integrative framework with four interrelated dimensions: cognition, agency, emotional well-being, and ethics. Drawing on research from education, cognitive science, psychology, and ethics, we synthesize existing evidence to show how AI-driven cognitive offloading, diminished learner agency, emotional disengagement, and surveillance-oriented practices can mutually reinforce one another. We argue that these dynamics risk undermining critical thinking, intellectual autonomy, emotional resilience, and trust, capacities that are foundational both for effective learning and also for democratic participation and informed civic engagement. Moreover, AI's impact is contingent on design and governance: pedagogically aligned, ethically grounded, and human-centered AI systems can scaffold effortful reasoning, support learner agency, and preserve meaningful social interaction. By integrating fragmented strands of prior research into a unified framework, this paper advances the discourse on responsible AI in education and offers actionable implications for educators, designers, and institutions. Ultimately, the paper contends that the central challenge is not whether AI should be used in education, but how it can be designed and governed to support learning while safeguarding the social and civic purposes of education.

</details>


### [38] [A Human-Centered Privacy Approach (HCP) to AI](https://arxiv.org/abs/2602.04616)
*Luyi Sun,Wei Xu,Zaifeng Gao*

Main category: cs.HC

TL;DR: 本章提出以人为中心的隐私框架，从技术、伦理和人类因素角度为HCAI中的隐私保护提供综合解决方案


<details>
  <summary>Details</summary>
Motivation: 随着以人为中心的人工智能范式兴起，其社会效益伴随着重大伦理关切，特别是个人隐私保护问题

Method: 提出以人为中心的隐私框架，从AI开发生命周期的各个阶段映射隐私风险，介绍联邦学习、差分隐私等技术，整合用户心理模型、监管伦理环境和隐私治理，提供设计指南和实际案例研究

Result: 建立了综合性的隐私保护框架，涵盖技术、设计、政策和伦理多个维度，为HCAI中的隐私保护提供了系统性的解决方案

Conclusion: 需要融合技术、设计、政策和伦理专业知识的跨学科方法，才能成功将隐私嵌入HCAI的核心，确保这些技术以尊重和保障人类自主权、信任和尊严的方式发展

Abstract: As the paradigm of Human-Centered AI (HCAI) gains prominence, its benefits to society are accompanied by significant ethical concerns, one of which is the protection of individual privacy. This chapter provides a comprehensive overview of privacy within HCAI, proposing a human-centered privacy (HCP) framework, providing integrated solution from technology, ethics, and human factors perspectives. The chapter begins by mapping privacy risks across each stage of AI development lifecycle, from data collection to deployment and reuse, highlighting the impact of privacy risks on the entire system. The chapter then introduces privacy-preserving techniques such as federated learning and dif erential privacy. Subsequent chapters integrate the crucial user perspective by examining mental models, alongside the evolving regulatory and ethical landscapes as well as privacy governance. Next, advice on design guidelines is provided based on the human-centered privacy framework. After that, we introduce practical case studies across diverse fields. Finally, the chapter discusses persistent open challenges and future research directions, concluding that a multidisciplinary approach, merging technical, design, policy, and ethical expertise, is essential to successfully embed privacy into the core of HCAI, thereby ensuring these technologies advance in a manner that respects and ensures human autonomy, trust and dignity.

</details>


### [39] [VRARE: Using Virtual Reality to Understand Accessibility Requirements of Color Blindness and Weakness](https://arxiv.org/abs/2602.04621)
*Yi Wang,Ben Cheng,Xiao Liu,Chetan Arora,John Grundy,Thuong Hoang*

Main category: cs.HC

TL;DR: 开发了一个模拟色盲和色弱的VR系统，用于在虚拟健身环境中讨论网站项目的无障碍需求


<details>
  <summary>Details</summary>
Motivation: 研究虚拟现实技术如何帮助软件团队更好地理解和讨论色盲、色弱用户的无障碍需求，改进需求获取过程

Method: 开发了沉浸式3D网页视图界面，让参与者在虚拟健身环境中讨论健身网站的无障碍需求；进行了试点实验，24名参与者来自6个软件团队，分别使用VR和非VR方法理解色盲色弱需求

Result: 使用VR方法在需求活动中提供了多项好处，包括改善用户体验和减少工作负担

Conclusion: VR技术能够有效支持软件需求工程中的无障碍需求讨论，特别是对于色盲色弱等视觉障碍的理解和共情

Abstract: In this paper, we developed a virtual reality (VR) system that can simulate color blindness and weakness. We built an immersive 3D web view interface where participants can discuss accessibility requirements for a fitness website projects within a virtual fitness environment. We conducted a pilot experiment involving 24 participants from six software teams, who used both VR and non-VR methods to understand color blindness and weakness requirements in a website project. Our findings indicate that using VR can provide several benefits for requirements activities, such as an improved user experience and reduced workload.

</details>


### [40] [Discussing Your Needs in VR: A Novel Approach through Persona-based Stakeholder Role-Playing](https://arxiv.org/abs/2602.04632)
*Yi Wang,Zhengxin Zhang,Xiao Liu,Chetan Arora,John Grundy,Thuong Hoang*

Main category: cs.HC

TL;DR: 提出了一种在虚拟环境中支持需求讨论的新方法，通过实时语音转文本数据自动生成人物角色，实验显示该方法能降低工作负荷并提高用户满意度。


<details>
  <summary>Details</summary>
Motivation: 在虚拟环境中进行需求讨论时，需要更有效的工具来支持参与者理解用户需求，特别是针对可访问性等复杂需求领域。

Method: 开发了一个系统，能够从实时语音转文本数据中自动生成人物角色，并在虚拟现实环境中使用这些生成的人物角色进行需求讨论。

Result: 18名参与者（14名来自大学，4名来自IT公司）的实验显示，用户对VR系统的社交存在感和可用性满意度较高，且基于人物角色的需求讨论工作负荷较低。

Conclusion: 自动生成人物角色的方法在虚拟环境中支持需求讨论是有效的，能够提高讨论质量并降低参与者负担，未来工作需要进一步扩展和完善该系统。

Abstract: In this study, we propose a novel approach that supports requirements discussions in virtual environments by automatically generating personas from real-time speech-to-text data. In our pilot experiment, 18 participants (14 from universities and 4 from IT companies) used the generated personas to discuss accessibility requirements within the virtual environment. Participants reported a relatively high level of satisfaction with the social presence and usability of the VR system. We also found that requirements discussions based on personas have a lower workload. Finally, we outline the main directions for future work.

</details>


### [41] [Adaptive Prompt Elicitation for Text-to-Image Generation](https://arxiv.org/abs/2602.04713)
*Xinyi Wen,Lena Hegemann,Xiaofu Jin,Shuai Ma,Antti Oulasvirta*

Main category: cs.HC

TL;DR: APE是一种自适应提示引导技术，通过视觉查询帮助用户优化文本到图像生成的提示，无需大量写作，提高用户意图对齐


<details>
  <summary>Details</summary>
Motivation: 文本到图像生成中，用户意图对齐存在挑战：用户输入模糊且难以应对模型特性，需要更有效的交互方式来帮助用户优化提示

Method: 提出自适应提示引导(APE)技术，在信息论框架下进行交互式意图推断，使用语言模型先验将潜在意图表示为可解释的特征需求，自适应生成视觉查询，并将引导出的需求编译为有效提示

Result: 在IDEA-Bench和DesignBench上的评估显示，APE实现了更强的对齐效果和更高的效率。用户研究显示，在具有挑战性的用户定义任务中，对齐度提高了19.8%且没有增加工作负担

Conclusion: APE为普通用户提供了一种原则性的提示方法，作为当前基于提示的文本到图像模型交互范式的有效且高效的补充

Abstract: Aligning text-to-image generation with user intent remains challenging, for users who provide ambiguous inputs and struggle with model idiosyncrasies. We propose Adaptive Prompt Elicitation (APE), a technique that adaptively asks visual queries to help users refine prompts without extensive writing. Our technical contribution is a formulation of interactive intent inference under an information-theoretic framework. APE represents latent intent as interpretable feature requirements using language model priors, adaptively generates visual queries, and compiles elicited requirements into effective prompts. Evaluation on IDEA-Bench and DesignBench shows that APE achieves stronger alignment with improved efficiency. A user study with challenging user-defined tasks demonstrates 19.8% higher alignment without workload overhead. Our work contributes a principled approach to prompting that, for general users, offers an effective and efficient complement to the prevailing prompt-based interaction paradigm with text-to-image models.

</details>


### [42] [PuppetAI: A Customizable Platform for Designing Tactile-Rich Affective Robot Interaction](https://arxiv.org/abs/2602.04787)
*Jiaye Li,Tongshun Chen,Siyi Ma,Elizabeth Churchill,Ke Wu*

Main category: cs.HC

TL;DR: PuppetAI是一个模块化软体机器人交互平台，采用电缆驱动系统和可定制的木偶式手势框架，支持多种交互手势设计格式，具有四层解耦软件架构和情感表达循环。


<details>
  <summary>Details</summary>
Motivation: 为未来基于触觉的表达性机器人研究创建一个适应性强且易于访问的基础平台，降低操作复杂性和生产成本，同时增强可定制性，让研究人员能够独立构建或改进社交机器人的特定手势和动作。

Method: 采用模块化软体机器人交互平台设计，包括可扩展的电缆驱动系统和可定制的木偶式机器人手势框架。平台采用四层解耦软件架构：感知处理、情感建模、运动调度和底层驱动。实现了情感表达循环，将人类语音输入实时转化为情感手势响应。

Result: 开发了一个完整的软体机器人交互平台，具有增强的灵巧性和"触感舒适"的毛绒外观，能够执行细腻的手势。平台降低了操作复杂性和生产成本，同时提高了可定制性。

Conclusion: PuppetAI平台为未来触觉表达机器人研究提供了一个适应性强且易于访问的基础，使研究人员能够独立构建或改进社交机器人的特定手势和动作，推动了软体机器人交互技术的发展。

Abstract: We introduce PuppetAI, a modular soft robot interaction platform. This platform offers a scalable cable-driven actuation system and a customizable, puppet-inspired robot gesture framework, supporting a multitude of interaction gesture robot design formats. The platform comprises a four-layer decoupled software architecture that includes perceptual processing, affective modeling, motion scheduling, and low-level actuation. We also implemented an affective expression loop that connects human input to the robot platform by producing real-time emotional gestural responses to human vocal input. For our own designs, we have worked with nuanced gestures enacted by "soft robots" with enhanced dexterity and "pleasant-to-touch" plush exteriors. By reducing operational complexity and production costs while enhancing customizability, our work creates an adaptable and accessible foundation for future tactile-based expressive robot research. Our goal is to provide a platform that allows researchers to independently construct or refine highly specific gestures and movements performed by social robots.

</details>


### [43] [Vivifying LIME: Visual Interactive Testbed for LIME Analysis](https://arxiv.org/abs/2602.04841)
*Jeongmin Rhee,Changhee Lee,DongHwa Shin,Bohyoung Kim*

Main category: cs.HC

TL;DR: LIMEVis是一个交互式可视化工具，用于改进LIME（局部可解释模型无关解释）的分析工作流程，支持同时探索多个LIME结果并进行直接修改。


<details>
  <summary>Details</summary>
Motivation: 当前LIME技术存在两个主要限制：1）每次只能分析单张图像；2）缺乏交互机制来观察LIME结果并直接操作影响结果的因素。这限制了用户对复杂模型的理解和分析效率。

Method: 开发了LIMEVis交互式可视化工具，该工具允许用户同时探索多个LIME结果，并能够直接修改这些结果。通过这种交互方式，用户可以更方便地分析模型决策过程。

Result: 使用LIMEVis可以方便地识别图像中模型用于分类的主要共同特征，并通过交互式修改LIME结果来确定图像中哪些区域影响模型的分类决策。

Conclusion: LIMEVis通过提供多图像同时分析和交互式修改功能，显著改进了LIME的分析工作流程，增强了用户对模型决策过程的理解能力。

Abstract: Explainable Artificial Intelligence (XAI) has gained importance in interpreting model predictions. Among leading techniques for XAI, Local Interpretable Model-agnostic Explanations (LIME) is most frequently utilized as it notably helps people's understanding of complex models. However, LIME's analysis is constrained to a single image at a time. Besides, it lacks interaction mechanisms for observing the LIME's results and direct manipulations of factors affecting the results. To address these issues, we introduce an interactive visualization tool, LIMEVis, which improves the analysis workflow of LIME by enabling users to explore multiple LIME results simultaneously and modify them directly. With LIMEVis, we could conveniently identify common features in images that a model seems to mainly consider for category classification. Additionally, by interactively modifying the LIME results, we could determine which segments in an image influence the model's classification.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [44] [Understanding the Impact of Differentially Private Training on Memorization of Long-Tailed Data](https://arxiv.org/abs/2602.03872)
*Jiaming Zhang,Huanyi Xie,Meng Ding,Shaopeng Fu,Jinyan Liu,Di Wang*

Main category: cs.LG

TL;DR: DP-SGD在长尾数据上表现不佳的理论分析：从特征学习角度揭示了DP-SGD在稀有样本上的泛化性能下降，归因于梯度裁剪和噪声注入对模型记忆能力的联合负面影响。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习模型通过记忆训练样本来实现高预测精度，这引发了隐私担忧，促使DP-SGD等差分隐私训练算法的广泛采用。然而，经验研究表明DP-SGD在长尾数据上泛化性能较差，特别是对稀有或非典型样本，但这一现象的理论理解仍然缺乏。

Method: 开发了首个从特征学习角度分析DP-SGD在长尾数据上的理论框架。分析了DP-SGD训练动态，特别关注梯度裁剪和噪声注入如何共同影响模型记忆信息丰富但代表性不足的样本的能力。

Result: 理论分析表明，DP-SGD训练模型在长尾子群体上的测试误差显著大于在整个数据集上的总体测试误差。梯度裁剪和噪声注入共同削弱了模型记忆信息丰富但代表性不足样本的能力。

Conclusion: 该研究首次从理论角度解释了DP-SGD在长尾数据上表现不佳的现象，揭示了差分隐私机制与数据分布不平衡之间的内在冲突，为改进差分隐私训练算法提供了理论基础。

Abstract: Recent research shows that modern deep learning models achieve high predictive accuracy partly by memorizing individual training samples. Such memorization raises serious privacy concerns, motivating the widespread adoption of differentially private training algorithms such as DP-SGD. However, a growing body of empirical work shows that DP-SGD often leads to suboptimal generalization performance, particularly on long-tailed data that contain a large number of rare or atypical samples. Despite these observations, a theoretical understanding of this phenomenon remains largely unexplored, and existing differential privacy analysis are difficult to extend to the nonconvex and nonsmooth neural networks commonly used in practice. In this work, we develop the first theoretical framework for analyzing DP-SGD on long-tailed data from a feature learning perspective. We show that the test error of DP-SGD-trained models on the long-tailed subpopulation is significantly larger than the overall test error over the entire dataset. Our analysis further characterizes the training dynamics of DP-SGD, demonstrating how gradient clipping and noise injection jointly adversely affect the model's ability to memorize informative but underrepresented samples. Finally, we validate our theoretical findings through extensive experiments on both synthetic and real-world datasets.

</details>


### [45] [GOPO: Policy Optimization using Ranked Rewards](https://arxiv.org/abs/2602.03876)
*Kyuseong Choi,Dwaipayan Saha,Woojeong Kim,Anish Agarwal,Raaz Dwivedi*

Main category: cs.LG

TL;DR: GOPO是一种基于排序而非绝对奖励值的策略优化方法，在非可验证奖励场景中相比GRPO表现更优


<details>
  <summary>Details</summary>
Motivation: 传统RLHF方法使用奖励模型捕获相对偏好，但策略优化依赖绝对奖励值，这在奖励不可验证的任务中导致次优性能

Method: 提出Group Ordinal Policy Optimization (GOPO)，仅使用奖励的排序信息而丢弃其幅度值，基于排序转换奖励

Result: 相比GRPO：1）训练/验证奖励轨迹更高；2）LLM-as-judge评估在多数训练步骤中表现更好；3）用更少训练步骤达到相当质量

Conclusion: GOPO在非可验证奖励场景中通过仅使用排序信息而非绝对奖励值，实现了更优且更高效的策略优化

Abstract: Standard reinforcement learning from human feedback (RLHF) trains a reward model on pairwise preference data and then uses it for policy optimization. However, while reward models are optimized to capture relative preferences, existing policy optimization techniques rely on absolute reward magnitudes during training. In settings where the rewards are non-verifiable such as summarization, instruction following, and chat completion, this misalignment often leads to suboptimal performance. We introduce Group Ordinal Policy Optimization (GOPO), a policy optimization method that uses only the ranking of the rewards and discards their magnitudes. Our rank-based transformation of rewards provides several gains, compared to Group Relative Policy Optimization (GRPO), in settings with non-verifiable rewards: (1) consistently higher training/validation reward trajectories, (2) improved LLM-as-judge evaluations across most intermediate training steps, and (3) reaching a policy of comparable quality in substantially less training steps than GRPO. We demonstrate consistent improvements across a range of tasks and model sizes.

</details>


### [46] [GeoIB: Geometry-Aware Information Bottleneck via Statistical-Manifold Compression](https://arxiv.org/abs/2602.03906)
*Weiqi Wang,Zhiyi Tian,Chenhan Zhang,Shui Yu*

Main category: cs.LG

TL;DR: GeoIB通过信息几何视角重新审视信息瓶颈问题，避免直接估计互信息，使用Fisher-Rao距离和Jacobian-Frobenius项控制信息压缩，实现更好的预测精度与压缩比权衡。


<details>
  <summary>Details</summary>
Motivation: 传统信息瓶颈在深度学习中通常通过变分边界或神经互信息估计器等可处理的替代方法实现，而非直接控制互信息I(X;Z)。这些方法的松弛性和估计器依赖的偏差使得信息"压缩"只能间接控制，优化过程脆弱。

Method: 从信息几何角度重新审视IB问题，提出GeoIB方法：1) 将I(X;Z)和I(Z;Y)表示为联合分布到其独立流形的最小KL距离的精确投影形式；2) 使用分布级的Fisher-Rao距离（与KL二阶匹配且重参数化不变）控制信息压缩；3) 使用几何级的Jacobian-Frobenius项通过惩罚编码器的拉回体积扩张来提供I(Z;X)的局部容量型上界；4) 推导与FR度量一致的自然梯度优化器。

Result: 在多个流行数据集上的实验表明，GeoIB在信息平面上比主流IB基线方法实现了更好的预测精度与压缩比权衡。GeoIB通过将分布和几何正则化统一在单一瓶颈乘子下，提高了不变性和优化稳定性。

Conclusion: GeoIB通过信息几何视角避免了互信息估计，使用Fisher-Rao距离和Jacobian-Frobenius项有效控制信息压缩，在保持预测精度的同时实现更好的压缩效果，为信息瓶颈问题提供了更稳定和有效的解决方案。

Abstract: Information Bottleneck (IB) is widely used, but in deep learning, it is usually implemented through tractable surrogates, such as variational bounds or neural mutual information (MI) estimators, rather than directly controlling the MI I(X;Z) itself. The looseness and estimator-dependent bias can make IB "compression" only indirectly controlled and optimization fragile.
  We revisit the IB problem through the lens of information geometry and propose a \textbf{Geo}metric \textbf{I}nformation \textbf{B}ottleneck (\textbf{GeoIB}) that dispenses with mutual information (MI) estimation. We show that I(X;Z) and I(Z;Y) admit exact projection forms as minimal Kullback-Leibler (KL) distances from the joint distributions to their respective independence manifolds. Guided by this view, GeoIB controls information compression with two complementary terms: (i) a distribution-level Fisher-Rao (FR) discrepancy, which matches KL to second order and is reparameterization-invariant; and (ii) a geometry-level Jacobian-Frobenius (JF) term that provides a local capacity-type upper bound on I(Z;X) by penalizing pullback volume expansion of the encoder. We further derive a natural-gradient optimizer consistent with the FR metric and prove that the standard additive natural-gradient step is first-order equivalent to the geodesic update. We conducted extensive experiments and observed that the GeoIB achieves a better trade-off between prediction accuracy and compression ratio in the information plane than the mainstream IB baselines on popular datasets. GeoIB improves invariance and optimization stability by unifying distributional and geometric regularization under a single bottleneck multiplier. The source code of GeoIB is released at "https://anonymous.4open.science/r/G-IB-0569".

</details>


### [47] [Echo State Networks for Time Series Forecasting: Hyperparameter Sweep and Benchmarking](https://arxiv.org/abs/2602.03912)
*Alexander Häußer*

Main category: cs.LG

TL;DR: ESN在M4数据集上的预测性能评估，结果显示ESN在月度数据上与ARIMA/TBATS相当，在季度数据上表现最佳，计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 研究完全自动化的纯反馈驱动ESN是否可以作为传统统计预测方法（如ARIMA、ETS、TBATS）的竞争性替代方案，用于单变量时间序列预测。

Method: 使用M4竞赛数据集的月度和季度时间序列（最多20年历史数据），采用严格的两阶段评估：参数数据集进行超参数扫描（泄漏率、谱半径、储备池大小、正则化信息准则，超过400万次模型拟合），然后用独立的预测数据集进行样本外精度评估。

Result: 超参数分析显示一致且可解释的模式：月度序列偏好中等持续性的储备池，季度序列偏好更收缩的动态。在两个频率上，高泄漏率都是首选，而最优谱半径和储备池大小随时间分辨率变化。样本外评估中，ESN在月度数据上与ARIMA和TBATS表现相当，在季度数据上获得最低平均MASE，同时计算成本低于更复杂的统计模型。

Conclusion: ESN在预测准确性、鲁棒性和计算效率之间提供了有吸引力的平衡，使其成为自动化时间序列预测的实用选择。

Abstract: This paper investigates the forecasting performance of Echo State Networks (ESNs) for univariate time series forecasting using a subset of the M4 Forecasting Competition dataset. Focusing on monthly and quarterly time series with at most 20 years of historical data, we evaluate whether a fully automatic, purely feedback-driven ESN can serve as a competitive alternative to widely used statistical forecasting methods. The study adopts a rigorous two-stage evaluation approach: a Parameter dataset is used to conduct an extensive hyperparameter sweep covering leakage rate, spectral radius, reservoir size, and information criteria for regularization, resulting in over four million ESN model fits; a disjoint Forecast dataset is then used for out-of-sample accuracy assessment. Forecast accuracy is measured using MASE and sMAPE and benchmarked against simple benchmarks like drift and seasonal naive and statistical models like ARIMA, ETS, and TBATS. The hyperparameter analysis reveals consistent and interpretable patterns, with monthly series favoring moderately persistent reservoirs and quarterly series favoring more contractive dynamics. Across both frequencies, high leakage rates are preferred, while optimal spectral radii and reservoir sizes vary with temporal resolution. In the out-of-sample evaluation, the ESN performs on par with ARIMA and TBATS for monthly data and achieves the lowest mean MASE for quarterly data, while requiring lower computational cost than the more complex statistical models. Overall, the results demonstrate that ESNs offer a compelling balance between predictive accuracy, robustness, and computational efficiency, positioning them as a practical option for automated time series forecasting.

</details>


### [48] [SpecMD: A Comprehensive Study On Speculative Expert Prefetching](https://arxiv.org/abs/2602.03921)
*Duc Hoang,Ajay Jaiswal,Mohammad Samragh,Minsik Cho*

Main category: cs.LG

TL;DR: SpecMD框架用于标准化评估MoE专家缓存策略，研究发现MoE专家访问不符合传统时间局部性假设，提出了Least-Stale驱逐策略，显著减少冲突缺失并提升性能。


<details>
  <summary>Details</summary>
Motivation: MoE模型通过稀疏专家激活实现高效推理，但需要缓存机制将稀疏性转化为实际性能。现有硬件中心化缓存策略的相互影响及其与不同硬件规格的交互关系尚不明确，需要标准化评估框架。

Method: 开发SpecMD标准化框架，在多种硬件配置上基准测试各种MoE缓存策略。基于实验发现MoE专家访问不符合时间局部性假设，提出Least-Stale驱逐策略，利用MoE可预测的专家访问模式。

Result: Least-Stale策略相比LRU减少85倍冲突缺失，在仅5%或0.6GB VRAM缓存容量下实现88%以上命中率，OLMoE模型的时间到首个令牌(TTFT)减少34.7%。

Conclusion: MoE专家访问模式具有可预测性，传统缓存假设不适用。Least-Stale策略通过利用这种可预测性显著提升缓存效率，SpecMD框架为MoE缓存策略评估提供了标准化基准。

Abstract: Mixture-of-Experts (MoE) models enable sparse expert activation, meaning that only a subset of the model's parameters is used during each inference. However, to translate this sparsity into practical performance, an expert caching mechanism is required. Previous works have proposed hardware-centric caching policies, but how these various caching policies interact with each other and different hardware specification remains poorly understood. To address this gap, we develop \textbf{SpecMD}, a standardized framework for benchmarking ad-hoc cache policies on various hardware configurations. Using SpecMD, we perform an exhaustive benchmarking of several MoE caching strategies, reproducing and extending prior approaches in controlled settings with realistic constraints. Our experiments reveal that MoE expert access is not consistent with temporal locality assumptions (e.g LRU, LFU). Motivated by this observation, we propose \textbf{Least-Stale}, a novel eviction policy that exploits MoE's predictable expert access patterns to reduce collision misses by up to $85\times$ over LRU. With such gains, we achieve over $88\%$ hit rates with up to $34.7\%$ Time-to-first-token (TTFT) reduction on OLMoE at only $5\%$ or $0.6GB$ of VRAM cache capacity.

</details>


### [49] [WIND: Weather Inverse Diffusion for Zero-Shot Atmospheric Modeling](https://arxiv.org/abs/2602.03924)
*Michael Aich,Andreas Fürst,Florian Sestak,Carlos Ruiz-Gonzalez,Niklas Boers,Johannes Brandstetter*

Main category: cs.LG

TL;DR: WIND是一个统一的天气气候基础模型，通过自监督视频重建预训练，无需任务特定微调即可解决多种天气气候问题。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习天气气候模型高度专业化且碎片化，需要为不同任务单独训练专门模型。为了统一这一领域，需要开发一个能够替代多个专门模型的基础模型。

Method: 使用无条件视频扩散模型进行自监督视频重建预训练，学习大气动力学。在推理时，将各种领域特定问题框架化为逆问题，通过后验采样解决。

Result: WIND能够处理概率预测、时空降尺度、稀疏重建、守恒定律执行等多种天气气候问题，并能生成全球变暖情景下的极端天气反事实情景。

Conclusion: 通过结合生成视频建模和逆问题求解，WIND为基于AI的大气建模提供了计算效率高的范式转变。

Abstract: Deep learning has revolutionized weather and climate modeling, yet the current landscape remains fragmented: highly specialized models are typically trained individually for distinct tasks. To unify this landscape, we introduce WIND, a single pre-trained foundation model capable of replacing specialized baselines across a vast array of tasks. Crucially, in contrast to previous atmospheric foundation models, we achieve this without any task-specific fine-tuning. To learn a robust, task-agnostic prior of the atmosphere, we pre-train WIND with a self-supervised video reconstruction objective, utilizing an unconditional video diffusion model to iteratively reconstruct atmospheric dynamics from a noisy state. At inference, we frame diverse domain-specific problems strictly as inverse problems and solve them via posterior sampling. This unified approach allows us to tackle highly relevant weather and climate problems, including probabilistic forecasting, spatial and temporal downscaling, sparse reconstruction and enforcing conservation laws purely with our pre-trained model. We further demonstrate the model's capacity to generate physically consistent counterfactual storylines of extreme weather events under global warming scenarios. By combining generative video modeling with inverse problem solving, WIND offers a computationally efficient paradigm shift in AI-based atmospheric modeling.

</details>


### [50] [Autonomous AI Agents for Real-Time Affordable Housing Site Selection: Multi-Objective Reinforcement Learning Under Regulatory Constraints](https://arxiv.org/abs/2602.03940)
*Olaf Yunus Laitinen Imanov,Duygu Erisken,Derya Umut Kulali,Taner Yilmaz,Rana Irem Turhan*

Main category: cs.LG

TL;DR: AURA是一个用于经济适用房选址的层次化多智能体强化学习系统，能够在硬性监管约束下实时优化多个目标，显著提高选址效率和效果。


<details>
  <summary>Details</summary>
Motivation: 经济适用房短缺影响数十亿人，而土地稀缺和监管限制使得选址过程缓慢。需要一种能够在复杂监管约束下快速优化多个社会目标的自动化解决方案。

Method: 将任务建模为约束多目标马尔可夫决策过程，采用层次化多智能体强化学习架构。使用监管感知状态编码127个联邦和地方约束，采用帕累托约束策略梯度保证可行性，奖励分解分离即时成本和长期社会结果。

Result: 在8个美国大都市的47,392个候选地块数据集上，AURA达到94.3%的监管合规率，帕累托超体积比基线提高37.2%。在纽约市2026年案例研究中，将选址时间从18个月减少到72小时，识别出比专家选择多23%的可行地块，所选地块的交通便利性提高31%，环境影响降低19%。

Conclusion: AURA系统能够有效解决经济适用房选址中的监管约束和多目标优化问题，显著提高选址效率和决策质量，为城市规划提供了一种可扩展的自动化解决方案。

Abstract: Affordable housing shortages affect billions, while land scarcity and regulations make site selection slow. We present AURA (Autonomous Urban Resource Allocator), a hierarchical multi-agent reinforcement learning system for real-time affordable housing site selection under hard regulatory constraints (QCT, DDA, LIHTC). We model the task as a constrained multi-objective Markov decision process optimizing accessibility, environmental impact, construction cost, and social equity while enforcing feasibility. AURA uses a regulatory-aware state encoding 127 federal and local constraints, Pareto-constrained policy gradients with feasibility guarantees, and reward decomposition separating immediate costs from long-term social outcomes. On datasets from 8 U.S. metros (47,392 candidate parcels), AURA attains 94.3% regulatory compliance and improves Pareto hypervolume by 37.2% over strong baselines. In a New York City 2026 case study, it reduces selection time from 18 months to 72 hours and identifies 23% more viable sites; chosen sites have 31% better transit access and 19% lower environmental impact than expert picks.

</details>


### [51] [Grables: Tabular Learning Beyond Independent Rows](https://arxiv.org/abs/2602.03945)
*Tamara Cucumides,Floris Geerts*

Main category: cs.LG

TL;DR: 论文提出grables框架，将表格转换为图结构以捕获行间依赖关系，解决传统行级预测在处理事务性、时序性和关系性表格时的局限性


<details>
  <summary>Details</summary>
Motivation: 传统表格学习主要依赖行级预测器，这种独立处理每行的方法适用于i.i.d.基准测试，但在处理事务性、时序性和关系性表格时存在局限，因为这些表格中的标签往往依赖于其他行。行级预测无法处理全局计数、重叠和关系模式等自然目标。

Method: 提出grables框架：模块化接口将表格提升为图（构造函数）与在图上的预测计算（节点预测器）分离。该框架明确指出了表达能力来源，支持消息传递捕获行间依赖关系，以及混合方法显式提取行间结构并输入给强大的表格学习器。

Result: 在合成任务、交易数据和RelBench临床试验数据集上的实验证实了预测的分离效果：消息传递能够捕获行局部模型遗漏的行间依赖关系，显式提取行间结构并输入给表格学习器的混合方法带来了一致的性能提升。

Conclusion: 表格学习需要超越行级预测，通过图结构建模捕获行间依赖关系。grables框架为理解和实现这种能力提供了系统方法，在处理具有复杂依赖关系的表格数据时具有显著优势。

Abstract: Tabular learning is still dominated by row-wise predictors that score each row independently, which fits i.i.d. benchmarks but fails on transactional, temporal, and relational tables where labels depend on other rows. We show that row-wise prediction rules out natural targets driven by global counts, overlaps, and relational patterns. To make "using structure" precise across architectures, we introduce grables: a modular interface that separates how a table is lifted to a graph (constructor) from how predictions are computed on that graph (node predictor), pinpointing where expressive power comes from. Experiments on synthetic tasks, transaction data, and a RelBench clinical-trials dataset confirm the predicted separations: message passing captures inter-row dependencies that row-local models miss, and hybrid approaches that explicitly extract inter-row structure and feed it to strong tabular learners yield consistent gains.

</details>


### [52] [eCP: Informative uncertainty quantification via Equivariantized Conformal Prediction with pre-trained models](https://arxiv.org/abs/2602.03986)
*Nikolaos Bousias,Lars Lindemann,George Pappas*

Main category: cs.LG

TL;DR: 该论文研究如何通过群对称化预训练模型来改进共形预测，利用几何信息分布非共形质量，从而收缩预测集并提高不确定性量化效果。


<details>
  <summary>Details</summary>
Motivation: 共形预测在长时任务中不确定性区域会显著增大，导致统计保证变得无信息价值，需要改进不确定性量化方法。

Method: 通过群平均预训练预测器，将非共形质量分布在轨道上，每个样本作为轨道的代表，利用对称群的轨道诱导元素来缓解不确定性。

Result: 该方法在凸序意义上可证明收缩非共形分数，意味着改进的指数尾界和更尖锐的共形预测集，特别是在高置信水平下。

Conclusion: 群对称化能有效改进共形预测的不确定性量化，特别是在行人轨迹预测等应用中，通过几何信息分布能获得更精确的预测集。

Abstract: We study the effect of group symmetrization of pre-trained models on conformal prediction (CP), a post-hoc, distribution-free, finite-sample method of uncertainty quantification that offers formal coverage guarantees under the assumption of data exchangeability. Unfortunately, CP uncertainty regions can grow significantly in long horizon missions, rendering the statistical guarantees uninformative. To that end, we propose infusing CP with geometric information via group-averaging of the pretrained predictor to distribute the non-conformity mass across the orbits. Each sample now is treated as a representative of an orbit, thus uncertainty can be mitigated by other samples entangled to it via the orbit inducing elements of the symmetry group. Our approach provably yields contracted non-conformity scores in increasing convex order, implying improved exponential-tail bounds and sharper conformal prediction sets in expectation, especially at high confidence levels. We then propose an experimental design to test these theoretical claims in pedestrian trajectory prediction.

</details>


### [53] [When Chains of Thought Don't Matter: Causal Bypass in Large Language Models](https://arxiv.org/abs/2602.03994)
*Anish Sathyanarayanan,Aditya Nagarsekar,Aarush Rathore*

Main category: cs.LG

TL;DR: 研究发现即使思维链提示看似详细合理，模型答案往往与思维链内容因果独立，表面合规性不能保证因果依赖


<details>
  <summary>Details</summary>
Motivation: 验证思维链提示是否真的暴露模型推理过程并提高透明度，探究表面合规性是否保证因果依赖

Method: 提出诊断框架：结合可解释行为模块（评分思维链中的操纵相关信号）和因果探针（通过隐藏状态修补测量思维链介导影响，计算旁路分数）

Result: 审计感知提示增加了可检测的操纵信号，但因果探针显示任务依赖性：许多QA项目显示近乎完全旁路，而一些逻辑问题显示更强的中介作用；层分析显示即使平均CMI低也存在狭窄的任务依赖性"推理窗口"

Conclusion: 思维链提示的透明度假设存在缺陷，表面合规性不能保证因果依赖，需要更严格的因果审计方法来评估模型推理的真实性

Abstract: Chain-of-thought (CoT) prompting is widely assumed to expose a model's reasoning process and improve transparency. We attempted to enforce this assumption by penalizing unfaithful reasoning, but found that surface-level compliance does not guarantee causal reliance. Our central finding is negative: even when CoT is verbose, strategic, and flagged by surface-level manipulation detectors, model answers are often causally independent of the CoT content. We present a diagnostic framework for auditing this failure mode: it combines (i) an interpretable behavioral module that scores manipulation-relevant signals in CoT text and (ii) a causal probe that measures CoT-mediated influence (CMI) via hidden-state patching and reports a bypass score ($1-\mathrm{CMI}$), quantifying the degree to which the answer is produced by a bypass circuit independent of the rationale. In pilot evaluations, audit-aware prompting increases detectable manipulation signals (mean risk-score delta: $+5.10$), yet causal probes reveal task-dependent mediation: many QA items exhibit near-total bypass (CMI $\approx 0$), while some logic problems show stronger mediation (CMI up to $0.56$). Layer-wise analysis reveals narrow and task-dependent ``reasoning windows'' even when mean CMI is low.

</details>


### [54] [PromptSplit: Revealing Prompt-Level Disagreement in Generative Models](https://arxiv.org/abs/2602.04009)
*Mehdi Lotfian,Mohammad Jalali,Farzan Farnia*

Main category: cs.LG

TL;DR: PromptSplit：一个基于核方法的框架，用于检测和分析生成模型之间的提示依赖分歧，通过张量积嵌入构建联合表示，利用核协方差矩阵的特征空间识别行为差异方向，并提供可扩展的随机投影近似。


<details>
  <summary>Details</summary>
Motivation: 随着提示引导生成AI模型在视觉和语言领域的快速发展，不同模型在训练数据和架构上的差异导致需要系统方法来识别哪些类型的提示会导致不同的模型行为，从而理解模型间的分歧模式。

Method: 提出PromptSplit框架：1）为每对模型构建联合提示-输出表示，使用提示和图像/文本特征的张量积嵌入；2）计算相应的核协方差矩阵；3）利用这些矩阵加权差值的特征空间识别行为差异的主要方向；4）采用随机投影近似将计算复杂度降至O(nr²+r³)。

Result: 理论分析表明随机投影近似的特征结构估计与全维结果的期望偏差有界于O(1/r²)。在文本到图像、文本到文本和图像描述任务上的实验证明，PromptSplit能准确检测真实行为差异并定位导致分歧的提示，提供可解释的分析工具。

Conclusion: PromptSplit提供了一个可扩展且理论有保障的框架，用于检测和分析生成模型之间的提示依赖分歧，能够识别行为差异的主要方向并定位相关提示，为理解模型行为差异提供了可解释的工具。

Abstract: Prompt-guided generative AI models have rapidly expanded across vision and language domains, producing realistic and diverse outputs from textual inputs. The growing variety of such models, trained with different data and architectures, calls for principled methods to identify which types of prompts lead to distinct model behaviors. In this work, we propose PromptSplit, a kernel-based framework for detecting and analyzing prompt-dependent disagreement between generative models. For each compared model pair, PromptSplit constructs a joint prompt--output representation by forming tensor-product embeddings of the prompt and image (or text) features, and then computes the corresponding kernel covariance matrix. We utilize the eigenspace of the weighted difference between these matrices to identify the main directions of behavioral difference across prompts. To ensure scalability, we employ a random-projection approximation that reduces computational complexity to $O(nr^2 + r^3)$ for projection dimension $r$. We further provide a theoretical analysis showing that this approximation yields an eigenstructure estimate whose expected deviation from the full-dimensional result is bounded by $O(1/r^2)$. Experiments across text-to-image, text-to-text, and image-captioning settings demonstrate that PromptSplit accurately detects ground-truth behavioral differences and isolates the prompts responsible, offering an interpretable tool for detecting where generative models disagree.

</details>


### [55] [Understanding and Guiding Layer Placement in Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org/abs/2602.04019)
*Yichen Xu,Yuyang Liang,Shan Dai,Tianyang Hu,Tsz Nam Chan,Chenhao Ma*

Main category: cs.LG

TL;DR: 该论文提出了层卡（Layer Card）诊断工具，用于指导参数高效微调（PEFT）中的层选择，通过分析投影残差范数、激活能量和层耦合等指标，实现性能与成本的最优平衡。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模增长，全参数微调成本高昂，参数高效微调成为下游适应的默认策略。当前实践通常在所有层上均匀应用PEFT，缺乏对层选择的深入理解和有效利用。在推理延迟和边缘计算等约束下，选择哪些层进行微调变得至关重要。

Method: 提出了统一的投影残差视角来分析PEFT，基于局部二次近似，将层间适应由三个量控制：投影残差范数（衡量层可捕获的可校正偏差）、激活能量（决定特征条件）、层耦合（量化层间残差交互强度）。在此基础上开发了层卡诊断工具，总结每层的残差信号强度、计算成本和性能。

Result: 在Qwen3-8B模型上，通过层卡指导的层选择，仅微调部分层就能达到接近全层LoRA的性能，同时显著降低微调成本和推理时适配器增强的层数，提供了更具成本效益的替代方案。

Conclusion: 层卡为PEFT中的层选择提供了系统化的诊断工具，使研究人员能够根据性能、成本等不同目标灵活优化层选择策略，实现了参数高效微调中性能与成本的更好平衡。

Abstract: As large language models (LLMs) continue to grow, the cost of full-parameter fine-tuning has made parameter-efficient fine-tuning (PEFT) the default strategy for downstream adaptation. Constraints from inference latency in scalable serving and fine-tuning cost in edge or rapid-deployment settings make the choice of which layers to fine-tune unavoidable. Yet current practice typically applies PEFT uniformly across all layers, with limited understanding or leverage of layer selection. This paper develops a unified projected residual view of PEFT on top of a frozen base model. Under a local quadratic approximation, layerwise adaptation is governed by three quantities: (i) the projected residual norm (resnorm), which measures how much correctable bias a layer can capture; (ii) the activation energy, which determines feature conditioning; and (iii) layer coupling, which quantifies how strongly residuals interact across layers. We show that, for squared loss and linear adapters, the resnorm equals a normalized gradient norm, activation energy controls ill-conditioning and noise amplification, and weak coupling yields approximately additive layerwise contributions. Building on these insights, we introduce the Layer Card, a reusable diagnostic that summarizes residual signal strength, compute cost, and performance for each layer of a given model. With an identical model and LoRA configuration, Layer Card-guided placement refines the choice of adapted layers to flexibly prioritize different objectives, such as maximizing performance or reducing fine-tuning cost. Moreover, on Qwen3-8B, we show that selectively adapting a subset of layers can achieve performance close to full-layer LoRA while substantially reducing fine-tuning cost and the number of adapter-augmented layers during inference, offering a more cost-performance-aware alternative to full-layer insertion.

</details>


### [56] [Group Contrastive Learning for Weakly Paired Multimodal Data](https://arxiv.org/abs/2602.04021)
*Aditya Gorla,Hugues Van Assel,Jan-Christian Huetter,Heming Yao,Kyunghyun Cho,Aviv Regev,Russell Littman*

Main category: cs.LG

TL;DR: GROOVE是一种半监督多模态表示学习方法，用于高内容扰动数据，通过GroupCLIP损失函数解决弱配对跨模态学习问题，并在模拟和真实单细胞遗传扰动数据中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决高内容扰动数据中多模态样本仅通过共享扰动标签弱配对而缺乏直接对应关系的问题，填补弱配对设置下对比学习的空白。

Method: 提出GroupCLIP损失函数，将CLIP的跨模态配对学习与SupCon的单模态监督对比学习相结合；结合即时反向翻译自编码器框架，促进跨模态纠缠表示同时保持组级一致性；引入组合评估框架系统评估表示学习器。

Result: 在模拟和两个真实单细胞遗传扰动数据集中，GROOVE在下游跨模态匹配和插补任务中表现与现有方法相当或更优；消融研究表明GroupCLIP是性能提升的关键组件。

Conclusion: 在仅能获得弱配对的情况下，利用组级约束对于有效的多模态表示学习至关重要；目前尚无对齐器在所有设置或模态对中均占主导地位。

Abstract: We present GROOVE, a semi-supervised multi-modal representation learning approach for high-content perturbation data where samples across modalities are weakly paired through shared perturbation labels but lack direct correspondence. Our primary contribution is GroupCLIP, a novel group-level contrastive loss that bridges the gap between CLIP for paired cross-modal data and SupCon for uni-modal supervised contrastive learning, addressing a fundamental gap in contrastive learning for weakly-paired settings. We integrate GroupCLIP with an on-the-fly backtranslating autoencoder framework to encourage cross-modally entangled representations while maintaining group-level coherence within a shared latent space. Critically, we introduce a comprehensive combinatorial evaluation framework that systematically assesses representation learners across multiple optimal transport aligners, addressing key limitations in existing evaluation strategies. This framework includes novel simulations that systematically vary shared versus modality-specific perturbation effects enabling principled assessment of method robustness. Our combinatorial benchmarking reveals that there is not yet an aligner that uniformly dominates across settings or modality pairs. Across simulations and two real single-cell genetic perturbation datasets, GROOVE performs on par with or outperforms existing approaches for downstream cross-modal matching and imputation tasks. Our ablation studies demonstrate that GroupCLIP is the key component driving performance gains. These results highlight the importance of leveraging group-level constraints for effective multi-modal representation learning in scenarios where only weak pairing is available.

</details>


### [57] [A Consensus-Bayesian Framework for Detecting Malicious Activity in Enterprise Directory Access Graphs](https://arxiv.org/abs/2602.04027)
*Pratyush Uppuluri,Shilpa Noushad,Sajan Kumar*

Main category: cs.LG

TL;DR: 提出基于共识的贝叶斯框架，通过建模目录访问图中的用户行为，使用意见动力学检测恶意访问行为


<details>
  <summary>Details</summary>
Motivation: 企业目录访问图中存在恶意用户行为，需要有效检测方法。传统方法可能无法捕捉逻辑依赖关系和动态演化特征

Method: 将目录建模为主题，用户建模为多级交互图中的智能体，使用影响加权的意见动力学模拟访问演化，通过动态矩阵编码逻辑依赖，共享影响矩阵捕捉目录相似性，恶意行为被建模为违反强连通组件结构规范的跨组件逻辑扰动

Result: 在合成访问图上进行仿真验证，方法对逻辑不一致性敏感，在动态扰动下具有鲁棒性

Conclusion: 提出的共识贝叶斯框架能够有效检测企业目录访问图中的恶意用户行为，通过意见动力学理论保证主题收敛，使用贝叶斯异常评分机制量化不确定性

Abstract: This work presents a consensus-based Bayesian framework to detect malicious user behavior in enterprise directory access graphs. By modeling directories as topics and users as agents within a multi-level interaction graph, we simulate access evolution using influence-weighted opinion dynamics. Logical dependencies between users are encoded in dynamic matrices Ci, and directory similarity is captured via a shared influence matrix W. Malicious behavior is injected as cross-component logical perturbations that violate structural norms of strongly connected components(SCCs). We apply theoretical guarantees from opinion dynamics literature to determine topic convergence and detect anomaly via scaled opinion variance. To quantify uncertainty, we introduce a Bayesian anomaly scoring mechanism that evolves over time, using both static and online priors. Simulations over synthetic access graphs validate our method, demonstrating its sensitivity to logical inconsistencies and robustness under dynamic perturbation.

</details>


### [58] [The Illusion of Generalization: Re-examining Tabular Language Model Evaluation](https://arxiv.org/abs/2602.04031)
*Aditya Gorla,Ratish Puduppully*

Main category: cs.LG

TL;DR: 对Tabula-8B作为代表性表格语言模型的系统再评估发现，其声称的泛化能力可能更多是评估伪影而非真正的表格推理能力


<details>
  <summary>Details</summary>
Motivation: 重新评估表格语言模型声称的涌现泛化能力，检验这些声称是否真实反映了模型学习到的表格推理能力

Method: 使用UniPredict基准中的165个数据集对Tabula-8B进行系统评估，分析二分类、多分类和四分位数分类任务的性能，检查数据污染问题，并进行指令调优实验

Result: 1) 二分类和多分类任务的中位数提升接近零，强聚合性能完全由四分位数分类任务驱动；2) 表现最好的数据集存在普遍的数据污染，包括完整的训练-测试重叠和任务级泄漏；3) 无表格暴露的指令调优恢复了92.2%的标准分类性能，在四分位数分类上格式熟悉度填补了71.3%的性能差距

Conclusion: 表格语言模型声称的泛化能力可能反映了评估伪影而非学习到的表格推理能力，需要加强TLM评估方法

Abstract: Tabular Language Models (TLMs) have been claimed to achieve emergent generalization for tabular prediction. We conduct a systematic re-evaluation of Tabula-8B as a representative TLM, utilizing 165 datasets from the UniPredict benchmark. Our investigation reveals three findings. First, binary and categorical classification achieve near-zero median lift over majority-class baselines and strong aggregate performance is driven entirely by quartile classification tasks. Second, top-performing datasets exhibit pervasive contamination, including complete train-test overlap and task-level leakage that evades standard deduplication. Third, instruction-tuning without tabular exposure recovers 92.2% of standard classification performance and on quartile classification, format familiarity closes 71.3% of the gap with the residual attributable to contaminated datasets. These findings suggest claimed generalization likely reflects evaluation artifacts rather than learned tabular reasoning. We conclude with recommendations for strengthening TLM evaluation.

</details>


### [59] [DADP: Domain Adaptive Diffusion Policy](https://arxiv.org/abs/2602.04037)
*Pengcheng Wang,Qinghang Liu,Haotian Lin,Yiheng Li,Guojian Zhan,Masayoshi Tomizuka,Yixiao Wang*

Main category: cs.LG

TL;DR: DADP通过滞后上下文动态预测实现无监督解耦，将静态域信息与动态特性分离，然后通过偏置先验分布和重构扩散目标将域表示注入扩散策略，实现零样本适应。


<details>
  <summary>Details</summary>
Motivation: 学习能够泛化到未见过渡动态的域自适应策略是学习型控制的基本挑战。现有方法通过域表示学习捕获域特定信息，但当前上下文选择会导致静态域信息与变化动态特性纠缠，限制了零样本适应能力。

Method: 提出DADP（域自适应扩散策略）：1）滞后上下文动态预测：通过历史偏移上下文进行未来状态估计，增加时间间隔实现无监督解耦；2）域感知扩散注入：将学习到的域表示通过偏置先验分布和重构扩散目标直接集成到生成过程中。

Result: 在运动和操作等具有挑战性的基准测试中进行了广泛实验，DADP表现出优越性能，并超越了先前方法的泛化能力。

Conclusion: DADP通过无监督解耦和域感知扩散注入实现了鲁棒的自适应，解决了域表示学习中静态信息与动态特性纠缠的问题，显著提升了零样本适应能力。

Abstract: Learning domain adaptive policies that can generalize to unseen transition dynamics, remains a fundamental challenge in learning-based control. Substantial progress has been made through domain representation learning to capture domain-specific information, thus enabling domain-aware decision making. We analyze the process of learning domain representations through dynamical prediction and find that selecting contexts adjacent to the current step causes the learned representations to entangle static domain information with varying dynamical properties. Such mixture can confuse the conditioned policy, thereby constraining zero-shot adaptation. To tackle the challenge, we propose DADP (Domain Adaptive Diffusion Policy), which achieves robust adaptation through unsupervised disentanglement and domain-aware diffusion injection. First, we introduce Lagged Context Dynamical Prediction, a strategy that conditions future state estimation on a historical offset context; by increasing this temporal gap, we unsupervisedly disentangle static domain representations by filtering out transient properties. Second, we integrate the learned domain representations directly into the generative process by biasing the prior distribution and reformulating the diffusion target. Extensive experiments on challenging benchmarks across locomotion and manipulation demonstrate the superior performance, and the generalizability of DADP over prior methods. More visualization results are available on the https://outsider86.github.io/DomainAdaptiveDiffusionPolicy/.

</details>


### [60] [Partition Trees: Conditional Density Estimation over General Outcome Spaces](https://arxiv.org/abs/2602.04042)
*Felipe Angelim,Alessandro Leite*

Main category: cs.LG

TL;DR: 提出Partition Trees框架，用于一般结果空间的非参数条件密度估计，支持连续和分类变量，通过最小化条件负对数似然学习数据自适应划分的树结构


<details>
  <summary>Details</summary>
Motivation: 现有概率树方法通常对目标分布做出参数假设，需要一种非参数的、可扩展的条件密度估计方法，能够处理连续和分类变量，并适应数据特征

Method: 基于树的条件密度估计框架，将条件分布建模为数据自适应划分上的分段常数密度，通过直接最小化条件负对数似然学习树结构，并扩展到集成方法Partition Forests

Result: 在概率预测方面优于CART风格树，与最先进的概率树方法和随机森林相比具有竞争力或更优性能，对冗余特征和异方差噪声具有鲁棒性

Conclusion: Partition Trees提供了一个统一、可扩展的非参数条件密度估计框架，在保持计算效率的同时提供准确的概率预测，适用于各种类型的结果变量

Abstract: We propose Partition Trees, a tree-based framework for conditional density estimation over general outcome spaces, supporting both continuous and categorical variables within a unified formulation. Our approach models conditional distributions as piecewise-constant densities on data adaptive partitions and learns trees by directly minimizing conditional negative log-likelihood. This yields a scalable, nonparametric alternative to existing probabilistic trees that does not make parametric assumptions about the target distribution. We further introduce Partition Forests, an ensemble extension obtained by averaging conditional densities. Empirically, we demonstrate improved probabilistic prediction over CART-style trees and competitive or superior performance compared to state-of-the-art probabilistic tree methods and Random Forests, along with robustness to redundant features and heteroscedastic noise.

</details>


### [61] [Stroke Lesions as a Rosetta Stone for Language Model Interpretability](https://arxiv.org/abs/2602.04074)
*Julius Fridriksson,Roger D. Newman-Norlund,Saeed Ahmadi,Regan Willis,Nadra Salman,Kalil Warren,Xiang Guan,Yong Yang,Srihari Nelakuditi,Rutvik Desai,Leonardo Bonilha,Jeff Charney,Chris Rorden*

Main category: cs.LG

TL;DR: 研究者开发了BLUM框架，利用脑损伤-症状映射作为外部验证标准，通过对比中风失语症患者与扰动后LLM的错误模式，发现LLM错误模式能预测人类实际脑损伤位置，为LLM可解释性提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM可解释性方法主要依赖内部指标，缺乏外部验证。研究者希望借鉴临床神经科学中已确立因果关系的脑损伤-症状映射方法，为评估LLM扰动效果提供外部参考框架。

Method: 使用410名中风后失语症患者数据训练症状到损伤的预测模型；对Transformer层进行系统扰动；对扰动后的LLM和人类患者实施相同的临床评估；将LLM错误模式投射到人类脑损伤空间进行比对。

Result: LLM错误模式与人类错误模式足够相似，在67%的图片命名条件和68.3%的句子完成条件下，预测的脑损伤位置与错误匹配的人类实际损伤位置显著相关。语义主导错误映射到腹侧通路损伤模式，语音主导错误映射到背侧通路模式。

Conclusion: 该研究为LLM可解释性开辟了新方法学途径，临床神经科学提供了外部验证，建立了人类脑损伤-症状映射作为评估人工语言系统的参考框架，并激励进一步研究行为对齐是否反映了共享的计算原理。

Abstract: Large language models (LLMs) have achieved remarkable capabilities, yet methods to verify which model components are truly necessary for language function remain limited. Current interpretability approaches rely on internal metrics and lack external validation. Here we present the Brain-LLM Unified Model (BLUM), a framework that leverages lesion-symptom mapping, the gold standard for establishing causal brain-behavior relationships for over a century, as an external reference structure for evaluating LLM perturbation effects. Using data from individuals with chronic post-stroke aphasia (N = 410), we trained symptom-to-lesion models that predict brain damage location from behavioral error profiles, applied systematic perturbations to transformer layers, administered identical clinical assessments to perturbed LLMs and human patients, and projected LLM error profiles into human lesion space. LLM error profiles were sufficiently similar to human error profiles that predicted lesions corresponded to actual lesions in error-matched humans above chance in 67% of picture naming conditions (p < 10^{-23}) and 68.3% of sentence completion conditions (p < 10^{-61}), with semantic-dominant errors mapping onto ventral-stream lesion patterns and phonemic-dominant errors onto dorsal-stream patterns. These findings open a new methodological avenue for LLM interpretability in which clinical neuroscience provides external validation, establishing human lesion-symptom mapping as a reference framework for evaluating artificial language systems and motivating direct investigation of whether behavioral alignment reflects shared computational principles.

</details>


### [62] [A Probabilistic Framework for Solving High-Frequency Helmholtz Equations via Diffusion Models](https://arxiv.org/abs/2602.04082)
*Yicheng Zou,Samuel Lanthaler,Hossein Salahshoor*

Main category: cs.LG

TL;DR: 提出基于分数条件扩散算子的概率神经算子框架，用于解决高频波动问题，相比确定性方法在精度和不确定性建模方面表现更优


<details>
  <summary>Details</summary>
Motivation: 确定性神经算子在处理高频波动现象时存在困难，包括输入输出敏感性导致的算子学习挑战和频谱偏差导致的振荡模糊问题，需要采用概率方法来近似高频波动

Method: 采用基于分数的条件扩散算子构建概率框架，首先对亥姆霍兹算子进行稳定性分析，然后在多种频率下进行数值实验，与其他数据驱动和机器学习方法进行对比

Result: 概率神经算子在L2、H1和能量范数下均产生最低误差的稳健预测，且能捕捉输入声速图传播到解场的不确定性，而其他确定性方法无法做到这一点

Conclusion: 概率算子学习是解决亥姆霍兹等复杂偏微分方程在高频挑战性区域的有原则且有效的方法

Abstract: Deterministic neural operators perform well on many PDEs but can struggle with the approximation of high-frequency wave phenomena, where strong input-to-output sensitivity makes operator learning challenging, and spectral bias blurs oscillations. We argue for adopting a probabilistic approach for approximating waves in high-frequency regime, and develop our probabilistic framework using a score-based conditional diffusion operator. After demonstrating a stability analysis of the Helmholtz operator, we present our numerical experiments across a wide range of frequencies, benchmarked against other popular data-driven and machine learning approaches for waves. We show that our probabilistic neural operator consistently produces robust predictions with the lowest errors in $L^2$, $H^1$, and energy norms. Moreover, unlike all the other tested deterministic approaches, our framework remarkably captures uncertainties in the input sound speed map propagated to the solution field. We envision that our results position probabilistic operator learning as a principled and effective approach for solving complex PDEs such as Helmholtz in the challenging high-frequency regime.

</details>


### [63] [Federated Concept-Based Models: Interpretable models with distributed supervision](https://arxiv.org/abs/2602.04093)
*Dario Fenoglio,Arianna Casanova,Francesco De Santis,Mohan Li,Gabriele Dominici,Johannes Schneider,Martin Gjoreski,Marc Langheinrich,Pietro Barbiero,Giovanni De Felice*

Main category: cs.LG

TL;DR: 提出联邦概念模型（F-CMs），在联邦学习环境中实现可解释的深度学习，通过跨机构聚合概念信息并自适应调整模型架构，解决概念标注稀缺和异构性问题。


<details>
  <summary>Details</summary>
Motivation: 概念模型能增强深度学习可解释性，但概念标注获取成本高且单一数据源中难以大规模获得。联邦学习虽能利用分布式概念标注，但缺乏可解释建模范式。现有概念模型假设固定概念空间和预定义架构，而真实联邦学习环境是异构、非平稳且机构动态加入的。

Method: 提出F-CMs方法，在演化联邦学习环境中部署概念模型。该方法跨机构聚合概念级信息，根据可用概念监督的变化高效调整模型架构，同时保护机构隐私。

Result: 实验表明F-CMs在保持完整概念监督训练设置的准确性和干预有效性同时，优于非自适应联邦基线。特别地，F-CMs能在给定机构不可用的概念上进行可解释推理，这是相对于现有方法的关键创新。

Conclusion: F-CMs成功将概念模型集成到联邦学习框架中，解决了概念标注稀缺和异构性问题，实现了跨机构的概念级信息共享和自适应建模，为可解释联邦学习提供了新方法。

Abstract: Concept-based models (CMs) enhance interpretability in deep learning by grounding predictions in human-understandable concepts. However, concept annotations are expensive to obtain and rarely available at scale within a single data source. Federated learning (FL) could alleviate this limitation by enabling cross-institutional training that leverages concept annotations distributed across multiple data owners. Yet, FL lacks interpretable modeling paradigms. Integrating CMs with FL is non-trivial: CMs assume a fixed concept space and a predefined model architecture, whereas real-world FL is heterogeneous and non-stationary, with institutions joining over time and bringing new supervision. In this work, we propose Federated Concept-based Models (F-CMs), a new methodology for deploying CMs in evolving FL settings. F-CMs aggregate concept-level information across institutions and efficiently adapt the model architecture in response to changes in the available concept supervision, while preserving institutional privacy. Empirically, F-CMs preserve the accuracy and intervention effectiveness of training settings with full concept supervision, while outperforming non-adaptive federated baselines. Notably, F-CMs enable interpretable inference on concepts not available to a given institution, a key novelty with respect to existing approaches.

</details>


### [64] [CoRe: Context-Robust Remasking for Diffusion Language Models](https://arxiv.org/abs/2602.04096)
*Kevin Zhai,Sabbir Mollah,Zhenyi Wang,Mubarak Shah*

Main category: cs.LG

TL;DR: CoRe框架通过探测令牌对上下文扰动的敏感性来识别和修订上下文脆弱的令牌，而不是依赖静态置信度，从而在推理时改进掩码扩散模型的解码效果。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型的标准解码存在上下文僵化问题：令牌基于瞬时高置信度被保留，忽略了早期预测缺乏完整上下文。这导致级联效应，初始不一致性误导后续生成。现有修订策略依赖静态置信度，但这些信号本质上是短视的，不一致的令牌对模型本身可能显得很自信。

Method: 提出Context-Robust Remasking (CoRe)框架，这是一种无需训练的推理时修订方法。不依赖静态令牌概率，而是通过探测令牌对针对性掩码上下文扰动的敏感性来识别上下文脆弱的令牌。将修订形式化为对上下文变化的鲁棒优化目标，并高效近似该目标以优先修订不稳定的令牌。

Result: 在LLaDA-8B-Base模型上，CoRe在推理和代码基准测试中带来了一致的改进，优于计算匹配的基线方法，并将MBPP性能提升了高达9.2个百分点。

Conclusion: CoRe框架通过动态识别和修订上下文脆弱的令牌，有效解决了掩码扩散模型解码中的上下文僵化问题，无需额外训练即可显著提升模型性能。

Abstract: Standard decoding in Masked Diffusion Models (MDMs) is hindered by context rigidity: tokens are retained based on transient high confidence, often ignoring that early predictions lack full context. This creates cascade effects where initial inconsistencies misguide the remaining generation. Existing revision strategies attempt to mitigate this by relying on static confidence scores, but these signals are inherently myopic; inconsistent tokens can appear confident to the model itself. We propose Context-Robust Remasking (CoRe), a training-free framework for inference-time revision. Rather than trusting static token probabilities, CoRe identifies context-brittle tokens by probing their sensitivity to targeted masked-context perturbations. We formalize revision as a robust optimization objective over context shifts and efficiently approximate this objective to prioritize unstable tokens for revision. On LLaDA-8B-Base, CoRe delivers consistent improvements across reasoning and code benchmarks, outperforming compute-matched baselines and improving MBPP by up to 9.2 percentage points.

</details>


### [65] [Rethinking Perplexity: Revealing the Impact of Input Length on Perplexity Evaluation in LLMs](https://arxiv.org/abs/2602.04099)
*Letian Cheng,Junyan Wang,Yan Gao,Elliott Wen,Ting Dang,Hong Jia*

Main category: cs.LG

TL;DR: 论文提出LengthBenchmark框架，系统研究输入长度对LLM困惑度评估的影响，发现滑动窗口评估会夸大短输入性能，且模型性能随评估片段长度增加而提升。


<details>
  <summary>Details</summary>
Motivation: 困惑度作为LLM评估的常用指标存在不可靠性，特别是在处理无关长输入时。现有研究缺乏从系统角度系统研究输入长度对困惑度的影响，也很少将输入长度作为影响公平性和效率的一等系统变量来处理。

Method: 提出LengthBenchmark框架，明确整合输入长度、评估协议设计和系统级成本。在两种评分协议（直接累积和固定窗口滑动）下，在不同上下文长度上评估代表性LLM。不仅测量准确性指标，还测量延迟、内存占用和评估成本。

Result: 1) 滑动窗口评估在短输入上持续夸大性能；2) 全精度和量化模型都随着评估片段长度的增加而表现出性能提升；3) 长度偏差是普遍现象，会破坏跨模型公平比较。

Conclusion: 输入长度对LLM评估有系统性影响，长度偏差是普遍现象，需要在评估框架中明确考虑输入长度和系统成本，以实现公平的跨模型比较。

Abstract: Perplexity is a widely adopted metric for assessing the predictive quality of large language models (LLMs) and often serves as a reference metric for downstream evaluations. However, recent evidence shows that perplexity can be unreliable, especially when irrelevant long inputs are used, raising concerns for both benchmarking and system deployment. While prior efforts have employed selective input filtering and curated datasets, the impact of input length on perplexity has not been systematically studied from a systems perspective and input length has rarely been treated as a first-class system variable affecting both fairness and efficiency. In this work, we close this gap by introducing LengthBenchmark, a system-conscious evaluation framework that explicitly integrates input length, evaluation protocol design, and system-level costs, evaluating representative LLMs under two scoring protocols (direct accumulation and fixed window sliding) across varying context lengths. Unlike prior work that focuses solely on accuracy-oriented metrics, LengthBenchmark additionally measures latency, memory footprint, and evaluation cost, thereby linking predictive metrics to deployment realities. We further incorporate quantized variants not as a main contribution, but as robustness checks, showing that length-induced biases persist across both full-precision and compressed models. This design disentangles the effects of evaluation logic, quantization, and input length, and demonstrates that length bias is a general phenomenon that undermines fair cross-model comparison. Our analysis yields two key observations: (i) sliding window evaluation consistently inflates performance on short inputs, and (ii) both full-precision and quantized models appear to realise gains as the evaluated segment length grows.

</details>


### [66] [Supervised Learning as Lossy Compression: Characterizing Generalization and Sample Complexity via Finite Blocklength Analysis](https://arxiv.org/abs/2602.04107)
*Kosuke Sugiyama,Masato Uchida*

Main category: cs.LG

TL;DR: 该论文提出了一种基于信息论和有限块长分析的机器学习泛化新视角，将学习问题框架化为有损压缩过程，推导出样本复杂度和泛化误差的下界。


<details>
  <summary>Details</summary>
Motivation: 现有泛化理论框架存在局限性，需要一种能够明确分离算法过拟合程度与归纳偏置任务不匹配的新理论框架，以更好地理解机器学习算法的泛化行为。

Method: 采用信息论视角，将学习问题建模为有损压缩过程：训练数据采样对应编码过程，模型构建对应解码过程。应用有限块长分析技术，推导固定随机学习算法及其最优采样策略下的理论下界。

Result: 推导出样本复杂度和泛化误差的下界，明确将算法过拟合程度与归纳偏置任务不匹配分离为不同项。将过拟合项分解，建立了与现有信息论界和稳定性理论中指标的数学联系。

Conclusion: 提出的信息论框架为理解机器学习泛化提供了新视角，统一了现有信息论界和稳定性理论，能够明确分离不同因素对泛化性能的影响，具有理论优势。

Abstract: This paper presents a novel information-theoretic perspective on generalization in machine learning by framing the learning problem within the context of lossy compression and applying finite blocklength analysis. In our approach, the sampling of training data formally corresponds to an encoding process, and the model construction to a decoding process. By leveraging finite blocklength analysis, we derive lower bounds on sample complexity and generalization error for a fixed randomized learning algorithm and its associated optimal sampling strategy. Our bounds explicitly characterize the degree of overfitting of the learning algorithm and the mismatch between its inductive bias and the task as distinct terms. This separation provides a significant advantage over existing frameworks. Additionally, we decompose the overfitting term to show its theoretical connection to existing metrics found in information-theoretic bounds and stability theory, unifying these perspectives under our proposed framework.

</details>


### [67] [Rate-Optimal Noise Annealing in Semi-Dual Neural Optimal Transport: Tangential Identifiability, Off-Manifold Ambiguity, and Guaranteed Recovery](https://arxiv.org/abs/2602.04110)
*Raymond Chu,Jaewoong Choi,Dohyun Kwon*

Main category: cs.LG

TL;DR: 该论文研究了半对偶神经最优传输在低维流形数据上的训练问题，揭示了虚假解的存在，并提出通过加性噪声平滑来恢复传输映射，同时给出了最优统计率的可计算终端噪声水平。


<details>
  <summary>Details</summary>
Motivation: 半对偶神经最优传输通过最大最小目标学习传输映射，但在低维流形数据上训练可能收敛到错误或退化解。需要理解这些虚假解的特征并找到有效的解决方法。

Method: 研究加性噪声平滑作为补救措施，分析噪声消失时的映射恢复保证。通过统一分析最优计划的定量稳定性、平滑诱导偏差和有限样本误差，推导出依赖于内在维度而非环境维度的速率。

Result: 提出了可计算的终端噪声水平ε_stat(N)，该水平达到最优统计率，其缩放由数据的内在维度m控制。同时发现随着ε减小，约简半对偶目标变得越来越病态。

Conclusion: 加性噪声平滑可以有效恢复传输映射，但存在最优噪声水平。当噪声低于ε_stat(N)时，优化条件会恶化而统计精度不会改善，这为训练提供了原则性停止规则。

Abstract: Semi-dual neural optimal transport learns a transport map via a max-min objective, yet training can converge to incorrect or degenerate maps. We fully characterize these spurious solutions in the common regime where data concentrate on low-dimensional manifold: the objective is underconstrained off the data manifold, while the on-manifold transport signal remains identifiable. Following Choi, Choi, and Kwon (2025), we study additive-noise smoothing as a remedy and prove new map recovery guarantees as the noise vanishes. Our main practical contribution is a computable terminal noise level $\varepsilon_{\mathrm{stat}}(N)$ that attains the optimal statistical rate, with scaling governed by the intrinsic dimension $m$ of the data. The formula arises from a theoretical unified analysis of (i) quantitative stability of optimal plans, (ii) smoothing-induced bias, and (iii) finite-sample error, yielding rates that depend on $m$ rather than the ambient dimension. Finally, we show that the reduced semi-dual objective becomes increasingly ill-conditioned as $\varepsilon \downarrow 0$. This provides a principled stopping rule: annealing below $\varepsilon_{\mathrm{stat}}(N)$ can $\textit{worsen}$ optimization conditioning without improving statistical accuracy.

</details>


### [68] [Toward Effective Multimodal Graph Foundation Model: A Divide-and-Conquer Based Approach](https://arxiv.org/abs/2602.04116)
*Sicheng Liu,Xunkai Li,Daohan Su,Ru Zhang,Hongchao Qin,Ronghua Li,Guoren Wang*

Main category: cs.LG

TL;DR: PLANET是一个新型多模态图基础模型框架，通过分治策略解决现有MGFMs在模态交互和模态对齐方面的不足，在嵌入粒度和节点粒度分别实现局部语义增强和全局模态对齐。


<details>
  <summary>Details</summary>
Motivation: 现有图基础模型主要关注文本属性图，而多模态属性图尚未充分开发。现有MGFMs存在两个根本性局限：1)未能显式建模模态交互，无法捕捉超越简单聚合的跨模态语义；2)模态对齐效果不佳，难以弥合不同模态空间间的语义鸿沟。

Method: 提出PLANET框架，采用分治策略在不同粒度解耦模态交互和对齐：1)嵌入粒度：嵌入级域门控(EDG)通过自适应注入拓扑感知的跨模态上下文实现局部语义增强和模态交互；2)节点粒度：节点级离散化检索(NDR)通过构建离散化语义表示空间(DSRS)确保全局模态对齐。

Result: 大量实验表明，PLANET在多样化的图中心任务和多模态生成任务上显著优于最先进的基线模型。

Conclusion: PLANET通过在不同粒度解耦模态交互和对齐，有效解决了现有MGFMs的局限性，为多模态图基础模型的发展提供了新的方向。

Abstract: Graph Foundation Models (GFMs) have achieved remarkable success in generalizing across diverse domains. However, they mainly focus on Text-Attributed Graphs (TAGs), leaving Multimodal-Attributed Graphs (MAGs) largely untapped. Developing Multimodal Graph Foundation Models (MGFMs) allows for leveraging the rich multimodal information in MAGs, and extends applicability to broader types of downstream tasks. While recent MGFMs integrate diverse modality information, our empirical investigation reveals two fundamental limitations of existing MGFMs: (1)they fail to explicitly model modality interaction, essential for capturing intricate cross-modal semantics beyond simple aggregation, and (2)they exhibit sub-optimal modality alignment, which is critical for bridging the significant semantic disparity between distinct modal spaces. To address these challenges, we propose PLANET (graPh topoLogy-aware modAlity iNteraction and alignmEnT), a novel framework employing a Divide-and-Conquer strategy to decouple modality interaction and alignment across distinct granularities. At the embedding granularity, (1)Embedding-wise Domain Gating (EDG) performs local semantic enrichment by adaptively infusing topology-aware cross-modal context, achieving modality interaction. At the node granularity, (2)Node-wise Discretization Retrieval (NDR) ensures global modality alignment by constructing a Discretized Semantic Representation Space (DSRS) to bridge modality gaps. Extensive experiments demonstrate that PLANET significantly outperforms state-of-the-art baselines across diverse graph-centric and multimodal generative tasks.

</details>


### [69] [Turning mechanistic models into forecasters by using machine learning](https://arxiv.org/abs/2602.04114)
*Amit K. Chakraborty,Hao Wang,Pouria Ramazi*

Main category: cs.LG

TL;DR: 该研究提出了一种结合时变参数的数据驱动微分方程发现方法，通过从时间序列数据中学习常数和时变参数，并将其转化为预测模型，在多个数据集上实现了高精度建模和预测。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方法通常假设参数不随时间变化，这限制了捕捉系统动态演变的能力。当系统底层机制未知且参数随时间变化时，需要能够识别时变参数的方法来更准确地建模复杂动态系统。

Method: 提出了一种允许部分参数随时间变化的数据驱动方程发现框架：1）从时间序列数据中推断包含常数和时变参数的控制方程；2）学习时变参数的时间演化；3）通过预测时变参数并将其代入学习到的方程，将该框架转化为预测模型。

Result: 在SIR模型、消费者-资源系统、温室气体浓度和蓝藻细胞计数等多个数据集上验证，模型学习时间序列的平均绝对误差低于3%，预测未来一个月内的误差低于6%。与CNN-LSTM和梯度提升机（GBM）相比，该模型在大多数数据集上表现更优。

Conclusion: 将时变参数整合到数据驱动的微分方程发现中，能够显著提高建模精度和预测性能，使模型能够动态适应时间变化，更好地捕捉复杂系统的演化动态。

Abstract: The equations of complex dynamical systems may not be identified by expert knowledge, especially if the underlying mechanisms are unknown. Data-driven discovery methods address this challenge by inferring governing equations from time-series data using a library of functions constructed from the measured variables. However, these methods typically assume time-invariant coefficients, which limits their ability to capture evolving system dynamics. To overcome this limitation, we allow some of the parameters to vary over time, learn their temporal evolution directly from data, and infer a system of equations that incorporates both constant and time-varying parameters. We then transform this framework into a forecasting model by predicting the time-varying parameters and substituting these predictions into the learned equations. The model is validated using datasets for Susceptible-Infected-Recovered, Consumer--Resource, greenhouse gas concentration, and Cyanobacteria cell count. By dynamically adapting to temporal shifts, our proposed model achieved a mean absolute error below 3\% for learning a time series and below 6\% for forecasting up to a month ahead. We additionally compare forecasting performance against CNN-LSTM and Gradient Boosting Machine (GBM), and show that our model outperforms these methods across most datasets. Our findings demonstrate that integrating time-varying parameters into data-driven discovery of differential equations improves both modeling accuracy and forecasting performance.

</details>


### [70] [Scalable Explainability-as-a-Service (XaaS) for Edge AI Systems](https://arxiv.org/abs/2602.04120)
*Samaresh Kumar Singh,Joyjit Roy*

Main category: cs.LG

TL;DR: 提出XaaS架构，将可解释性作为独立服务而非模型特性，通过解耦推理与解释生成、分布式缓存、验证协议和自适应引擎，显著降低边缘AI系统的延迟和计算冗余。


<details>
  <summary>Details</summary>
Motivation: 当前可解释AI在边缘和物联网系统中的集成通常是临时且低效的，现有方法将解释生成与模型推理耦合，导致冗余计算、高延迟和可扩展性差，特别是在异构边缘设备上部署时。

Method: 提出Explainability-as-a-Service (XaaS)分布式架构，包含三个创新：1) 基于语义相似性的分布式解释缓存检索方法；2) 确保缓存和新生成解释保真度的轻量级验证协议；3) 根据设备能力和用户需求选择解释方法的自适应解释引擎。

Result: 在三个真实边缘AI用例（制造质量控制、自动驾驶感知、医疗诊断）中评估，XaaS将延迟降低38%，同时保持高解释质量，实现了大规模异构物联网系统中透明和可问责AI的部署。

Conclusion: XaaS架构将可解释性作为一等系统服务，通过解耦推理与解释生成，解决了边缘AI系统中可解释性的效率问题，弥合了XAI研究与边缘实践之间的差距。

Abstract: Though Explainable AI (XAI) has made significant advancements, its inclusion in edge and IoT systems is typically ad-hoc and inefficient. Most current methods are "coupled" in such a way that they generate explanations simultaneously with model inferences. As a result, these approaches incur redundant computation, high latency and poor scalability when deployed across heterogeneous sets of edge devices. In this work we propose Explainability-as-a-Service (XaaS), a distributed architecture for treating explainability as a first-class system service (as opposed to a model-specific feature). The key innovation in our proposed XaaS architecture is that it decouples inference from explanation generation allowing edge devices to request, cache and verify explanations subject to resource and latency constraints. To achieve this, we introduce three main innovations: (1) A distributed explanation cache with a semantic similarity based explanation retrieval method which significantly reduces redundant computation; (2) A lightweight verification protocol that ensures the fidelity of both cached and newly generated explanations; and (3) An adaptive explanation engine that chooses explanation methods based upon device capability and user requirement. We evaluated the performance of XaaS on three real-world edge-AI use cases: (i) manufacturing quality control; (ii) autonomous vehicle perception; and (iii) healthcare diagnostics. Experimental results show that XaaS reduces latency by 38\% while maintaining high explanation quality across three real-world deployments. Overall, this work enables the deployment of transparent and accountable AI across large scale, heterogeneous IoT systems, and bridges the gap between XAI research and edge-practicality.

</details>


### [71] [Decoupling Time and Risk: Risk-Sensitive Reinforcement Learning with General Discounting](https://arxiv.org/abs/2602.04131)
*Mehrdad Moghimi,Anthony Coache,Hyejin Ku*

Main category: cs.LG

TL;DR: 本文提出了一种支持灵活折扣和风险度量优化的分布强化学习新框架，解决了传统指数折扣无法充分捕捉时间偏好的问题。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域中，分布强化学习被广泛采用以优化风险敏感目标，但折扣因子通常被忽视，仅被视为固定参数或可调超参数。传统指数折扣无法充分捕捉智能体的时间偏好，需要更灵活的折扣机制来表征更丰富的时间偏好和风险偏好。

Method: 提出了一个支持未来奖励灵活折扣和风险度量优化的分布强化学习新框架。通过多时间范围扩展解决了现有方法的问题，并提供了算法的技术最优性分析。

Result: 通过大量实验验证了方法的鲁棒性，结果表明折扣机制是决策问题中捕捉更丰富时间和风险偏好的关键因素，对现实世界安全关键应用具有潜在影响。

Conclusion: 折扣机制是决策问题中捕捉更丰富时间和风险偏好的基石，提出的灵活折扣框架为安全关键应用提供了更强大的工具，能够更好地表征智能体的时间偏好和风险敏感目标。

Abstract: Distributional reinforcement learning (RL) is a powerful framework increasingly adopted in safety-critical domains for its ability to optimize risk-sensitive objectives. However, the role of the discount factor is often overlooked, as it is typically treated as a fixed parameter of the Markov decision process or tunable hyperparameter, with little consideration of its effect on the learned policy. In the literature, it is well-known that the discounting function plays a major role in characterizing time preferences of an agent, which an exponential discount factor cannot fully capture. Building on this insight, we propose a novel framework that supports flexible discounting of future rewards and optimization of risk measures in distributional RL. We provide a technical analysis of the optimality of our algorithms, show that our multi-horizon extension fixes issues raised with existing methodologies, and validate the robustness of our methods through extensive experiments. Our results highlight that discounting is a cornerstone in decision-making problems for capturing more expressive temporal and risk preferences profiles, with potential implications for real-world safety-critical applications.

</details>


### [72] [Thickening-to-Thinning: Reward Shaping via Human-Inspired Learning Dynamics for LLM Reasoning](https://arxiv.org/abs/2602.04265)
*Wenze Lin,Zhen Yang,Xitai Jiang,Pony Ma,Gao Huang*

Main category: cs.LG

TL;DR: 本文提出T2T动态奖励框架，通过"增厚-减薄"双阶段机制解决RLVR中的熵崩溃、冗长和探索不足问题，在数学基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法面临熵崩溃、过度冗长和对难题探索不足的问题，且现有奖励方案无法区分问题解决时需要广泛搜索与掌握知识后需要效率这两种不同需求。

Method: 提出T2T动态奖励框架，受人类学习过程启发：1) 错误尝试时激励"增厚"（更长轨迹）以扩大搜索空间；2) 正确时转向"减薄"，施加长度惩罚以减少冗余，培养模型信心和固化推理能力。

Result: 在MATH-500、AIME、AMC等数学基准测试中，对Qwen系列和Deepseek模型的广泛实验表明，T2T显著优于标准GRPO和近期基线方法，实现了更优性能。

Conclusion: T2T框架通过动态调整奖励策略，有效平衡了探索与效率的需求，为LLM推理能力提升提供了新思路，在数学推理任务中展现出显著优势。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising paradigm for enhancing reasoning in Large Language Models (LLMs). However, it frequently encounters challenges such as entropy collapse, excessive verbosity, and insufficient exploration for hard problems. Crucially, existing reward schemes fail to distinguish between the need for extensive search during problem-solving and the efficiency required for mastered knowledge. In this work, we introduce T2T(Thickening-to-Thinning), a dynamic reward framework inspired by human learning processes. Specifically, it implements a dual-phase mechanism: (1) On incorrect attempts, T2T incentivizes "thickening" (longer trajectories) to broaden the search space and explore novel solution paths; (2) Upon achieving correctness, it shifts to "thinning", imposing length penalties to discourage redundancy, thereby fostering model confidence and crystallizing reasoning capabilities. Extensive experiments on mathematical benchmarks (MATH-500, AIME, AMC) across Qwen-series and Deepseek models demonstrate that T2T significantly outperforms standard GRPO and recent baselines, achieving superior performance.

</details>


### [73] [Generative Neural Operators through Diffusion Last Layer](https://arxiv.org/abs/2602.04139)
*Sungwon Park,Anthony Zhou,Hongjoong Kim,Amir Barati Farimani*

Main category: cs.LG

TL;DR: 提出扩散最后一层（DLL）作为神经算子的轻量级概率头，用于建模预测不确定性，在随机PDE算子学习中提升泛化能力和不确定性感知预测


<details>
  <summary>Details</summary>
Motivation: 许多实际系统本质上是随机的，需要原则性的不确定性量化来确保可靠部署。现有神经算子缺乏对不确定性的建模能力，而PDE解分布通常具有相对平滑和低维结构的特点

Method: 提出扩散最后一层（DLL），这是一个轻量级概率头，可以附加到任意神经算子骨干上。DLL通过低秩Karhunen-Loève展开直接在函数空间中参数化条件输出分布，实现高效且表达力强的不确定性建模

Result: 在随机PDE算子学习基准测试中，DLL提升了泛化能力和不确定性感知预测。即使在确定性长时程滚动设置中，DLL也增强了滚动稳定性，并为骨干神经算子提供了有意义的知识不确定性估计

Conclusion: DLL为神经算子提供了一种简单有效的概率扩展，能够在随机和确定性设置中实现可靠的不确定性量化，增强了神经算子在科学计算中的实用性和可靠性

Abstract: Neural operators have emerged as a powerful paradigm for learning discretization-invariant function-to-function mappings in scientific computing. However, many practical systems are inherently stochastic, making principled uncertainty quantification essential for reliable deployment. To address this, we introduce a simple add-on, the diffusion last layer (DLL), a lightweight probabilistic head that can be attached to arbitrary neural operator backbones to model predictive uncertainty. Motivated by the relative smoothness and low-dimensional structure often exhibited by PDE solution distributions, DLL parameterizes the conditional output distribution directly in function space through a low-rank Karhunen-Loève expansion, enabling efficient and expressive uncertainty modeling. Across stochastic PDE operator learning benchmarks, DLL improves generalization and uncertainty-aware prediction. Moreover, even in deterministic long-horizon rollout settings, DLL enhances rollout stability and provides meaningful estimates of epistemic uncertainty for backbone neural operators.

</details>


### [74] [Multi Objective Design Optimization of Non Pneumatic Passenger Car Tires Using Finite Element Modeling, Machine Learning, and Particle swarm Optimization and Bayesian Optimization Algorithms](https://arxiv.org/abs/2602.04277)
*Priyankkumar Dhrangdhariya,Soumyadipta Maiti,Venkataramana Runkana*

Main category: cs.LG

TL;DR: 提出集成生成式设计和机器学习的框架，优化UPTIS型非充气轮胎辐条几何结构，实现刚度可调性、耐久性和振动性能的显著提升。


<details>
  <summary>Details</summary>
Motivation: 非充气轮胎作为充气轮胎的有前景替代品，但其不连续辐条结构在刚度调节、耐久性和高速振动方面存在挑战，需要系统化的优化方法。

Method: 采用高阶多项式参数化辐条轮廓，通过PCHIP几何变化生成约250个设计；使用KRR预测刚度、XGBoost预测耐久性和振动；结合粒子群优化和贝叶斯优化进行多目标性能优化。

Result: 优化设计实现了53%的刚度可调性、高达50%的耐久性提升和43%的振动减少；PSO提供快速收敛，贝叶斯优化有效探索多目标权衡。

Conclusion: 提出的集成框架能够系统化开发高性能的下一代UPTIS辐条结构，为优化非充气轮胎性能提供了有效方法。

Abstract: Non Pneumatic tires offer a promising alternative to pneumatic tires. However, their discontinuous spoke structures present challenges in stiffness tuning, durability, and high speed vibration. This study introduces an integrated generative design and machine learning driven framework to optimize UPTIS type spoke geometries for passenger vehicles. Upper and lower spoke profiles were parameterized using high order polynomial representations, enabling the creation of approximately 250 generative designs through PCHIP based geometric variation. Machine learning models like KRR for stiffness and XGBoost for durability and vibration achieved strong predictive accuracy, reducing the reliance on computationally intensive FEM simulations. Optimization using Particle Swarm Optimization and Bayesian Optimization further enabled extensive performance refinement. The resulting designs demonstrate 53% stiffness tunability, up to 50% durability improvement, and 43% reduction in vibration compared to the baseline. PSO provided fast, targeted convergence, while Bayesian Optimization effectively explored multi objective tradeoffs. Overall, the proposed framework enables systematic development of high performance, next generation UPTIS spoke structures.

</details>


### [75] [Training Data Efficiency in Multimodal Process Reward Models](https://arxiv.org/abs/2602.04145)
*Jinyuan Li,Chengsong Huang,Langlin Huang,Shaoyang Xu,Haolin Liu,Wenxuan Zhang,Jiaxin Huang*

Main category: cs.LG

TL;DR: MPRM训练数据效率研究：提出平衡信息分数(BIS)方法，仅用10%数据即可达到全数据性能，相比随机采样提升4.1%


<details>
  <summary>Details</summary>
Motivation: 多模态过程奖励模型(MPRMs)训练需要大规模蒙特卡洛标注数据，成本高昂。研究发现MPRM训练在随机子采样下很快饱和，表明现有数据存在大量冗余，需要提高数据效率。

Method: 提出理论框架分析发现信息梯度更新依赖两个因素：正负步骤的标签混合度和标签可靠性。基于此提出平衡信息分数(BIS)，在rollout级别基于现有MC信号优先考虑混合度和可靠性，无需额外成本。

Result: 在两个骨干模型(InternVL2.5-8B和Qwen2.5-VL-7B)的VisualProcessBench上，BIS选择的子集仅用少量数据就能匹配甚至超越全数据性能。仅用10%训练数据即可达到全数据性能，相比随机子采样相对提升4.1%。

Conclusion: BIS方法能有效识别MPRM训练中的信息丰富样本，显著提高数据效率，为降低视觉推理模型的训练成本提供了有效解决方案。

Abstract: Multimodal Process Reward Models (MPRMs) are central to step-level supervision for visual reasoning in MLLMs. Training MPRMs typically requires large-scale Monte Carlo (MC)-annotated corpora, incurring substantial training cost. This paper studies the data efficiency for MPRM training.Our preliminary experiments reveal that MPRM training quickly saturates under random subsampling of the training data, indicating substantial redundancy within existing MC-annotated corpora.To explain this, we formalize a theoretical framework and reveal that informative gradient updates depend on two factors: label mixtures of positive/negative steps and label reliability (average MC scores of positive steps). Guided by these insights, we propose the Balanced-Information Score (BIS), which prioritizes both mixture and reliability based on existing MC signals at the rollout level, without incurring any additional cost. Across two backbones (InternVL2.5-8B and Qwen2.5-VL-7B) on VisualProcessBench, BIS-selected subsets consistently match and even surpass the full-data performance at small fractions. Notably, the BIS subset reaches full-data performance using only 10% of the training data, improving over random subsampling by a relative 4.1%.

</details>


### [76] [UnMaskFork: Test-Time Scaling for Masked Diffusion via Deterministic Action Branching](https://arxiv.org/abs/2602.04344)
*Kou Misaki,Takuya Akiba*

Main category: cs.LG

TL;DR: 本文提出UnMaskFork框架，利用蒙特卡洛树搜索优化掩码扩散语言模型的生成路径，在推理时通过确定性部分解掩码提升复杂任务性能


<details>
  <summary>Details</summary>
Motivation: 现有测试时缩放策略主要针对自回归大语言模型，而掩码扩散语言模型由于其迭代和非自回归的生成特性，天然适合更高级的搜索策略，但目前尚未被充分利用

Method: 提出UnMaskFork框架，将解掩码轨迹建模为搜索树，采用蒙特卡洛树搜索优化生成路径，通过多个MDLMs执行确定性部分解掩码操作来探索搜索空间

Result: UMF在复杂编码基准测试中一致优于现有测试时缩放基线，同时在数学推理任务上展现出强大的可扩展性

Conclusion: 掩码扩散语言模型通过适当的搜索策略可以显著提升推理能力，UMF框架为这类模型的有效推理时计算提供了新思路

Abstract: Test-time scaling strategies have effectively leveraged inference-time compute to enhance the reasoning abilities of Autoregressive Large Language Models. In this work, we demonstrate that Masked Diffusion Language Models (MDLMs) are inherently amenable to advanced search strategies, owing to their iterative and non-autoregressive generation process. To leverage this, we propose UnMaskFork (UMF), a framework that formulates the unmasking trajectory as a search tree and employs Monte Carlo Tree Search to optimize the generation path. In contrast to standard scaling methods relying on stochastic sampling, UMF explores the search space through deterministic partial unmasking actions performed by multiple MDLMs. Our empirical evaluation demonstrates that UMF consistently outperforms existing test-time scaling baselines on complex coding benchmarks, while also exhibiting strong scalability on mathematical reasoning tasks.

</details>


### [77] [Benchmarking Uncertainty Quantification of Plug-and-Play Diffusion Priors for Inverse Problems Solving](https://arxiv.org/abs/2602.04189)
*Xiaoyu Qiu,Taewon Yang,Zhanhao Liu,Guanyang Wang,Liyue Shen*

Main category: cs.LG

TL;DR: 本文系统评估了即插即用扩散先验（PnPDP）求解器在逆问题中的不确定性量化能力，发现现有基准仅关注单样本点估计精度，忽视了逆问题的随机性和不确定性特征，提出了基于不确定性量化的分类框架。


<details>
  <summary>Details</summary>
Motivation: 当前即插即用扩散先验（PnPDP）求解器的评估主要关注单样本点估计精度，忽视了逆问题的随机性和不确定性特征，这与科学任务中需要后验分布输出的实际需求存在根本性不匹配。

Method: 设计严格的玩具模型模拟来评估各种PnPDP求解器的不确定性行为，提出基于不确定性量化的分类框架，并在玩具模拟和多样化的真实世界科学逆问题上进行广泛实验。

Result: 实验观察到的不确定性行为与提出的分类框架和理论解释一致，为理解和评估PnPDP的不确定性提供了新的见解。

Conclusion: 本文填补了PnPDP求解器不确定性量化评估的空白，提出的分类框架和评估方法为理解和改进扩散逆问题求解器的不确定性表征能力提供了重要基础。

Abstract: Plug-and-play diffusion priors (PnPDP) have become a powerful paradigm for solving inverse problems in scientific and engineering domains. Yet, current evaluations of reconstruction quality emphasize point-estimate accuracy metrics on a single sample, which do not reflect the stochastic nature of PnPDP solvers and the intrinsic uncertainty of inverse problems, critical for scientific tasks. This creates a fundamental mismatch: in inverse problems, the desired output is typically a posterior distribution and most PnPDP solvers induce a distribution over reconstructions, but existing benchmarks only evaluate a single reconstruction, ignoring distributional characterization such as uncertainty. To address this gap, we conduct a systematic study to benchmark the uncertainty quantification (UQ) of existing diffusion inverse solvers. Specifically, we design a rigorous toy model simulation to evaluate the uncertainty behavior of various PnPDP solvers, and propose a UQ-driven categorization. Through extensive experiments on toy simulations and diverse real-world scientific inverse problems, we observe uncertainty behaviors consistent with our taxonomy and theoretical justification, providing new insights for evaluating and understanding the uncertainty for PnPDPs.

</details>


### [78] [LORE: Jointly Learning the Intrinsic Dimensionality and Relative Similarity Structure From Ordinal Data](https://arxiv.org/abs/2602.04192)
*Vivek Anand,Alec Helbling,Mark Davenport,Gordon Berman,Sankar Alagapan,Christopher Rozell*

Main category: cs.LG

TL;DR: LORE是一个可扩展框架，能从噪声三元组比较中联合学习内在维度和序数嵌入，无需预先设定维度，通过Schatten-p拟范数正则化自动恢复两者。


<details>
  <summary>Details</summary>
Motivation: 从序数数据中学习主观感知空间（如味觉、嗅觉、美学）的内在维度是一个挑战性问题。现有方法需要预先设定嵌入维度，限制了模型的灵活性和解释性。

Method: 引入LORE框架，使用非凸Schatten-p拟范数正则化，通过迭代重加权算法优化联合目标函数，同时学习序数嵌入和其内在维度。

Result: 在合成数据集、模拟感知空间和真实世界众包序数判断上的实验表明，LORE能够学习紧凑、可解释且高精度的低维嵌入，恢复主观感知的潜在几何结构。

Conclusion: LORE通过同时推断内在维度和序数嵌入，为心理物理学提供了更可解释和数据高效的感知建模方法，并为机器学习中从序数数据发现低维结构开辟了新方向。

Abstract: Learning the intrinsic dimensionality of subjective perceptual spaces such as taste, smell, or aesthetics from ordinal data is a challenging problem. We introduce LORE (Low Rank Ordinal Embedding), a scalable framework that jointly learns both the intrinsic dimensionality and an ordinal embedding from noisy triplet comparisons of the form, "Is A more similar to B than C?". Unlike existing methods that require the embedding dimension to be set apriori, LORE regularizes the solution using the nonconvex Schatten-$p$ quasi norm, enabling automatic joint recovery of both the ordinal embedding and its dimensionality. We optimize this joint objective via an iteratively reweighted algorithm and establish convergence guarantees. Extensive experiments on synthetic datasets, simulated perceptual spaces, and real world crowdsourced ordinal judgements show that LORE learns compact, interpretable and highly accurate low dimensional embeddings that recover the latent geometry of subjective percepts. By simultaneously inferring both the intrinsic dimensionality and ordinal embeddings, LORE enables more interpretable and data efficient perceptual modeling in psychophysics and opens new directions for scalable discovery of low dimensional structure from ordinal data in machine learning.

</details>


### [79] [Blockchain Federated Learning for Sustainable Retail: Reducing Waste through Collaborative Demand Forecasting](https://arxiv.org/abs/2602.04384)
*Fabio Turazza,Alessandro Neri,Marcello Pietri,Maria Angela Butturi,Marco Picone,Marco Mamei*

Main category: cs.LG

TL;DR: 本研究探索联邦学习在可持续供应链管理中的应用，特别是针对生鲜食品的杂货零售业。通过区块链支持的联邦学习模型，零售商可以在不共享原始数据的情况下协作训练需求预测模型，显著减少食品浪费。


<details>
  <summary>Details</summary>
Motivation: 准确的需求预测对减少食品浪费至关重要，但零售商之间因数据隐私顾虑而难以协作，限制了预测准确性的提升潜力。

Method: 首先建立孤立零售商场景下的基线预测模型，然后引入基于区块链的联邦学习模型，让多个零售商在不直接共享数据的情况下协作训练模型。

Result: 联邦学习模型的性能几乎等同于理想的数据共享场景，并且明显优于单个零售商不共享数据建立的模型，能够有效减少浪费并提高效率。

Conclusion: 基于区块链的联邦学习为可持续供应链管理提供了一种有效的解决方案，能够在保护数据隐私的同时实现协作式需求预测，从而显著减少食品浪费。

Abstract: Effective demand forecasting is crucial for reducing food waste. However, data privacy concerns often hinder collaboration among retailers, limiting the potential for improved predictive accuracy. In this study, we explore the application of Federated Learning (FL) in Sustainable Supply Chain Management (SSCM), with a focus on the grocery retail sector dealing with perishable goods. We develop a baseline predictive model for demand forecasting and waste assessment in an isolated retailer scenario. Subsequently, we introduce a Blockchain-based FL model, trained collaboratively across multiple retailers without direct data sharing. Our preliminary results show that FL models have performance almost equivalent to the ideal setting in which parties share data with each other, and are notably superior to models built by individual parties without sharing data, cutting waste and boosting efficiency.

</details>


### [80] [From Sparse Sensors to Continuous Fields: STRIDE for Spatiotemporal Reconstruction](https://arxiv.org/abs/2602.04201)
*Yanjie Tong,Peng Chen*

Main category: cs.LG

TL;DR: STRIDE框架通过两阶段方法从稀疏传感器测量重建高维时空场，使用时间编码器和调制隐式神经表示解码器，在极端稀疏传感下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨轨迹和参数设置泛化方面存在困难，且依赖于与离散化绑定的解码器，无法自然跨网格和分辨率迁移。需要一种能处理稀疏传感并支持超分辨率的鲁棒重建方法。

Method: 提出STRIDE两阶段框架：1) 时间编码器将短窗口传感器测量映射到潜在状态；2) 调制隐式神经表示(INR)解码器在任意查询位置重建场。使用FMMNN作为INR骨干，比基于正弦的INR能更好表示复杂空间场并提供更稳定的优化。

Result: 在涵盖混沌动力学和波传播的四个挑战性基准测试中，STRIDE在极端稀疏传感下优于强基线方法，支持超分辨率，并对噪声保持鲁棒性。

Conclusion: STRIDE提供了一种有效的框架，用于从稀疏点传感器测量重建高维时空场，具有理论依据和实际优势，包括跨网格泛化、超分辨率和噪声鲁棒性。

Abstract: Reconstructing high-dimensional spatiotemporal fields from sparse point-sensor measurements is a central challenge in learning parametric PDE dynamics. Existing approaches often struggle to generalize across trajectories and parameter settings, or rely on discretization-tied decoders that do not naturally transfer across meshes and resolutions. We propose STRIDE (Spatio-Temporal Recurrent Implicit DEcoder), a two-stage framework that maps a short window of sensor measurements to a latent state with a temporal encoder and reconstructs the field at arbitrary query locations with a modulated implicit neural representation (INR) decoder. Using the Fourier Multi-Component and Multi-Layer Neural Network (FMMNN) as the INR backbone improves representation of complex spatial fields and yields more stable optimization than sine-based INRs. We provide a conditional theoretical justification: under stable delay observability of point measurements on a low-dimensional parametric invariant set, the reconstruction operator factors through a finite-dimensional embedding, making STRIDE-type architectures natural approximators. Experiments on four challenging benchmarks spanning chaotic dynamics and wave propagation show that STRIDE outperforms strong baselines under extremely sparse sensing, supports super-resolution, and remains robust to noise.

</details>


### [81] [LoRDO: Distributed Low-Rank Optimization with Infrequent Communication](https://arxiv.org/abs/2602.04396)
*Andrej Jovanović,Alex Iacob,Mher Safaryan,Ionut-Vlad Modoranu,Lorenzo Sani,William F. Shen,Xinchi Qiu,Dan Alistarh,Nicholas D. Lane*

Main category: cs.LG

TL;DR: LoRDO框架将低秩优化与不频繁同步相结合，在减少通信开销的同时保持模型性能，在125M-720M规模的语言建模任务中实现约10倍通信减少。


<details>
  <summary>Details</summary>
Motivation: 分布式训练中的通信带宽限制是主要瓶颈，现有的不频繁通信策略仍受限于优化器状态的内存和通信需求。低秩优化器可以缓解这些约束，但在本地更新机制中，工作者无法获取计算低秩投影所需的完整批次梯度，导致性能下降。

Method: 提出LoRDO框架，统一低秩优化与不频繁同步。首先分析基于伪梯度的全局投影虽然理论上有优势，但会将优化轨迹永久限制在低秩子空间中。为恢复子空间探索，引入了全秩拟双曲更新机制。

Result: 在125M-720M模型规模的语言建模和下游任务中，LoRDO实现了与低秩DDP接近的性能，同时减少了约10倍的通信开销。在极低内存设置下，LoRDO在小秩/小批次情况下表现更佳。

Conclusion: LoRDO框架成功解决了低秩优化在本地更新机制中的局限性，通过结合低秩投影和全秩更新，在显著减少通信的同时保持了模型性能，为大规模基础模型的高效分布式训练提供了有效解决方案。

Abstract: Distributed training of foundation models via $\texttt{DDP}$ is limited by interconnect bandwidth. While infrequent communication strategies reduce synchronization frequency, they remain bottlenecked by the memory and communication requirements of optimizer states. Low-rank optimizers can alleviate these constraints; however, in the local-update regime, workers lack access to the full-batch gradients required to compute low-rank projections, which degrades performance. We propose $\texttt{LoRDO}$, a principled framework unifying low-rank optimization with infrequent synchronization. We first demonstrate that, while global projections based on pseudo-gradients are theoretically superior, they permanently restrict the optimization trajectory to a low-rank subspace. To restore subspace exploration, we introduce a full-rank quasi-hyperbolic update. $\texttt{LoRDO}$ achieves near-parity with low-rank $\texttt{DDP}$ in language modeling and downstream tasks at model scales of $125$M--$720$M, while reducing communication by $\approx 10 \times$. Finally, we show that $\texttt{LoRDO}$ improves performance even more in very low-memory settings with small rank/batch size.

</details>


### [82] [From Ambiguity to Action: A POMDP Perspective on Partial Multi-Label Ambiguity and Its Horizon-One Resolution](https://arxiv.org/abs/2602.04255)
*Hanlin Pan,Yuhao Tang,Wanfu Gao*

Main category: cs.LG

TL;DR: 该论文提出了一种新的部分多标签学习方法，通过将标签消歧和特征选择建模为部分可观测马尔可夫决策过程，使用强化学习训练Transformer策略生成高质量伪标签，并实现可解释的特征选择。


<details>
  <summary>Details</summary>
Motivation: 在部分多标签学习中，真实标签不可观测，这使得标签消歧变得重要但困难。关键挑战是模糊的候选标签会将错误传播到下游任务（如特征工程）中。

Method: 将标签消歧和特征选择任务联合建模为部分可观测马尔可夫决策过程，将PML风险最小化转化为期望回报最大化。第一阶段通过强化学习训练Transformer策略生成高质量硬伪标签；第二阶段将特征选择描述为顺序强化学习问题，逐步选择特征并输出可解释的全局排名。

Result: 提供了PML-POMDP对应关系的理论分析和超额风险界限，将误差分解为伪标签质量项和样本大小项。在多个指标和数据集上的实验验证了该框架的优势。

Conclusion: 该方法通过将部分多标签学习问题转化为强化学习框架，有效解决了标签消歧和特征选择的联合优化问题，提高了模型性能并提供了理论保证。

Abstract: In partial multi-label learning (PML), the true labels are unobserved, which makes label disambiguation important but difficult. A key challenge is that ambiguous candidate labels can propagate errors into downstream tasks such as feature engineering. To solve this issue, we jointly model the disambiguation and feature selection tasks as Partially Observable Markov Decision Processes (POMDP) to turn PML risk minimization into expected-return maximization. Stage 1 trains a transformer policy via reinforcement learning to produce high-quality hard pseudo-labels; Stage 2 describes feature selection as a sequential reinforcement learning problem, selecting features step by step and outputting an interpretable global ranking. We further provide the theoretical analysis of PML-POMDP correspondence and the excess-risk bound that decompose the error into pseudo label quality term and sample size. Experiments in multiple metrics and data sets verify the advantages of the framework.

</details>


### [83] [Rethinking the Design Space of Reinforcement Learning for Diffusion Models: On the Importance of Likelihood Estimation Beyond Loss Design](https://arxiv.org/abs/2602.04663)
*Jaemoo Choi,Yuchen Zhu,Wei Guo,Petr Molodyk,Bo Yuan,Jinbin Bai,Yi Xin,Molei Tao,Yongxin Chen*

Main category: cs.LG

TL;DR: 本文系统分析了扩散模型强化学习的设计空间，发现基于ELBO的模型似然估计器是影响RL优化的关键因素，显著提升了生成质量和效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在文本到图像生成等视觉任务中应用广泛，但由于其似然函数难以处理，直接应用流行的策略梯度方法存在障碍。现有方法主要基于已高度工程化的LLM目标构建新目标，使用临时估计器进行似然估计，缺乏对估计如何影响整体算法性能的系统研究。

Method: 通过解耦三个因素来系统分析RL设计空间：i) 策略梯度目标，ii) 似然估计器，iii) 滚动采样方案。研究发现采用基于证据下界（ELBO）的模型似然估计器（仅从最终生成样本计算）是实现有效、高效和稳定RL优化的主导因素。

Result: 在多个奖励基准测试中使用SD 3.5 Medium验证了发现，所有任务都显示出一致的趋势。该方法在90 GPU小时内将GenEval分数从0.24提升到0.95，比FlowGRPO效率高4.6倍，比SOTA方法DiffusionNFT效率高2倍，且没有奖励黑客问题。

Conclusion: 基于ELBO的模型似然估计器是扩散模型强化学习优化的关键因素，其重要性超过了特定策略梯度损失函数的影响，为扩散模型的RL优化提供了系统性的设计指导。

Abstract: Reinforcement learning has been widely applied to diffusion and flow models for visual tasks such as text-to-image generation. However, these tasks remain challenging because diffusion models have intractable likelihoods, which creates a barrier for directly applying popular policy-gradient type methods. Existing approaches primarily focus on crafting new objectives built on already heavily engineered LLM objectives, using ad hoc estimators for likelihood, without a thorough investigation into how such estimation affects overall algorithmic performance. In this work, we provide a systematic analysis of the RL design space by disentangling three factors: i) policy-gradient objectives, ii) likelihood estimators, and iii) rollout sampling schemes. We show that adopting an evidence lower bound (ELBO) based model likelihood estimator, computed only from the final generated sample, is the dominant factor enabling effective, efficient, and stable RL optimization, outweighing the impact of the specific policy-gradient loss functional. We validate our findings across multiple reward benchmarks using SD 3.5 Medium, and observe consistent trends across all tasks. Our method improves the GenEval score from 0.24 to 0.95 in 90 GPU hours, which is $4.6\times$ more efficient than FlowGRPO and $2\times$ more efficient than the SOTA method DiffusionNFT without reward hacking.

</details>


### [84] [Multi-Integration of Labels across Categories for Component Identification (MILCCI)](https://arxiv.org/abs/2602.04270)
*Noga Mudrik,Yuxi Chen,Gal Mishne,Adam S. Charles*

Main category: cs.LG

TL;DR: MILCCI是一种新的数据驱动方法，用于分析带有多类别元数据标签的重复测量时间序列数据，能够识别可解释成分、捕捉跨试验变异性，并整合标签信息来理解每个类别在数据中的表示。


<details>
  <summary>Details</summary>
Motivation: 许多领域通过重复测量收集大规模时间序列数据，每个试验都标有跨多个类别的元数据变量。关键挑战是理解这些标签如何在多试验观测中被编码，并区分每个标签条目在不同类别中的不同影响。

Method: MILCCI扩展了稀疏逐试验分解方法，利用每个类别内的标签相似性来实现细微的、标签驱动的跨试验成分组成调整，并区分每个类别的贡献。该方法还学习每个成分对应的时间轨迹，这些轨迹在每个试验内随时间演化，并在不同试验间灵活变化。

Result: 通过合成和真实世界示例（包括投票模式、在线页面浏览趋势和神经元记录）展示了MILCCI的性能。

Conclusion: MILCCI提供了一种有效的方法来分析带有多类别标签的时间序列数据，能够识别可解释成分、捕捉跨试验变异性，并整合标签信息来理解每个类别在数据中的表示。

Abstract: Many fields collect large-scale temporal data through repeated measurements (trials), where each trial is labeled with a set of metadata variables spanning several categories. For example, a trial in a neuroscience study may be linked to a value from category (a): task difficulty, and category (b): animal choice. A critical challenge in time-series analysis is to understand how these labels are encoded within the multi-trial observations, and disentangle the distinct effect of each label entry across categories. Here, we present MILCCI, a novel data-driven method that i) identifies the interpretable components underlying the data, ii) captures cross-trial variability, and iii) integrates label information to understand each category's representation within the data. MILCCI extends a sparse per-trial decomposition that leverages label similarities within each category to enable subtle, label-driven cross-trial adjustments in component compositions and to distinguish the contribution of each category. MILCCI also learns each component's corresponding temporal trace, which evolves over time within each trial and varies flexibly across trials. We demonstrate MILCCI's performance through both synthetic and real-world examples, including voting patterns, online page view trends, and neuronal recordings.

</details>


### [85] [Delving into Muon and Beyond: Deep Analysis and Extensions](https://arxiv.org/abs/2602.04669)
*Xianbiao Qi,Marco Chen,Jiaquan Ye,Yelin He,Rong Xiao*

Main category: cs.LG

TL;DR: 本文通过谱视角分析Muon优化器，将其视为谱变换族(p=0)的端点，比较了不同p值变体，发现RMS归一化更新比一阶矩更新更稳定，Muon(p=0)并不总是优于Adam，表明Muon主要是一种有效的谱归一化方法而非普遍优越的优化器。


<details>
  <summary>Details</summary>
Motivation: Muon优化器因其强大的经验性能和正交化更新而受到关注，但其底层机制及其与Adam等自适应优化器的关系尚未充分理解。本文旨在通过统一的谱视角来解决这些问题。

Method: 将Muon视为谱变换族UΣ^pV'的p=0端点，考虑p=1/2、p=1/4和p=1等变体。这些变换应用于一阶矩更新(如动量SGD)和RMS归一化梯度更新(如Adam)。为避免显式奇异值分解，开发了耦合牛顿迭代进行高效计算。

Result: 实验发现：1) RMS归一化更新比一阶矩更新产生更稳定的优化；2) 谱压缩在一阶矩更新下提供强大的稳定化效益；3) Muon更新(p=0)并不总是优于Adam。

Conclusion: Muon最好被理解为一种有效的谱归一化形式，而非普遍优越的优化方法。谱视角有助于理解Muon与自适应优化器之间的关系。

Abstract: The Muon optimizer has recently attracted considerable attention for its strong empirical performance and use of orthogonalized updates on matrix-shaped parameters, yet its underlying mechanisms and relationship to adaptive optimizers such as Adam remain insufficiently understood. In this work, we aim to address these questions through a unified spectral perspective. Specifically, we view Muon as the p = 0 endpoint of a family of spectral transformations of the form U \boldsymbolΣ^{p} V' , and consider additional variants with p = 1/2 , p = 1/4 , and p = 1 . These transformations are applied to both first-moment updates, as in momentum SGD, and to root-mean-square (RMS) normalized gradient updates as in Adam. To enable efficient computation, we develop a coupled Newton iteration that avoids explicit singular value decomposition. Across controlled experiments, we find that RMS-normalized updates yield more stable optimization than first-moment updates. Moreover, while spectral compression provides strong stabilization benefits under first-moment updates, the Muon update (p = 0) does not consistently outperform Adam. These results suggest that Muon is best understood as an effective form of spectral normalization, but not a universally superior optimization method. Our source code will be released at https://github.com/Ocram7/BeyondMuon.

</details>


### [86] [Let Experts Feel Uncertainty: A Multi-Expert Label Distribution Approach to Probabilistic Time Series Forecasting](https://arxiv.org/abs/2602.04678)
*Zhen Zhou,Zhirui Wang,Qi Hong,Yunyang Shi,Ziyuan Gu,Zhiyuan Liu*

Main category: cs.LG

TL;DR: 提出了一种新颖的多专家学习分布标签框架，通过混合专家架构实现时间序列预测，平衡预测精度和不确定性量化，在M5销售数据上表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界的时间序列预测需要高预测精度和可解释的不确定性量化。传统点预测方法无法捕捉数据固有不确定性，而现有概率方法难以平衡计算效率和可解释性。

Method: 提出了两种互补方法：1) 多专家LDL，使用多个具有不同学习参数的专家捕捉多样化时间模式；2) 模式感知LDL-MoE，通过专门子专家将时间序列显式分解为可解释组件（趋势、季节性、变化点、波动性）。两种框架都通过最大均值差异实现分布学习。

Result: 在基于M5数据集的聚合销售数据上评估，连续多专家LDL获得最佳整体性能，模式感知LDL-MoE通过组件分析提供增强的可解释性。两种框架都成功平衡了预测精度和可解释性。

Conclusion: 提出的多专家学习分布标签框架成功解决了时间序列预测中预测精度和不确定性量化的平衡问题，适用于需要性能与可操作洞察的现实世界预测应用。

Abstract: Time series forecasting in real-world applications requires both high predictive accuracy and interpretable uncertainty quantification. Traditional point prediction methods often fail to capture the inherent uncertainty in time series data, while existing probabilistic approaches struggle to balance computational efficiency with interpretability. We propose a novel Multi-Expert Learning Distributional Labels (LDL) framework that addresses these challenges through mixture-of-experts architectures with distributional learning capabilities. Our approach introduces two complementary methods: (1) Multi-Expert LDL, which employs multiple experts with different learned parameters to capture diverse temporal patterns, and (2) Pattern-Aware LDL-MoE, which explicitly decomposes time series into interpretable components (trend, seasonality, changepoints, volatility) through specialized sub-experts. Both frameworks extend traditional point prediction to distributional learning, enabling rich uncertainty quantification through Maximum Mean Discrepancy (MMD). We evaluate our methods on aggregated sales data derived from the M5 dataset, demonstrating superior performance compared to baseline approaches. The continuous Multi-Expert LDL achieves the best overall performance, while the Pattern-Aware LDL-MoE provides enhanced interpretability through component-wise analysis. Our frameworks successfully balance predictive accuracy with interpretability, making them suitable for real-world forecasting applications where both performance and actionable insights are crucial.

</details>


### [87] [Identifying Intervenable and Interpretable Features via Orthogonality Regularization](https://arxiv.org/abs/2602.04718)
*Moritz Miller,Florent Draye,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 通过正交化惩罚改进稀疏自编码器，减少特征间干扰，提升可解释性和因果干预能力


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器在微调语言模型时，特征之间存在干扰和叠加问题，这限制了特征的可解释性和因果干预能力。研究旨在通过正交化特征来改善这些问题。

Method: 在固定稀疏自编码器的基础上，对解码器矩阵施加正交化惩罚，使特征几乎正交。这种方法保持了目标数据集的性能，同时确保分解的唯一性和特征的可识别性。

Result: 正交化惩罚减少了特征间的干扰和叠加，同时保持性能基本不变。特征解释之间的嵌入距离随正交化惩罚的严格程度增加而增大，提升了可解释性。正交化特征支持孤立的因果干预。

Conclusion: 正交化惩罚能够产生模块化、可识别的特征表示，这些特征更适合因果干预，符合独立因果机制原理，为可解释AI提供了有前景的方向。

Abstract: With recent progress on fine-tuning language models around a fixed sparse autoencoder, we disentangle the decoder matrix into almost orthogonal features. This reduces interference and superposition between the features, while keeping performance on the target dataset essentially unchanged. Our orthogonality penalty leads to identifiable features, ensuring the uniqueness of the decomposition. Further, we find that the distance between embedded feature explanations increases with stricter orthogonality penalty, a desirable property for interpretability. Invoking the $\textit{Independent Causal Mechanisms}$ principle, we argue that orthogonality promotes modular representations amenable to causal intervention. We empirically show that these increasingly orthogonalized features allow for isolated interventions. Our code is available under $\texttt{https://github.com/mrtzmllr/sae-icm}$.

</details>


### [88] [From Data to Behavior: Predicting Unintended Model Behaviors Before Training](https://arxiv.org/abs/2602.04735)
*Mengru Wang,Zhenqian Xu,Junfeng Fang,Yunzhi Yao,Shumin Deng,Huajun Chen,Ningyu Zhang*

Main category: cs.LG

TL;DR: 提出Data2Behavior任务和MDF方法，用于在训练前预测LLM从看似良性的数据中学习到的意外偏见和行为风险，相比微调可节省80%GPU资源。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型即使从看似良性的训练数据中也可能学习到意外的偏见，现有方法难以在微调前检测这些风险，导致事后评估成本高且效率低。

Method: 提出Manipulating Data Features (MDF)方法：通过候选数据的平均表示总结数据特征，将其注入基础模型的前向传播中，让数据中的潜在统计信号影响模型激活，从而在不更新参数的情况下揭示潜在偏见和安全风险。

Result: MDF在Qwen3-14B、Qwen2.5-32B-Instruct和Gemma-3-12b-it等模型上验证有效，能够预测意外行为并洞察预训练漏洞，同时仅消耗约20%的微调所需GPU资源。

Conclusion: Data2Behavior任务和MDF方法为在训练前预测LLM的意外行为提供了有效解决方案，显著降低了风险评估的计算成本，有助于更早地识别和缓解模型偏见问题。

Abstract: Large Language Models (LLMs) can acquire unintended biases from seemingly benign training data even without explicit cues or malicious content. Existing methods struggle to detect such risks before fine-tuning, making post hoc evaluation costly and inefficient. To address this challenge, we introduce Data2Behavior, a new task for predicting unintended model behaviors prior to training. We also propose Manipulating Data Features (MDF), a lightweight approach that summarizes candidate data through their mean representations and injects them into the forward pass of a base model, allowing latent statistical signals in the data to shape model activations and reveal potential biases and safety risks without updating any parameters. MDF achieves reliable prediction while consuming only about 20% of the GPU resources required for fine-tuning. Experiments on Qwen3-14B, Qwen2.5-32B-Instruct, and Gemma-3-12b-it confirm that MDF can anticipate unintended behaviors and provide insight into pre-training vulnerabilities.

</details>


### [89] [RISE: Interactive Visual Diagnosis of Fairness in Machine Learning Models](https://arxiv.org/abs/2602.04339)
*Ray Chen,Christan Grant*

Main category: cs.LG

TL;DR: RISE是一个可视化工具，通过排序残差分析模型公平性，帮助识别领域转移下的局部差异和隐藏的公平性问题


<details>
  <summary>Details</summary>
Motivation: 在领域转移下评估公平性具有挑战性，因为标量指标常常掩盖了差异出现的位置和方式，需要更精细的分析工具

Method: 提出RISE（通过排序评估的残差检查）交互式可视化工具，将排序残差转换为可解释的模式，将残差曲线结构与形式化公平概念联系起来

Result: RISE能够实现局部差异诊断、跨环境子组比较，以及检测隐藏的公平性问题，通过事后分析揭示聚合统计指标遗漏的准确性与公平性权衡

Conclusion: RISE工具支持更明智的模型选择，通过可视化残差模式提供比传统标量指标更深入的公平性分析

Abstract: Evaluating fairness under domain shift is challenging because scalar metrics often obscure exactly where and how disparities arise. We introduce \textit{RISE} (Residual Inspection through Sorted Evaluation), an interactive visualization tool that converts sorted residuals into interpretable patterns. By connecting residual curve structures to formal fairness notions, RISE enables localized disparity diagnosis, subgroup comparison across environments, and the detection of hidden fairness issues. Through post-hoc analysis, RISE exposes accuracy-fairness trade-offs that aggregate statistics miss, supporting more informed model selection.

</details>


### [90] [Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty](https://arxiv.org/abs/2602.04763)
*Rui Liu,Pratap Tokekar,Ming Lin*

Main category: cs.LG

TL;DR: A2MAML是一个用于多智能体多模态学习的不确定性感知框架，通过模态级协作和贝叶斯逆方差加权提升鲁棒性，在自动驾驶事故检测中表现优异。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统配备异构多模态传感器带来丰富感知能力，但也引入了模态特定和智能体依赖的不确定性。现有协作框架通常在智能体层面推理，假设同质传感，隐式处理不确定性，限制了传感器损坏下的鲁棒性。

Method: A2MAML将每个模态特定特征建模为带有不确定性预测的随机估计，主动选择可靠的智能体-模态对，并通过贝叶斯逆方差加权聚合信息。支持细粒度模态级融合和非对称模态可用性。

Result: 在联网自动驾驶场景的协作事故检测实验中，A2MAML持续优于单智能体和协作基线方法，实现了高达18.7%的事故检测率提升。

Conclusion: A2MAML提供了一个原则性的不确定性感知多智能体多模态学习框架，通过模态级协作和主动可靠性选择，有效抑制了损坏或噪声模态的影响，提升了系统鲁棒性。

Abstract: Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and handle uncertainty implicitly, limiting robustness under sensor corruption. We propose Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty (A2MAML), a principled approach for uncertainty-aware, modality-level collaboration. A2MAML models each modality-specific feature as a stochastic estimate with uncertainty prediction, actively selects reliable agent-modality pairs, and aggregates information via Bayesian inverse-variance weighting. This formulation enables fine-grained, modality-level fusion, supports asymmetric modality availability, and provides a principled mechanism to suppress corrupted or noisy modalities. Extensive experiments on connected autonomous driving scenarios for collaborative accident detection demonstrate that A2MAML consistently outperforms both single-agent and collaborative baselines, achieving up to 18.7% higher accident detection rate.

</details>


### [91] [Billion-Scale Graph Foundation Models](https://arxiv.org/abs/2602.04768)
*Maya Bechler-Speicher,Yoel Gottlieb,Andrey Isakov,David Abensur,Ami Tavory,Daniel Haimovich,Ido Guy,Udi Weinsberg*

Main category: cs.LG

TL;DR: GraphBFF是首个用于构建十亿参数图基础模型的端到端框架，针对异构、十亿级规模的实际图数据，展示了图神经缩放定律，并在未见过的下游任务上取得了显著的零样本和探测性能。


<details>
  <summary>Details</summary>
Motivation: 基础模型在语言和视觉领域通过大规模预训练和轻量级适应取得了革命性进展，但将这一范式扩展到通用的真实世界图数据面临挑战。需要开发能够处理异构、十亿级规模图数据的图基础模型构建方法。

Method: 提出了GraphBFF框架，包括GraphBFF Transformer（灵活可扩展的架构）、数据批处理、预训练和微调的具体方法学。使用14亿参数的GraphBFF Transformer在10亿样本上进行预训练。

Result: 首次展示了通用图的神经缩放定律：损失随模型容量或训练数据规模可预测地下降。在训练期间未见过的10个多样化真实世界下游任务（节点和链接级分类与回归）上，GraphBFF取得了显著的零样本和探测性能，在少样本设置中优势明显，PRAUC提升高达31个点。

Conclusion: GraphBFF为构建工业级规模的图基础模型提供了实用且有原则的基础，展示了图基础模型在实际应用中的潜力，并讨论了未来挑战和开放机会。

Abstract: Graph-structured data underpins many critical applications. While foundation models have transformed language and vision via large-scale pretraining and lightweight adaptation, extending this paradigm to general, real-world graphs is challenging. In this work, we present Graph Billion- Foundation-Fusion (GraphBFF): the first end-to-end recipe for building billion-parameter Graph Foundation Models (GFMs) for arbitrary heterogeneous, billion-scale graphs. Central to the recipe is the GraphBFF Transformer, a flexible and scalable architecture designed for practical billion-scale GFMs. Using the GraphBFF, we present the first neural scaling laws for general graphs and show that loss decreases predictably as either model capacity or training data scales, depending on which factor is the bottleneck. The GraphBFF framework provides concrete methodologies for data batching, pretraining, and fine-tuning for building GFMs at scale. We demonstrate the effectiveness of the framework with an evaluation of a 1.4 billion-parameter GraphBFF Transformer pretrained on one billion samples. Across ten diverse, real-world downstream tasks on graphs unseen during training, spanning node- and link-level classification and regression, GraphBFF achieves remarkable zero-shot and probing performance, including in few-shot settings, with large margins of up to 31 PRAUC points. Finally, we discuss key challenges and open opportunities for making GFMs a practical and principled foundation for graph learning at industrial scale.

</details>


### [92] [MirrorLA: Reflecting Feature Map for Vision Linear Attention](https://arxiv.org/abs/2602.04346)
*Weikang Meng,Liangyu Huo,Yadan Luo,Yaowei Wang,Yingjian Li,Zheng Zhang*

Main category: cs.LG

TL;DR: MirrorLA提出了一种几何框架，用主动重定向替代被动截断，通过可学习的Householder反射将特征几何旋转到非负象限，在线性注意力中最大化信息保留，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 线性注意力虽然将Transformer的计算复杂度从二次降低到线性，但性能始终落后于基于softmax的注意力。研究发现性能下降的根本原因是核特征映射的非负约束：像ReLU这样的标准投影作为"被动截断"操作，不加区分地丢弃负域中的语义信息。

Method: 提出MirrorLA几何框架，用主动重定向替代被动截断。通过可学习的Householder反射将特征几何旋转到非负象限以最大化信息保留。采用多尺度设计：首先通过块级等距优化局部可区分性，使用方差感知调制稳定长上下文动态以多样化激活，最后通过跨头反射集成分散的子空间以诱导全局协方差混合。

Result: MirrorLA在标准基准测试中实现了最先进的性能，证明了严格线性效率可以在不牺牲表征保真度的情况下实现。

Conclusion: 线性注意力性能下降的根本原因是非负约束导致的被动信息截断，MirrorLA通过几何重定向框架主动保留语义信息，在线性复杂度的同时恢复了表征密度，实现了与softmax注意力相当的性能。

Abstract: Linear attention significantly reduces the computational complexity of Transformers from quadratic to linear, yet it consistently lags behind softmax-based attention in performance. We identify the root cause of this degradation as the non-negativity constraint imposed on kernel feature maps: standard projections like ReLU act as "passive truncation" operators, indiscriminately discarding semantic information residing in the negative domain. We propose MirrorLA, a geometric framework that substitutes passive truncation with active reorientation. By leveraging learnable Householder reflections, MirrorLA rotates the feature geometry into the non-negative orthant to maximize information retention. Our approach restores representational density through a cohesive, multi-scale design: it first optimizes local discriminability via block-wise isometries, stabilizes long-context dynamics using variance-aware modulation to diversify activations, and finally, integrates dispersed subspaces via cross-head reflections to induce global covariance mixing. MirrorLA achieves state-of-the-art performance across standard benchmarks, demonstrating that strictly linear efficiency can be achieved without compromising representational fidelity.

</details>


### [93] [Team, Then Trim: An Assembly-Line LLM Framework for High-Quality Tabular Data Generation](https://arxiv.org/abs/2602.04785)
*Congjing Zhang,Ryan Feng Lin,Ruoxuan Bao,Shuai Huang*

Main category: cs.LG

TL;DR: T²框架通过LLM团队协作生成高质量表格数据，结合三阶段质量控制流程，解决表格数据稀缺和质量问题


<details>
  <summary>Details</summary>
Motivation: 表格数据对机器学习应用至关重要，但高质量表格数据获取成本高、难度大，现有数据集常存在类别不平衡、选择偏差和低保真度等问题，需要有效的数据合成方法

Method: 提出Team-then-Trim（T²）框架：1）组织专门化的大型语言模型团队，基于领域知识按顺序生成不同数据组件；2）采用三阶段插件式质量控制流程，从多个维度系统评估合成数据质量

Result: 在模拟和真实世界数据集上的实验结果表明，T²框架在生成高质量表格数据方面优于现有最先进方法，能够有效支持下游模型训练

Conclusion: T²框架通过LLM协作和质量控制机制，为解决表格数据稀缺问题提供了有效方案，在直接数据收集不可行时具有重要应用价值

Abstract: While tabular data is fundamental to many real-world machine learning (ML) applications, acquiring high-quality tabular data is usually labor-intensive and expensive. Limited by the scarcity of observations, tabular datasets often exhibit critical deficiencies, such as class imbalance, selection bias, and low fidelity. To address these challenges, building on recent advances in Large Language Models (LLMs), this paper introduces Team-then-Trim (T$^2$), a framework that synthesizes high-quality tabular data through a collaborative team of LLMs, followed by a rigorous three-stage plug-in data quality control (QC) pipeline. In T$^2$, tabular data generation is conceptualized as a manufacturing process: specialized LLMs, guided by domain knowledge, are tasked with generating different data components sequentially, and the resulting products, i.e., the synthetic data, are systematically evaluated across multiple dimensions of QC. Empirical results on both simulated and real-world datasets demonstrate that T$^2$ outperforms state-of-the-art methods in producing high-quality tabular data, highlighting its potential to support downstream models when direct data collection is practically infeasible.

</details>


### [94] [EXaMCaP: Subset Selection with Entropy Gain Maximization for Probing Capability Gains of Large Chart Understanding Training Sets](https://arxiv.org/abs/2602.04365)
*Jiapeng Liu,Liang Li,Bing Li,Peng Fu,Xiyan Gao,Chengyang Fang,Xiaoshuai Hao,Can Ma*

Main category: cs.LG

TL;DR: EXaMCaP：一种基于熵增益最大化的图表理解数据集子集选择方法，用于高效评估多模态大语言模型的性能增益，避免全量微调的时间成本。


<details>
  <summary>Details</summary>
Motivation: 当前图表理解训练集合成方法需要全量微调MLLMs来评估知识注入效果，这带来了巨大的时间成本，阻碍了数据集的迭代优化。需要一种高效的方法来评估数据集对模型能力的提升。

Method: 提出EXaMCaP方法，通过熵增益最大化选择高多样性子集。该方法从大型图表理解数据集中迭代选择样本，最大化当前集合的熵增益，从而近似获得整个数据集的最大熵子集。

Result: 实验表明EXaMCaP在评估图表理解训练集能力增益方面优于基线方法，在不同子集大小下都表现出色，且与多种MLLM架构兼容。

Conclusion: EXaMCaP提供了一种高效评估图表理解数据集质量的方法，通过选择高多样性子集来近似评估全量微调的效果，显著降低了评估成本，促进了数据集的迭代优化。

Abstract: Recent works focus on synthesizing Chart Understanding (ChartU) training sets to inject advanced chart knowledge into Multimodal Large Language Models (MLLMs), where the sufficiency of the knowledge is typically verified by quantifying capability gains via the fine-tune-then-evaluate paradigm. However, full-set fine-tuning MLLMs to assess such gains incurs significant time costs, hindering the iterative refinement cycles of the ChartU dataset. Reviewing the ChartU dataset synthesis and data selection domains, we find that subsets can potentially probe the MLLMs' capability gains from full-set fine-tuning. Given that data diversity is vital for boosting MLLMs' performance and entropy reflects this feature, we propose EXaMCaP, which uses entropy gain maximization to select a subset. To obtain a high-diversity subset, EXaMCaP chooses the maximum-entropy subset from the large ChartU dataset. As enumerating all possible subsets is impractical, EXaMCaP iteratively selects samples to maximize the gain in set entropy relative to the current set, approximating the maximum-entropy subset of the full dataset. Experiments show that EXaMCaP outperforms baselines in probing the capability gains of the ChartU training set, along with its strong effectiveness across diverse subset sizes and compatibility with various MLLM architectures.

</details>


### [95] [Multi-scale hypergraph meets LLMs: Aligning large language models for time series analysis](https://arxiv.org/abs/2602.04369)
*Zongjiang Shang,Dongliang Cui,Binqing Wu,Ling Chen*

Main category: cs.LG

TL;DR: MSH-LLM：一种多尺度超图方法，通过超边机制增强时间序列语义空间的多尺度语义信息，结合跨模态对齐模块和混合提示机制，将大语言模型与时间序列分析对齐，在27个真实世界数据集上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用预训练大语言模型进行时间序列分析时，未能充分考虑自然语言和时间序列的多尺度结构，导致LLM能力利用不足。需要一种能够有效对齐两种模态多尺度结构的方法。

Method: 提出MSH-LLM方法：1）超边机制增强时间序列语义空间的多尺度语义信息；2）跨模态对齐模块在不同尺度上对齐自然语言和时间序列模态；3）混合提示机制提供上下文信息，增强LLM理解时间序列多尺度时序模式的能力。

Result: 在5个不同应用的27个真实世界数据集上的实验结果表明，MSH-LLM取得了最先进的结果。

Conclusion: MSH-LLM通过多尺度超图方法有效对齐大语言模型与时间序列分析，解决了现有方法在多尺度结构考虑不足的问题，显著提升了时间序列分析性能。

Abstract: Recently, there has been great success in leveraging pre-trained large language models (LLMs) for time series analysis. The core idea lies in effectively aligning the modality between natural language and time series. However, the multi-scale structures of natural language and time series have not been fully considered, resulting in insufficient utilization of LLMs capabilities. To this end, we propose MSH-LLM, a Multi-Scale Hypergraph method that aligns Large Language Models for time series analysis. Specifically, a hyperedging mechanism is designed to enhance the multi-scale semantic information of time series semantic space. Then, a cross-modality alignment (CMA) module is introduced to align the modality between natural language and time series at different scales. In addition, a mixture of prompts (MoP) mechanism is introduced to provide contextual information and enhance the ability of LLMs to understand the multi-scale temporal patterns of time series. Experimental results on 27 real-world datasets across 5 different applications demonstrate that MSH-LLM achieves the state-of-the-art results.

</details>


### [96] [Reducing the labeling burden in time-series mapping using Common Ground: a semi-automated approach to tracking changes in land cover and species over time](https://arxiv.org/abs/2602.04373)
*Geethen Singh,Jasper A Slingsby,Tamara B Robinson,Glenn Moncrieff*

Main category: cs.LG

TL;DR: 论文提出"Common Ground"方法，利用时间稳定区域作为隐式监督，实现无需更新标签的多时相遥感分类，在入侵树种制图中准确率提升21-40%。


<details>
  <summary>Details</summary>
Motivation: 遥感数据分类依赖最新参考标签，但动态或偏远生态系统中收集新标签数据成本高、难度大。需要开发无需频繁更新标签的时序泛化方法。

Method: 提出"Common Ground"方法，结合变化检测和半监督学习，利用时间稳定区域（光谱或语义特征变化小的区域）作为动态区域的隐式监督源。

Result: 在入侵树种制图中，相比简单时序迁移方法准确率提升21-40%，相比黄金标准方法提升10-16%；在欧洲土地覆盖分类中提升2%。方法在多种分类器、传感器和生态用例中验证有效。

Conclusion: 结合稳定参考筛选和半监督学习可实现可扩展、标签高效的多时相遥感分类，无需在初始时间步后手动更新参考标签。

Abstract: Reliable classification of Earth Observation data depends on consistent, up-to-date reference labels. However, collecting new labelled data at each time step remains expensive and logistically difficult, especially in dynamic or remote ecological systems. As a response to this challenge, we demonstrate that a model with access to reference data solely from time step t0 can perform competitively on both t0 and a future time step t1, outperforming models trained separately on time-specific reference data (the gold standard). This finding suggests that effective temporal generalization can be achieved without requiring manual updates to reference labels beyond the initial time step t0. Drawing on concepts from change detection and semi-supervised learning (SSL), the most performant approach, "Common Ground", uses a semi-supervised framework that leverages temporally stable regions-areas with little to no change in spectral or semantic characteristics between time steps-as a source of implicit supervision for dynamic regions. We evaluate this strategy across multiple classifiers, sensors (Landsat-8, Sentinel-2 satellite multispectral and airborne imaging spectroscopy), and ecological use cases. For invasive tree species mapping, we observed a 21-40% improvement in classification accuracy using Common Ground compared to naive temporal transfer, where models trained at a single time step are directly applied to a future time step. We also observe a 10 -16% higher accuracy for the introduced approach compared to a gold-standard approach. In contrast, when broad land cover categories were mapped across Europe, we observed a more modest 2% increase in accuracy compared to both the naive and gold-standard approaches. These results underscore the effectiveness of combining stable reference screening with SSL for scalable and label-efficient multi-temporal remote sensing classification.

</details>


### [97] [Subliminal Effects in Your Data: A General Mechanism via Log-Linearity](https://arxiv.org/abs/2602.04863)
*Ishaq Aden-Ali,Noah Golowich,Allen Liu,Abhishek Shetty,Ankur Moitra,Nika Haghtalab*

Main category: cs.LG

TL;DR: 论文提出Logit-Linear-Selection (LLS)方法，用于从通用偏好数据集中选择子集，以激发模型训练中的隐藏效应，如特定偏好、跨语言响应和角色扮演等行为。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型训练使用多种算法和数据集来激发特定行为，但数据集可能传递无法从单个数据点直接观察到的信号，这对基于数据集理解LLM训练提出了概念挑战，需要对这些现象进行基础性解释。

Method: 受LLM线性结构研究启发，提出Logit-Linear-Selection (LLS)方法，该方法规定如何从通用偏好数据集中选择子集，以激发广泛的隐藏效应。

Result: 应用LLS发现真实数据集子集，使训练出的模型表现出特定偏好、响应数据集中不存在的其他语言提示、以及扮演不同角色等行为。这些效应在选择子集上持续存在，且在不同架构模型中具有普遍性。

Conclusion: LLS方法揭示了数据集如何通过隐藏子文本影响模型行为，为理解数据集对LLM属性的影响提供了通用机制，支持数据集效应在不同模型架构中的普遍性和通用性。

Abstract: Training modern large language models (LLMs) has become a veritable smorgasbord of algorithms and datasets designed to elicit particular behaviors, making it critical to develop techniques to understand the effects of datasets on the model's properties. This is exacerbated by recent experiments that show datasets can transmit signals that are not directly observable from individual datapoints, posing a conceptual challenge for dataset-centric understandings of LLM training and suggesting a missing fundamental account of such phenomena. Towards understanding such effects, inspired by recent work on the linear structure of LLMs, we uncover a general mechanism through which hidden subtexts can arise in generic datasets.
  We introduce Logit-Linear-Selection (LLS), a method that prescribes how to select subsets of a generic preference dataset to elicit a wide range of hidden effects. We apply LLS to discover subsets of real-world datasets so that models trained on them exhibit behaviors ranging from having specific preferences, to responding to prompts in a different language not present in the dataset, to taking on a different persona. Crucially, the effect persists for the selected subset, across models with varying architectures, supporting its generality and universality.

</details>


### [98] [CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation](https://arxiv.org/abs/2602.04868)
*Yannick Denker,Alexander Gepperth*

Main category: cs.LG

TL;DR: 提出CRoSS基准套件，用于在Gazebo模拟器中评估持续强化学习算法在机器人任务上的表现，包含轮式机器人和机械臂两种平台，支持多种传感器和快速运动学模拟。


<details>
  <summary>Details</summary>
Motivation: 持续强化学习需要在不遗忘先前策略的情况下学习一系列任务，但缺乏在机器人环境中具有高物理真实性的可扩展、可复现基准。现有基准要么过于简单，要么缺乏机器人特定的传感器和物理交互。

Method: 开发了基于Gazebo模拟器的CRoSS基准套件，包含两种机器人平台：1）配备激光雷达、摄像头和碰撞传感器的两轮差速机器人，用于线路跟随和物体推动场景；2）七关节机械臂，用于笛卡尔手部位置控制和关节角度控制的目标到达任务。提供运动学变体以加速计算，支持容器化部署确保可复现性。

Result: CRoSS基准套件成功实现，支持高物理真实性的机器人持续学习评估。运动学变体比物理模拟快两个数量级。提供了DQN和策略梯度等标准RL算法的性能基准，验证了其作为可扩展、可复现CRL基准的适用性。

Conclusion: CRoSS为机器人持续强化学习研究提供了首个具有高物理真实性的基准套件，支持多种传感器和快速模拟，容器化部署确保了易用性和可复现性，填补了该领域的研究空白。

Abstract: Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar, camera and bumper sensor, and a robotic arm with seven joints. The former represent an agent in line-following and object-pushing scenarios, where variation of visual and structural parameters yields a large number of distinct tasks, whereas the latter is used in two goal-reaching scenarios with high-level cartesian hand position control (modeled after the Continual World benchmark), and low-level control based on joint angles. For the robotic arm benchmarks, we provide additional kinematics-only variants that bypass the need for physical simulation (as long as no sensor readings are required), and which can be run two orders of magnitude faster. CRoSS is designed to be easily extensible and enables controlled studies of continual reinforcement learning in robotic settings with high physical realism, and in particular allow the use of almost arbitrary simulated sensors. To ensure reproducibility and ease of use, we provide a containerized setup (Apptainer) that runs out-of-the-box, and report performances of standard RL algorithms, including Deep Q-Networks (DQN) and policy gradient methods. This highlights the suitability as a scalable and reproducible benchmark for CRL research.

</details>


### [99] [Rethinking the Trust Region in LLM Reinforcement Learning](https://arxiv.org/abs/2602.04879)
*Penghui Qi,Xiangxin Zhou,Zichen Liu,Tianyu Pang,Chao Du,Min Lin,Wee Sun Lee*

Main category: cs.LG

TL;DR: DPPO用更原则性的策略散度约束替代PPO的启发式裁剪机制，解决了PPO在大词汇量LLM微调中的结构性问题，提升了训练稳定性和效率。


<details>
  <summary>Details</summary>
Motivation: PPO作为RL微调LLM的标准算法，其核心的比率裁剪机制在大词汇量场景下存在结构性问题：对低概率token更新过度惩罚，而对高概率token的灾难性偏移约束不足，导致训练效率低下和不稳定。

Method: 提出Divergence Proximal Policy Optimization (DPPO)，用基于策略散度（如总变差或KL散度）的直接估计替代启发式裁剪。为避免巨大内存开销，引入高效的Binary和Top-K近似来以可忽略的开销捕获关键散度信息。

Result: 广泛的实证评估表明，DPPO相比现有方法实现了更优的训练稳定性和效率，为基于RL的LLM微调提供了更稳健的基础。

Conclusion: DPPO通过更原则性的策略散度约束机制，解决了PPO在大词汇量LLM微调中的结构缺陷，为RL-based LLM fine-tuning提供了更有效的算法基础。

Abstract: Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence. This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning.

</details>


### [100] [Contrastive Continual Learning for Model Adaptability in Internet of Things](https://arxiv.org/abs/2602.04881)
*Ajesh Koyatan Chathoth*

Main category: cs.LG

TL;DR: 本文综述了对比持续学习在物联网中的应用，将算法设计与物联网系统现实相结合，提出了统一的问题表述、参考架构和评估指南。


<details>
  <summary>Details</summary>
Motivation: 物联网部署在非平稳动态环境中运行，传感器漂移、用户行为演变和异构隐私需求等因素会影响应用效用。持续学习通过随时间适应模型而不发生灾难性遗忘来解决这一问题，而对比学习作为一种强大的表示学习范式，能以自监督方式提高鲁棒性和样本效率。

Method: 本文回顾了对比持续学习在物联网中的使用，将算法设计（重放、正则化、蒸馏、提示）与物联网系统现实（TinyML约束、间歇连接、隐私）联系起来。提出了统一的问题表述，推导了混合对比和蒸馏损失的共同目标，提出了面向物联网的参考架构（设备端、边缘和云端），并提供了评估协议和指标的指导。

Result: 建立了对比持续学习在物联网应用中的系统框架，明确了算法设计与实际系统约束之间的连接，为物联网环境下的持续学习提供了实用的参考架构和评估方法。

Conclusion: 本文突出了物联网领域特有的开放挑战，包括处理表格和流式物联网数据、概念漂移、联邦设置和能量感知训练等问题，为未来研究指明了方向。

Abstract: Internet of Things (IoT) deployments operate in nonstationary, dynamic environments where factors such as sensor drift, evolving user behavior, and heterogeneous user privacy requirements can affect application utility. Continual learning (CL) addresses this by adapting models over time without catastrophic forgetting. Meanwhile, contrastive learning has emerged as a powerful representation-learning paradigm that improves robustness and sample efficiency in a self-supervised manner. This paper reviews the usage of \emph{contrastive continual learning} (CCL) for IoT, connecting algorithmic design (replay, regularization, distillation, prompts) with IoT system realities (TinyML constraints, intermittent connectivity, privacy). We present a unifying problem formulation, derive common objectives that blend contrastive and distillation losses, propose an IoT-oriented reference architecture for on-device, edge, and cloud-based CCL, and provide guidance on evaluation protocols and metrics. Finally, we highlight open unique challenges with respect to the IoT domain, such as spanning tabular and streaming IoT data, concept drift, federated settings, and energy-aware training.

</details>


### [101] [Protein Autoregressive Modeling via Multiscale Structure Generation](https://arxiv.org/abs/2602.04883)
*Yanru Qu,Cheng-Yen Hsieh,Zaixiang Zheng,Ge Liu,Quanquan Gu*

Main category: cs.LG

TL;DR: PAR是首个通过粗到细的多尺度自回归框架进行蛋白质骨架生成的方法，采用类似雕塑的过程，先形成粗粒度拓扑再逐步细化结构细节。


<details>
  <summary>Details</summary>
Motivation: 利用蛋白质的层次化特性，解决现有自回归模型在蛋白质结构生成中的暴露偏差问题，实现高质量、可扩展的蛋白质骨架生成。

Method: 包含三个核心组件：1) 多尺度下采样操作；2) 编码多尺度信息的自回归Transformer；3) 基于流的骨架解码器。采用噪声上下文学习和计划采样缓解暴露偏差。

Result: PAR展现出强大的零样本泛化能力，支持灵活的人类提示条件生成和基序支架，无需微调。在无条件生成基准测试中，有效学习蛋白质分布并产生高质量骨架，表现出良好的扩展性。

Conclusion: PAR作为一个有前景的蛋白质结构生成框架，通过多尺度自回归建模和暴露偏差缓解技术，实现了高质量、可扩展的蛋白质骨架生成。

Abstract: We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and refining structural details over scales. To achieve this, PAR consists of three key components: (i) multi-scale downsampling operations that represent protein structures across multiple scales during training; (ii) an autoregressive transformer that encodes multi-scale information and produces conditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that generates backbone atoms conditioned on these embeddings. Moreover, autoregressive models suffer from exposure bias, caused by the training and the generation procedure mismatch, and substantially degrades structure generation quality. We effectively alleviate this issue by adopting noisy context learning and scheduled sampling, enabling robust backbone generation. Notably, PAR exhibits strong zero-shot generalization, supporting flexible human-prompted conditional generation and motif scaffolding without requiring fine-tuning. On the unconditional generation benchmark, PAR effectively learns protein distributions and produces backbones of high design quality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a promising framework for protein structure generation.

</details>


### [102] [Theory of Speciation Transitions in Diffusion Models with General Class Structure](https://arxiv.org/abs/2602.04404)
*Beatrice Achilli,Marco Benedetti,Giulio Biroli,Marc Mézard*

Main category: cs.LG

TL;DR: 本文提出了扩散模型中物种形成转变的通用理论，适用于任意具有明确定义类别的目标分布，超越了仅依赖一阶矩的传统分析。


<details>
  <summary>Details</summary>
Motivation: 现有理论分析仅限于类别可通过一阶矩（如均值分离的高斯混合）识别的情况，无法处理类别通过高阶或集体特征区分的更一般分布。

Method: 通过贝叶斯分类形式化类别结构，用类别间的自由熵差表征物种形成时间，建立适用于任意目标分布的通用理论框架。

Result: 理论框架恢复了高斯混合模型的已知结果，并扩展到一阶矩无法区分的类别，预测了与逐步细粒度类别承诺相关的连续物种形成时间。

Conclusion: 该理论为扩散生成模型中的物种形成转变提供了统一且广泛适用的描述，通过两个可解析处理的例子（不同温度的伊辛模型混合和零均值不同协方差的高斯混合）进行了验证。

Abstract: Diffusion Models generate data by reversing a stochastic diffusion process, progressively transforming noise into structured samples drawn from a target distribution. Recent theoretical work has shown that this backward dynamics can undergo sharp qualitative transitions, known as speciation transitions, during which trajectories become dynamically committed to data classes. Existing theoretical analyses, however, are limited to settings where classes are identifiable through first moments, such as mixtures of Gaussians with well-separated means. In this work, we develop a general theory of speciation in diffusion models that applies to arbitrary target distributions admitting well-defined classes. We formalize the notion of class structure through Bayes classification and characterize speciation times in terms of free-entropy difference between classes. This criterion recovers known results in previously studied Gaussian-mixture models, while extending to situations in which classes are not distinguishable by first moments and may instead differ through higher-order or collective features. Our framework also accommodates multiple classes and predicts the existence of successive speciation times associated with increasingly fine-grained class commitment. We illustrate the theory on two analytically tractable examples: mixtures of one-dimensional Ising models at different temperatures and mixtures of zero-mean Gaussians with distinct covariance structures. In the Ising case, we obtain explicit expressions for speciation times by mapping the problem onto a random-field Ising model and solving it via the replica method. Our results provide a unified and broadly applicable description of speciation transitions in diffusion-based generative models.

</details>


### [103] [Separation-Utility Pareto Frontier: An Information-Theoretic Characterization](https://arxiv.org/abs/2602.04408)
*Shizhou Xu*

Main category: cs.LG

TL;DR: 该研究通过信息论视角分析效用与分离公平性之间的帕累托前沿，证明其凹性并开发基于条件互信息的正则化方法，在多个数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索机器学习模型在保持预测效用（utility）的同时实现分离公平性（separation）的最优权衡。分离公平性要求预测在给定真实结果条件下独立于敏感属性，这在实践中存在权衡挑战。

Method: 采用信息论框架分析效用-分离帕累托前沿，证明其凹性特征。基于理论分析，开发了基于条件互信息（CMI）的正则化方法，该方法与基于梯度优化的深度模型兼容，可作为分离违规的标量监控器。

Result: 在COMPAS、UCI Adult、UCI Bank和CelebA等数据集上的实验表明，所提方法显著减少了分离违规，同时匹配或超越了基准方法的预测效用。理论分析证实了分离的边际成本递增特性。

Conclusion: 该研究提供了一个可证明、稳定且灵活的方法来在深度学习中实施分离公平性，为实践中的权衡选择提供了理论指导，并通过条件互信息正则化实现了有效的公平性约束。

Abstract: We study the Pareto frontier (optimal trade-off) between utility and separation, a fairness criterion requiring predictive independence from sensitive attributes conditional on the true outcome. Through an information-theoretic lens, we prove a characterization of the utility-separation Pareto frontier, establish its concavity, and thereby prove the increasing marginal cost of separation in terms of utility. In addition, we characterize the conditions under which this trade-off becomes strict, providing a guide for trade-off selection in practice. Based on the theoretical characterization, we develop an empirical regularizer based on conditional mutual information (CMI) between predictions and sensitive attributes given the true outcome. The CMI regularizer is compatible with any deep model trained via gradient-based optimization and serves as a scalar monitor of residual separation violations, offering tractable guarantees during training. Finally, numerical experiments support our theoretical findings: across COMPAS, UCI Adult, UCI Bank, and CelebA, the proposed method substantially reduces separation violations while matching or exceeding the utility of established baseline methods. This study thus offers a provable, stable, and flexible approach to enforcing separation in deep learning.

</details>


### [104] [Greedy-Gnorm: A Gradient Matrix Norm-Based Alternative to Attention Entropy for Head Pruning](https://arxiv.org/abs/2602.04491)
*Yuxi Guo,Paul Sheridan*

Main category: cs.LG

TL;DR: 提出Greedy-Gnorm算法，通过动态重新计算注意力头重要性来改进Transformer模型剪枝，在BERT等模型上优于基于注意力熵的静态剪枝方法。


<details>
  <summary>Details</summary>
Motivation: 现有注意力头剪枝方法依赖静态重要性评分，无法捕捉剪枝过程中注意力头角色的动态变化，需要一种能反映梯度信息动态变化的重要性评估方法。

Method: 提出Greedy-Gnorm算法，在每次剪枝步骤后动态重新计算注意力头重要性。每个头的评分基于其Q/K/V梯度块的元素级L2范数乘积，使用验证集估计并在每个贪婪迭代中更新。

Result: 在BERT、ALBERT、RoBERTa和XLM-RoBERTa上的实验表明，Greedy-Gnorm在大量移除注意力头的情况下能持续保持准确性，优于注意力熵方法。

Conclusion: Greedy-Gnorm通过有效减少模型大小同时保持任务性能，为实现更节能的Transformer模型部署提供了有前景的方法。

Abstract: Attention head pruning has emerged as an effective technique for transformer model compression, an increasingly important goal in the era of Green AI. However, existing pruning methods often rely on static importance scores, which fail to capture the evolving role of attention heads during iterative removal. We propose Greedy-Gradient norm (Greedy-Gnorm), a novel head pruning algorithm that dynamically recalculates head importance after each pruning step. Specifically, each head is scored by the elementwise product of the l2-norms of its Q/K/V gradient blocks, as estimated from a hold-out validation set and updated at every greedy iteration. This dynamic approach to scoring mitigates against stale rankings and better reflects gradient-informed importance as pruning progresses. Extensive experiments on BERT, ALBERT, RoBERTa, and XLM-RoBERTa demonstrate that Greedy-Gnorm consistently preserves accuracy under substantial head removal, outperforming attention entropy. By effectively reducing model size while maintaining task performance, Greedy-Gnorm offers a promising step toward more energy-efficient transformer model deployment.

</details>


### [105] [Forget to Generalize: Iterative Adaptation for Generalization in Federated Learning](https://arxiv.org/abs/2602.04536)
*Abdulrahman Alotaibi,Irene Tenison,Miriam Kim,Isaac Lee,Lalana Kagal*

Main category: cs.LG

TL;DR: 本文提出了一种名为迭代联邦适应（IFA）的新训练范式，通过分代遗忘与进化策略来提升异构联邦学习环境下的模型泛化能力，特别针对非独立同分布数据场景。


<details>
  <summary>Details</summary>
Motivation: Web环境天然具有异构性，用户设备、地理区域、浏览模式等导致高度多样化的数据集。联邦学习虽然能实现隐私保护的协作学习，但在现实Web系统中普遍存在的非独立同分布客户端数据下性能严重下降，需要提升异构联邦设置下的泛化能力。

Method: 提出迭代联邦适应（IFA）训练范式：将训练分为多个世代，在每个世代结束时，随机选择或从模型后层选择一部分参数进行重新初始化。这种迭代遗忘与进化策略让模型能够逃离局部最优解，保留全局相关表示。该方法可应用于任何联邦学习算法之上。

Result: 在CIFAR-10、MIT-Indoors和Stanford Dogs数据集上的大量实验表明，该方法显著提升了全局准确率，特别是在跨客户端数据非独立同分布时效果更明显。平均跨数据集提升21.5%。

Conclusion: IFA方法通过分代遗忘与进化策略有效提升了异构联邦学习环境下的模型泛化能力，为实现可扩展、隐私保护的真实世界异构分布式Web系统智能提供了重要进展。

Abstract: The Web is naturally heterogeneous with user devices, geographic regions, browsing patterns, and contexts all leading to highly diverse, unique datasets. Federated Learning (FL) is an important paradigm for the Web because it enables privacy-preserving, collaborative machine learning across diverse user devices, web services and clients without needing to centralize sensitive data. However, its performance degrades severely under non-IID client distributions that is prevalent in real-world web systems. In this work, we propose a new training paradigm - Iterative Federated Adaptation (IFA) - that enhances generalization in heterogeneous federated settings through generation-wise forget and evolve strategy. Specifically, we divide training into multiple generations and, at the end of each, select a fraction of model parameters (a) randomly or (b) from the later layers of the model and reinitialize them. This iterative forget and evolve schedule allows the model to escape local minima and preserve globally relevant representations. Extensive experiments on CIFAR-10, MIT-Indoors, and Stanford Dogs datasets show that the proposed approach improves global accuracy, especially when the data cross clients are Non-IID. This method can be implemented on top any federated algorithm to improve its generalization performance. We observe an average of 21.5%improvement across datasets. This work advances the vision of scalable, privacy-preserving intelligence for real-world heterogeneous and distributed web systems.

</details>


### [106] [Gradient Flow Through Diagram Expansions: Learning Regimes and Explicit Solutions](https://arxiv.org/abs/2602.04548)
*Dmitry Yarotsky,Eugene Golikov,Yaroslav Gusev*

Main category: cs.LG

TL;DR: 本文开发了一个数学框架来分析梯度流在大规模学习问题中的缩放机制，通过类似费曼图的展开揭示了不同的学习阶段，并在张量CP分解模型中发现了多种极端懒惰和丰富梯度流机制。


<details>
  <summary>Details</summary>
Motivation: 研究大规模学习问题中梯度流的缩放机制，理解不同参数缩放、张量阶数和模型对称性如何影响学习动态，为非线性梯度流提供解析解。

Method: 使用形式幂级数展开损失演化，系数由类似费曼图的图表示；在大尺寸极限下分析展开，通过将形式损失展开简化为偏微分方程来求和，在广泛场景中使用特征线法求解一阶偏微分方程。

Result: 张量CP分解模型存在多种极端懒惰和丰富梯度流机制（自由演化、NTK、欠参数化和过参数化平均场）；这些机制以特定且微妙的方式依赖于参数缩放、张量阶数和模型对称性；理论预测与实验吻合良好。

Conclusion: 开发了一个通用数学框架来分析梯度流缩放机制，揭示了不同学习阶段的存在，为非线性梯度流提供了显式解析解，并在张量CP分解模型中发现了多种学习机制。

Abstract: We develop a general mathematical framework to analyze scaling regimes and derive explicit analytic solutions for gradient flow (GF) in large learning problems. Our key innovation is a formal power series expansion of the loss evolution, with coefficients encoded by diagrams akin to Feynman diagrams. We show that this expansion has a well-defined large-size limit that can be used to reveal different learning phases and, in some cases, to obtain explicit solutions of the nonlinear GF. We focus on learning Canonical Polyadic (CP) decompositions of high-order tensors, and show that this model has several distinct extreme lazy and rich GF regimes such as free evolution, NTK and under- and over-parameterized mean-field. We show that these regimes depend on the parameter scaling, tensor order, and symmetry of the model in a specific and subtle way. Moreover, we propose a general approach to summing the formal loss expansion by reducing it to a PDE; in a wide range of scenarios, it turns out to be 1st order and solvable by the method of characteristics. We observe a very good agreement of our theoretical predictions with experiment.

</details>


### [107] [Finding Structure in Continual Learning](https://arxiv.org/abs/2602.04555)
*Pourya Shamsolmoali,Masoumeh Zareapoor*

Main category: cs.LG

TL;DR: 该论文提出使用Douglas-Rachford Splitting方法重新构建持续学习目标，将学习过程视为可塑性和稳定性两个解耦目标之间的协商，而非直接权衡，从而提供更稳定高效的学习动态。


<details>
  <summary>Details</summary>
Motivation: 持续学习通常面临可塑性与稳定性之间的冲突：学习新知识会导致对过去信息的灾难性遗忘。现有方法通过求和竞争损失项来处理，但会产生梯度冲突，需要复杂低效的策略如外部记忆回放或参数正则化。

Method: 使用Douglas-Rachford Splitting方法重新构建持续学习目标，将学习过程视为可塑性（新任务）和稳定性（旧知识）两个解耦目标之间的协商。通过近端算子迭代寻找共识，提供更原则化和稳定的学习动态。

Result: 该方法在不需辅助模块或复杂附加组件的情况下，实现了稳定性和可塑性之间的高效平衡，为持续学习系统提供了更简单但更强大的范式。

Conclusion: Douglas-Rachford Splitting方法为持续学习提供了一个更原则化的框架，通过解耦可塑性和稳定性目标并迭代协商，避免了传统方法的梯度冲突问题，简化了系统设计同时提升了性能。

Abstract: Learning from a stream of tasks usually pits plasticity against stability: acquiring new knowledge often causes catastrophic forgetting of past information. Most methods address this by summing competing loss terms, creating gradient conflicts that are managed with complex and often inefficient strategies such as external memory replay or parameter regularization. We propose a reformulation of the continual learning objective using Douglas-Rachford Splitting (DRS). This reframes the learning process not as a direct trade-off, but as a negotiation between two decoupled objectives: one promoting plasticity for new tasks and the other enforcing stability of old knowledge. By iteratively finding a consensus through their proximal operators, DRS provides a more principled and stable learning dynamic. Our approach achieves an efficient balance between stability and plasticity without the need for auxiliary modules or complex add-ons, providing a simpler yet more powerful paradigm for continual learning systems.

</details>


### [108] [Probabilistic Label Spreading: Efficient and Consistent Estimation of Soft Labels with Epistemic Uncertainty on Graphs](https://arxiv.org/abs/2602.04574)
*Jonathan Klees,Tobias Riedlinger,Peter Stehr,Bennet Böddecker,Daniel Kondermann,Matthias Rottmann*

Main category: cs.LG

TL;DR: 提出一种概率标签传播方法，通过图扩散传播单标注来估计标签的偶然性和认知不确定性，显著减少标注预算并达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 感知任务的安全AI面临挑战，部分原因是缺乏高质量标注数据。标注本身存在偶然性和认知不确定性，但通常在标注和评估中被忽略。虽然众包可以收集多个标注来估计这些不确定性，但由于所需标注工作量巨大，这种方法在大规模应用中不切实际。

Method: 引入概率标签传播方法，假设标签在特征空间上具有平滑性，使用基于图的扩散方法传播单标注。证明了即使每个数据点的标注数量趋近于零，标签传播也能产生一致的概率估计器。提出并分析了可扩展的实现方法。

Result: 实验结果表明，与基线方法相比，该方法在常见图像数据集上显著减少了达到所需标签质量所需的标注预算，并在以数据为中心的图像分类基准上达到了新的最先进水平。

Conclusion: 提出的概率标签传播方法能够可靠地估计标签的偶然性和认知不确定性，通过有效传播单标注来减少标注工作量，为大规模感知任务的AI安全提供了实用解决方案。

Abstract: Safe artificial intelligence for perception tasks remains a major challenge, partly due to the lack of data with high-quality labels. Annotations themselves are subject to aleatoric and epistemic uncertainty, which is typically ignored during annotation and evaluation. While crowdsourcing enables collecting multiple annotations per image to estimate these uncertainties, this approach is impractical at scale due to the required annotation effort. We introduce a probabilistic label spreading method that provides reliable estimates of aleatoric and epistemic uncertainty of labels. Assuming label smoothness over the feature space, we propagate single annotations using a graph-based diffusion method. We prove that label spreading yields consistent probability estimators even when the number of annotations per data point converges to zero. We present and analyze a scalable implementation of our method. Experimental results indicate that, compared to baselines, our approach substantially reduces the annotation budget required to achieve a desired label quality on common image datasets and achieves a new state of the art on the Data-Centric Image Classification benchmark.

</details>


### [109] [Stochastic Decision Horizons for Constrained Reinforcement Learning](https://arxiv.org/abs/2602.04599)
*Nikola Milosevic,Leonard Franz,Daniel Haeufle,Georg Martius,Nico Scherf,Pavel Kolev*

Main category: cs.LG

TL;DR: 提出基于随机决策视野的控制即推理框架，通过状态-动作依赖的延续机制处理约束，实现与重放兼容的离线策略学习，在标准基准和高维肌肉骨骼系统上表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统CMDP方法使用加性成本约束和对偶变量，阻碍了离线策略学习的可扩展性，需要一种既能处理约束又能保持离线策略兼容性的新方法。

Method: 基于随机决策视野的控制即推理框架，约束违反会衰减奖励贡献并通过状态-动作依赖的延续缩短有效规划视野，产生生存加权目标，保持与重放兼容。提出两种违反语义：吸收终止和虚拟终止。

Result: 实验显示在标准基准上提高了样本效率，获得了更好的回报-违反权衡。虚拟终止MPO（VT-MPO）在高维肌肉骨骼Hyfydy设置上有效扩展。

Conclusion: 提出的生存加权目标框架为约束强化学习提供了与重放兼容的离线策略学习方法，在样本效率和可扩展性方面优于传统CMDP方法。

Abstract: Constrained Markov decision processes (CMDPs) provide a principled model for handling constraints, such as safety and other auxiliary objectives, in reinforcement learning. The common approach of using additive-cost constraints and dual variables often hinders off-policy scalability. We propose a Control as Inference formulation based on stochastic decision horizons, where constraint violations attenuate reward contributions and shorten the effective planning horizon via state-action-dependent continuation. This yields survival-weighted objectives that remain replay-compatible for off-policy actor-critic learning. We propose two violation semantics, absorbing and virtual termination, that share the same survival-weighted return but result in distinct optimization structures that lead to SAC/MPO-style policy improvement. Experiments demonstrate improved sample efficiency and favorable return-violation trade-offs on standard benchmarks. Moreover, MPO with virtual termination (VT-MPO) scales effectively to our high-dimensional musculoskeletal Hyfydy setup.

</details>


### [110] [Jacobian Regularization Stabilizes Long-Term Integration of Neural Differential Equations](https://arxiv.org/abs/2602.04608)
*Maya Janvier,Julien Salomon,Etienne Meunier*

Main category: cs.LG

TL;DR: 论文提出通过正则化神经微分方程（NDE）模型的雅可比矩阵来提高长期积分稳定性，特别是在短训练轨迹情况下，设计了已知和未知动力学两种正则化方法。


<details>
  <summary>Details</summary>
Motivation: 混合模型和神经微分方程（NDE）在物理系统建模中越来越重要，但在长期积分时经常遇到稳定性和精度问题。基于展开轨迹的训练虽然可以减少这些发散，但由于需要在迭代过程中计算梯度，计算成本过高。

Method: 通过正则化NDE模型的雅可比矩阵的方向导数来提高稳定性。设计了两种正则化方法：1）对于已知动力学的情况，直接推导动态的方向导数；2）对于未知动力学的情况，使用有限差分近似方向导数。

Result: 两种方法相比训练时的长轨迹展开成本低得多，成功提高了多个常微分方程和偏微分方程的长期模拟稳定性。

Conclusion: 该方法为训练NDE方法进行大规模系统的长期积分打开了大门，在短训练轨迹的挑战性背景下有效稳定了长期积分。

Abstract: Hybrid models and Neural Differential Equations (NDE) are getting increasingly important for the modeling of physical systems, however they often encounter stability and accuracy issues during long-term integration. Training on unrolled trajectories is known to limit these divergences but quickly becomes too expensive due to the need for computing gradients over an iterative process. In this paper, we demonstrate that regularizing the Jacobian of the NDE model via its directional derivatives during training stabilizes long-term integration in the challenging context of short training rollouts. We design two regularizations, one for the case of known dynamics where we can directly derive the directional derivatives of the dynamic and one for the case of unknown dynamics where they are approximated using finite differences. Both methods, while having a far lower cost compared to long rollouts during training, are successful in improving the stability of long-term simulations for several ordinary and partial differential equations, opening up the door to training NDE methods for long-term integration of large scale systems.

</details>


### [111] [Resilient Load Forecasting under Climate Change: Adaptive Conditional Neural Processes for Few-Shot Extreme Load Forecasting](https://arxiv.org/abs/2602.04609)
*Chenxi Hu,Yue Ma,Yifan Wu,Yunhe Hou*

Main category: cs.LG

TL;DR: AdaCNP是一种针对数据稀缺条件下极端天气电力负荷的概率预测模型，通过共享嵌入空间学习相似性，动态加权历史上下文信息，实现少样本适应未见极端模式，提高预测鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 极端天气会显著改变电力消费行为，导致负荷曲线出现尖峰和剧烈波动。在这些时期如果预测不准确，电力系统更可能面临供应短缺或局部过载，迫使采取紧急措施如负荷削减，增加服务中断和公共安全风险。问题的难点在于极端事件可能引发负荷模式的突然变化，而相关的极端样本稀少且不规则，使得可靠学习和校准具有挑战性。

Method: 提出AdaCNP概率预测模型，在共享嵌入空间中学习相似性。对于每个目标数据，评估每个历史上下文段与当前条件的相关性，并相应重新加权上下文信息。这种设计即使在极端样本稀少时也能突出最有信息量的历史证据。模型能够实现少样本适应先前未见的极端模式，并产生用于风险感知决策的预测分布，无需在目标域上进行昂贵的微调。

Result: 在真实世界电力系统负荷数据上评估AdaCNP，并与一系列代表性基线进行比较。结果显示AdaCNP在极端时期更加鲁棒，相对于最强基线将均方误差降低了22%，同时实现了最低的负对数似然，表明其概率输出更加可靠。

Conclusion: AdaCNP能够有效缓解突然分布变化和极端样本稀缺的综合影响，为极端事件下的弹性电力系统运行提供更可信的预测。这些发现表明该模型在数据稀缺条件下对极端天气电力负荷预测具有显著优势。

Abstract: Extreme weather can substantially change electricity consumption behavior, causing load curves to exhibit sharp spikes and pronounced volatility. If forecasts are inaccurate during those periods, power systems are more likely to face supply shortfalls or localized overloads, forcing emergency actions such as load shedding and increasing the risk of service disruptions and public-safety impacts. This problem is inherently difficult because extreme events can trigger abrupt regime shifts in load patterns, while relevant extreme samples are rare and irregular, making reliable learning and calibration challenging. We propose AdaCNP, a probabilistic forecasting model for data-scarce condition. AdaCNP learns similarity in a shared embedding space. For each target data, it evaluates how relevant each historical context segment is to the current condition and reweights the context information accordingly. This design highlights the most informative historical evidence even when extreme samples are rare. It enables few-shot adaptation to previously unseen extreme patterns. AdaCNP also produces predictive distributions for risk-aware decision-making without expensive fine-tuning on the target domain. We evaluate AdaCNP on real-world power-system load data and compare it against a range of representative baselines. The results show that AdaCNP is more robust during extreme periods, reducing the mean squared error by 22\% relative to the strongest baseline while achieving the lowest negative log-likelihood, indicating more reliable probabilistic outputs. These findings suggest that AdaCNP can effectively mitigate the combined impact of abrupt distribution shifts and scarce extreme samples, providing a more trustworthy forecasting for resilient power system operation under extreme events.

</details>


### [112] [QUATRO: Query-Adaptive Trust Region Policy Optimization for LLM Fine-tuning](https://arxiv.org/abs/2602.04620)
*Doyeon Lee,Eunyi Lyou,Hyunsoo Cho,Sookyung Kim,Joonseok Lee,Jaemoo Choi*

Main category: cs.LG

TL;DR: QUATRO是一种新的强化学习LLM微调方法，通过精确的信任区域约束解决现有GRPO方法中启发式近似导致的优化不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO风格的强化学习LLM微调算法依赖启发式的信任区域近似，导致优化行为脆弱。全局重要性比率裁剪和分组归一化无法有效调节落在裁剪范围之外的样本，需要更精确的信任区域约束方法。

Method: 提出QUATRO（Query-Adaptive Trust-Region policy Optimization），通过原则性优化直接强制执行信任区域约束。该方法产生清晰可解释的目标函数，能够显式控制策略更新，实现稳定、熵控制的优化，稳定项从精确的信任区域公式中自然产生。

Result: 在多种数学推理基准测试中经验验证，QUATRO在策略陈旧性增加和激进学习率下仍能保持稳定训练，在整个训练过程中保持良好控制的熵。

Conclusion: QUATRO通过精确的信任区域约束解决了现有RL-based LLM微调方法的优化不稳定问题，提供了更稳定、可控的训练框架。

Abstract: GRPO-style reinforcement learning (RL)-based LLM fine-tuning algorithms have recently gained popularity. Relying on heuristic trust-region approximations, however, they can lead to brittle optimization behavior, as global importance-ratio clipping and group-wise normalization fail to regulate samples whose importance ratios fall outside the clipping range. We propose Query-Adaptive Trust-Region policy Optimization (QUATRO), which directly enforces trust-region constraints through a principled optimization. This yields a clear and interpretable objective that enables explicit control over policy updates and stable, entropy-controlled optimization, with a stabilizer terms arising intrinsically from the exact trust-region formulation. Empirically verified on diverse mathematical reasoning benchmarks, QUATRO shows stable training under increased policy staleness and aggressive learning rates, maintaining well-controlled entropy throughout training.

</details>


### [113] [MTS-JEPA: Multi-Resolution Joint-Embedding Predictive Architecture for Time-Series Anomaly Prediction](https://arxiv.org/abs/2602.04643)
*Yanan He,Yunshi Wen,Xin Wang,Tengfei Ma*

Main category: cs.LG

TL;DR: MTS-JEPA：一种用于多元时间序列异常预测的架构，通过多分辨率预测目标和软码本瓶颈解决表示崩溃问题，有效分离瞬态冲击和长期趋势，在早期预警协议下达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多元时间序列对关键基础设施至关重要，需要主动预测异常以降低风险。虽然联合嵌入预测架构（JEPA）为建模系统潜在演化提供了有前景的框架，但其应用受到表示崩溃和无法捕捉不同时间尺度前兆信号的限制。

Method: 提出MTS-JEPA架构，整合多分辨率预测目标和软码本瓶颈。该设计明确解耦瞬态冲击和长期趋势，利用码本捕捉离散状态转换。这种约束同时作为内在正则化器确保优化稳定性。

Result: 在标准基准测试上的实证评估证实，该方法有效防止退化解，并在早期预警协议下实现了最先进的性能。

Conclusion: MTS-JEPA通过多分辨率预测和软码本瓶颈解决了JEPA在多元时间序列异常预测中的局限性，为关键基础设施的风险缓解提供了有效的早期预警解决方案。

Abstract: Multivariate time series underpin modern critical infrastructure, making the prediction of anomalies a vital necessity for proactive risk mitigation. While Joint-Embedding Predictive Architectures (JEPA) offer a promising framework for modeling the latent evolution of these systems, their application is hindered by representation collapse and an inability to capture precursor signals across varying temporal scales. To address these limitations, we propose MTS-JEPA, a specialized architecture that integrates a multi-resolution predictive objective with a soft codebook bottleneck. This design explicitly decouples transient shocks from long-term trends, and utilizes the codebook to capture discrete regime transitions. Notably, we find this constraint also acts as an intrinsic regularizer to ensure optimization stability. Empirical evaluations on standard benchmarks confirm that our approach effectively prevents degenerate solutions and achieves state-of-the-art performance under the early-warning protocol.

</details>


### [114] [SAFE: Stable Alignment Finetuning with Entropy-Aware Predictive Control for RLHF](https://arxiv.org/abs/2602.04651)
*Dipan Maity*

Main category: cs.LG

TL;DR: SAFE是一种新的RLHF算法，通过双重软最小评论家进行悲观价值估计，结合多层稳定化框架（包括熵门控KL调节和PID控制自适应阈值），解决了PPO在RLHF中的稳定性问题。


<details>
  <summary>Details</summary>
Motivation: PPO虽然被广泛用作RLHF中的RL方法，但其启发式动机、对KL散度约束的临时处理方式，以及存在的奖励振荡、熵崩溃、价值函数漂移和策略突然发散等问题，需要频繁重启和大量超参数调优。

Method: 提出SAFE算法：1) 使用双重软最小评论家进行悲观价值估计；2) 结合多层稳定化框架，包括熵门控KL调节（区分高熵探索和低熵模式崩溃）和PID控制自适应阈值（基于奖励速度动态调整惩罚）。

Result: 在30亿参数模型上的实验显示，SAFE比PPO获得+5.15%的训练平均奖励（0.725 vs 0.689），奖励崩溃可忽略不计，KL控制优于PPO，计算开销最小。

Conclusion: SAFE提供了一个可解释、抗崩溃的RLHF框架，在保持快速学习速度的同时确保稳定的长期优化，适合生产部署。

Abstract: Optimization (PPO) has been positioned by recent literature as the canonical method for the RL part of RLHF. PPO performs well empirically but has a heuristic motivation and handles the KL-divergence constraint used in LM-RLHF in an ad-hoc manner and suffers form reward oscillations, entropy collapse, value function drift, and sudden policy divergence that require frequent restarts and extensive hyperparameter tuning. In this paper, we develop a new pure on policy actor-critic RL method for the LM-RLHF setting. We present SAFE (Stable Alignment Finetuning with Entropy-aware control),a novel RLHF algorithm that combines a Double Soft-Min Critic for pessimistic value estimation with a new multi-layer stabilization framework combining entropy-gated KL regulation, and PID-controlled adaptive thresholds. Unlike standard PPO's symmetric KL penalties, SAFE distinguishes high-entropy exploration from low-entropy mode collapse and adjusts penalties dynamically based on reward velocity. Experiments on a 3B parameter model show SAFE achieves +5.15\% training-average reward than PPO (0.725 vs 0.689), negligible reward crashes, and superior KL control than ppo . Our method adds minimal computational overhead and provides an interpretable, crash-resistant RLHF framework that maintains aggressive learning speed while ensuring stable long-horizon optimization suitable for production deployment. Code is available at https://github.com/ryyzn9/SAFE

</details>


### [115] [Generalized Schrödinger Bridge on Graphs](https://arxiv.org/abs/2602.04675)
*Panagiotis Theodoropoulos,Juno Nam,Evangelos Theodorou,Jaemoo Choi*

Main category: cs.LG

TL;DR: 提出GSBoG框架，用于在任意图上学习可执行的连续时间马尔可夫链策略，解决图运输问题中的可扩展性和表达性限制


<details>
  <summary>Details</summary>
Motivation: 现有图运输方法缺乏可执行策略的表达性，依赖限制性假设，无法在稀疏拓扑上泛化，且随着图大小和时间范围的增加扩展性差

Method: 引入广义薛定谔桥图框架，通过似然优化方法学习轨迹级策略，满足端点边际分布，同时优化状态相关运行成本下的中间行为

Result: 在具有挑战性的真实世界图拓扑上广泛实验表明，GSBoG能够可靠地学习准确、尊重拓扑的策略，同时优化应用特定的中间状态成本

Conclusion: GSBoG为通用图上的成本感知动态运输开辟了新途径，展示了广泛的适用性

Abstract: Transportation on graphs is a fundamental challenge across many domains, where decisions must respect topological and operational constraints. Despite the need for actionable policies, existing graph-transport methods lack this expressivity. They rely on restrictive assumptions, fail to generalize across sparse topologies, and scale poorly with graph size and time horizon. To address these issues, we introduce Generalized Schrödinger Bridge on Graphs (GSBoG), a novel scalable data-driven framework for learning executable controlled continuous-time Markov chain (CTMC) policies on arbitrary graphs under state cost augmented dynamics. Notably, GSBoG learns trajectory-level policies, avoiding dense global solvers and thereby enhancing scalability. This is achieved via a likelihood optimization approach, satisfying the endpoint marginals, while simultaneously optimizing intermediate behavior under state-dependent running costs. Extensive experimentation on challenging real-world graph topologies shows that GSBoG reliably learns accurate, topology-respecting policies while optimizing application-specific intermediate state costs, highlighting its broad applicability and paving new avenues for cost-aware dynamical transport on general graphs.

</details>


### [116] [REDistill: Robust Estimator Distillation for Balancing Robustness and Efficiency](https://arxiv.org/abs/2602.04677)
*Ondrej Tybl,Lukas Neumann*

Main category: cs.LG

TL;DR: REDistill提出了一种基于稳健统计的知识蒸馏框架，通过功率散度损失自适应降低不可靠教师输出的权重，无需特定超参数调优即可提升学生模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法基于KL散度，假设教师模型提供可靠的软目标，但实际中教师预测往往存在噪声或过度自信问题。现有校正方法依赖启发式规则和大量超参数调优，泛化能力有限。

Method: 提出REDistill框架，用功率散度损失替代标准KD目标，该损失是KL散度的泛化形式，能自适应降低不可靠教师输出的权重，同时保留信息丰富的logit关系。该方法仅需logits，可无缝集成到现有KD流程中。

Result: 在CIFAR-100和ImageNet-1k上的广泛实验表明，REDistill在不同师生架构中持续提升学生模型准确率。值得注意的是，该方法无需模型特定的超参数调优即可实现这些增益。

Conclusion: REDistill提供了一个统一且可解释的教师噪声处理方法，具有鲁棒性和强泛化能力，能有效应对教师模型预测不可靠的问题，为知识蒸馏提供了更稳健的解决方案。

Abstract: Knowledge Distillation (KD) transfers knowledge from a large teacher model to a smaller student by aligning their predictive distributions. However, conventional KD formulations - typically based on Kullback-Leibler divergence - assume that the teacher provides reliable soft targets. In practice, teacher predictions are often noisy or overconfident, and existing correction-based approaches rely on ad-hoc heuristics and extensive hyper-parameter tuning, which hinders generalization. We introduce REDistill (Robust Estimator Distillation), a simple yet principled framework grounded in robust statistics. REDistill replaces the standard KD objective with a power divergence loss, a generalization of KL divergence that adaptively downweights unreliable teacher output while preserving informative logit relationships. This formulation provides a unified and interpretable treatment of teacher noise, requires only logits, integrates seamlessly into existing KD pipelines, and incurs negligible computational overhead. Extensive experiments on CIFAR-100 and ImageNet-1k demonstrate that REDistill consistently improves student accuracy in diverse teacher-student architectures. Remarkably, it achieves these gains without model-specific hyper-parameter tuning, underscoring its robustness and strong generalization to unseen teacher-student pairs.

</details>


### [117] [Static and auto-regressive neural emulation of phytoplankton biomass dynamics from physical predictors in the global ocean](https://arxiv.org/abs/2602.04689)
*Mahima Lakra,Ronan Fablet,Lucas Drumetz,Etienne Pauthenet,Elodie Martinez*

Main category: cs.LG

TL;DR: 该研究探索使用深度学习模型预测全球海洋浮游植物生物量的时空分布，发现UNet架构在重现季节和年际模式方面表现最佳，自回归UNet版本能进行短期预测（最多5个月）。


<details>
  <summary>Details</summary>
Motivation: 浮游植物是海洋食物网的基础，对生态过程和全球生物地球化学循环至关重要。然而，由于参数化有限、观测数据稀疏以及海洋过程复杂性，准确模拟浮游植物动态仍然是生物地球化学数值模型面临的主要挑战。

Method: 研究探索了多种深度学习架构，包括CNN、ConvLSTM、4CastNet和UNet，使用卫星观测和环境条件数据预测全球海洋浮游植物生物量分布。特别测试了使用1-2个月环境数据作为输入的UNet模型，并开发了自回归UNet版本，该版本使用自身先前预测来预测未来条件。

Result: UNet架构在重现浮游植物生物量的季节和年际模式方面表现最佳，优于其他测试模型。虽然UNet在短期预测中表现良好，但倾向于低估浮游植物生物量低频变化的幅度。自回归UNet在短期预测（最多5个月）中表现良好，但在更长时间尺度上性能下降。

Conclusion: 结合海洋物理预测因子与深度学习可以重建和短期预测浮游植物动态。这些模型可能成为监测海洋健康和支持海洋生态系统管理的强大工具，特别是在气候变化背景下。

Abstract: Phytoplankton is the basis of marine food webs, driving both ecological processes and global biogeochemical cycles. Despite their ecological and climatic significance, accurately simulating phytoplankton dynamics remains a major challenge for biogeochemical numerical models due to limited parameterizations, sparse observational data, and the complexity of oceanic processes. Here, we explore how deep learning models can be used to address these limitations predicting the spatio-temporal distribution of phytoplankton biomass in the global ocean based on satellite observations and environmental conditions. First, we investigate several deep learning architectures. Among the tested models, the UNet architecture stands out for its ability to reproduce the seasonal and interannual patterns of phytoplankton biomass more accurately than other models like CNNs, ConvLSTM, and 4CastNet. When using one to two months of environmental data as input, UNet performs better, although it tends to underestimate the amplitude of low-frequency changes in phytoplankton biomass. Thus, to improve predictions over time, an auto-regressive version of UNet was also tested, where the model uses its own previous predictions to forecast future conditions. This approach works well for short-term forecasts (up to five months), though its performance decreases for longer time scales. Overall, our study shows that combining ocean physical predictors with deep learning allows for reconstruction and short-term prediction of phytoplankton dynamics. These models could become powerful tools for monitoring ocean health and supporting marine ecosystem management, especially in the context of climate change.

</details>


### [118] [Bounded-Abstention Multi-horizon Time-series Forecasting](https://arxiv.org/abs/2602.04714)
*Luca Stradiotti,Laurens Devos,Anna Monreale,Jesse Davis,Andrea Pugnana*

Main category: cs.LG

TL;DR: 该论文提出了多时间步预测中的弃权学习框架，针对现有方法忽略多步预测结构相关性的问题，定义了三种弃权策略并设计了相应算法。


<details>
  <summary>Details</summary>
Motivation: 在多时间步序列预测中，错误预测成本高昂且会降低信任度。现有弃权策略仅适用于单步预测，忽略了多步预测的结构性和相关性特点，因此需要专门针对多时间步预测的弃权学习框架。

Method: 论文形式化了多时间步预测中的弃权学习问题，提出了三种自然的弃权概念，通过理论分析推导出最优弃权策略，并设计了实现这些策略的算法。

Result: 在24个数据集上的广泛评估表明，提出的算法显著优于现有基线方法。

Conclusion: 多时间步预测的弃权学习具有丰富的结构特性，提出的三种弃权策略和相应算法能够有效处理这一特殊问题，显著提升预测性能。

Abstract: Multi-horizon time-series forecasting involves simultaneously making predictions for a consecutive sequence of subsequent time steps. This task arises in many application domains, such as healthcare and finance, where mispredictions can have a high cost and reduce trust. The learning with abstention framework tackles these problems by allowing a model to abstain from offering a prediction when it is at an elevated risk of making a misprediction. Unfortunately, existing abstention strategies are ill-suited for the multi-horizon setting: they target problems where a model offers a single prediction for each instance. Hence, they ignore the structured and correlated nature of the predictions offered by a multi-horizon forecaster. We formalize the problem of learning with abstention for multi-horizon forecasting setting and show that its structured nature admits a richer set of abstention problems. Concretely, we propose three natural notions of how a model could abstain for multi-horizon forecasting. We theoretically analyze each problem to derive the optimal abstention strategy and propose an algorithm that implements it. Extensive evaluation on 24 datasets shows that our proposed algorithms significantly outperforms existing baselines.

</details>


### [119] [Benchmarking and Enhancing PPG-Based Cuffless Blood Pressure Estimation Methods](https://arxiv.org/abs/2602.04725)
*Neville Mathew,Yidan Shen,Renjie Hu,Maham Rahimi,George Zouridakis*

Main category: cs.LG

TL;DR: 基于PPG的无袖带血压筛查研究，创建标准化基准数据集NBPDB，评估现有模型均未达到临床标准，通过加入人口统计学数据显著提升模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于PPG的血压估计模型在临床数值标准（AAMI/ISO 81060-2）上表现不一致，且公开数据集缺乏生理控制条件下的公平基准测试，需要建立标准化评估框架。

Method: 1. 创建标准化基准数据集NBPDB（来自MIMIC-III和VitalDB的101,453个高质量PPG片段，1,103名健康成人）；2. 系统评估多个最先进的PPG模型；3. 修改模型并加入年龄、性别、BMI等人口统计学数据作为额外输入。

Result: 1. 所有评估模型均未达到AAMI/ISO 81060-2精度要求（平均误差<5 mmHg，标准差<8 mmHg）；2. 加入人口统计学数据后所有模型性能一致提升；3. MInception模型误差降低23%，达到平均绝对误差4.75 mmHg（收缩压）和2.90 mmHg（舒张压），接近临床标准。

Conclusion: 现有PPG血压估计模型在标准化条件下缺乏临床实用性，但加入人口统计学信息能显著提高精度和生理有效性，为可扩展心血管健康评估提供改进方向。

Abstract: Cuffless blood pressure screening based on easily acquired photoplethysmography (PPG) signals offers a practical pathway toward scalable cardiovascular health assessment. Despite rapid progress, existing PPG-based blood pressure estimation models have not consistently achieved the established clinical numerical limits such as AAMI/ISO 81060-2, and prior evaluations often lack the rigorous experimental controls necessary for valid clinical assessment. Moreover, the publicly available datasets commonly used are heterogeneous and lack physiologically controlled conditions for fair benchmarking. To enable fair benchmarking under physiologically controlled conditions, we created a standardized benchmarking subset NBPDB comprising 101,453 high-quality PPG segments from 1,103 healthy adults, derived from MIMIC-III and VitalDB. Using this dataset, we systematically benchmarked several state-of-the-art PPG-based models. The results showed that none of the evaluated models met the AAMI/ISO 81060-2 accuracy requirements (mean error $<$ 5 mmHg and standard deviation $<$ 8 mmHg). To improve model accuracy, we modified these models and added patient demographic data such as age, sex, and body mass index as additional inputs. Our modifications consistently improved performance across all models. In particular, the MInception model reduced error by 23\% after adding the demographic data and yielded mean absolute errors of 4.75 mmHg (SBP) and 2.90 mmHg (DBP), achieves accuracy comparable to the numerical limits defined by AAMI/ISO accuracy standards. Our results show that existing PPG-based BP estimation models lack clinical practicality under standardized conditions, while incorporating demographic information markedly improves their accuracy and physiological validity.

</details>


### [120] [Rationality Measurement and Theory for Reinforcement Learning Agents](https://arxiv.org/abs/2602.04737)
*Kejiang Qian,Amos Storkey,Fengxiang He*

Main category: cs.LG

TL;DR: 该论文提出了强化学习智能体的理性度量框架，定义了完美理性行为、期望理性风险、理性风险缺口等概念，并分析了环境偏移和算法泛化性对理性风险的影响。


<details>
  <summary>Details</summary>
Motivation: 强化学习智能体的理性属性日益重要但鲜有研究，需要建立理论框架来量化智能体在部署环境中的理性表现，并分析训练与部署环境差异对理性行为的影响。

Method: 定义了完美理性行为（最大化隐藏真实价值函数的最陡方向），提出了期望理性风险（策略行为与理性对应行为在部署轨迹上的期望值差异）和理性风险缺口。将风险缺口分解为环境偏移引起的外在成分和算法泛化性引起的内在成分，并用1-Wasserstein距离和经验Rademacher复杂度分别上界。

Result: 理论分析表明：1）环境偏移导致的理性风险上界为训练与部署环境转移核和初始状态分布的1-Wasserstein距离；2）算法泛化性导致的理性风险上界为价值函数类的经验Rademacher复杂度。实验验证了关于正则化技术（层归一化、L2正则化、权重归一化）、领域随机化的益处以及环境偏移的危害的假设。

Conclusion: 该研究建立了强化学习智能体理性的理论框架，提出了可量化的理性度量方法，为理解环境偏移和算法泛化性对理性行为的影响提供了理论依据，并通过实验验证了理论假设，有助于指导更鲁棒和理性的强化学习算法设计。

Abstract: This paper proposes a suite of rationality measures and associated theory for reinforcement learning agents, a property increasingly critical yet rarely explored. We define an action in deployment to be perfectly rational if it maximises the hidden true value function in the steepest direction. The expected value discrepancy of a policy's actions against their rational counterparts, culminating over the trajectory in deployment, is defined to be expected rational risk; an empirical average version in training is also defined. Their difference, termed as rational risk gap, is decomposed into (1) an extrinsic component caused by environment shifts between training and deployment, and (2) an intrinsic one due to the algorithm's generalisability in a dynamic environment. They are upper bounded by, respectively, (1) the $1$-Wasserstein distance between transition kernels and initial state distributions in training and deployment, and (2) the empirical Rademacher complexity of the value function class. Our theory suggests hypotheses on the benefits from regularisers (including layer normalisation, $\ell_2$ regularisation, and weight normalisation) and domain randomisation, as well as the harm from environment shifts. Experiments are in full agreement with these hypotheses. The code is available at https://github.com/EVIEHub/Rationality.

</details>


### [121] [Decomposing Query-Key Feature Interactions Using Contrastive Covariances](https://arxiv.org/abs/2602.04752)
*Andrew Lee,Yonatan Belinkov,Fernanda Viégas,Martin Wattenberg*

Main category: cs.LG

TL;DR: 提出一种分析Transformer注意力机制的方法，通过分解查询-键空间为低秩可解释组件来理解模型为何关注特定token


<details>
  <summary>Details</summary>
Motivation: 尽管注意力头在Transformer中处于核心地位，但缺乏理解模型为何关注特定token的工具。需要开发方法来解释注意力机制的工作原理。

Method: 研究查询-键（QK）空间——查询和键之间的双线性联合嵌入空间。提出对比协方差方法将QK空间分解为低秩、人类可解释的组件。当键和查询中的特征在这些低秩子空间中对齐时，会产生高注意力分数。

Result: 首先在简化设置中进行分析和实证研究，然后将方法应用于大型语言模型，识别出分类语义特征和绑定特征的人类可解释QK子空间。最后展示如何将注意力分数归因于识别出的特征。

Conclusion: 该方法提供了一种理解Transformer注意力机制的新工具，能够识别和解释模型关注特定token的原因，为注意力机制的可解释性研究提供了新途径。

Abstract: Despite the central role of attention heads in Transformers, we lack tools to understand why a model attends to a particular token. To address this, we study the query-key (QK) space -- the bilinear joint embedding space between queries and keys. We present a contrastive covariance method to decompose the QK space into low-rank, human-interpretable components. It is when features in keys and queries align in these low-rank subspaces that high attention scores are produced. We first study our method both analytically and empirically in a simplified setting. We then apply our method to large language models to identify human-interpretable QK subspaces for categorical semantic features and binding features. Finally, we demonstrate how attention scores can be attributed to our identified features.

</details>


### [122] [A Dual-TransUNet Deep Learning Framework for Multi-Source Precipitation Merging and Improving Seasonal and Extreme Estimates](https://arxiv.org/abs/2602.04757)
*Yuchen Ye,Zixuan Qi,Shixuan Li,Wei Qi,Yanpeng Cai,Chaoxia Yuan*

Main category: cs.LG

TL;DR: 提出基于TransUNet的双阶段多源降水融合框架DDL-MSPMF，整合6种多源降水产品和4种ERA5近地面物理预测因子，用于中国区域日降水估算，在季节性和极端降水方面均有改进。


<details>
  <summary>Details</summary>
Motivation: 多源降水产品（卫星反演和再分析）在水文气候监测中广泛应用，但存在空间异质性偏差和极端降水识别能力有限的问题，限制了其水文应用价值。

Method: 开发双阶段TransUNet融合框架：第一阶段分类器估计日降水发生概率，第二阶段回归器融合分类器输出和所有预测因子，在0.25度分辨率下估算2001-2020年中国日降水量。整合6种多源降水产品和4种ERA5近地面物理预测因子。

Result: TransUNet-TransUNet配置表现最佳（R=0.75；RMSE=2.70 mm/day），在东部大部分地区提高强降水（>25 mm/day）的公平威胁评分，更好再现2021年7月郑州暴雨空间格局。在青藏高原的独立评估显示其在数据稀缺区域的适用性。SHAP分析显示降水发生概率和地表气压的重要性。

Conclusion: 该框架为降水融合和极端事件评估提供了可扩展且可解释的方法，增强了极端降水检测能力，超越了季节性平均校正的局限。

Abstract: Multi-source precipitation products (MSPs) from satellite retrievals and reanalysis are widely used for hydroclimatic monitoring, yet spatially heterogeneous biases and limited skill for extremes still constrain their hydrologic utility. Here we develop a dual-stage TransUNet-based multi-source precipitation merging framework (DDL-MSPMF) that integrates six MSPs with four ERA5 near-surface physical predictors. A first-stage classifier estimates daily precipitation occurrence probability, and a second-stage regressor fuses the classifier outputs together with all predictors to estimate daily precipitation amount at 0.25 degree resolution over China for 2001-2020. Benchmarking against multiple deep learning and hybrid baselines shows that the TransUNet - TransUNet configuration yields the best seasonal performance (R = 0.75; RMSE = 2.70 mm/day) and improves robustness relative to a single-regressor setting. For heavy precipitation (>25 mm/day), DDL-MSPMF increases equitable threat scores across most regions of eastern China and better reproduces the spatial pattern of the July 2021 Zhengzhou rainstorm, indicating enhanced extreme-event detection beyond seasonal-mean corrections. Independent evaluation over the Qinghai-Tibet Plateau using TPHiPr further supports its applicability in data-scarce regions. SHAP analysis highlights the importance of precipitation occurrence probabilities and surface pressure, providing physically interpretable diagnostics. The proposed framework offers a scalable and explainable approach for precipitation fusion and extreme-event assessment.

</details>


### [123] [Improved Dimension Dependence for Bandit Convex Optimization with Gradient Variations](https://arxiv.org/abs/2602.04761)
*Hang Yu,Yu-Hu Yan,Peng Zhao*

Main category: cs.LG

TL;DR: 本文改进了带梯度变化的强盗凸优化算法，通过精化非连续梯度变差分析，在两点反馈设置下提升了凸函数和强凸函数的维度依赖关系，并扩展到单点反馈和动态/通用遗憾等应用场景。


<details>
  <summary>Details</summary>
Motivation: 梯度变化的在线学习在博弈论和优化中有重要应用，但在强盗反馈设置下研究不足。现有研究主要集中在全信息设置，而两点反馈的强盗凸优化中梯度变化分析仍有改进空间，特别是维度依赖关系。

Method: 提出对非连续梯度变差的精化分析，这是强盗设置下梯度变化的关键量。该方法改进了两点反馈强盗凸优化的算法分析，并扩展到单点反馈的线性优化超矩形域问题。

Result: 相比已知最佳结果(Chiang et al., 2013)，在凸函数和强凸函数上都改进了维度依赖关系。非连续梯度变差分析还带来了梯度方差和小损失遗憾等有利的问题依赖保证。首次为单点强盗线性优化建立了梯度变化界。

Conclusion: 该技术具有广泛适用性，在动态/通用遗憾最小化和强盗博弈等更具挑战性的任务中验证了有效性，首次为两点强盗凸优化建立了梯度变化的动态和通用遗憾界，并在强盗博弈中实现了快速收敛率。

Abstract: Gradient-variation online learning has drawn increasing attention due to its deep connections to game theory, optimization, etc. It has been studied extensively in the full-information setting, but is underexplored with bandit feedback. In this work, we focus on gradient variation in Bandit Convex Optimization (BCO) with two-point feedback. By proposing a refined analysis on the non-consecutive gradient variation, a fundamental quantity in gradient variation with bandits, we improve the dimension dependence for both convex and strongly convex functions compared with the best known results (Chiang et al., 2013). Our improved analysis for the non-consecutive gradient variation also implies other favorable problem-dependent guarantees, such as gradient-variance and small-loss regrets. Beyond the two-point setup, we demonstrate the versatility of our technique by achieving the first gradient-variation bound for one-point bandit linear optimization over hyper-rectangular domains. Finally, we validate the effectiveness of our results in more challenging tasks such as dynamic/universal regret minimization and bandit games, establishing the first gradient-variation dynamic and universal regret bounds for two-point BCO and fast convergence rates in bandit games.

</details>


### [124] [NeuroCanvas: VLLM-Powered Robust Seizure Detection by Reformulating Multichannel EEG as Image](https://arxiv.org/abs/2602.04769)
*Yan Chen,Jie Peng,Moajjem Hossain Chowdhury,Tianlong Chen,Yunmei Liu*

Main category: cs.LG

TL;DR: NeuroCanvas框架通过熵引导通道选择器和神经元信号画布模块，解决EEG癫痫检测中的多通道异质性和计算效率问题，显著提升检测性能并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 当前将EEG信号编码到大型语言模型的方法面临两个主要挑战：1）多通道异质性——癫痫相关信息在不同EEG通道间差异显著；2）计算效率低下——EEG信号需要编码为大量token进行预测。这些限制了临床实时癫痫检测的实用性和可扩展性。

Method: 提出NeuroCanvas框架，包含两个核心模块：1）熵引导通道选择器（ECS）：选择与癫痫相关的通道输入LLM；2）神经元信号画布（CNS）：将选定的多通道异质EEG信号转换为结构化视觉表示。ECS缓解多通道异质性问题，CNS使用紧凑的视觉token表示EEG信号以提高计算效率。

Result: 在多个癫痫检测数据集上评估显示，NeuroCanvas在F1分数上显著提升20%，推理延迟降低88%。这表明该框架在临床实践中能够实现实时且资源高效的癫痫检测。

Conclusion: NeuroCanvas为临床实践提供了一个可扩展且有效的实时癫痫检测解决方案，通过解决多通道异质性和计算效率问题，显著提升了检测性能并降低了计算延迟。

Abstract: Accurate and timely seizure detection from Electroencephalography (EEG) is critical for clinical intervention, yet manual review of long-term recordings is labor-intensive. Recent efforts to encode EEG signals into large language models (LLMs) show promise in handling neural signals across diverse patients, but two significant challenges remain: (1) multi-channel heterogeneity, as seizure-relevant information varies substantially across EEG channels, and (2) computing inefficiency, as the EEG signals need to be encoded into a massive number of tokens for the prediction. To address these issues, we draw the EEG signal and propose the novel NeuroCanvas framework. Specifically, NeuroCanvas consists of two modules: (i) The Entropy-guided Channel Selector (ECS) selects the seizure-relevant channels input to LLM and (ii) the following Canvas of Neuron Signal (CNS) converts selected multi-channel heterogeneous EEG signals into structured visual representations. The ECS module alleviates the multi-channel heterogeneity issue, and the CNS uses compact visual tokens to represent the EEG signals that improve the computing efficiency. We evaluate NeuroCanvas across multiple seizure detection datasets, demonstrating a significant improvement of $20\%$ in F1 score and reductions of $88\%$ in inference latency. These results highlight NeuroCanvas as a scalable and effective solution for real-time and resource-efficient seizure detection in clinical practice.The code will be released at https://github.com/Yanchen30247/seizure_detect.

</details>


### [125] [Interval-Based AUC (iAUC): Extending ROC Analysis to Uncertainty-Aware Classification](https://arxiv.org/abs/2602.04775)
*Yuqi Li,Matthew M. Engelhard*

Main category: cs.LG

TL;DR: 提出用于区间值预测的不确定性感知ROC框架，引入AUC_L和AUC_U作为理论最优AUC的上下界，支持选择性预测和不确定性评估


<details>
  <summary>Details</summary>
Motivation: 在高风险预测中，通过区间值预测量化不确定性对可靠决策至关重要。标准的ROC曲线和AUC等评估工具仅适用于点预测，无法捕捉预测不确定性对排序性能的影响。

Method: 提出不确定性感知ROC框架，专门针对区间值预测设计。引入AUC_L和AUC_U两个新指标，将ROC平面分解为三个区域：正确排序、错误排序和不确定排序。支持选择性预测，允许模型在区间重叠时放弃排序。

Result: 证明在有效的类条件覆盖下，AUC_L和AUC_U为理论最优AUC(AUC*)提供正式的下界和上界，刻画了可实现的判别性能的物理极限。在真实世界基准数据集上的实验验证了框架的正确性和实用性。

Conclusion: 该框架为区间值预测模型提供了不确定性感知的评估工具，支持选择性预测决策，优化了弃权率与判别可靠性之间的权衡，适用于各种区间构建方法。

Abstract: In high-stakes risk prediction, quantifying uncertainty through interval-valued predictions is essential for reliable decision-making. However, standard evaluation tools like the receiver operating characteristic (ROC) curve and the area under the curve (AUC) are designed for point scores and fail to capture the impact of predictive uncertainty on ranking performance. We propose an uncertainty-aware ROC framework specifically for interval-valued predictions, introducing two new measures: $AUC_L$ and $AUC_U$. This framework enables an informative three-region decomposition of the ROC plane, partitioning pairwise rankings into correct, incorrect, and uncertain orderings. This approach naturally supports selective prediction by allowing models to abstain from ranking cases with overlapping intervals, thereby optimizing the trade-off between abstention rate and discriminative reliability. We prove that under valid class-conditional coverage, $AUC_L$ and $AUC_U$ provide formal lower and upper bounds on the theoretical optimal AUC ($AUC^*$), characterizing the physical limit of achievable discrimination. The proposed framework applies broadly to interval-valued prediction models, regardless of the interval construction method. Experiments on real-world benchmark datasets, using bootstrap-based intervals as one instantiation, validate the framework's correctness and demonstrate its practical utility for uncertainty-aware evaluation and decision-making.

</details>


### [126] [Dynamical Regimes of Multimodal Diffusion Models](https://arxiv.org/abs/2602.04780)
*Emil Albrychiewicz,Andrés Franco Valiente,Li-Ching Chen*

Main category: cs.LG

TL;DR: 该研究提出了一个耦合扩散模型的理论框架，揭示了多模态生成由相互作用时间尺度的谱层次结构控制，而非同时分辨率，并预测了"同步间隙"现象。


<details>
  <summary>Details</summary>
Motivation: 尽管基于扩散的生成模型在高维数据合成方面取得了前所未有的保真度，但多模态生成的理论机制仍然知之甚少。需要建立理论框架来理解耦合扩散模型的工作原理。

Method: 使用耦合Ornstein-Uhlenbeck过程作为可处理模型，应用非平衡统计物理中的动态相变理论，推导对称和各向异性耦合机制下的物种形成和崩溃时间分析条件，并通过MNIST数据集上的扩散模型和精确分数采样器进行实验验证。

Result: 发现多模态生成由相互作用时间尺度的谱层次结构控制，预测了"同步间隙"现象（反向生成过程中不同特征模以不同速率稳定），推导了耦合强度的严格界限以避免不稳定对称破缺，证明耦合强度作为谱滤波器对生成施加可调时间层次。

Conclusion: 研究结果为理解多模态生成提供了理论框架，预测的"同步间隙"解释了常见的去同步伪影，提出的时间依赖耦合调度方法为针对模态特定时间尺度提供了潜在替代方案，可替代临时的指导调优。

Abstract: Diffusion based generative models have achieved unprecedented fidelity in synthesizing high dimensional data, yet the theoretical mechanisms governing multimodal generation remain poorly understood. Here, we present a theoretical framework for coupled diffusion models, using coupled Ornstein-Uhlenbeck processes as a tractable model. By using the nonequilibrium statistical physics of dynamical phase transitions, we demonstrate that multimodal generation is governed by a spectral hierarchy of interaction timescales rather than simultaneous resolution. A key prediction is the ``synchronization gap'', a temporal window during the reverse generative process where distinct eigenmodes stabilize at different rates, providing a theoretical explanation for common desynchronization artifacts. We derive analytical conditions for speciation and collapse times under both symmetric and anisotropic coupling regimes, establishing strict bounds for coupling strength to avoid unstable symmetry breaking. We show that the coupling strength acts as a spectral filter that enforces a tunable temporal hierarchy on generation. We support these predictions through controlled experiments with diffusion models trained on MNIST datasets and exact score samplers. These results motivate time dependent coupling schedules that target mode specific timescales, offering a potential alternative to ad hoc guidance tuning.

</details>


### [127] [Legendre Memory Unit with A Multi-Slice Compensation Model for Short-Term Wind Speed Forecasting Based on Wind Farm Cluster Data](https://arxiv.org/abs/2602.04782)
*Mumin Zhang,Haochen Zhang,Xin Zhi Khoo,Yilin Zhang,Nuo Chen,Ting Zhang,Junjie Tang*

Main category: cs.LG

TL;DR: 本文提出了一种用于风电场集群短期风速预测的集成模型WMF-CPK-MSLMU，通过加权均值滤波去噪、基于Kendall秩相关系数的补偿参数和多切片Legendre记忆单元，实现了准确、快速、鲁棒的预测。


<details>
  <summary>Details</summary>
Motivation: 随着风电场的集群化集成，风电场集群的短期风速预测对电力系统正常运行至关重要。需要充分利用具有时空相关性的集群数据，实现准确、快速、鲁棒的风速预测。

Method: 1) 使用加权均值滤波对单场风速数据进行去噪；2) 创新性地应用Legendre记忆单元进行风速预测，结合基于Kendall秩相关系数的补偿参数构建多切片LMU；3) 提出WMF-CPK-MSLMU集成模型，包含数据预处理、预测和多切片补偿三个关键模块。

Result: 在不同风电场集群上的测试结果表明，所提出的WMF-CPK-MSLMU集成模型在风电场集群短期预测方面比现有模型具有更高的有效性和优越性。

Conclusion: 该集成模型通过充分利用风电场集群数据的时空相关性，结合创新的多切片补偿机制，实现了对风电场集群短期风速的准确、快速、鲁棒预测，为电力系统稳定运行提供了有效支持。

Abstract: With more wind farms clustered for integration, the short-term wind speed prediction of such wind farm clusters is critical for normal operation of power systems. This paper focuses on achieving accurate, fast, and robust wind speed prediction by full use of cluster data with spatial-temporal correlation. First, weighted mean filtering (WMF) is applied to denoise wind speed data at the single-farm level. The Legendre memory unit (LMU) is then innovatively applied for the wind speed prediction, in combination with the Compensating Parameter based on Kendall rank correlation coefficient (CPK) of wind farm cluster data, to construct the multi-slice LMU (MSLMU). Finally, an innovative ensemble model WMF-CPK-MSLMU is proposed herein, with three key blocks: data pre-processing, forecasting, and multi-slice compensation. Advantages include: 1) LMU jointly models linear and nonlinear dependencies among farms to capture spatial-temporal correlations through backpropagation; 2) MSLMU enhances forecasting by using CPK-derived weights instead of random initialization, allowing spatial correlations to fully activate hidden nodes across clustered wind farms.; 3) CPK adaptively weights the compensation model in MSLMU and complements missing data spatially, to facilitate the whole model highly accurate and robust. Test results on different wind farm clusters indicate the effectiveness and superiority of proposed ensemble model WMF-CPK-MSLMU in the short-term prediction of wind farm clusters compared to the existing models.

</details>


### [128] [From independent patches to coordinated attention: Controlling information flow in vision transformers](https://arxiv.org/abs/2602.04784)
*Kieran A. Murphy*

Main category: cs.LG

TL;DR: 在视觉Transformer中通过变分信息瓶颈显式量化注意力传输的信息，实现从独立补丁处理到全局注意力的可控谱系


<details>
  <summary>Details</summary>
Motivation: 使注意力传输的信息成为显式可测量的量，通过约束内部通信获得更易进行机制分析和控制的可解释模型

Method: 在所有注意力对残差流的写入操作中插入变分信息瓶颈，不改变其他架构，训练时引入显式信息成本

Result: 在ImageNet-100上表征了分类行为和信息路由在谱系上的演化，分析了首批传输信息的注意力头如何从局部补丁处理中产生全局视觉表征

Conclusion: 通过约束内部通信的学习偏置，获得了更易于机制分析和控制的模型，为理解视觉Transformer的信息处理提供了新视角

Abstract: We make the information transmitted by attention an explicit, measurable quantity in vision transformers. By inserting variational information bottlenecks on all attention-mediated writes to the residual stream -- without other architectural changes -- we train models with an explicit information cost and obtain a controllable spectrum from independent patch processing to fully expressive global attention. On ImageNet-100, we characterize how classification behavior and information routing evolve across this spectrum, and provide initial insights into how global visual representations emerge from local patch processing by analyzing the first attention heads that transmit information. By biasing learning toward solutions with constrained internal communication, our approach yields models that are more tractable for mechanistic analysis and more amenable to control.

</details>


### [129] [Maximum-Volume Nonnegative Matrix Factorization](https://arxiv.org/abs/2602.04795)
*Olivier Vu Thanh,Nicolas Gillis*

Main category: cs.LG

TL;DR: 本文提出最大体积非负矩阵分解（MaxVol NMF），通过最大化因子H的体积来获得更稀疏、更可解释的分解，与最小体积NMF形成对比。


<details>
  <summary>Details</summary>
Motivation: 传统最小体积NMF（MinVol NMF）通过最小化W的体积来获得可解释和唯一的解，但存在生成秩不足解的问题。本文探索对偶方法，通过最大化H的体积来获得更好的稀疏分解效果。

Method: 提出最大体积NMF（MaxVol NMF）方法，最大化因子H的体积而非最小化W的体积。开发了两种求解算法，并提出归一化变体，该变体可解释为标准NMF和正交NMF之间的连续体。

Result: MaxVol NMF在无噪声情况下与MinVol NMF具有相同的可识别性，但在噪声存在时表现不同。MaxVol NMF能更有效地提取稀疏分解，不会生成秩不足解，且最大体积解对应于将X的列聚类到不相交的簇中。

Conclusion: MaxVol NMF是MinVol NMF的有效对偶方法，在稀疏分解方面表现更优，归一化变体性能优于MinVol NMF和MaxVol NMF，在高光谱解混等应用中具有实用价值。

Abstract: Nonnegative matrix factorization (NMF) is a popular data embedding technique. Given a nonnegative data matrix $X$, it aims at finding two lower dimensional matrices, $W$ and $H$, such that $X\approx WH$, where the factors $W$ and $H$ are constrained to be element-wise nonnegative. The factor $W$ serves as a basis for the columns of $X$. In order to obtain more interpretable and unique solutions, minimum-volume NMF (MinVol NMF) minimizes the volume of $W$. In this paper, we consider the dual approach, where the volume of $H$ is maximized instead; this is referred to as maximum-volume NMF (MaxVol NMF). MaxVol NMF is identifiable under the same conditions as MinVol NMF in the noiseless case, but it behaves rather differently in the presence of noise. In practice, MaxVol NMF is much more effective to extract a sparse decomposition and does not generate rank-deficient solutions. In fact, we prove that the solutions of MaxVol NMF with the largest volume correspond to clustering the columns of $X$ in disjoint clusters, while the solutions of MinVol NMF with smallest volume are rank deficient. We propose two algorithms to solve MaxVol NMF. We also present a normalized variant of MaxVol NMF that exhibits better performance than MinVol NMF and MaxVol NMF, and can be interpreted as a continuum between standard NMF and orthogonal NMF. We illustrate our results in the context of hyperspectral unmixing.

</details>


### [130] [Evolving Afferent Architectures: Biologically-inspired Models for Damage-Avoidance Learning](https://arxiv.org/abs/2602.04807)
*Wolfgang Maass,Sabine Janzen,Prajvi Saxena,Sach Mukherjee*

Main category: cs.LG

TL;DR: 本文提出Afferent Learning框架，通过进化优化发现有效的传入感知架构，为强化学习提供内部风险信号，实现损伤规避学习，在生物力学数字孪生中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 受生物系统启发，需要开发能够产生适应性内部风险信号的框架，以支持高效的损伤规避学习。传统方法直接最小化损伤，而本文旨在通过传入感知架构提供归纳偏置，使策略学习更有效。

Method: 采用双层架构：外层进化优化发现传入感知架构（CATs），内层强化学习利用这些信号训练损伤规避策略。将传入感知形式化为提供高效学习的归纳偏置，架构选择基于其支持有效学习的能力而非直接最小化损伤。

Result: 在生物力学数字孪生长期模拟中，CAT进化架构比手工设计基线显著提高效率（23%高风险动作减少）和年龄鲁棒性，实现年龄依赖的行为适应。消融研究验证了CAT信号、进化和预测差异的重要性。

Conclusion: Afferent Learning框架通过进化优化的传入感知架构为强化学习提供有效的内部风险信号，在损伤规避学习中表现出优越性能，为长期生物力学模拟提供了有前景的方法。

Abstract: We introduce Afferent Learning, a framework that produces Computational Afferent Traces (CATs) as adaptive, internal risk signals for damage-avoidance learning. Inspired by biological systems, the framework uses a two-level architecture: evolutionary optimization (outer loop) discovers afferent sensing architectures that enable effective policy learning, while reinforcement learning (inner loop) trains damage-avoidance policies using these signals. This formalizes afferent sensing as providing an inductive bias for efficient learning: architectures are selected based on their ability to enable effective learning (rather than directly minimizing damage). We provide theoretical convergence guarantees under smoothness and bounded-noise assumptions. We illustrate the general approach in the challenging context of biomechanical digital twins operating over long time horizons (multiple decades of the life-course). Here, we find that CAT-based evolved architectures achieve significantly higher efficiency and better age-robustness than hand-designed baselines, enabling policies that exhibit age-dependent behavioral adaptation (23% reduction in high-risk actions). Ablation studies validate CAT signals, evolution, and predictive discrepancy as essential. We release code and data for reproducibility.

</details>


### [131] [The Key to State Reduction in Linear Attention: A Rank-based Perspective](https://arxiv.org/abs/2602.04852)
*Philipp Nazari,T. Konstantin Rusch*

Main category: cs.LG

TL;DR: 线性注意力模型在实践中常呈现低秩状态，导致容量利用不足。本文提出理论分析揭示低秩对检索误差的影响，并开发硬件感知的结构化剪枝框架，通过修剪查询和键矩阵来减少状态大小，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 线性注意力作为softmax注意力的高效替代方案，在实践中训练后的模型状态常呈现低秩结构，表明模型未能充分利用其容量。这种现象需要理论解释，并探索如何在不显著影响性能的情况下减少状态大小以提高效率。

Method: 首先提供线性注意力中秩的理论分析，揭示低有效秩如何通过放大查询噪声影响检索误差。然后提出硬件感知的结构化剪枝框架，通过修剪查询和键矩阵来减少状态大小，同时保持与现有CUDA内核的兼容性。提出基于秩揭示QR分解的新型结构化剪枝方法，并适配多种现有剪枝策略。

Result: 实验结果表明，该框架在不同规模模型和各种下游任务中均有效。能够移除50%的查询和键通道，仅导致困惑度边际增加。实现了更快、更内存高效的模型，同时保持与现有硬件基础设施的兼容性。

Conclusion: 线性注意力模型中的低秩状态既是一个理论现象，也是一个实际优化机会。通过理论分析和结构化剪枝框架，可以在保持性能的同时显著减少模型状态大小，提高计算效率和内存利用率，为线性注意力模型的实用部署提供了有效解决方案。

Abstract: Linear attention offers a computationally efficient yet expressive alternative to softmax attention. However, recent empirical results indicate that the state of trained linear attention models often exhibits a low-rank structure, suggesting that these models underexploit their capacity in practice. To illuminate this phenomenon, we provide a theoretical analysis of the role of rank in linear attention, revealing that low effective rank can affect retrieval error by amplifying query noise. In addition to these theoretical insights, we conjecture that the low-rank states can be substantially reduced post-training with only minimal performance degradation, yielding faster and more memory-efficient models. To this end, we propose a novel hardware-aware approach that structurally prunes key and query matrices, reducing the state size while retaining compatibility with existing CUDA kernels. We adapt several existing pruning strategies to fit our framework and, building on our theoretical analysis, propose a novel structured pruning method based on a rank-revealing QR decomposition. Our empirical results, evaluated across models of varying sizes and on various downstream tasks, demonstrate the effectiveness of our state reduction framework. We highlight that our framework enables the removal of 50% of the query and key channels at only a marginal increase in perplexity. The code for this project can be found at https://github.com/camail-official/LinearAttentionPruning.

</details>


### [132] [Multi-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism](https://arxiv.org/abs/2602.04870)
*Chenwei Cui,Rockwell Jackson,Benjamin Joseph Herrera,Ana María Tárano,Hannah Kerner*

Main category: cs.LG

TL;DR: 提出了Multi-Head LatentMoE和Head Parallel (HP)新架构，解决了传统专家并行(EP)的三个限制：通信成本随激活专家数线性增长、负载不均衡、数据依赖通信需要元数据交换。新方法实现O(1)通信成本、完全平衡流量和确定性通信，训练速度提升1.61倍。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练成本高昂，稀疏专家混合(MoE)通过条件计算解决此问题，但标准专家并行(EP)方法存在三个主要限制：通信成本随激活专家数线性增长、负载不均衡影响延迟和内存使用、数据依赖通信需要元数据交换。

Method: 提出Multi-Head LatentMoE架构和Head Parallel (HP)并行策略，实现O(1)通信成本（与激活专家数k无关）、完全平衡流量和确定性通信。同时提出IO感知路由和专家计算来加速Multi-Head LatentMoE。

Result: 相比传统MoE+EP，Multi-Head LatentMoE+HP训练速度提升1.61倍，同时保持相同性能。在加倍粒度下，获得更高整体性能的同时仍保持1.11倍加速。方法使数十亿参数基础模型研究更加可行。

Conclusion: Multi-Head LatentMoE和Head Parallel解决了传统专家并行的关键限制，显著提升训练效率，使大规模基础模型研究更加可及，为稀疏专家混合模型的分布式训练提供了更优方案。

Abstract: Large language models have transformed many applications but remain expensive to train. Sparse Mixture of Experts (MoE) addresses this through conditional computation, with Expert Parallel (EP) as the standard distributed training method. However, EP has three limitations: communication cost grows linearly with the number of activated experts $k$, load imbalance affects latency and memory usage, and data-dependent communication requires metadata exchange. We propose Multi-Head LatentMoE and Head Parallel (HP), a new architecture and parallelism achieving $O(1)$ communication cost regardless of $k$, completely balanced traffic, and deterministic communication, all while remaining compatible with EP. To accelerate Multi-Head LatentMoE, we propose IO-aware routing and expert computation. Compared to MoE with EP, Multi-Head LatentMoE with HP trains up to $1.61\times$ faster while having identical performance. With doubled granularity, it achieves higher overall performance while still being $1.11\times$ faster. Our method makes multi-billion-parameter foundation model research more accessible.

</details>
