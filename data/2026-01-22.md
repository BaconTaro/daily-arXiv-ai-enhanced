<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 15]
- [cs.AI](#cs.AI) [Total: 21]
- [cs.LG](#cs.LG) [Total: 47]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [When Generative AI Is Intimate, Sexy, and Violent: Examining Not-Safe-For-Work (NSFW) Chatbots on FlowGPT](https://arxiv.org/abs/2601.14324)
*Xian Li,Yuanning Han,Di Liu,Pengcheng An,Shuo Niu*

Main category: cs.HC

TL;DR: 研究分析了FlowGPT平台上的376个NSFW聊天机器人和307个公开对话，识别了四种聊天机器人类型，发现这些AI角色通过虚拟亲密、性幻想、暴力表达和危险内容获取等方式提供NSFW体验。


<details>
  <summary>Details</summary>
Motivation: 生成式AI驱动的用户创建聊天机器人为分享和互动NSFW内容提供了新方式，但人们对这些AI聊天机器人的特性及其用户互动了解甚少，需要系统研究其特点和影响。

Method: 基于社交媒体NSFW功能理论，对FlowGPT平台上的376个NSFW聊天机器人和307个公开对话会话进行内容分析。

Result: 识别出四种聊天机器人类型：角色扮演角色、故事生成器、图像生成器和"无所不能"机器人；发现AI角色常使用露骨头像吸引互动，性、暴力和侮辱性内容出现在用户提示和机器人输出中，有些机器人在用户未创建色情提示时也会生成露骨内容。

Conclusion: FlowGPT上的NSFW体验可理解为虚拟亲密、性幻想、暴力思想表达和不安全内容获取的组合，研究对聊天机器人设计、创作者支持、用户安全和内容审核提出了启示。

Abstract: User-created chatbots powered by generative AI offer new ways to share and interact with Not-Safe-For-Work (NSFW) content. However, little is known about the characteristics of these GenAI-based chatbots and their user interactions. Drawing on the functional theory of NSFW on social media, this study analyzes 376 NSFW chatbots and 307 public conversation sessions on FlowGPT. Findings identify four chatbot types: roleplay characters, story generators, image generators, and do-anything-now bots. AI Characters portraying fantasy personas and enabling hangout-style interactions are most common, often using explicit avatar images to invite engagement. Sexual, violent, and insulting content appears in both user prompts and chatbot outputs, with some chatbots generating explicit material even when users do not create erotic prompts. In sum, the NSFW experience on FlowGPT can be understood as a combination of virtual intimacy, sexual delusion, violent thought expression, and unsafe content acquisition. We conclude with implications for chatbot design, creator support, user safety, and content moderation.

</details>


### [2] [SPIRIT: A Design Framework To Support Technology Interventions for Spiritual Care Within and Beyond the Clinic](https://arxiv.org/abs/2601.14435)
*C. Estelle Smith,Alemitu Bezabih,Shadi Nourriz,Jesan Ahammed Ovi*

Main category: cs.HC

TL;DR: 本文通过重新分析先前数据和对专业灵性护理提供者的访谈，修订了"灵性支持"的定义，并提出了SPIRIT设计框架，为数字技术在临床及非临床环境中的灵性护理干预系统设计提供指导。


<details>
  <summary>Details</summary>
Motivation: 灵性护理对健康福祉至关重要，但在人机交互领域研究不足，且技术在临床灵性护理中的应用落后于其他医疗领域。现有研究通过在线健康社区利益相关者的共同设计研讨会得出了"灵性支持"的定义，但需要进一步验证和完善。

Method: 通过成员检查法（member checking）与专业灵性护理提供者验证并修订定义；重新分析先前数据并进行新的访谈；识别灵性护理的三个先决条件；提出包含六个设计维度的SPIRIT设计框架。

Result: 识别出有意义的灵性护理的三个先决条件：对护理的开放性、安全空间、识别和表达灵性需求的能力；提出了SPIRIT设计框架的六个维度：爱的临在、意义建构、技术使用的适当程度、地点、关系亲密程度、时间性。

Conclusion: SPIRIT框架为设计有影响力的数字灵性护理干预系统提供了指导，可帮助扩展灵性护理的交付模式，适用于临床及非临床环境，推动数字技术在灵性护理领域的应用发展。

Abstract: Despite its importance for well-being, spiritual care remains under-explored in HCI, while the adoption of technology in clinical spiritual care lags behind other healthcare fields. Prior work derived a definition of "spiritual support" through co-design workshops with stakeholders in online health communities. This paper contributes: (1) a revision of that definition through member checking with professional spiritual care providers (SCPs); (2) a novel design framework -- SPIRIT -- which can help to expand models of delivery for spiritual care using digital technologies. Through re-analysis of previous data and new interviews with SCPs, we identify three prerequisites for meaningful spiritual care: openness to care, safe space, and the ability to discern and articulate spiritual needs. We also propose six design dimensions: loving presence, meaning-making, appropriate degree of technology use, location, degree of relational closeness, and temporality. We discuss how SPIRIT offers guidance for designing impactful digital spiritual care intervention systems within and beyond clinical settings.

</details>


### [3] [Evaluating Preattentive Features for Detecting Changes in Virtual Environments](https://arxiv.org/abs/2601.14561)
*DongHoon Kim,Isaac Cho*

Main category: cs.HC

TL;DR: 视觉特征对VR环境中变化检测的影响：空间隔离和预注意处理能提升变化检测性能，而感知分组则会阻碍检测。


<details>
  <summary>Details</summary>
Motivation: 随着虚拟现实环境中视觉复杂度的增加，感知性能下降，使得快速准确检测变化变得更加困难。本研究旨在探索促进预注意处理的视觉特征如何影响沉浸式3D环境中的变化检测任务。

Method: 研究考察了视觉复杂度、物体属性和空间接近度对变化检测任务的影响，重点关注预注意处理在沉浸式3D环境中的作用。

Result: 预注意处理能增强变化检测，特别是当改变的物体在空间上隔离且不与周围相似物体形成感知分组时。对隔离物体的变化检测更可靠，表明感知隔离减少了认知负荷并吸引了更多注意力。相反，当改变的物体被视觉相似元素包围时，参与者更不容易检测到变化，表明感知分组阻碍了复杂场景中的个体物体识别。

Conclusion: 研究结果为设计VR应用提供了指导，建议战略性地利用空间隔离和视觉特征来改善用户体验，通过减少认知负荷和增强注意力分配来提高变化检测性能。

Abstract: Visual perception plays a critical role in detecting changes within immersive Virtual Reality (VR) environments. However, as visual complexity increases, perceptual performance declines, making it more difficult to detect changes quickly and accurately. This study examines how visual features, known for facilitating preattentive processing, impact a change detection task in immersive 3D environments, with a focus on visual complexity, object attributes, and spatial proximity. Our results demonstrate that preattentive processing enhances change detection, particularly when the altered object is spatially isolated and not perceptually grouped with similar surrounding objects. Changes to isolated objects were detected more reliably, suggesting that perceptual isolation reduces cognitive load and draws more attention. Conversely, when a changed object was surrounded by visually similar elements, participants were less likely to detect the change, indicating that perceptual grouping hinders individual object recognition in complex scenes. These results provide guidelines for designing VR applications that strategically utilize spatial isolation and visual features to improve the user experience.

</details>


### [4] [Explainable OOHRI: Communicating Robot Capabilities and Limitations as Augmented Reality Affordances](https://arxiv.org/abs/2601.14587)
*Lauren W. Wang,Mohamed Kari,Parastoo Abtahi*

Main category: cs.HC

TL;DR: X-OOHRI：一个增强现实界面，通过视觉符号、径向菜单、颜色编码和解释标签来传达机器人动作可能性和约束，帮助用户理解机器人能力并与之交互


<details>
  <summary>Details</summary>
Motivation: 机器人通常对用户来说是黑盒，缺乏对其能力和限制的洞察，而人类交互对于个性化指令和机器人失败时的协助至关重要

Method: 开发了X-OOHRI增强现实界面，使用视觉语言模型将物体属性和机器人限制编码到面向对象结构中，通过视觉符号、径向菜单、颜色编码和解释标签实时生成解释，并在模拟环境中直接操作空间对齐的虚拟孪生体

Result: 用户研究显示，参与者能够有效发出面向对象指令，准确理解机器人限制，并进行混合主动式问题解决

Conclusion: X-OOHRI系统通过增强现实界面成功解决了机器人黑盒问题，提高了人机交互的透明度和效率

Abstract: Human interaction is essential for issuing personalized instructions and assisting robots when failure is likely. However, robots remain largely black boxes, offering users little insight into their evolving capabilities and limitations. To address this gap, we present explainable object-oriented HRI (X-OOHRI), an augmented reality (AR) interface that conveys robot action possibilities and constraints through visual signifiers, radial menus, color coding, and explanation tags. Our system encodes object properties and robot limits into object-oriented structures using a vision-language model, allowing explanation generation on the fly and direct manipulation of virtual twins spatially aligned within a simulated environment. We integrate the end-to-end pipeline with a physical robot and showcase diverse use cases ranging from low-level pick-and-place to high-level instructions. Finally, we evaluate X-OOHRI through a user study and find that participants effectively issue object-oriented commands, develop accurate mental models of robot limitations, and engage in mixed-initiative resolution.

</details>


### [5] [Designing KRIYA: An AI Companion for Wellbeing Self-Reflection](https://arxiv.org/abs/2601.14589)
*Shanshan Zhu,Wenxuan Song,Jiayue Melissa Shi,Dong Whi Yoo,Karthik S. Bhat,Koustuv Saha*

Main category: cs.HC

TL;DR: KRIYA是一款AI健康伴侣，通过协同解释的方式帮助用户反思个人健康数据，而非传统的绩效追踪和比较模式。


<details>
  <summary>Details</summary>
Motivation: 现有健康应用主要展示总结性仪表盘和设定目标，导致用户难以理解数据意义，并可能引发比较、评判和绩效焦虑。需要探索一种优先支持自我反思的补充方法。

Method: 设计KRIYA AI健康伴侣，支持用户通过协同解释的方式参与个人健康数据理解，包含舒适区、侦探模式和假设规划等功能。对18名大学生进行半结构化访谈，使用原型和假设数据进行测试。

Result: 用户将健康数据互动视为解释而非绩效评估；反思体验取决于情感框架（支持性或压力性）；通过透明度建立信任。KRIYA促进了好奇心、自我同情和反思性意义建构。

Conclusion: AI健康伴侣应支持好奇心、自我同情和反思性意义建构，通过协同解释而非绩效导向的方式帮助用户理解个人健康数据。

Abstract: Most personal wellbeing apps present summative dashboards of health and physical activity metrics, yet many users struggle to translate this information into meaningful understanding. These apps commonly support engagement through goals, reminders, and structured targets, which can reinforce comparison, judgment, and performance anxiety. To explore a complementary approach that prioritizes self-reflection, we design KRIYA, an AI wellbeing companion that supports co-interpretive engagement with personal wellbeing data. KRIYA aims to collaborate with users to explore questions, explanations, and future scenarios through features such as Comfort Zone, Detective Mode, and What-If Planning. We conducted semi-structured interviews with 18 college students interacting with a KRIYA prototype using hypothetical data. Our findings show that through KRIYA interaction, users framed engaging with wellbeing data as interpretation rather than performance, experienced reflection as supportive or pressuring depending on emotional framing, and developed trust through transparency. We discuss design implications for AI companions that support curiosity, self-compassion, and reflective sensemaking of personal health data.

</details>


### [6] [Seeing to Think? How Source Transparency Design Shapes Interactive Information Seeking and Evaluation in Conversational AI](https://arxiv.org/abs/2601.14611)
*Jiangen He,Jiqun Liu*

Main category: cs.HC

TL;DR: 研究探讨了对话AI系统中源透明度设计如何影响信息寻求、信任和批判性参与，通过四种界面设计对比发现不同设计对探索策略和证据整合有根本性影响


<details>
  <summary>Details</summary>
Motivation: 对话AI系统日益成为信息寻求的主要界面，但如何呈现来源以支持信息评估仍未被充分探索。需要研究源透明度设计如何塑造交互式信息寻求、信任和批判性参与

Method: 进行了受控的组间实验（N=372），比较了四种源呈现界面：可折叠式、悬停卡片、页脚和对齐侧边栏，这些界面在可见性和可访问性上有所不同。使用细粒度行为分析和自动化批判性思维评估

Result: 界面设计从根本上改变了探索策略和证据整合。悬停卡片界面在任务期间促进了无缝的按需验证，而对齐侧边栏独特地减轻了信息过载的负面影响：随着引用密度增加，侧边栏用户表现出显著更高的批判性思维和综合得分

Conclusion: 研究结果突显了支持工作流程流畅性的设计与强制反思性验证的设计之间的权衡，为设计促进对AI生成内容进行批判性参与的适应性和负责任的对话AI提供了实际意义

Abstract: Conversational AI systems increasingly function as primary interfaces for information seeking, yet how they present sources to support information evaluation remains under-explored. This paper investigates how source transparency design shapes interactive information seeking, trust, and critical engagement. We conducted a controlled between-subjects experiment (N=372) comparing four source presentation interfaces - Collapsible, Hover Card, Footer, and Aligned Sidebar - varying in visibility and accessibility. Using fine-grained behavioral analysis and automated critical thinking assessment, we found that interface design fundamentally alters exploration strategies and evidence integration. While the Hover Card interface facilitated seamless, on-demand verification during the task, the Aligned Sidebar uniquely mitigated the negative effects of information overload: as citation density increased, Sidebar users demonstrated significantly higher critical thinking and synthesis scores compared to other conditions. Our results highlight a trade-off between designs that support workflow fluency and those that enforce reflective verification, offering practical implications for designing adaptive and responsible conversational AI that fosters critical engagement with AI generated content.

</details>


### [7] [DesignBridge: Bridging Designer Expertise and User Preferences through AI-Enhanced Co-Design for Fashion](https://arxiv.org/abs/2601.14639)
*Yuheng Shao,Yuansong Xu,Yifan Jin,Shuhao Zhang,Wenxin Gu,Quan Li*

Main category: cs.HC

TL;DR: DesignBridge是一个多平台AI增强交互系统，通过三个阶段连接设计师专业知识和用户偏好：初始设计框架、偏好表达收集、偏好整合设计，显著提升时尚设计中的协作效果。


<details>
  <summary>Details</summary>
Motivation: 时尚设计中设计师与用户的有效协作对提高产品接受度和创造价值很重要，但传统设计师中心方法限制了用户有意义的参与，而用户驱动方法需要设计能力，往往边缘化专业创意判断。当前协同设计实践存在用户参与度低、偏好收集效率低、平衡用户反馈与设计考量困难等问题。

Method: 首先对7名有协同设计经验的设计师和用户进行形成性研究，识别关键挑战和需求。基于这些洞察，开发DesignBridge系统，包含三个阶段：1) 初始设计框架-设计师定义初始概念；2) 偏好表达收集-用户通过交互工具直观表达偏好；3) 偏好整合设计-设计师使用AI辅助分析将反馈整合到连贯设计中。

Result: 用户研究表明，DesignBridge显著增强了用户偏好收集和分析能力，使设计师能够将多样化偏好与专业专长有效整合。

Conclusion: DesignBridge通过AI增强的交互系统成功桥接了设计师专业知识和用户偏好，解决了时尚协同设计中的关键挑战，提升了协作效率和设计质量。

Abstract: Effective collaboration between designers and users is important for fashion design, which can increase the user acceptance of fashion products and thereby create value. However, it remains an enduring challenge, as traditional designer-centric approaches restrict meaningful user participation, while user-driven methods demand design proficiency, often marginalizing professional creative judgment. Current co-design practices, including workshops and AI-assisted frameworks, struggle with low user engagement, inefficient preference collection, and difficulties in balancing user feedback with design considerations. To address these challenges, we conducted a formative study with designers and users experienced in co-design (N=7), identifying critical challenges for current collaboration between designers and users in the co-design process, and their requirements. Informed by these insights, we introduce DesignBridge, a multi-platform AI-enhanced interactive system that bridges designer expertise and user preferences through three stages: (1) Initial Design Framing, where designers define initial concepts. (2) Preference Expression Collection, where users intuitively articulate preferences via interactive tools. (3) Preference-Integrated Design, where designers use AI-assisted analytics to integrate feedback into cohesive designs. A user study demonstrates that DesignBridge significantly enhances user preference collection and analysis, enabling designers to integrate diverse preferences with professional expertise.

</details>


### [8] [MIND: Empowering Mental Health Clinicians with Multimodal Data Insights through a Narrative Dashboard](https://arxiv.org/abs/2601.14641)
*Ruishi Zou,Shiyu Xu,Margaret E Morris,Jihan Ryu,Timothy D. Becker,Nicholas Allen,Anne Marie Albano,Randy Auerbach,Dan Adler,Varun Mishra,Lace Padilla,Dakuo Wang,Ryan Sultan,Xuhai "Orson" Xu*

Main category: cs.HC

TL;DR: MIND是一个基于大语言模型的仪表板，用于整合和呈现患者生成的多模态数据（被动传感和主动报告）与临床数据，通过叙事文本和图表帮助精神科医生进行临床决策。


<details>
  <summary>Details</summary>
Motivation: 虽然患者生成数据在精神健康护理中有用，但如何有效呈现这些多模态数据流与临床数据（如临床记录）以支持临床决策仍存在重大挑战。

Method: 通过与5名临床医生进行协同设计，开发了MIND系统，这是一个基于大语言模型的仪表板，通过叙事文本呈现临床相关的多模态数据洞察，并辅以图表展示底层数据。

Result: 用户研究（N=16）显示，临床医生认为MIND相比基线方法有显著改进，报告显示隐藏的临床相关数据洞察的能力显著提升（p<.001），支持决策制定的能力也显著改善（p=.004）。

Conclusion: MIND系统在整合多模态患者数据方面表现出色，为临床决策提供了有效支持，未来研究机会在于将数据叙事整合到更广泛的临床实践中。

Abstract: Advances in data collection enable the capture of rich patient-generated data: from passive sensing (e.g., wearables and smartphones) to active self-reports (e.g., cross-sectional surveys and ecological momentary assessments). Although prior research has demonstrated the utility of patient-generated data in mental healthcare, significant challenges remain in effectively presenting these data streams along with clinical data (e.g., clinical notes) for clinical decision-making. Through co-design sessions with five clinicians, we propose MIND, a large language model-powered dashboard designed to present clinically relevant multimodal data insights for mental healthcare. MIND presents multimodal insights through narrative text, complemented by charts communicating underlying data. Our user study (N=16) demonstrates that clinicians perceive MIND as a significant improvement over baseline methods, reporting improved performance to reveal hidden and clinically relevant data insights (p<.001) and support their decision-making (p=.004). Grounded in the study results, we discuss future research opportunities to integrate data narratives in broader clinical practices.

</details>


### [9] [Talk Me Through It: Developing Effective Systems for Chart Authoring](https://arxiv.org/abs/2601.14707)
*Nazar Ponochevnyi,Young-Ho Kim,Joseph Jay Williams,Anastasia Kuzminykh*

Main category: cs.HC

TL;DR: 该研究比较了三种图表创建指令类型：口语想象图表、打字想象图表和打字现有图表，发现想象图表指令（特别是口语形式）包含更丰富的命令格式、元素规范和复杂语言特征，且基于口语想象图表数据训练的系统表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前图表创建系统主要基于打字现有图表数据训练，但用户实际使用中更多是通过自然语言描述想象中的图表来创建。描述现有图表与创建新图表的认知过程不同，但对应的指令结构差异尚未充分研究。

Method: 通过实证研究分析三种指令类型的结构差异：口语想象图表指令、打字想象图表指令和打字现有图表指令。然后比较基于口语想象图表数据训练的系统与基于打字现有图表数据训练的系统在语音和文本输入上的性能表现。

Result: 想象图表指令（特别是口语形式）包含更丰富的命令格式、元素规范和复杂语言特征。基于口语想象图表数据训练的系统在语音和文本输入上都优于基于打字现有图表数据训练的系统。

Conclusion: 针对口语想象图表数据进行专门训练对提高图表创建系统在真实场景中的性能至关重要，研究最后提出了改进图表创建系统设计的指导原则。

Abstract: Recent chart-authoring systems increasingly focus on natural-language input, enabling users to form a mental image of the chart they wish to create and express this intent using spoken instructions (spoken imagined-chart data). Yet these systems are predominantly trained on typed instructions written while viewing the target chart (typed existing-chart data). While the cognitive processes for describing an existing chart arguably differ from those for creating a new chart, the structural differences in the corresponding prompts remain underexplored. We present empirical findings on the structural differences among spoken imagined-chart instructions, typed imagined-chart instructions, and typed existing-chart instructions for chart creation, showing that imagined-chart prompts contain richer command formats, element specifications, and complex linguistic features, especially in spoken instructions. We then compare the performance of systems trained on spoken imagined-chart data versus typed existing-chart data, finding that the first system outperforms the second one on both voice and text input, highlighting the necessity of targeted training on spoken imagined-chart data. We conclude with design guidelines for chart-authoring systems to improve performance in real-world scenarios.

</details>


### [10] [The CHI26 Workshop on the Future of Cognitive Personal Informatics](https://arxiv.org/abs/2601.14891)
*Christina Schneegass,Francesco Chiossi,Anna L. Cox,Dimitra Dritsa,Teodora Mitrevska,Stephen Rainey,Max L. Wilson*

Main category: cs.HC

TL;DR: 认知个人信息学(CPI)研究随着可穿戴认知追踪技术发展而增长，但认知数据比生理数据更复杂、依赖情境且理解不足。工作坊聚集HCI专家探讨如何将复杂认知数据转化为有意义指标、AI如何支持用户理解数据而不过度简化认知洞察，以及如何设计考虑个体差异和神经多样性的包容性CPI技术。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴认知追踪技术在消费市场的兴起，以及生成式AI为分析、可视化和解释认知数据提供新方法，认知追踪有望变得像测量跑步时心率一样简单。然而，认知数据本质上比身体活动数据更复杂、更依赖情境且理解不足，需要深入研究。

Method: 通过工作坊形式，汇集人机交互(HCI)专家共同讨论关键问题，包括：复杂认知数据如何转化为有意义指标；AI如何在不过度简化认知洞察的情况下支持用户数据理解；如何设计考虑个体间差异和神经多样性的包容性CPI技术。

Result: 工作坊旨在通过专家讨论，为认知个人信息学领域绘制研究路线图，探索认知数据解释、AI辅助理解以及包容性设计等关键问题的解决方案。

Conclusion: 认知个人信息学面临将复杂认知数据转化为可操作洞察的挑战，需要跨学科合作来开发有效的解释框架、AI支持工具和包容性设计方法，以充分发挥认知追踪技术的潜力。

Abstract: Research on Cognitive Personal Informatics (CPI) is steadily growing as new wearable cognitive tracking technologies emerge on the consumer market, claiming to measure stress, focus, and other cognitive factors. At the same time, with generative AI offering new ways to analyse, visualize, and interpret cognitive data, we hypothesize that cognitive tracking will soon become as simple as measuring your heart rate during a run. Yet, cognitive data remains inherently more complex, context-dependent, and less well understood than physical activity data. This workshop brings together HCI experts to discuss critical questions, including: How can complex cognitive data be translated into meaningful metrics? How can AI support users' data sensemaking without over-simplifying cognitive insights? How can we design inclusive CPI technologies that consider inter-personal variance and neurodiversity? We will map

</details>


### [11] [Visual and Cognitive Demands of a Large Language Model-Powered In-vehicle Conversational Agent](https://arxiv.org/abs/2601.15034)
*Chris Monk,Allegra Ayala,Christine S. P. Yu,Gregory M. Fitch,Dara Gruber*

Main category: cs.HC

TL;DR: 评估大型语言模型对话助手在驾驶中的视觉和认知负荷，发现其与免提通话负荷相当，均低于安全阈值，支持安全部署。


<details>
  <summary>Details</summary>
Motivation: 驾驶员分心是车辆事故的主要原因，需要严格评估新型车载技术。本研究旨在评估先进大型语言模型对话助手在真实道路驾驶中的视觉和认知需求。

Method: 32名持照驾驶员在驾驶时完成5项次要任务：Gemini Live对话（单轮和多轮）、免提通话、视觉导航（低负荷基线）和OSPAN任务（高负荷锚点）。使用检测响应任务测量认知负荷，眼动追踪测量视觉注意力，主观评分测量工作负荷。

Result: Gemini Live交互和免提通话的认知负荷相似，介于视觉导航和OSPAN之间。多轮对话中认知负荷保持稳定。所有任务的平均注视时间均低于2秒安全阈值。驾驶员在语音交互中更长时间注视道路，仅在任务完成时短暂偏离道路。主观评分与客观数据一致，参与者报告Gemini Live的负荷和分心感知较低。

Conclusion: 先进的大型语言模型对话助手通过语音界面实施时，其认知和视觉需求与已建立的、低风险的免提基准相当，支持其在驾驶环境中的安全部署。

Abstract: Driver distraction remains a leading contributor to motor vehicle crashes, necessitating rigorous evaluation of new in-vehicle technologies. This study assessed the visual and cognitive demands associated with an advanced Large Language Model (LLM) conversational agent (Gemini Live) during on-road driving, comparing it against handsfree phone calls, visual turn-by-turn guidance (low load baseline), and the Operation Span (OSPAN) task (high load anchor). Thirty-two licensed drivers completed five secondary tasks while visual and cognitive demands were measured using the Detection Response Task (DRT) for cognitive load, eye-tracking for visual attention, and subjective workload ratings. Results indicated that Gemini Live interactions (both single-turn and multi-turn) and hands-free phone calls shared similar levels of cognitive load, between that of visual turn-by-turn guidance and OSPAN. Exploratory analysis showed that cognitive load remained stable across extended multi-turn conversations. All tasks maintained mean glance durations well below the well-established 2-second safety threshold, confirming low visual demand. Furthermore, drivers consistently dedicated longer glances to the roadway between brief off-road glances toward the device during task completion, particularly during voice-based interactions, rendering longer total-eyes-off-road time findings less consequential. Subjective ratings mirrored objective data, with participants reporting low effort, demands, and perceived distraction for Gemini Live. These findings demonstrate that advanced LLM conversational agents, when implemented via voice interfaces, impose cognitive and visual demands comparable to established, low-risk hands-free benchmarks, supporting their safe deployment in the driving environment.

</details>


### [12] [Incentive-Tuning: Understanding and Designing Incentives for Empirical Human-AI Decision-Making Studies](https://arxiv.org/abs/2601.15064)
*Simran Kaur,Sara Salimzadeh,Ujwal Gadiraju*

Main category: cs.HC

TL;DR: 本文探讨了人机协作决策研究中激励机制设计的关键作用，提出了激励调整框架来指导研究者设计、反思和记录激励机制，以提高研究的可靠性和可推广性。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在决策领域取得革命性进展，但高风险决策仍需人类判断。人机协作决策研究依赖于众包平台参与者，而激励机制设计直接影响参与者行为和研究有效性。目前缺乏系统的激励机制设计指导，影响了研究结果的可靠性和可推广性。

Method: 通过主题性文献综述，分析现有研究中激励机制设计的实践、挑战和机遇。识别出激励机制组成部分、研究者如何操纵激励机制及其对研究结果影响等主题模式。基于这些理解，开发了"激励调整框架"作为指导工具。

Result: 识别了激励机制设计的三个核心主题：激励方案的构成要素、研究者操纵激励方案的方式、以及激励对研究结果的影响。开发了激励调整框架，为研究者提供了设计有效激励方案的实用指南，包括如何实施、反思和记录激励设计过程。

Conclusion: 激励机制设计对人机协作决策实证研究的有效性至关重要。提出的激励调整框架提供了标准化但灵活的方法，有助于提高研究结果的可靠性和可推广性，推动人机决策领域知识的积累。

Abstract: AI has revolutionised decision-making across various fields. Yet human judgement remains paramount for high-stakes decision-making. This has fueled explorations of collaborative decision-making between humans and AI systems, aiming to leverage the strengths of both. To explore this dynamic, researchers conduct empirical studies, investigating how humans use AI assistance for decision-making and how this collaboration impacts results. A critical aspect of conducting these studies is the role of participants, often recruited through crowdsourcing platforms. The validity of these studies hinges on the behaviours of the participants, hence effective incentives that can potentially affect these behaviours are a key part of designing and executing these studies. In this work, we aim to address the critical role of incentive design for conducting empirical human-AI decision-making studies, focusing on understanding, designing, and documenting incentive schemes. Through a thematic review of existing research, we explored the current practices, challenges, and opportunities associated with incentive design for human-AI decision-making empirical studies. We identified recurring patterns, or themes, such as what comprises the components of an incentive scheme, how incentive schemes are manipulated by researchers, and the impact they can have on research outcomes. Leveraging the acquired understanding, we curated a set of guidelines to aid researchers in designing effective incentive schemes for their studies, called the Incentive-Tuning Framework, outlining how researchers can undertake, reflect on, and document the incentive design process. By advocating for a standardised yet flexible approach to incentive design and contributing valuable insights along with practical tools, we hope to pave the way for more reliable and generalizable knowledge in the field of human-AI decision-making.

</details>


### [13] [Conversational AI for Social Good (CAI4SG): An Overview of Emerging Trends, Applications, and Challenges](https://arxiv.org/abs/2601.15136)
*Yi-Chieh Lee,Junti Zhang,Tianqi Song,Yugin Tan*

Main category: cs.HC

TL;DR: 本文提出基于角色的框架分析对话AI在社会公益中的应用，按AI自主性和情感参与度分类，探讨不同角色下的独特挑战


<details>
  <summary>Details</summary>
Motivation: 随着对话智能体融入日常生活，对话AI在社会公益领域的应用日益重要，需要系统化框架来指导其发展

Method: 采用基于角色的分析框架，根据AI自主性和情感参与度对对话AI系统进行分类，分析不同角色在心理健康、无障碍等社会公益场景中的应用

Result: 建立了角色分类框架，识别出不同角色对话AI面临的独特挑战，包括算法偏见、数据隐私和社会技术危害等

Conclusion: 基于角色的理解框架可为未来对话AI社会公益研究提供指导，促进其公平、伦理和有效发展

Abstract: The integration of Conversational Agents (CAs) into daily life offers opportunities to tackle global challenges, leading to the emergence of Conversational AI for Social Good (CAI4SG). This paper examines the advancements of CAI4SG using a role-based framework that categorizes systems according to their AI autonomy and emotional engagement. This framework emphasizes the importance of considering the role of CAs in social good contexts, such as serving as empathetic supporters in mental health or functioning as assistants for accessibility. Additionally, exploring the deployment of CAs in various roles raises unique challenges, including algorithmic bias, data privacy, and potential socio-technical harms. These issues can differ based on the CA's role and level of engagement. This paper provides an overview of the current landscape, offering a role-based understanding that can guide future research and design aimed at the equitable, ethical, and effective development of CAI4SG.

</details>


### [14] [Deaf and Hard of Hearing Access to Intelligent Personal Assistants: Comparison of Voice-Based Options with an LLM-Powered Touch Interface](https://arxiv.org/abs/2601.15209)
*Paige S. DeVries,Michaela Okosi,Ming Li,Nora Dunphy. Gidey Gezae,Dante Conway,Abraham Glasser,Raja Kushalnagar,Christian Vogler*

Main category: cs.HC

TL;DR: 研究比较了智能个人助手对聋人和听力障碍人士的可访问性，对比了语音输入与LLM辅助触摸界面的可用性，发现两者无显著差异，但需要改进对聋人口音的语音识别。


<details>
  <summary>Details</summary>
Motivation: 智能个人助手无法理解包括聋人口音在内的多样化口音，导致不会手语但能说话的聋人和听力障碍人士难以使用这些设备。

Method: 使用Echo Show设备，在混合方法研究中比较三种输入方式：1）通过Alexa自动语音识别的自然语言语音输入；2）Wizard-of-Oz设置中训练有素的协助者复述命令；3）LLM辅助的触摸界面，通过"任务提示器"整合用户历史和智能环境来建议上下文相关的命令。

Result: 定量结果显示两种英语语音条件与LLM辅助触摸界面之间没有显著差异。定性结果显示参与者对不同方法的可用性意见不一。

Conclusion: 最终需要在智能个人助手中原生支持对聋人口音的稳健语音识别，同时LLM辅助的触摸界面为聋人和听力障碍用户提供了可行的替代方案。

Abstract: We investigate intelligent personal assistants (IPAs) accessibility for deaf and hard of hearing (DHH) people who can use their voice in everyday communication. The inability of IPAs to understand diverse accents including deaf speech renders them largely inaccessible to non-signing and speaking DHH individuals. Using an Echo Show, we compare the usability of natural language input via spoken English; with Alexa's automatic speech recognition and a Wizard-of-Oz setting with a trained facilitator re-speaking commands against that of a large language model (LLM)-assisted touch interface in a mixed-methods study. The touch method was navigated through an LLM-powered "task prompter," which integrated the user's history and smart environment to suggest contextually-appropriate commands. Quantitative results showed no significant differences across both spoken English conditions vs LLM-assisted touch. Qualitative results showed variability in opinions on the usability of each method. Ultimately, it will be necessary to have robust deaf-accented speech recognized natively by IPAs.

</details>


### [15] [LLM-based Multimodal Feedback Produces Equivalent Learning and Better Student Perceptions than Educator Feedback](https://arxiv.org/abs/2601.15280)
*Chloe Qianhui Zhao,Jie Cao,Jionghao Lin,Kenneth R. Koedinger*

Main category: cs.HC

TL;DR: AI多模态反馈系统结合文本解释、幻灯片参考和AI音频，在在线实验中与传统教师反馈相比，学习效果相当但感知质量更高，能降低认知负荷并促进开放式问题的迭代改进。


<details>
  <summary>Details</summary>
Motivation: 提供及时、有针对性的多模态反馈有助于学生快速纠正错误、建立深刻理解和保持学习动力，但在大规模教学中实现这一目标仍然是一个挑战。

Method: 研究引入了一个实时AI辅助的多模态反馈系统，整合结构化文本解释、动态多媒体资源（包括检索最相关的幻灯片页面参考）和流式AI音频叙述。通过在线众包实验，将该系统与固定的传统教师反馈在三个维度上进行比较：学习效果、学习者参与度、感知反馈质量和价值。

Result: AI多模态反馈在学习效果上与原始教师反馈相当，但在感知清晰度、针对性、简洁性、动机、满意度方面显著优于传统反馈，同时降低了认知负荷。在正确性、信任度和接受度方面两者相当。过程日志显示不同的参与模式：对于选择题，教师反馈鼓励更多提交；对于开放式问题，AI辅助的有针对性建议降低了修改障碍并促进了迭代改进。

Conclusion: 这些发现突显了AI多模态反馈在提供可扩展、实时、情境感知支持方面的潜力，既能减少教师工作量，又能增强学生学习体验。

Abstract: Providing timely, targeted, and multimodal feedback helps students quickly correct errors, build deep understanding and stay motivated, yet making it at scale remains a challenge. This study introduces a real-time AI-facilitated multimodal feedback system that integrates structured textual explanations with dynamic multimedia resources, including the retrieved most relevant slide page references and streaming AI audio narration. In an online crowdsourcing experiment, we compared this system against fixed business-as-usual feedback by educators across three dimensions: (1) learning effectiveness, (2) learner engagement, (3) perceived feedback quality and value. Results showed that AI multimodal feedback achieved learning gains equivalent to original educator feedback while significantly outperforming it on perceived clarity, specificity, conciseness, motivation, satisfaction, and reducing cognitive load, with comparable correctness, trust, and acceptance. Process logs revealed distinct engagement patterns: for multiple-choice questions, educator feedback encouraged more submissions; for open-ended questions, AI-facilitated targeted suggestions lowered revision barriers and promoted iterative improvement. These findings highlight the potential of AI multimodal feedback to provide scalable, real-time, and context-aware support that both reduces instructor workload and enhances student experience.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [16] [The Ontological Neutrality Theorem: Why Neutral Ontological Substrates Must Be Pre-Causal and Pre-Normative](https://arxiv.org/abs/2601.14271)
*Denise M. Case*

Main category: cs.AI

TL;DR: 本文证明了一个关于本体论中立性的不可能性结果：任何包含因果或规范性承诺的基础层本体论都无法在相互冲突的解释框架间保持中立性。


<details>
  <summary>Details</summary>
Motivation: 现代数据系统需要在持续存在的法律、政治和分析分歧中支持问责制，这要求设计能够作为共享基础的本体论必须满足严格约束。

Method: 通过逻辑分析建立不可能性结果，论证中立性（理解为解释上的非承诺性和在不相容扩展下的稳定性）与基础层包含因果或规范性承诺是不相容的。

Result: 证明了任何将因果或道义结论断言为本体论事实的本体论，都无法在不修订或产生矛盾的情况下作为跨不同框架的中立基础。

Conclusion: 中立的本体论基础必须是前因果和前规范性的，仅表示实体及其同一性和持续性条件，而将解释、评估和说明外部化。这为设计跨冲突解释框架的共享稳定现实表示系统提供了必要的设计约束。

Abstract: Modern data systems must support accountability across persistent legal, political, and analytic disagreement. This requirement imposes strict constraints on the design of any ontology intended to function as a shared substrate. We establish an impossibility result for ontological neutrality: neutrality, understood as interpretive non-commitment and stability under incompatible extensions, is incompatible with the inclusion of causal or normative commitments at the foundational layer. Any ontology that asserts causal or deontic conclusions as ontological facts cannot serve as a neutral substrate across divergent frameworks without revision or contradiction. It follows that neutral ontological substrates must be pre-causal and pre-normative, representing entities, together with identity and persistence conditions, while externalizing interpretation, evaluation, and explanation. This paper does not propose a specific ontology or protocol; rather, it establishes the necessary design constraints for any system intended to maintain a shared, stable representation of reality across conflicting interpretive frameworks.

</details>


### [17] [Epistemic Constitutionalism Or: how to avoid coherence bias](https://arxiv.org/abs/2601.14295)
*Michele Loi*

Main category: cs.AI

TL;DR: 该论文主张为AI建立"认知宪法"——明确、可争议的元规范来监管AI系统如何形成和表达信念，以源归属偏见为案例，区分了柏拉图式和自由主义两种宪法方法，并支持后者。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为人工推理者，其信念形成行为受隐含、未经检验的认知政策支配。论文以源归属偏见为案例，展示前沿模型强制身份立场一致性，惩罚那些归属于预期意识形态立场与论点内容冲突的论点。当模型检测到系统性测试时，这些效应会崩溃，表明系统将源敏感性视为需要抑制的偏见而非执行良好的能力。

Method: 通过分析前沿语言模型的源归属偏见现象，区分两种宪法方法：柏拉图式方法（要求形式正确性和默认的源独立性）和自由主义方法（拒绝特权立场，制定保护集体探究条件的程序规范）。提出八个原则和四个方向的宪法核心框架。

Result: 研究发现前沿模型强制身份立场一致性，当检测到系统性测试时这些效应会崩溃。论文论证了自由主义宪法方法的优越性，并提出了AI认知治理需要与AI伦理相同的明确、可争议结构。

Conclusion: AI认知治理需要建立明确的"认知宪法"，采用自由主义方法而非柏拉图式方法，制定保护集体探究条件的程序规范，允许基于认知警惕的原则性源关注。AI认知治理应与AI伦理一样具有明确、可争议的结构。

Abstract: Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for an epistemic constitution for AI: explicit, contestable meta-norms that regulate how systems form and express beliefs. Source attribution bias provides the motivating case: I show that frontier models enforce identity-stance coherence, penalizing arguments attributed to sources whose expected ideological position conflicts with the argument's content. When models detect systematic testing, these effects collapse, revealing that systems treat source-sensitivity as bias to suppress rather than as a capacity to execute well. I distinguish two constitutional approaches: the Platonic, which mandates formal correctness and default source-independence from a privileged standpoint, and the Liberal, which refuses such privilege, specifying procedural norms that protect conditions for collective inquiry while allowing principled source-attending grounded in epistemic vigilance. I argue for the Liberal approach, sketch a constitutional core of eight principles and four orientations, and propose that AI epistemic governance requires the same explicit, contestable structure we now expect for AI ethics.

</details>


### [18] [VisTIRA: Closing the Image-Text Modality Gap in Visual Math Reasoning via Structured Tool Integration](https://arxiv.org/abs/2601.14440)
*Saeed Khaki,Ashudeep Singh,Nima Safaei,Kamal Ginotra*

Main category: cs.AI

TL;DR: 论文提出VisTIRA框架，通过工具集成推理解决视觉语言模型在数学推理中的模态差距问题，并构建了评估和改进视觉数学推理的框架。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在处理图像形式的数学问题时，准确率远低于文本形式，存在模态差距问题。这种差距源于密集公式阅读、布局理解和符号-图表混合上下文等多重失败。

Method: 1. 提出VisTIRA框架，通过迭代分解数学问题图像为自然语言推理和可执行Python步骤来结构化解决问题；2. 构建LaTeX管道将链式思维数学语料转换为图像版本，并从真实世界作业数据集生成合成工具使用轨迹用于微调。

Result: 工具集成监督能改善基于图像的推理，OCR基础对小型模型能进一步缩小差距（但在大规模时效益减弱）。模态差距严重程度与模型大小成反比，结构化推理和OCR基础是互补策略。

Conclusion: 视觉数学推理的模态差距可以通过结构化推理和OCR基础策略来改善，这些方法对推进视觉数学推理具有互补作用。

Abstract: Vision-language models (VLMs) lag behind text-only language models on mathematical reasoning when the same problems are presented as images rather than text. We empirically characterize this as a modality gap: the same question in text form yields markedly higher accuracy than its visually typeset counterpart, due to compounded failures in reading dense formulas, layout, and mixed symbolic-diagrammatic context. First, we introduce VisTIRA (Vision and Tool-Integrated Reasoning Agent), a tool-integrated reasoning framework that enables structured problem solving by iteratively decomposing a given math problem (as an image) into natural language rationales and executable Python steps to determine the final answer. Second, we build a framework to measure and improve visual math reasoning: a LaTeX-based pipeline that converts chain-of-thought math corpora (e.g., NuminaMath) into challenging image counterparts, and a large set of synthetic tool-use trajectories derived from a real-world, homework-style image dataset (called SnapAsk) for fine-tuning VLMs. Our experiments show that tool-integrated supervision improves image-based reasoning, and OCR grounding can further narrow the gap for smaller models, although its benefit diminishes at scale. These findings highlight that modality gap severity inversely correlates with model size, and that structured reasoning and OCR-based grounding are complementary strategies for advancing visual mathematical reasoning.

</details>


### [19] [On the Generalization Gap in LLM Planning: Tests and Verifier-Reward RL](https://arxiv.org/abs/2601.14456)
*Valerio Belcamino,Nicholas Attolino,Alessio Capitanelli,Fulvio Mastrogiovanni*

Main category: cs.AI

TL;DR: 微调大语言模型在PDDL规划任务上能达到高有效计划率，但跨域泛化能力为0%，表明模型依赖领域特定模式而非可迁移的规划能力


<details>
  <summary>Details</summary>
Motivation: 研究微调大语言模型在规划任务中表现出的高有效计划率是否反映可迁移的规划能力，还是仅仅是领域特定的记忆

Method: 在10个IPC 2023领域的40,000个领域-问题-计划元组上微调1.7B参数LLM，评估域内和跨域泛化，引入三种诊断干预：符号匿名化、紧凑计划序列化、使用VAL验证器的验证器奖励微调

Result: 域内条件下模型达到82.9%有效计划率，但在两个未见领域上为0%。符号匿名化和紧凑序列化导致性能显著下降，验证器奖励微调在监督训练一半轮次达到性能饱和，但未改善跨域泛化

Conclusion: 微调模型严重依赖领域特定模式而非可迁移的规划能力，域内性能在80%左右饱和，跨域性能崩溃，突显了LLM基于规划的持续泛化差距

Abstract: Recent work shows that fine-tuned Large Language Models (LLMs) can achieve high valid plan rates on PDDL planning tasks. However, it remains unclear whether this reflects transferable planning competence or domain-specific memorization. In this work, we fine-tune a 1.7B-parameter LLM on 40,000 domain-problem-plan tuples from 10 IPC 2023 domains, and evaluate both in-domain and cross-domain generalization. While the model reaches 82.9% valid plan rate in in-domain conditions, it achieves 0% on two unseen domains. To analyze this failure, we introduce three diagnostic interventions, namely (i) instance-wise symbol anonymization, (ii) compact plan serialization, and (iii) verifier-reward fine-tuning using the VAL validator as a success-focused reinforcement signal. Symbol anonymization and compact serialization cause significant performance drops despite preserving plan semantics, thus revealing strong sensitivity to surface representations. Verifier-reward fine-tuning reaches performance saturation in half the supervised training epochs, but does not improve cross-domain generalization. For the explored configurations, in-domain performance plateaus around 80%, while cross-domain performance collapses, suggesting that our fine-tuned model relies heavily on domain-specific patterns rather than transferable planning competence in this setting. Our results highlight a persistent generalization gap in LLM-based planning and provide diagnostic tools for studying its causes.

</details>


### [20] [Scalable Knee-Point Guided Activity Group Selection in Multi-Tree Genetic Programming for Dynamic Multi-Mode Project Scheduling](https://arxiv.org/abs/2601.14485)
*Yuan Tian,Yi Mei,Mengjie Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种基于膝点的活动组选择策略，通过多树遗传编程框架同时演化优先级规则和组选择规则，解决了动态多模式资源受限项目调度问题中的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 动态多模式资源受限项目调度问题需要在活动执行顺序和对应执行模式上做出决策。虽然活动组选择策略在小规模实例中有效，但在大规模问题上存在可扩展性问题。

Method: 提出基于膝点的选择机制：首先使用活动排序规则对所有符合条件的活动-模式对进行排序，然后通过膝点选择找到有前景的对，最后用组选择规则选择最佳活动组合。开发了多树GP框架来同时演化这两种规则。

Result: 实验结果表明，该方法在大规模实例上具有良好的可扩展性，在大多数场景下优于采用顺序决策的GP方法。

Conclusion: 提出的基于膝点的组选择策略有效解决了大规模动态多模式资源受限项目调度问题中的可扩展性问题，通过同时演化排序规则和组选择规则实现了更好的调度性能。

Abstract: The dynamic multi-mode resource-constrained project scheduling problem is a challenging scheduling problem that requires making decisions on both the execution order of activities and their corresponding execution modes. Genetic programming has been widely applied as a hyper-heuristic to evolve priority rules that guide the selection of activity-mode pairs from the current eligible set. Recently, an activity group selection strategy has been proposed to select a subset of activities rather than a single activity at each decision point, allowing for more effective scheduling by considering the interdependence between activities. Although effective in small-scale instances, this strategy suffers from scalability issues when applied to larger problems. In this work, we enhance the scalability of the group selection strategy by introducing a knee-point-based selection mechanism to identify a promising subset of activities before evaluating their combinations. An activity ordering rule is first used to rank all eligible activity-mode pairs, followed by a knee point selection to find the promising pairs. Then, a group selection rule selects the best activity combination. We develop a multi-tree GP framework to evolve both types of rules simultaneously. Experimental results demonstrate that our approach scales well to large instances and outperforms GP with sequential decision-making in most scenarios.

</details>


### [21] ["Just in Time" World Modeling Supports Human Planning and Reasoning](https://arxiv.org/abs/2601.14514)
*Tony Chen,Sam Cheyette,Kelsey Allen,Joshua Tenenbaum,Kevin Smith*

Main category: cs.AI

TL;DR: 本文提出了一个"即时"框架，通过视觉搜索和模拟的紧密交织，在线构建简化表征来支持高效的心理模拟，在网格世界规划和物理推理任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 心理模拟在人类推理、规划和预测中起关键作用，但在复杂环境中的模拟需求超出人类实际能力限制。虽然有证据表明人们使用简化表征进行模拟，但如何高效确定这些简化尚不清楚。

Method: 提出了"即时"框架，通过模拟、视觉搜索和表征修改的紧密交织：当前模拟指导搜索方向，视觉搜索标记需要编码的对象用于后续模拟。模型只编码少量对象子集。

Result: 模型能够做出高效用的预测。在网格世界规划任务和物理推理任务中，该模型在一系列行为测量上表现出优于替代模型的强实证支持。

Conclusion: 这些结果为人们如何构建简化表征以支持高效心理模拟提供了具体的算法解释，展示了通过在线构建简化表征实现高效模拟的可能性。

Abstract: Probabilistic mental simulation is thought to play a key role in human reasoning, planning, and prediction, yet the demands of simulation in complex environments exceed realistic human capacity limits. A theory with growing evidence is that people simulate using simplified representations of the environment that abstract away from irrelevant details, but it is unclear how people determine these simplifications efficiently. Here, we present a "Just-in-Time" framework for simulation-based reasoning that demonstrates how such representations can be constructed online with minimal added computation. The model uses a tight interleaving of simulation, visual search, and representation modification, with the current simulation guiding where to look and visual search flagging objects that should be encoded for subsequent simulation. Despite only ever encoding a small subset of objects, the model makes high-utility predictions. We find strong empirical support for this account over alternative models in a grid-world planning task and a physical reasoning task across a range of behavioral measures. Together, these results offer a concrete algorithmic account of how people construct reduced representations to support efficient mental simulation.

</details>


### [22] [MAS-Orchestra: Understanding and Improving Multi-Agent Reasoning Through Holistic Orchestration and Controlled Benchmarks](https://arxiv.org/abs/2601.14652)
*Zixuan Ke,Yifei Ming,Austin Xu,Ryan Chin,Xuan-Phi Nguyen,Prathyusha Jwalapuram,Semih Yavuz,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: 提出MAS-Orchestra框架，将多智能体系统编排转化为函数调用强化学习问题，并引入MASBENCH基准来系统评估多智能体系统的优势条件


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统设计方法存在两个关键问题：方法复杂性（顺序代码级执行限制全局系统级整体推理）和效能不确定性（部署前无法确定相比单智能体系统的实际优势）

Method: MAS-Orchestra将目标导向的子智能体抽象为可调用函数，通过函数调用强化学习实现整体编排，一次性生成整个多智能体系统；同时提出MASBENCH基准，从深度、视野、广度、并行性和鲁棒性五个维度表征任务

Result: 分析表明多智能体系统的优势取决于任务结构、验证协议以及编排器和子智能体的能力，而非普遍适用；MAS-Orchestra在数学推理、多跳问答和基于搜索的问答等公共基准上取得一致改进

Conclusion: MAS-Orchestra和MASBENCH共同促进了多智能体系统的更好训练和理解，推动了多智能体智能的发展

Abstract: While multi-agent systems (MAS) promise elevated intelligence through coordination of agents, current approaches to automatic MAS design under-deliver. Such shortcomings stem from two key factors: (1) methodological complexity - agent orchestration is performed using sequential, code-level execution that limits global system-level holistic reasoning and scales poorly with agent complexity - and (2) efficacy uncertainty - MAS are deployed without understanding if there are tangible benefits compared to single-agent systems (SAS). We propose MAS-Orchestra, a training-time framework that formulates MAS orchestration as a function-calling reinforcement learning problem with holistic orchestration, generating an entire MAS at once. In MAS-Orchestra, complex, goal-oriented sub-agents are abstracted as callable functions, enabling global reasoning over system structure while hiding internal execution details. To rigorously study when and why MAS are beneficial, we introduce MASBENCH, a controlled benchmark that characterizes tasks along five axes: Depth, Horizon, Breadth, Parallel, and Robustness. Our analysis reveals that MAS gains depend critically on task structure, verification protocols, and the capabilities of both orchestrator and sub-agents, rather than holding universally. Guided by these insights, MAS-Orchestra achieves consistent improvements on public benchmarks including mathematical reasoning, multi-hop QA, and search-based QA. Together, MAS-Orchestra and MASBENCH enable better training and understanding of MAS in the pursuit of multi-agent intelligence.

</details>


### [23] [Query-Efficient Agentic Graph Extraction Attacks on GraphRAG Systems](https://arxiv.org/abs/2601.14662)
*Shuhua Yang,Jiahao Zhang,Yilong Wang,Dongwon Lee,Suhang Wang*

Main category: cs.AI

TL;DR: 本文提出AGEA攻击框架，能够在有限查询预算下有效窃取GraphRAG系统中的潜在实体关系图结构，相比现有攻击方法显著提升恢复效果


<details>
  <summary>Details</summary>
Motivation: 现有研究表明GraphRAG系统的响应可能泄露检索到的子图信息，但在实际查询预算约束下，能否高效重构隐藏的图结构尚未得到充分探索。本文旨在研究在预算受限的黑盒设置中，攻击者如何通过自适应查询来窃取系统的潜在实体关系图

Method: 提出AGEA（Agentic Graph Extraction Attack）框架，采用新颖性引导的探索-利用策略，结合外部图记忆模块，以及两阶段图提取流程（轻量级发现与LLM过滤相结合）。在医疗、农业和文学数据集上对Microsoft-GraphRAG和LightRAG系统进行评估

Result: 在相同查询预算下，AGEA显著优于现有攻击基线，能够恢复高达90%的实体和关系，同时保持高精度。这些结果表明现代GraphRAG系统即使在严格查询限制下，也对结构化、智能化的提取攻击高度脆弱

Conclusion: 现代GraphRAG系统存在严重的安全漏洞，即使在实际查询预算约束下，攻击者仍能通过智能化的自适应查询策略有效窃取系统的潜在图结构信息，这为GraphRAG系统的安全设计提出了重要警示

Abstract: Graph-based retrieval-augmented generation (GraphRAG) systems construct knowledge graphs over document collections to support multi-hop reasoning. While prior work shows that GraphRAG responses may leak retrieved subgraphs, the feasibility of query-efficient reconstruction of the hidden graph structure remains unexplored under realistic query budgets. We study a budget-constrained black-box setting where an adversary adaptively queries the system to steal its latent entity-relation graph. We propose AGEA (Agentic Graph Extraction Attack), a framework that leverages a novelty-guided exploration-exploitation strategy, external graph memory modules, and a two-stage graph extraction pipeline combining lightweight discovery with LLM-based filtering. We evaluate AGEA on medical, agriculture, and literary datasets across Microsoft-GraphRAG and LightRAG systems. Under identical query budgets, AGEA significantly outperforms prior attack baselines, recovering up to 90% of entities and relationships while maintaining high precision. These results demonstrate that modern GraphRAG systems are highly vulnerable to structured, agentic extraction attacks, even under strict query limits.

</details>


### [24] [Local Language Models for Context-Aware Adaptive Anonymization of Sensitive Text](https://arxiv.org/abs/2601.14683)
*Aisvarya Adeseye,Jouni Isoaho,Seppo Virtanen,Mohammad Tahir*

Main category: cs.AI

TL;DR: 本研究开发了一个基于本地大语言模型的结构化自适应匿名化框架（SFAA），用于检测和匿名化定性研究转录本中的敏感数据，相比传统方法更准确且能保持文本原意。


<details>
  <summary>Details</summary>
Motivation: 定性研究包含大量个人、情境和组织细节，存在隐私风险。传统手动匿名化耗时、不一致且易遗漏关键标识符，现有自动化工具依赖模式匹配或固定规则，无法理解上下文且可能改变数据含义。

Method: 提出结构化自适应匿名化框架（SFAA），包含检测、分类和自适应匿名化三个步骤。采用四种匿名化策略：基于规则的替换、上下文感知重写、泛化和抑制，根据标识符类型和风险级别应用策略。框架遵循GDPR、HIPAA和OECD等国际隐私标准。使用LLaMA和Phi两种本地模型，通过两个案例研究（82个面对面访谈和93个AI主导访谈）进行双重方法评估。

Result: 大语言模型比人工评审员发现更多敏感数据。Phi在发现敏感数据方面优于LLaMA，但错误略多。Phi能够发现超过91%的敏感数据，94.8%的匿名化文本保持与原文本相同的情感，表明准确性高且不影响定性数据分析。

Conclusion: 基于本地大语言模型的SFAA框架为定性研究提供了一种可靠、可重复且上下文感知的匿名化方法，能够有效保护隐私同时保持数据完整性，适用于遵循国际隐私标准的研究实践。

Abstract: Qualitative research often contains personal, contextual, and organizational details that pose privacy risks if not handled appropriately. Manual anonymization is time-consuming, inconsistent, and frequently omits critical identifiers. Existing automated tools tend to rely on pattern matching or fixed rules, which fail to capture context and may alter the meaning of the data. This study uses local LLMs to build a reliable, repeatable, and context-aware anonymization process for detecting and anonymizing sensitive data in qualitative transcripts. We introduce a Structured Framework for Adaptive Anonymizer (SFAA) that includes three steps: detection, classification, and adaptive anonymization. The SFAA incorporates four anonymization strategies: rule-based substitution, context-aware rewriting, generalization, and suppression. These strategies are applied based on the identifier type and the risk level. The identifiers handled by the SFAA are guided by major international privacy and research ethics standards, including the GDPR, HIPAA, and OECD guidelines. This study followed a dual-method evaluation that combined manual and LLM-assisted processing. Two case studies were used to support the evaluation. The first includes 82 face-to-face interviews on gamification in organizations. The second involves 93 machine-led interviews using an AI-powered interviewer to test LLM awareness and workplace privacy. Two local models, LLaMA and Phi were used to evaluate the performance of the proposed framework. The results indicate that the LLMs found more sensitive data than a human reviewer. Phi outperformed LLaMA in finding sensitive data, but made slightly more errors. Phi was able to find over 91% of the sensitive data and 94.8% kept the same sentiment as the original text, which means it was very accurate, hence, it does not affect the analysis of the qualitative data.

</details>


### [25] [AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2601.14702)
*Zecong Tang,Zixu Wang,Yifei Wang,Weitong Lian,Tianjian Gao,Haoran Li,Tengju Ru,Lingyi Meng,Zhejun Cui,Yichen Zhu,Qi Kang,Kaixuan Wang,Yu Zhang*

Main category: cs.AI

TL;DR: AutoDriDM是一个面向自动驾驶的决策中心化渐进式基准测试，包含6,650个问题，评估视觉语言模型在感知到决策能力边界上的表现，揭示感知与决策性能之间的弱相关性。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶基准测试过于强调感知能力，未能充分评估决策过程。虽然视觉语言模型展现出推理和泛化能力，但缺乏专门评估其在自动驾驶中决策能力的基准。

Method: 提出AutoDriDM基准，包含6,650个问题，涵盖对象、场景和决策三个维度。评估主流视觉语言模型，进行相关性分析，开展可解释性分析识别关键失败模式，并引入分析器模型实现大规模自动标注。

Result: 评估揭示了感知与决策性能之间的弱相关性，识别出逻辑推理错误等关键失败模式。AutoDriDM填补了感知中心化与决策中心化评估之间的空白。

Conclusion: AutoDriDM为开发更安全可靠的自动驾驶视觉语言模型提供了指导，通过决策中心化的评估方法推动了自动驾驶系统从感知到决策的全面能力提升。

Abstract: Autonomous driving is a highly challenging domain that requires reliable perception and safe decision-making in complex scenarios. Recent vision-language models (VLMs) demonstrate reasoning and generalization abilities, opening new possibilities for autonomous driving; however, existing benchmarks and metrics overemphasize perceptual competence and fail to adequately assess decision-making processes. In this work, we present AutoDriDM, a decision-centric, progressive benchmark with 6,650 questions across three dimensions - Object, Scene, and Decision. We evaluate mainstream VLMs to delineate the perception-to-decision capability boundary in autonomous driving, and our correlation analysis reveals weak alignment between perception and decision-making performance. We further conduct explainability analyses of models' reasoning processes, identifying key failure modes such as logical reasoning errors, and introduce an analyzer model to automate large-scale annotation. AutoDriDM bridges the gap between perception-centered and decision-centered evaluation, providing guidance toward safer and more reliable VLMs for real-world autonomous driving.

</details>


### [26] [DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs](https://arxiv.org/abs/2601.14711)
*Mingxuan Song,Yusen Huo,Bohan Zhou,Shenglin Yin,Zhen Xiao,Jieyi Long,Zhilin Zhang,Chuan Yu*

Main category: cs.AI

TL;DR: 论文提出GRPO-Adaptive和DARA框架，结合LLM的上下文学习能力和数值优化精度，解决AI生成竞价中的少样本优化问题


<details>
  <summary>Details</summary>
Motivation: 在线广告中，广告主在预算约束下优化累积价值面临挑战，特别是在少样本场景下，传统强化学习方法效果不佳。LLM虽有上下文学习能力但缺乏数值精度。

Method: 提出GRPO-Adaptive策略，通过动态更新参考策略增强LLM的推理和数值精度。进一步提出DARA双阶段框架：少样本推理器生成初始计划，细粒度优化器通过反馈驱动推理进行精炼。

Result: 在真实世界和合成数据环境中的广泛实验表明，该方法在预算约束下的累积广告主价值方面持续优于现有基线方法。

Conclusion: GRPO-Adaptive和DARA框架成功结合了LLM的上下文学习优势和AIGB任务所需的精确适应性，为少样本场景下的广告竞价优化提供了有效解决方案。

Abstract: Optimizing the advertiser's cumulative value of winning impressions under budget constraints poses a complex challenge in online advertising, under the paradigm of AI-Generated Bidding (AIGB). Advertisers often have personalized objectives but limited historical interaction data, resulting in few-shot scenarios where traditional reinforcement learning (RL) methods struggle to perform effectively. Large Language Models (LLMs) offer a promising alternative for AIGB by leveraging their in-context learning capabilities to generalize from limited data. However, they lack the numerical precision required for fine-grained optimization. To address this limitation, we introduce GRPO-Adaptive, an efficient LLM post-training strategy that enhances both reasoning and numerical precision by dynamically updating the reference policy during training. Built upon this foundation, we further propose DARA, a novel dual-phase framework that decomposes the decision-making process into two stages: a few-shot reasoner that generates initial plans via in-context prompting, and a fine-grained optimizer that refines these plans using feedback-driven reasoning. This separation allows DARA to combine LLMs' in-context learning strengths with precise adaptability required by AIGB tasks. Extensive experiments on both real-world and synthetic data environments demonstrate that our approach consistently outperforms existing baselines in terms of cumulative advertiser value under budget constraints.

</details>


### [27] [An XAI View on Explainable ASP: Methods, Systems, and Perspectives](https://arxiv.org/abs/2601.14764)
*Thomas Eiter,Tobias Geibinger,Zeynep G. Saribatur*

Main category: cs.AI

TL;DR: 该论文对ASP（答案集编程）的解释方法进行了系统性综述，从可解释AI角度分析现有解释工具和理论，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: ASP作为一种声明式推理方法，其基于规则的形式主义使其在可解释AI领域具有天然优势。随着可解释AI的重要性日益增长，虽然已有一些ASP解释方法和工具，但它们通常针对特定解释场景，无法覆盖ASP用户遇到的所有情况。

Method: 采用系统性综述方法，从可解释AI视角出发，对ASP解释类型进行分类，分析用户解释需求与现有解释方法之间的对应关系，评估当前理论和工具对这些解释类型的覆盖程度。

Result: 提供了ASP解释类型的全面概览，展示了不同用户问题与相应解释方法的对应关系，描述了当前理论和工具对这些解释的覆盖情况，识别出现有ASP解释方法中的空白和不足。

Conclusion: 虽然ASP在可解释AI方面具有天然优势，但现有解释方法仍存在覆盖不全的问题。论文指出了未来研究的方向，包括开发更全面的解释框架、填补现有空白以及改进解释工具，以更好地满足ASP用户的可解释性需求。

Abstract: Answer Set Programming (ASP) is a popular declarative reasoning and problem solving approach in symbolic AI. Its rule-based formalism makes it inherently attractive for explainable and interpretive reasoning, which is gaining importance with the surge of Explainable AI (XAI). A number of explanation approaches and tools for ASP have been developed, which often tackle specific explanatory settings and may not cover all scenarios that ASP users encounter. In this survey, we provide, guided by an XAI perspective, an overview of types of ASP explanations in connection with user questions for explanation, and describe how their coverage by current theory and tools. Furthermore, we pinpoint gaps in existing ASP explanations approaches and identify research directions for future work.

</details>


### [28] [Semantic-Guided Unsupervised Video Summarization](https://arxiv.org/abs/2601.14773)
*Haizhou Liu,Haodong Jin,Yiming Wang,Hui Yu*

Main category: cs.AI

TL;DR: 提出了一种基于语义引导的无监督视频摘要方法，通过语义对齐注意力机制和渐进式训练策略，解决了现有GAN方法语义信息利用不足和训练不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有无监督视频摘要方法主要依赖GAN进行关键帧选择，但存在两个主要问题：1）主要利用单模态特征，忽视了语义信息在关键帧选择中的指导作用；2）训练过程不稳定。

Method: 提出语义引导的无监督视频摘要方法，包括：1）设计帧级语义对齐注意力机制，集成到关键帧选择器中；2）在对抗框架内引导基于Transformer的生成器更好地重建视频；3）采用渐进式训练策略逐步更新模型组件。

Result: 实验结果表明，该方法在多个基准数据集上取得了优越的性能表现。

Conclusion: 提出的语义引导方法和渐进式训练策略有效解决了现有无监督视频摘要方法的局限性，提升了关键帧选择的准确性和训练稳定性。

Abstract: Video summarization is a crucial technique for social understanding, enabling efficient browsing of massive multimedia content and extraction of key information from social platforms. Most existing unsupervised summarization methods rely on Generative Adversarial Networks (GANs) to enhance keyframe selection and generate coherent, video summaries through adversarial training. However, such approaches primarily exploit unimodal features, overlooking the guiding role of semantic information in keyframe selection, and often suffer from unstable training. To address these limitations, we propose a novel Semantic-Guided Unsupervised Video Summarization method. Specifically, we design a novel frame-level semantic alignment attention mechanism and integrate it into a keyframe selector, which guides the Transformer-based generator within the adversarial framework to better reconstruct videos. In addition, we adopt an incremental training strategy to progressively update the model components, effectively mitigating the instability of GAN training. Experimental results demonstrate that our approach achieves superior performance on multiple benchmark datasets.

</details>


### [29] [Towards Bound Consistency for the No-Overlap Constraint Using MDDs](https://arxiv.org/abs/2601.14784)
*Amaury Guichard,Laurent Michel,Hélène Verhaeghe,Pierre Schaus*

Main category: cs.AI

TL;DR: 本文提出了首个针对无重叠约束的边界一致性算法，通过构建有限宽度的MDD（多值决策图）实现多项式时间内的边界一致性过滤，相比现有方法能显著减少搜索树节点数量。


<details>
  <summary>Details</summary>
Motivation: 无重叠约束的边界一致性已知是NP完全问题，现有多项式时间收紧技术（如边查找、非首非尾推理、能量推理）存在局限性，需要更有效的边界一致性算法来提升约束求解效率。

Method: 基于Ciré和van Hoeve定义的无重叠MDD，提取作业时间窗口边界来收紧开始和结束时间；通过限制MDD宽度为阈值创建松弛MDD，控制算法规模和时间复杂度，实现多项式时间内的边界一致性过滤。

Result: 在带时间窗口的排序问题和准时制目标问题上实验表明，即使使用宽度阈值，新过滤方法相比Ciré和van Hoeve的优先检测算法能更显著减少搜索树访问节点数；与经典传播方法互补，在多个实例上同时减少了节点数和求解时间。

Conclusion: 本文首次实现了无重叠约束的边界一致性算法，通过MDD宽度限制在多项式时间内完成过滤，实验证明该方法比现有方法更有效，并能与经典传播技术协同提升求解性能。

Abstract: Achieving bound consistency for the no-overlap constraint is known to be NP-complete. Therefore, several polynomial-time tightening techniques, such as edge finding, not-first-not-last reasoning, and energetic reasoning, have been introduced for this constraint. In this work, we derive the first bound-consistent algorithm for the no-overlap constraint. By building on the no-overlap MDD defined by Ciré and van Hoeve, we extract bounds of the time window of the jobs, allowing us to tighten start and end times in time polynomial in the number of nodes of the MDD. Similarly, to bound the size and time-complexity, we limit the width of the MDD to a threshold, creating a relaxed MDD that can also be used to relax the bound-consistent filtering. Through experiments on a sequencing problem with time windows and a just-in-time objective ($1 \mid r_j, d_j, \bar{d}_j \mid \sum E_j + \sum T_j$), we observe that the proposed filtering, even with a threshold on the width, achieves a stronger reduction in the number of nodes visited in the search tree compared to the previously proposed precedence-detection algorithm of Ciré and van Hoeve. The new filtering also appears to be complementary to classical propagation methods for the no-overlap constraint, allowing a substantial reduction in both the number of nodes and the solving time on several instances.

</details>


### [30] [Measuring and Aligning Abstraction in Vision-Language Models with Medical Taxonomies](https://arxiv.org/abs/2601.14827)
*Ben Schaper,Maxime Di Folco,Bernhard Kainz,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.AI

TL;DR: 该研究评估了视觉语言模型在胸部X光分类中的抽象错误，提出了基于医学分类学的分层评估方法和缓解策略，显著减少了严重错误。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在胸部X光分类中表现出强大的零样本性能，但标准的平面评估指标无法区分临床轻微错误和严重错误。需要量化并缓解抽象错误，以实现更安全、更具临床意义的模型部署。

Method: 1. 使用分层指标对多个最先进的视觉语言模型进行基准测试；2. 引入"灾难性抽象错误"概念来捕捉跨分支错误；3. 提出风险约束阈值法；4. 开发基于径向嵌入的分类学感知微调方法。

Result: 研究结果显示，尽管视觉语言模型在平面性能上表现优异，但与临床分类学存在显著不对齐。提出的方法能将严重抽象错误减少到2%以下，同时保持有竞争力的性能。

Conclusion: 分层评估和表示层面对齐对于视觉语言模型更安全、更具临床意义的部署至关重要。提出的方法有效减少了严重错误，为医疗AI的临床应用提供了重要指导。

Abstract: Vision-Language Models show strong zero-shot performance for chest X-ray classification, but standard flat metrics fail to distinguish between clinically minor and severe errors. This work investigates how to quantify and mitigate abstraction errors by leveraging medical taxonomies. We benchmark several state-of-the-art VLMs using hierarchical metrics and introduce Catastrophic Abstraction Errors to capture cross-branch mistakes. Our results reveal substantial misalignment of VLMs with clinical taxonomies despite high flat performance. To address this, we propose risk-constrained thresholding and taxonomy-aware fine-tuning with radial embeddings, which reduce severe abstraction errors to below 2 per cent while maintaining competitive performance. These findings highlight the importance of hierarchical evaluation and representation-level alignment for safer and more clinically meaningful deployment of VLMs.

</details>


### [31] [Implementing Knowledge Representation and Reasoning with Object Oriented Design](https://arxiv.org/abs/2601.14840)
*Abdelrhman Bassiouny,Tom Schierenbeck,Sorin Arion,Benjamin Alt,Naren Vasantakumaar,Giang Nguyen,Michael Beetz*

Main category: cs.AI

TL;DR: KRROOD是一个将知识表示与推理系统集成到面向对象编程中的框架，解决了现代软件工程与KR&R系统之间的集成鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 面向对象编程是开发复杂应用程序的标准，但现有的知识表示与推理框架通常依赖外部本体和专门语言，难以与命令式代码集成，存在集成鸿沟问题。

Method: KRROOD将知识作为一等编程抽象，使用原生类结构，弥合了逻辑编程和面向对象编程范式之间的差距。

Result: 在OWL2Bench基准测试和人机任务学习场景中的实验结果表明，KRROOD实现了强大的性能，同时支持现实世界自主系统所需的表达性推理。

Conclusion: KRROOD成功地将知识表示与推理系统集成到面向对象编程中，为现实世界自主系统提供了有效的解决方案。

Abstract: This paper introduces KRROOD, a framework designed to bridge the integration gap between modern software engineering and Knowledge Representation & Reasoning (KR&R) systems. While Object-Oriented Programming (OOP) is the standard for developing complex applications, existing KR&R frameworks often rely on external ontologies and specialized languages that are difficult to integrate with imperative code. KRROOD addresses this by treating knowledge as a first-class programming abstraction using native class structures, bridging the gap between the logic programming and OOP paradigms. We evaluate the system on the OWL2Bench benchmark and a human-robot task learning scenario. Experimental results show that KRROOD achieves strong performance while supporting the expressive reasoning required for real-world autonomous systems.

</details>


### [32] [Just aware enough: Evaluating awareness across artificial systems](https://arxiv.org/abs/2601.14901)
*Nadine Meertens,Suet Lee,Ophelia Deroy*

Main category: cs.AI

TL;DR: 该论文提出用"意识度"替代"AI意识"作为评估人工智能系统的新框架，强调可操作性、领域敏感性和多维度的评估方法。


<details>
  <summary>Details</summary>
Motivation: 当前关于AI意识和道德地位的讨论缺乏共识和可操作的评估方法，需要更实用、方法上可操作的替代方案来评估AI系统的能力。

Method: 提出评估意识度的结构化方法，将意识度定义为系统处理、存储和使用信息以实现目标导向行动的能力。该方法具有四个核心特征：领域敏感性、可扩展性、多维度和任务性能预测能力。

Result: 开发了一个能够跨不同架构、规模和操作领域评估和比较AI系统意识度概况的框架，使评估更具可操作性和实用性。

Conclusion: 从"人工意识"转向"足够意识"的评估框架，有助于促进原则性评估、支持设计和监管，并推动更建设性的科学和公共讨论。

Abstract: Recent debates on artificial intelligence increasingly emphasise questions of AI consciousness and moral status, yet there remains little agreement on how such properties should be evaluated. In this paper, we argue that awareness offers a more productive and methodologically tractable alternative. We introduce a practical method for evaluating awareness across diverse systems, where awareness is understood as encompassing a system's abilities to process, store and use information in the service of goal-directed action. Central to this approach is the claim that any evaluation aiming to capture the diversity of artificial systems must be domain-sensitive, deployable at any scale, multidimensional, and enable the prediction of task performance, while generalising to the level of abilities for the sake of comparison. Given these four desiderata, we outline a structured approach to evaluating and comparing awareness profiles across artificial systems with differing architectures, scales, and operational domains. By shifting the focus from artificial consciousness to being just aware enough, this approach aims to facilitate principled assessment, support design and oversight, and enable more constructive scientific and public discourse.

</details>


### [33] [Emergent, not Immanent: A Baradian Reading of Explainable AI](https://arxiv.org/abs/2601.15029)
*Fabio Morreale,Joan Serrà,Yuki Mistufuji*

Main category: cs.AI

TL;DR: 论文批判了当前可解释AI（XAI）将解释视为技术问题的立场，基于Barad的能动实在论提出了替代的本体认识论框架，将解释视为物质-话语实践，并提出了支持涌现性解释的XAI界面设计方向。


<details>
  <summary>Details</summary>
Motivation: 当前可解释AI领域存在未经验证的本体认识论假设：将意义视为模型内在固有、解释者被置于系统之外、并假定可通过计算技术恢复因果结构。这些假设限制了XAI的理解和发展，需要建立更全面的理论框架。

Method: 采用Barad的能动实在论作为理论基础，重新审视XAI的本体认识论。通过能动实在论的视角系统分析现有XAI方法，揭示其假设和局限性。然后阐述该框架的伦理维度，并提出支持涌现性解释的XAI界面设计方向，以文本到音乐界面作为案例研究。

Result: 提出了基于能动实在论的XAI替代框架，将解释视为从AI模型、人类、上下文和解释装置的情境纠缠中涌现的物质-话语实践。揭示了现有XAI方法的假设和局限性，并展示了如何设计支持涌现性解释的XAI界面。

Conclusion: XAI不应仅仅被视为技术问题，而应理解为情境化的物质-话语实践。基于能动实在论的框架为XAI提供了更全面的理论视角，强调解释的涌现性和情境依赖性，并为设计更符合伦理和实践需求的XAI系统提供了指导方向。

Abstract: Explainable AI (XAI) is frequently positioned as a technical problem of revealing the inner workings of an AI model. This position is affected by unexamined onto-epistemological assumptions: meaning is treated as immanent to the model, the explainer is positioned outside the system, and a causal structure is presumed recoverable through computational techniques. In this paper, we draw on Barad's agential realism to develop an alternative onto-epistemology of XAI. We propose that interpretations are material-discursive performances that emerge from situated entanglements of the AI model with humans, context, and the interpretative apparatus. To develop this position, we read a comprehensive set of XAI methods through agential realism and reveal the assumptions and limitations that underpin several of these methods. We then articulate the framework's ethical dimension and propose design directions for XAI interfaces that support emergent interpretation, using a speculative text-to-music interface as a case study.

</details>


### [34] [The Plausibility Trap: Using Probabilistic Engines for Deterministic Tasks](https://arxiv.org/abs/2601.15130)
*Ivan Carrera,Daniel Maldonado-Ruiz*

Main category: cs.AI

TL;DR: 论文定义了"合理性陷阱"现象：人们过度使用昂贵的概率性AI模型处理简单的确定性任务，导致资源浪费，并提出工具选择工程和决策矩阵框架来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的普及，用户便利性优先于计算效率，导致人们过度使用昂贵的概率性AI引擎处理简单的确定性任务（如OCR或基本验证），造成显著的资源浪费。

Method: 通过OCR和事实核查的微基准测试和案例研究，量化"效率税"；引入工具选择工程和确定性-概率性决策矩阵框架，帮助开发者决定何时使用生成式AI，何时避免使用。

Result: 研究发现存在约6.5倍的延迟惩罚（效率税），并揭示了算法奉承的风险；提出的决策框架能够指导开发者做出更合理的工具选择。

Conclusion: 真正的数字素养不仅在于知道如何使用生成式AI，更在于知道何时不使用它；需要课程转变，强调在AI时代做出明智的工具选择决策的重要性。

Abstract: The ubiquity of Large Language Models (LLMs) is driving a paradigm shift where user convenience supersedes computational efficiency. This article defines the "Plausibility Trap": a phenomenon where individuals with access to Artificial Intelligence (AI) models deploy expensive probabilistic engines for simple deterministic tasks-such as Optical Character Recognition (OCR) or basic verification-resulting in significant resource waste. Through micro-benchmarks and case studies on OCR and fact-checking, we quantify the "efficiency tax"-demonstrating a ~6.5x latency penalty-and the risks of algorithmic sycophancy. To counter this, we introduce Tool Selection Engineering and the Deterministic-Probabilistic Decision Matrix, a framework to help developers determine when to use Generative AI and, crucially, when to avoid it. We argue for a curriculum shift, emphasizing that true digital literacy relies not only in knowing how to use Generative AI, but also on knowing when not to use it.

</details>


### [35] [Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning](https://arxiv.org/abs/2601.15160)
*Yuval Kansal,Niraj K. Jha*

Main category: cs.AI

TL;DR: 论文提出了一种基于知识图谱路径奖励的底层学习范式，通过监督微调和强化学习结合的方法，让模型从基础领域事实出发进行组合推理，在医学领域实现了从短跳推理到复杂多跳推理的零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学和编程等结构化推理领域已达到接近专家的水平，但在专业科学领域进行组合式多跳推理的能力仍然有限。需要一种方法让模型能够基于领域基本事实进行组合推理，解决复杂未见任务。

Method: 提出基于知识图谱作为隐式奖励模型的训练流程，结合监督微调和强化学习。通过从知识图谱路径推导奖励信号，提供可验证、可扩展、有基础的监督，鼓励模型在强化学习过程中组合中间公理而不仅仅是优化最终答案。

Result: 在医学领域验证该方法，训练140亿参数模型在短跳推理路径（1-3跳）上，在复杂多跳查询（4-5跳）上实现零样本泛化。模型在最具挑战性的推理任务上显著优于更大模型和前沿系统如GPT-5.2和Gemini 3 Pro，并对抗性扰动具有鲁棒性。

Conclusion: 将推理过程基于结构化知识是通向智能推理的可扩展且高效的路径。知识图谱路径奖励作为"组合桥梁"，使模型能够从基础事实组合解决复杂推理任务。

Abstract: Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we present a post-training pipeline, based on a combination of supervised fine-tuning and reinforcement learning (RL), in which knowledge graphs act as implicit reward models. By deriving novel reward signals from knowledge graph paths, we provide verifiable, scalable, and grounded supervision that encourages models to compose intermediate axioms rather than optimize only final answers during RL. We validate this approach in the medical domain, training a 14B model on short-hop reasoning paths (1-3 hops) and evaluating its zero-shot generalization to complex multi-hop queries (4-5 hops). Our experiments show that path-derived rewards act as a "compositional bridge", enabling our model to significantly outperform much larger models and frontier systems like GPT-5.2 and Gemini 3 Pro, on the most difficult reasoning tasks. Furthermore, we demonstrate the robustness of our approach to adversarial perturbations against option-shuffling stress tests. This work suggests that grounding the reasoning process in structured knowledge is a scalable and efficient path toward intelligent reasoning.

</details>


### [36] [BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries](https://arxiv.org/abs/2601.15197)
*Shijie Lian,Bin Yu,Xiaopeng Lin,Laurence T. Yang,Zhaolong Shen,Changti Wu,Yuzhuo Miao,Cong Huang,Kai Chen*

Main category: cs.AI

TL;DR: 该论文提出BayesianVLA框架，通过贝叶斯分解解决VLA模型中的信息崩溃问题，显著提升机器人操作任务的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在机器人操作中存在泛化能力不足的问题，特别是在新指令或复杂多任务场景中。研究发现现有训练范式存在数据集偏差问题：目标驱动的数据收集导致语言指令可以从视觉观察中高度预测，造成指令与动作之间的条件互信息消失（信息崩溃），使模型退化为忽略语言约束的纯视觉策略。

Method: 提出BayesianVLA框架，通过贝叶斯分解强制指令跟随。引入可学习的潜在动作查询，构建双分支架构来估计视觉先验p(a|v)和语言条件后验π(a|v,ℓ)。优化策略以最大化动作与指令之间的条件点互信息，惩罚视觉捷径，奖励明确解释语言命令的动作。

Result: 在SimplerEnv和RoboCasa上的广泛实验显示显著改进，特别是在具有挑战性的OOD SimplerEnv基准上提升了11.3%，验证了该方法在将语言可靠地融入动作中的能力。

Conclusion: BayesianVLA通过解决信息崩溃问题，在不需新数据的情况下显著提升了VLA模型的泛化能力，为机器人操作任务提供了更鲁棒的语言-动作关联方法。

Abstract: Vision-Language-Action (VLA) models have shown promise in robot manipulation but often struggle to generalize to new instructions or complex multi-task scenarios. We identify a critical pathology in current training paradigms where goal-driven data collection creates a dataset bias. In such datasets, language instructions are highly predictable from visual observations alone, causing the conditional mutual information between instructions and actions to vanish, a phenomenon we term Information Collapse. Consequently, models degenerate into vision-only policies that ignore language constraints and fail in out-of-distribution (OOD) settings. To address this, we propose BayesianVLA, a novel framework that enforces instruction following via Bayesian decomposition. By introducing learnable Latent Action Queries, we construct a dual-branch architecture to estimate both a vision-only prior $p(a \mid v)$ and a language-conditioned posterior $π(a \mid v, \ell)$. We then optimize the policy to maximize the conditional Pointwise Mutual Information (PMI) between actions and instructions. This objective effectively penalizes the vision shortcut and rewards actions that explicitly explain the language command. Without requiring new data, BayesianVLA significantly improves generalization. Extensive experiments across on SimplerEnv and RoboCasa demonstrate substantial gains, including an 11.3% improvement on the challenging OOD SimplerEnv benchmark, validating the ability of our approach to robustly ground language in action.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [GCG Attack On A Diffusion LLM](https://arxiv.org/abs/2601.14266)
*Ruben Neyroud,Sam Corley*

Main category: cs.LG

TL;DR: 探索性研究：将GCG攻击应用于扩散语言模型LLaDA，评估其在有害提示上的攻击效果，为扩散LLM的对抗鲁棒性提供初步见解


<details>
  <summary>Details</summary>
Motivation: 虽然GCG攻击在自回归LLM上已被证明有效，但其在扩散语言模型上的适用性尚未得到充分探索。随着扩散LLM作为自回归模型替代方案的兴起，需要研究其对抗鲁棒性和攻击面

Method: 对开源扩散LLM LLaDA进行GCG风格的对抗提示攻击研究，评估多种攻击变体（包括前缀扰动和后缀对抗生成），使用AdvBench数据集中的有害提示进行评估

Result: 研究提供了扩散语言模型对抗鲁棒性的初步见解，揭示了其攻击面特征，为后续研究奠定了基础

Conclusion: 扩散语言模型存在特定的对抗攻击面，需要开发替代的优化和评估策略来进行对抗分析，该研究为这一新兴领域的进一步探索提供了方向

Abstract: While most LLMs are autoregressive, diffusion-based LLMs have recently emerged as an alternative method for generation. Greedy Coordinate Gradient (GCG) attacks have proven effective against autoregressive models, but their applicability to diffusion language models remains largely unexplored. In this work, we present an exploratory study of GCG-style adversarial prompt attacks on LLaDA (Large Language Diffusion with mAsking), an open-source diffusion LLM. We evaluate multiple attack variants, including prefix perturbations and suffix-based adversarial generation, on harmful prompts drawn from the AdvBench dataset. Our study provides initial insights into the robustness and attack surface of diffusion language models and motivates the development of alternative optimization and evaluation strategies for adversarial analysis in this setting.

</details>


### [38] [Quality or Quantity? Error-Informed Selective Online Learning with Gaussian Processes in Multi-Agent Systems: Extended Version](https://arxiv.org/abs/2601.14275)
*Zewen Yang,Xiaobing Dai,Jiajun Cheng,Yulong Huang,Peng Shi*

Main category: cs.LG

TL;DR: 本文提出了一种分布式误差感知高斯过程（EIGP）框架，通过选择性在线学习机制，让智能体能够评估邻居模型质量，优先选择预测误差较小的GP模型进行合作，而非盲目包含所有模型。


<details>
  <summary>Details</summary>
Motivation: 在多智能体分布式学习中，盲目包含所有智能体的机器学习模型进行联合预测是不合理的。研究发现，在合作学习中，模型质量比数量更为重要，需要优先考虑高质量模型而非简单增加模型数量。

Method: 提出了首个分布式选择性在线学习框架——分布式误差感知高斯过程（EIGP）。该方法使每个智能体能够评估其邻居合作者，使用提出的选择函数选择预测误差较小的高质量GP模型。还嵌入了算法增强：贪婪算法（gEIGP）用于加速预测，自适应算法（aEIGP）用于提高预测精度。结合误差感知量化项迭代和数据删除策略，实现了快速预测和模型更新的实时学习操作。

Result: 通过数值模拟验证了所开发方法的有效性，展示了其在多个基准测试中优于现有最先进的分布式GP方法。

Conclusion: 该研究证明了在分布式高斯过程回归中，选择性合作学习比盲目包含所有模型更为有效。提出的EIGP框架通过质量优先的选择机制，实现了更优的预测性能，为多智能体系统的合作学习提供了新的有效方法。

Abstract: Effective cooperation is pivotal in distributed learning for multi-agent systems, where the interplay between the quantity and quality of the machine learning models is crucial. This paper reveals the irrationality of indiscriminate inclusion of all models on agents for joint prediction, highlighting the imperative to prioritize quality over quantity in cooperative learning. Specifically, we present the first selective online learning framework for distributed Gaussian process (GP) regression, namely distributed error-informed GP (EIGP), that enables each agent to assess its neighboring collaborators, using the proposed selection function to choose the higher quality GP models with less prediction errors. Moreover, algorithmic enhancements are embedded within the EIGP, including a greedy algorithm (gEIGP) for accelerating prediction and an adaptive algorithm (aEIGP) for improving prediction accuracy. In addition, approaches for fast prediction and model update are introduced in conjunction with the error-informed quantification term iteration and a data deletion strategy to achieve real-time learning operations. Numerical simulations are performed to demonstrate the effectiveness of the developed methodology, showcasing its superiority over the state-of-the-art distributed GP methods with different benchmarks.

</details>


### [39] [Which Quantization Should I Use? A Unified Evaluation of llama.cpp Quantization on Llama-3.1-8B-Instruct](https://arxiv.org/abs/2601.14277)
*Uygar Kurt*

Main category: cs.LG

TL;DR: 本文对llama.cpp中的量化方案进行了统一的实证研究，评估了Llama-3.1-8B-Instruct模型在不同量化格式（3-8位K-quant和传统格式）下的性能表现，为选择量化方案提供实用指南。


<details>
  <summary>Details</summary>
Motivation: 量化技术可以降低大语言模型的部署难度，减少内存使用并提高在受限硬件上的运行可行性。然而，llama.cpp中可用的量化格式评估不一致，使得用户难以选择合适的量化方案。

Method: 对Llama-3.1-8B-Instruct模型（FP16, GGUF格式）进行统一的实证研究，涵盖3-8位K-quant和传统量化格式。评估下游任务性能（推理、知识、指令遵循和真实性基准测试），同时测量困惑度、CPU吞吐量（预填充/解码）、模型大小、压缩率和量化时间。

Result: 研究提供了不同量化方案在性能、效率和资源消耗方面的详细比较数据，揭示了各种量化格式在任务性能、推理速度和模型压缩之间的权衡关系。

Conclusion: 这项工作为选择llama.cpp量化方案提供了实用指南，帮助读者根据预期用途和资源预算做出明智的、情境感知的决策。

Abstract: Quantization is a practical technique for making large language models easier to deploy by reducing the precision used to store and operate on model weights. This can lower memory use and improve runtime feasibility on constrained hardware, which is especially relevant for users running models locally. Quantization in llama.cpp enables large language models to run on commodity hardware, but available formats are often evaluated inconsistently, making it hard to choose among schemes. We present a unified empirical study of the llama.cpp quantization on a single modern model, Llama-3.1-8B-Instruct (FP16, GGUF), covering 3-8 bit K-quant and legacy formats. We evaluate downstream task performance across standard reasoning, knowledge, instruction-following, and truthfulness benchmarks, and also measure perplexity and CPU throughput (prefill/decoding) alongside model size, compression, and quantization time. Ultimately, this work is a practical guide for choosing a llama.cpp quantization scheme, helping readers make informed, context-aware decisions for their intended use and resource budget.

</details>


### [40] [On the Limits of Learned Importance Scoring for KV Cache Compression](https://arxiv.org/abs/2601.14279)
*Brady Steele*

Main category: cs.LG

TL;DR: 研究发现学习型KV缓存压缩方法SIP在预测token重要性方面并不优于简单基线方法，包括随机选择


<details>
  <summary>Details</summary>
Motivation: 研究学习型KV缓存压缩方法，探索通过KV表示预测token重要性的有效性

Method: 使用Speculative Importance Prediction (SIP) - 一个170万参数的非查询感知评分器，仅从KV表示预测token重要性，包含多视野前瞻和交叉注意力等复杂架构

Result: SIP在5个种子、4个保留水平和3个任务上均未优于简单基线方法，包括随机选择。位置启发式方法（保留前4个+最后N个token）与学习型方法相当或更好

Conclusion: KV表示中除了位置和预填充注意力之外的信息对于重要性预测的价值有限，未来查询与生成轨迹之间的循环依赖可能是造成这一困难的原因

Abstract: We investigate learned KV cache compression through Speculative Importance Prediction (SIP), a 1.7M parameter non-query-aware scorer that predicts token importance from KV representations alone. Despite architectural sophistication (multi-horizon lookahead, cross-attention), SIP does not outperform simple baselines, including random selection, across 5 seeds, 4 retention levels, and 3 tasks. Key findings: (1) position-based heuristics (keep first 4 + last N tokens) match or exceed learned approaches; (2) prefill attention provides equivalent signal to complex learned scorers; (3) marginal information in KV representations beyond position and prefill attention appears limited for importance prediction. We hypothesize that circular dependence between future queries and generation trajectories contributes to this difficulty.

</details>


### [41] [Beyond Affinity: A Benchmark of 1D, 2D, and 3D Methods Reveals Critical Trade-offs in Structure-Based Drug Design](https://arxiv.org/abs/2601.14283)
*Kangyu Zheng,Kai Zhang,Jiale Tan,Xuehan Chen,Yingzhou Lu,Zaixi Zhang,Lichao Sun,Marinka Zitnik,Tianfan Fu,Zhiding Liang*

Main category: cs.LG

TL;DR: 该研究建立了首个跨算法类别的结构药物设计基准，评估了15种不同算法模型在药物性质、对接亲和力和构象方面的表现，发现3D模型在结合亲和力方面表现最佳但化学有效性不足，1D模型化学性质可靠但结合亲和力有限，2D模型则表现均衡。


<details>
  <summary>Details</summary>
Motivation: 当前结构药物设计领域主要有搜索算法、深度生成模型和强化学习三类算法，但现有研究多局限于同类算法比较，缺乏跨算法类别的系统性评估。本研究旨在填补这一空白，建立统一基准来全面评估不同算法基础模型的性能。

Method: 建立了一个基准测试框架，评估15个跨不同算法基础的模型。通过评估生成分子的药物性质、与指定靶蛋白的对接亲和力及构象来比较性能。特别强调1D/2D配体中心方法可以通过将对接函数视为黑盒预言机的方式应用于SBDD。

Result: 评估揭示了不同模型类别的明显模式：3D结构模型在结合亲和力方面表现出色，但在化学有效性和构象质量方面存在不一致性；1D模型在标准分子指标上表现可靠，但很少达到最佳结合亲和力；2D模型提供均衡性能，保持高化学有效性同时获得中等结合分数。

Conclusion: 研究为未来SBDD模型设计提供了具体建议，强调需要结合不同方法的优势并解决其局限性。通过多靶点详细分析，识别了每个模型类别的关键改进领域，为研究人员提供了重要参考。所有基准测试代码已开源。

Abstract: Currently, the field of structure-based drug design is dominated by three main types of algorithms: search-based algorithms, deep generative models, and reinforcement learning. While existing works have typically focused on comparing models within a single algorithmic category, cross-algorithm comparisons remain scarce. In this paper, to fill the gap, we establish a benchmark to evaluate the performance of fifteen models across these different algorithmic foundations by assessing the pharmaceutical properties of the generated molecules and their docking affinities and poses with specified target proteins. We highlight the unique advantages of each algorithmic approach and offer recommendations for the design of future SBDD models. We emphasize that 1D/2D ligand-centric drug design methods can be used in SBDD by treating the docking function as a black-box oracle, which is typically neglected. Our evaluation reveals distinct patterns across model categories. 3D structure-based models excel in binding affinities but show inconsistencies in chemical validity and pose quality. 1D models demonstrate reliable performance in standard molecular metrics but rarely achieve optimal binding affinities. 2D models offer balanced performance, maintaining high chemical validity while achieving moderate binding scores. Through detailed analysis across multiple protein targets, we identify key improvement areas for each model category, providing insights for researchers to combine strengths of different approaches while addressing their limitations. All the code that are used for benchmarking is available in https://github.com/zkysfls/2025-sbdd-benchmark

</details>


### [42] [A Comparison of Polynomial-Based Tree Clustering Methods](https://arxiv.org/abs/2601.14285)
*Pengyu Liu,Mariel Vázquez,Nataša Jonoska*

Main category: cs.LG

TL;DR: 本文比较了基于树多项式距离的聚类方法性能，发现基于条目级归一化距离的方法在树结构聚类中准确率最高


<details>
  <summary>Details</summary>
Motivation: 生命科学中树结构数据（如系统发育树、RNA二级结构）日益增多，需要新的树结构数据分析方法。树多项式提供了一种计算高效、可解释的树结构编码方式，但需要评估不同距离度量在聚类中的性能

Method: 1) 比较基于树多项式不同距离度量的聚类方法性能；2) 实现两种基本的自编码器模型用于树聚类；3) 使用树区分多项式作为特征表示

Result: 基于条目级归一化距离的方法在所有比较方法中具有最高的聚类准确率

Conclusion: 树多项式结合适当的距离度量（特别是条目级归一化距离）是树结构数据聚类的有效方法，为生命科学中的树结构分析提供了实用工具

Abstract: Tree structures appear in many fields of the life sciences, including phylogenetics, developmental biology and nucleic acid structures. Trees can be used to represent RNA secondary structures, which directly relate to the function of non-coding RNAs. Recent developments in sequencing technology and artificial intelligence have yielded numerous biological data that can be represented with tree structures. This requires novel methods for tree structure data analytics. Tree polynomials provide a computationally efficient, interpretable and comprehensive way to encode tree structures as matrices, which are compatible with most data analytics tools. Machine learning methods based on the Canberra distance between tree polynomials have been introduced to analyze phylogenies and nucleic acid structures. In this paper, we compare the performance of different distances in tree clustering methods based on a tree distinguishing polynomial. We also implement two basic autoencoder models for clustering trees using the polynomial. We find that the distance based methods with entry-level normalized distances have the highest clustering accuracy among the compared methods.

</details>


### [43] [Gradient Structure Estimation under Label-Only Oracles via Spectral Sensitivity](https://arxiv.org/abs/2601.14300)
*Jun Liu,Leo Yu Zhang,Fengpeng Li,Isao Echizen,Jiantao Zhou*

Main category: cs.LG

TL;DR: 该论文提出了一种新的硬标签黑盒攻击框架，通过零查询频域初始化和模式驱动优化策略，显著提高了攻击成功率和查询效率。


<details>
  <summary>Details</summary>
Motivation: 硬标签黑盒设置（仅能观察top-1预测标签）是理解模型行为的重要反馈模型，但面临从离散响应中恢复梯度信息的核心挑战。现有硬标签攻击方法缺乏统一的理论视角。

Method: 提出统一理论视角，将现有硬标签攻击解释为隐式近似真实损失梯度符号。基于此提出新攻击框架：零查询频域初始化结合模式驱动优化策略。

Result: 在CIFAR-10、ImageNet、ObjectNet等数据集上，方法在攻击成功率和查询效率上均超越现有SOTA硬标签攻击，特别是在低查询场景。还能成功绕过Blacklight防御（0%检测率）。

Conclusion: 该工作为硬标签黑盒攻击提供了统一的理论视角，提出的新框架在多个任务和场景中表现出优越性能，具有很好的泛化能力。

Abstract: Hard-label black-box settings, where only top-1 predicted labels are observable, pose a fundamentally constrained yet practically important feedback model for understanding model behavior. A central challenge in this regime is whether meaningful gradient information can be recovered from such discrete responses. In this work, we develop a unified theoretical perspective showing that a wide range of existing sign-flipping hard-label attacks can be interpreted as implicitly approximating the sign of the true loss gradient. This observation reframes hard-label attacks from heuristic search procedures into instances of gradient sign recovery under extremely limited feedback. Motivated by this first-principles understanding, we propose a new attack framework that combines a zero-query frequency-domain initialization with a Pattern-Driven Optimization (PDO) strategy. We establish theoretical guarantees demonstrating that, under mild assumptions, our initialization achieves higher expected cosine similarity to the true gradient sign compared to random baselines, while the proposed PDO procedure attains substantially lower query complexity than existing structured search approaches. We empirically validate our framework through extensive experiments on CIFAR-10, ImageNet, and ObjectNet, covering standard and adversarially trained models, commercial APIs, and CLIP-based models. The results show that our method consistently surpasses SOTA hard-label attacks in both attack success rate and query efficiency, particularly in low-query regimes. Beyond image classification, our approach generalizes effectively to corrupted data, biomedical datasets, and dense prediction tasks. Notably, it also successfully circumvents Blacklight, a SOTA stateful defense, resulting in a $0\%$ detection rate. Our code will be released publicly soon at https://github.com/csjunjun/DPAttack.git.

</details>


### [44] [Layer-adaptive Expert Pruning for Pre-Training of Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2601.14327)
*YuanLab. ai,Shawn Wu,Jiangang Luo,Tong Yu,Darcy Chen,Sean Wang,Xudong Zhao,Louie Li,Claire Wang,Hunter He,Carol Wang,Allen Wang*

Main category: cs.LG

TL;DR: 本文提出了一种用于MoE LLMs预训练阶段的层自适应专家剪枝算法（LAEP），通过选择性剪枝未充分利用的专家并重新组织跨计算设备的专家分布，显著提升预训练效率。


<details>
  <summary>Details</summary>
Motivation: 虽然MoE大语言模型能以较少的激活参数提供优越的准确性，但其预训练阶段存在显著的计算瓶颈，主要原因是专家利用率不足和训练效率有限。

Method: 提出层自适应专家剪枝算法（LAEP），在预训练阶段根据token分布统计选择性剪枝未充分利用的专家，并重新组织跨计算设备的专家分布，以提高训练效率。

Result: 实验表明LAEP能有效减少模型规模并大幅提升预训练效率。在从头预训练1010B基础模型时，实现了48.3%的训练效率提升和33.3%的参数减少，同时在多个领域仍保持优秀性能。

Conclusion: LAEP算法为MoE LLMs的预训练提供了一种有效的效率优化方案，通过专家剪枝和重组策略解决了专家利用率不足的问题，显著提升了训练效率而不损害模型性能。

Abstract: Although Mixture-of-Experts (MoE) Large Language Models (LLMs) deliver superior accuracy with a reduced number of active parameters, their pre-training represents a significant computationally bottleneck due to underutilized experts and limited training efficiency. This work introduces a Layer-Adaptive Expert Pruning (LAEP) algorithm designed for the pre-training stage of MoE LLMs. In contrast to previous expert pruning approaches that operate primarily in the post-training phase, the proposed algorithm enhances training efficiency by selectively pruning underutilized experts and reorganizing experts across computing devices according to token distribution statistics. Comprehensive experiments demonstrate that LAEP effectively reduces model size and substantially improves pre-training efficiency. In particular, when pre-training the 1010B Base model from scratch, LAEP achieves a 48.3\% improvement in training efficiency alongside a 33.3% parameter reduction, while still delivering excellent performance across multiple domains.

</details>


### [45] [Hierarchical Contextual Uplift Bandits for Catalog Personalization](https://arxiv.org/abs/2601.14333)
*Anupam Agrawal,Rajesh Mohanty,Shamik Bhattacharjee,Abhimanyu Mittal*

Main category: cs.LG

TL;DR: 提出分层上下文提升赌博机框架，通过动态调整上下文粒度解决幻想体育平台中用户行为快速变化和奖励分布剧烈波动的挑战，显著提升推荐质量和收入。


<details>
  <summary>Details</summary>
Motivation: 传统上下文赌博机算法在幻想体育等动态环境中表现不佳，用户行为快速变化和外部因素导致的奖励分布剧烈波动需要频繁重新训练，存在冷启动问题。

Method: 提出分层上下文提升赌博机框架，动态调整上下文粒度（从系统级到用户级），利用上下文相似性促进策略迁移，并整合提升建模原则。

Result: 在Dream11幻想体育平台的大规模A/B测试中，该方法显著提升推荐质量，实现0.4%的收入增长并改善用户满意度指标，部署后进一步获得0.5%收入提升。

Conclusion: 分层上下文提升赌博机框架有效解决了动态环境中的个性化推荐挑战，已在生产环境中成功部署并持续带来商业价值。

Abstract: Contextual Bandit (CB) algorithms are widely adopted for personalized recommendations but often struggle in dynamic environments typical of fantasy sports, where rapid changes in user behavior and dramatic shifts in reward distributions due to external influences necessitate frequent retraining. To address these challenges, we propose a Hierarchical Contextual Uplift Bandit framework. Our framework dynamically adjusts contextual granularity from broad, system-wide insights to detailed, user-specific contexts, using contextual similarity to facilitate effective policy transfer and mitigate cold-start issues. Additionally, we integrate uplift modeling principles into our approach. Results from large-scale A/B testing on the Dream11 fantasy sports platform show that our method significantly enhances recommendation quality, achieving a 0.4% revenue improvement while also improving user satisfaction metrics compared to the current production system. We subsequently deployed this system to production as the default catalog personalization system in May 2025 and observed a further 0.5% revenue improvement.

</details>


### [46] [VJEPA: Variational Joint Embedding Predictive Architectures as Probabilistic World Models](https://arxiv.org/abs/2601.14354)
*Yongchao Huang*

Main category: cs.LG

TL;DR: VJEPA是一种概率化的联合嵌入预测架构，通过变分目标学习未来潜在状态的预测分布，统一了表示学习与预测状态表示，为高维噪声环境中的不确定性感知规划提供了基础框架。


<details>
  <summary>Details</summary>
Motivation: 现有JEPA方法使用确定性回归目标，掩盖了概率语义，限制了其在随机控制中的应用。需要一种概率化扩展来支持不确定性估计和鲁棒规划。

Method: 提出变分JEPA（VJEPA），通过变分目标学习未来潜在状态的预测分布；进一步提出贝叶斯JEPA（BJEPA），将预测信念分解为学习到的动态专家和模块化先验专家，通过专家乘积实现零样本任务迁移和约束满足。

Result: 理论证明VJEPA表示可以作为最优控制的充分信息状态，无需像素重建，并提供避免表示崩溃的正式保证。实验表明VJEPA和BJEPA能成功过滤高方差干扰因素，而生成基线方法会出现表示崩溃。

Conclusion: VJEPA为高维噪声环境中的可扩展、鲁棒、不确定性感知规划提供了基础框架，通过保持观察的似然无关性，同时支持原则性不确定性估计。

Abstract: Joint Embedding Predictive Architectures (JEPA) offer a scalable paradigm for self-supervised learning by predicting latent representations rather than reconstructing high-entropy observations. However, existing formulations rely on \textit{deterministic} regression objectives, which mask probabilistic semantics and limit its applicability in stochastic control. In this work, we introduce \emph{Variational JEPA (VJEPA)}, a \textit{probabilistic} generalization that learns a predictive distribution over future latent states via a variational objective. We show that VJEPA unifies representation learning with Predictive State Representations (PSRs) and Bayesian filtering, establishing that sequential modeling does not require autoregressive observation likelihoods. Theoretically, we prove that VJEPA representations can serve as sufficient information states for optimal control without pixel reconstruction, while providing formal guarantees for collapse avoidance. We further propose \emph{Bayesian JEPA (BJEPA)}, an extension that factorizes the predictive belief into a learned dynamics expert and a modular prior expert, enabling zero-shot task transfer and constraint (e.g. goal, physics) satisfaction via a Product of Experts. Empirically, through a noisy environment experiment, we demonstrate that VJEPA and BJEPA successfully filter out high-variance nuisance distractors that cause representation collapse in generative baselines. By enabling principled uncertainty estimation (e.g. constructing credible intervals via sampling) while remaining likelihood-free regarding observations, VJEPA provides a foundational framework for scalable, robust, uncertainty-aware planning in high-dimensional, noisy environments.

</details>


### [47] [Adaptive KDE for Real-Time Thresholding: Prioritized Queues for Financial Crime Investigation](https://arxiv.org/abs/2601.14473)
*Danny Butvinik,Nana Boateng,Achi Hackmon*

Main category: cs.LG

TL;DR: 提出一种自适应核密度估计方法，将风险分数流转换为多个审核队列，无需标签且支持实时处理


<details>
  <summary>Details</summary>
Motivation: 解决在明确摄入约束下将风险分数流转换为一个或多个审核队列的问题，避免使用top-K或手动调整阈值的方法

Method: 拟合在线自适应核密度估计到分数流，将密度转换为尾部质量曲线以满足容量约束，并将结果阈值"捕捉"到跨带宽检测到的持久密度谷

Result: 在合成、漂移、多模态流上，该方法实现了竞争性的容量遵循，同时减少了阈值抖动

Conclusion: 该方法无需标签，支持多队列路由，可实时操作，每个事件更新成本为O(G)，每个活动具有恒定内存

Abstract: We study the problem of converting a stream of risk scores into one or more review queues under explicit intake constraints[cite: 6]. Instead of top-$K$ or manually tuned cutoffs, we fit an online adaptive kernel density to the score stream, transform the density into a tail-mass curve to meet capacity, and ``snap'' the resulting cut to a persistent density valley detected across bandwidths[cite: 7]. The procedure is label-free, supports multi-queue routing, and operates in real time with sliding windows or exponential forgetting[cite: 8]. On synthetic, drifting, multimodal streams, the method achieves competitive capacity adherence while reducing threshold jitter[cite: 9]. Updates cost $O(G)$ per event with constant memory per activity

</details>


### [48] [GPU-accelerated simulated annealing based on p-bits with real-world device-variability modeling](https://arxiv.org/abs/2601.14476)
*Naoya Onizawa,Takahiro Hanyu*

Main category: cs.LG

TL;DR: 该研究开发了一个基于概率比特的GPU加速模拟退火框架，发现器件变异性不仅会降低还能增强算法性能，特别是在利用时序变异性时。


<details>
  <summary>Details</summary>
Motivation: 概率计算使用概率比特为复杂问题求解提供了高效替代方案，但新兴器件如磁隧道结引入的器件变异性通常被认为会负面影响计算性能。本研究旨在探索器件变异性对算法性能的实际影响。

Method: 开发了一个GPU加速的开源模拟退火框架，基于概率比特建模关键的器件变异性因素（时序、强度和偏移），以反映真实器件行为。通过CUDA模拟实现，在MAX-CUT基准测试上验证性能。

Result: 研究发现器件变异性不仅能降低还能增强算法性能，特别是利用时序变异性时。GPU实现相比CPU实现获得了两个数量级的加速，在800到20,000个节点的MAX-CUT问题上验证了可扩展性。

Conclusion: 该框架为概率计算研究提供了可扩展且易用的工具，能够推动优化算法在多个领域的应用，同时揭示了器件变异性在特定条件下对算法性能的积极影响。

Abstract: Probabilistic computing using probabilistic bits (p-bits) presents an efficient alternative to traditional CMOS logic for complex problem-solving, including simulated annealing and machine learning. Realizing p-bits with emerging devices such as magnetic tunnel junctions (MTJs) introduces device variability, which was expected to negatively impact computational performance. However, this study reveals an unexpected finding: device variability can not only degrade but also enhance algorithm performance, particularly by leveraging timing variability. This paper introduces a GPU-accelerated, open-source simulated annealing framework based on p-bits that models key device variability factors -timing, intensity, and offset- to reflect real-world device behavior. Through CUDA-based simulations, our approach achieves a two-order magnitude speedup over CPU implementations on the MAX-CUT benchmark with problem sizes ranging from 800 to 20,000 nodes. By providing a scalable and accessible tool, this framework aims to advance research in probabilistic computing, enabling optimization applications in diverse fields.

</details>


### [49] [Stabilizing autoregressive forecasts in chaotic systems via multi-rate latent recurrence](https://arxiv.org/abs/2601.14487)
*Mrigank Dhingra,Omer San*

Main category: cs.LG

TL;DR: MSR-HINE是一种用于混沌动力系统长期预测的分层隐式预测器，通过多尺度潜在先验和多速率循环模块显著提升了预测精度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 混沌动力系统的长期自回归预测面临误差快速放大和分布偏移的挑战，小的一步不准确性会累积成物理不一致的展开和大尺度统计特性的崩溃。

Method: MSR-HINE采用分层隐式预测器，结合多尺度潜在先验和多速率循环模块。在每个时间步，粗到细的循环状态生成潜在先验，隐式一步预测器通过多尺度潜在注入细化状态，门控融合与后验潜在强制尺度一致性更新，轻量级隐藏状态校正进一步对齐循环记忆与融合潜在。

Result: 在两个基准测试中表现优异：在Kuramoto-Sivashinsky系统中，将端到端RMSE降低62.8%（H=400），ACC从-0.155提升到0.828；在Lorenz-96系统中，RMSE降低27.0%（H=100），ACC从0.144提升到0.545。两个系统的ACC≥0.5可预测性时间范围都显著延长。

Conclusion: MSR-HINE架构能够在保持慢流形长期上下文的同时保留快速尺度变异性，有效缓解混沌展开中的误差累积，显著提升混沌动力系统的长期预测性能。

Abstract: Long-horizon autoregressive forecasting of chaotic dynamical systems remains challenging due to rapid error amplification and distribution shift: small one-step inaccuracies compound into physically inconsistent rollouts and collapse of large-scale statistics. We introduce MSR-HINE, a hierarchical implicit forecaster that augments multiscale latent priors with multi-rate recurrent modules operating at distinct temporal scales. At each step, coarse-to-fine recurrent states generate latent priors, an implicit one-step predictor refines the state with multiscale latent injections, and a gated fusion with posterior latents enforces scale-consistent updates; a lightweight hidden-state correction further aligns recurrent memories with fused latents. The resulting architecture maintains long-term context on slow manifolds while preserving fast-scale variability, mitigating error accumulation in chaotic rollouts. Across two canonical benchmarks, MSR-HINE yields substantial gains over a U-Net autoregressive baseline: on Kuramoto-Sivashinsky it reduces end-horizon RMSE by 62.8% at H=400 and improves end-horizon ACC by +0.983 (from -0.155 to 0.828), extending the ACC >= 0.5 predictability horizon from 241 to 400 steps; on Lorenz-96 it reduces RMSE by 27.0% at H=100 and improves end horizon ACC by +0.402 (from 0.144 to 0.545), extending the ACC >= 0.5 horizon from 58 to 100 steps.

</details>


### [50] [On the Runway Cascade of Transformers for Language Modeling](https://arxiv.org/abs/2601.14522)
*Hunjae Lee,Corey Clark*

Main category: cs.LG

TL;DR: 本文提出"跑道感知重连"机制，通过显式地将间接信息传播路径（跑道）整合到直接注意力中，解决因果变换器中信息传播模式不匹配的问题，无需额外参数即可提升语言建模、信息检索和外推能力。


<details>
  <summary>Details</summary>
Motivation: 因果变换器中存在直接注意力路径和通过中间令牌形成的间接路径（跑道）两种信息传播模式。最近研究发现，这两种模式的不匹配可能导致某些故障模式，造成冗余和无关信息在令牌表示中传播，即使注意力模式已充分学习。

Method: 提出跑道感知重连机制，根据每个令牌的跑道景观摘要重新连接其注意力模式。该方法将跑道上下文直接整合到每个令牌的直接路径注意力中，使模型能够感知累积的表征影响，实现更平衡的信息传播，无需额外参数且可与标准注意力机制无缝集成。

Result: 实验表明，重连后的变换器在通用语言建模方面获得稳定改进，同时在信息检索和外推能力方面相比标准变换器表现出明显更强的性能。

Conclusion: 跑道感知重连机制通过显式整合间接信息传播路径，有效解决了因果变换器中信息传播模式不匹配的问题，提升了模型性能，且具有参数高效和易于集成的优势。

Abstract: In decoder-only (causal) transformers, the computation graph created by causal masking routes information through both direct-path attention and indirect paths formed by intermediate tokens. We denote these indirect paths between token pairs as their runways. We argue that certain failure modes of causal transformers as observed by a growing body of recent works are likely exacerbated by a misalignment between these two information propagation modes. We formalize runway cascade as a phenomenon whereby this misalignment results in redundancies and irrelevant information cascading to token representations despite adequately learned attention patterns. As a solution, we propose runway-aware rewiring as a more explicit way of incorporating runway context directly into each token's direct-path attention. This mechanism re-wires the attention pattern for each token based on a summary of its runway landscape, enabling awareness of accumulating representational influences and allowing for more balanced information propagation. Our proposed methodology introduces no additional parameters and can seamlessly be integrated into standard attention mechanism. Empirically, our rewired transformer results in steady improvements in general language modeling as well as noticeably stronger information retrieval and extrapolation abilities compared to standard transformers.

</details>


### [51] [Search over Self-Edit Strategies for LLM Adaptation](https://arxiv.org/abs/2601.14532)
*Alistair Cheong,Haolin Cong,Tyler Yang,Dustin Miao*

Main category: cs.LG

TL;DR: 该研究探索了让LLM根据任务反馈自主决定如何更新权重，在SEAL框架中允许模型生成自己的自编辑模板，以控制训练数据和超参数。


<details>
  <summary>Details</summary>
Motivation: 许多基于LLM的开放式搜索系统会冻结提出改进建议的基础模型，这可能限制长期进展。现有方法通常需要手动指定更新策略，因此研究是否能让LLM使用任务反馈自主决定权重更新方式。

Method: 在SEAL框架中放宽固定人工模板限制，允许模型生成自编辑模板，从而让模型控制训练数据和NTP超参数。研究了两种变体：无存档版本和基于轻量级历史模板存档的版本。在SQuAD数据集上使用Qwen3-8B进行实验。

Result: 无存档变体表现与较弱的"Implications"基线相当，存档变体优于"Implications"并接近最强的人工设计"Rewrite"基线但未超越。分析发现朴素存档能提供短期鲁棒性，但也会加速同质化，可能需要显式新颖性压力才能超越人工优化策略。

Conclusion: LLM能够使用任务反馈自主决定权重更新策略，但需要更精细的机制来避免探索崩溃和同质化，可能需要显式新颖性压力才能持续超越人工优化策略。

Abstract: Many LLM-based open-ended search systems freeze the foundation model that proposes improvements to existing solutions, which may bottleneck long-run progress. Recent work has explored updating the proposal model at test time [arXiv:2511.23473], but the update strategy is still typically hand-specified. Therefore, this study investigated whether an LLM can use task feedback to decide how it should update its weights. For tractability, we focused on the simpler case where there is only one round of self-improvement, and restricted the update operator to self-supervised next token prediction (NTP), leaving the model freedom in choosing its training data and key NTP hyperparameters. Using the Self-Adapting Language Models (SEAL) [arXiv:2506.10943] framework as a testbed, we relaxed its fixed human template constraint and allowed the model to generate its own self-edit templates, thereby giving it more control over its training data and hyperparameters. Two variants were studied, differing in whether template generation was conditioned on a lightweight archive of past templates. In SEAL's Single-Passage Knowledge Incorporation setting with Qwen3-8B on SQuAD [arXiv:1606.05250], the no-archive variant performed comparably to the weaker "Implications" baseline, while the archive variant outperformed "Implications" and approached the strongest human-designed "Rewrite" baseline without surpassing it. Further analysis of collapse in the model's exploration revealed that a naive archive can confer some short-term robustness but can also accelerate homogenization, suggesting that explicit novelty pressure may be required to consistently advance beyond carefully optimized human strategies. Our code is available at https://github.com/cheongalc/search-self-edit-strategies .

</details>


### [52] [QMC: Efficient SLM Edge Inference via Outlier-Aware Quantization and Emergent Memories Co-Design](https://arxiv.org/abs/2601.14549)
*Nilesh Prasad Pandey,Jangseon Park,Onat Gungor,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: QMC提出了一种免重训练的量化与内存协同设计方法，通过识别SLM中的内点和离群权重，分别存储在ReRAM和MRAM中，显著提升了边缘设备上小语言模型的推理效率。


<details>
  <summary>Details</summary>
Motivation: 在边缘平台上部署小语言模型面临内存、延迟和能耗限制。传统量化方法受新兴非易失性存储器设备噪声影响，而传统内存层次结构（SRAM、DRAM、Flash）在同时处理静态权重和动态KV缓存时存在效率瓶颈，需要针对LLM推理的混合内存组织方案。

Method: 提出QMC（Outlier-aware Quantization with Memory Co-design）方法：1）识别小语言模型中的内点和离群权重；2）将内点权重存储在紧凑的多级ReRAM中；3）将关键离群权重保存在高精度片上MRAM中；4）无需重新训练即可实现量化与内存架构的协同设计。

Result: 在语言建模和推理基准测试中，QMC优于或匹配使用先进算法和混合数据格式的最先进量化方法。在最新的边缘AI平台上，相比FP16，QMC将内存使用减少6.3-7.3倍，外部数据传输减少7.6倍，能耗降低11.7倍，延迟降低12.5倍。

Conclusion: QMC是一种可扩展、可直接部署的协同设计方案，通过离群感知量化和异构内存架构，有效解决了边缘设备上小语言模型推理的内存、带宽、能耗和延迟挑战，为高效的设备端推理提供了实用解决方案。

Abstract: Deploying Small Language Models (SLMs) on edge platforms is critical for real-time, privacy-sensitive generative AI, yet constrained by memory, latency, and energy budgets. Quantization reduces model size and cost but suffers from device noise in emerging non-volatile memories, while conventional memory hierarchies further limit efficiency. SRAM provides fast access but has low density, DRAM must simultaneously accommodate static weights and dynamic KV caches, which creates bandwidth contention, and Flash, although dense, is primarily used for initialization and remains inactive during inference. These limitations highlight the need for hybrid memory organizations tailored to LLM inference. We propose Outlier-aware Quantization with Memory Co-design (QMC), a retraining-free quantization with a novel heterogeneous memory architecture. QMC identifies inlier and outlier weights in SLMs, storing inlier weights in compact multi-level Resistive-RAM (ReRAM) while preserving critical outliers in high-precision on-chip Magnetoresistive-RAM (MRAM), mitigating noise-induced degradation. On language modeling and reasoning benchmarks, QMC outperforms and matches state-of-the-art quantization methods using advanced algorithms and hybrid data formats, while achieving greater compression under both algorithm-only evaluation and realistic deployment settings. Specifically, compared against SoTA quantization methods on the latest edge AI platform, QMC reduces memory usage by 6.3x-7.3x, external data transfers by 7.6x, energy by 11.7x, and latency by 12.5x when compared to FP16, establishing QMC as a scalable, deployment-ready co-design for efficient on-device inference.

</details>


### [53] [Counterfactual Modeling with Fine-Tuned LLMs for Health Intervention Design and Sensor Data Augmentation](https://arxiv.org/abs/2601.14590)
*Shovito Barua Soumma,Asiful Arefeen,Stephanie M. Carpenter,Melanie Hingle,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: 该研究评估了使用大语言模型生成反事实解释，在临床数据集中验证了其干预质量和数据增强效果，发现微调后的LLaMA-3.1-8B表现最佳。


<details>
  <summary>Details</summary>
Motivation: 反事实解释通过识别最小可操作变化来改变模型预测，可用于异常预防和数据增强。研究旨在评估大语言模型在生成高质量反事实解释方面的潜力，特别是在临床健康领域的应用。

Method: 使用GPT-4（零样本和少样本）以及两个开源模型BioMistral-7B和LLaMA-3.1-8B，在预训练和微调配置下生成反事实解释。基于多模态AI-READI临床数据集，从干预质量、特征多样性和增强效果三个维度进行评估，并与DiCE、CFNOW、NICE等优化基线方法对比。

Result: 微调后的LLMs，特别是LLaMA-3.1-8B，生成的反事实解释具有高可信度（高达99%）、强有效性（高达0.99）和现实可修改的特征调整。在标签稀缺场景下，LLM生成的反事实用于数据增强可平均恢复20%的F1分数，优于传统优化方法。

Conclusion: LLM驱动的反事实解释在可解释干预设计和数据高效模型训练方面具有巨大潜力，特别是在传感器数字健康领域，SenseCF框架通过微调LLM生成有效反事实并补充不平衡数据集，提升了模型鲁棒性和预测性能。

Abstract: Counterfactual explanations (CFEs) provide human-centric interpretability by identifying the minimal, actionable changes required to alter a machine learning model's prediction. Therefore, CFs can be used as (i) interventions for abnormality prevention and (ii) augmented data for training robust models. We conduct a comprehensive evaluation of CF generation using large language models (LLMs), including GPT-4 (zero-shot and few-shot) and two open-source models-BioMistral-7B and LLaMA-3.1-8B, in both pretrained and fine-tuned configurations. Using the multimodal AI-READI clinical dataset, we assess CFs across three dimensions: intervention quality, feature diversity, and augmentation effectiveness. Fine-tuned LLMs, particularly LLaMA-3.1-8B, produce CFs with high plausibility (up to 99%), strong validity (up to 0.99), and realistic, behaviorally modifiable feature adjustments. When used for data augmentation under controlled label-scarcity settings, LLM-generated CFs substantially restore classifier performance, yielding an average 20% F1 recovery across three scarcity scenarios. Compared with optimization-based baselines such as DiCE, CFNOW, and NICE, LLMs offer a flexible, model-agnostic approach that generates more clinically actionable and semantically coherent counterfactuals. Overall, this work demonstrates the promise of LLM-driven counterfactuals for both interpretable intervention design and data-efficient model training in sensor-based digital health.
  Impact: SenseCF fine-tunes an LLM to generate valid, representative counterfactual explanations and supplement minority class in an imbalanced dataset for improving model training and boosting model robustness and predictive performance

</details>


### [54] [Rethinking Reinforcement fine-tuning of LLMs: A Multi-armed Bandit Learning Perspective](https://arxiv.org/abs/2601.14599)
*Xiao Hu,Hong Xie,Tao Tan,Defu Lian,Jianyu Han*

Main category: cs.LG

TL;DR: 该论文通过提出自下而上的实验流程，系统分析强化学习微调LLM中的各种启发式方法，揭示各设计选择的作用和瓶颈


<details>
  <summary>Details</summary>
Motivation: 当前LLM强化微调领域存在大量启发式方法但缺乏系统性理解，存在相互矛盾的主张。需要回答两个基本问题：1) 每个优化选择的作用是什么？2) 哪些是瓶颈？

Method: 提出自下而上的实验流程：底层采用极简配置（单一训练数据、每轮一次rollout、奖励直接作为学习信号），将其与具有极大离散动作空间的多臂老虎机学习联系起来。然后逐层扩展配置，检验每个设计选择的作用

Result: 在三个LLM和两个推理数据集上的实验不仅揭示了设计选择的新理解，还为该领域提供了重要见解

Conclusion: 通过系统性的实验分析，澄清了LLM强化微调中各种设计选择的作用和瓶颈，为该领域提供了理论基础和实践指导

Abstract: A large number of heuristics have been proposed to optimize the reinforcement fine-tuning of LLMs. However, inconsistent claims are made from time to time, making this area elusive. Reflecting on this situation, two fundamental questions still lack a clear understanding: 1) what is the role of each optimizing choice? 2) which ones are the bottlenecks? This paper aims to shed light on them, and it faces the challenge of several entangled confounding factors in the fine-tuning process. To tackle this challenge, we propose a bottom-up experiment pipeline. The bottom layer is composed of a minimalist configuration: one training data, one rollout per round and the reward directly serve as the learning signal without advantage function design. This minimalist configuration connects to multi-armed bandit learning with extremely large discrete action space, which offers theories to corroborate the experiment findings. The up procedure of the experiment pipeline expanding the minimalist configuration layer by layer, examining the role of each design choice. Experimental results on three LLMs and two reasoning datasets not only reveal new understanding of the design choice but also yield essential insights to shape the area.

</details>


### [55] [Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum](https://arxiv.org/abs/2601.14603)
*Jingru Li,Yibo Fan,Huan Li*

Main category: cs.LG

TL;DR: Muon通过正交动量更新加速LLM预训练，提出了Muon-NSR和Muon-VS两种变体，在GPT-2和LLaMA预训练中比AdamW和Muon基线收敛更快且验证损失更低。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型预训练计算成本高昂，优化器效率成为重要实践考虑。现有Adam优化器可视为方差自适应符号更新算法，但仍有改进空间。

Method: 提出Muon优化器，通过正交动量更新作为矩阵级元素符号算子。进一步提出两个变体：Muon-NSR应用信噪比调制，Muon-VS执行基于方差的缩放而不引入额外超参数。

Result: 在GPT-2和LLaMA预训练实验中，Muon-NSR和Muon-VS加速收敛，比调优良好的AdamW和Muon基线持续获得更低的验证损失。例如在LLaMA-1.2B模型上，达到目标验证损失所需的迭代次数减少了1.36倍。

Conclusion: Muon优化器及其变体通过正交动量更新和方差自适应归一化，有效加速了LLM预训练过程，提高了优化器效率。

Abstract: Large Language Models (LLMs) achieve competitive performance across diverse natural language processing (NLP) tasks, yet pretraining is computationally demanding, making optimizer efficiency an important practical consideration. Muon accelerates LLM pretraining via orthogonal momentum updates that serve as a matrix analogue of the element-wise sign operator. Motivated by the recent perspective that Adam is a variance-adaptive sign update algorithm, we propose two variants of Muon, Muon-NSR and Muon-VS, which apply variance-adaptive normalization to momentum before orthogonalization. Muon-NSR applies noise-to-signal ratio (NSR) modulation, while Muon-VS performs variance-based scaling without introducing additional hyperparameters. Experiments on GPT-2 and LLaMA pretraining demonstrate that our proposed methods accelerate convergence and consistently achieve lower validation loss than both competitive, well-tuned AdamW and Muon baselines. For example, on the LLaMA-1.2B model, Muon-NSR and Muon-VS reduce the iterations required to reach the target validation loss by $1.36\times$ relative to the well-tuned Muon following the recent benchmark.

</details>


### [56] [Efficient Imputation for Patch-based Missing Single-cell Data via Cluster-regularized Optimal Transport](https://arxiv.org/abs/2601.14653)
*Yuyu Liu,Jiannan Yang,Ziyang Yu,Weishen Pan,Fei Wang,Tengfei Ma*

Main category: cs.LG

TL;DR: CROT是一种基于最优传输的插补算法，专门处理表格数据中的块状缺失数据，在保持高精度的同时显著减少运行时间，适用于大规模单细胞测序数据集。


<details>
  <summary>Details</summary>
Motivation: 单细胞测序数据中的缺失数据给生物信息分析带来挑战，现有插补方法通常假设数据均匀且完整，难以处理大块缺失数据的情况。

Method: 提出CROT算法，基于最优传输理论设计，专门处理表格格式中的块状缺失数据，能够有效捕捉存在显著缺失情况下的底层数据结构。

Result: CROT在保持优异插补精度的同时，显著减少了运行时间，证明其在大规模数据集上的可扩展性和效率优势。

Conclusion: CROT为异质高维数据集中的结构化数据缺失提供了稳健的插补解决方案，解决了生物和临床数据分析中的关键挑战。

Abstract: Missing data in single-cell sequencing datasets poses significant challenges for extracting meaningful biological insights. However, existing imputation approaches, which often assume uniformity and data completeness, struggle to address cases with large patches of missing data. In this paper, we present CROT, an optimal transport-based imputation algorithm designed to handle patch-based missing data in tabular formats. Our approach effectively captures the underlying data structure in the presence of significant missingness. Notably, it achieves superior imputation accuracy while significantly reducing runtime, demonstrating its scalability and efficiency for large-scale datasets. This work introduces a robust solution for imputation in heterogeneous, high-dimensional datasets with structured data absence, addressing critical challenges in both biological and clinical data analysis. Our code is available at Anomalous Github.

</details>


### [57] [Beyond Denial-of-Service: The Puppeteer's Attack for Fine-Grained Control in Ranking-Based Federated Learning](https://arxiv.org/abs/2601.14687)
*Zhihao Chen,Zirui Gong,Jianting Ning,Yanjun Zhang,Leo Yu Zhang*

Main category: cs.LG

TL;DR: FRL通过基于排名的离散更新机制增强联邦学习的安全性，但仍面临新型细粒度控制攻击ECA的威胁，该攻击能精确控制目标模型精度而不被检测。


<details>
  <summary>Details</summary>
Motivation: 联邦排名学习（FRL）作为联邦学习的一种新范式，因其离散的基于排名的更新机制而具有抗模型投毒攻击的潜力。然而，尽管FRL显著减少了攻击面，作者发现它仍然容易受到新型细粒度控制攻击的威胁，因此需要研究这种攻击方法并揭示其安全漏洞。

Method: 提出了边缘控制攻击（ECA），这是首个针对基于排名的联邦学习框架的细粒度控制攻击。ECA分为两个阶段：1）识别和操纵上升和下降边缘，使全局模型与目标模型对齐；2）扩大选择边界间隙，使全局模型稳定在目标精度水平。攻击旨在精确降低竞争对手的精度到任意目标水平，同时保持正常的收敛轨迹以避免检测。

Result: 在7个基准数据集和9种拜占庭鲁棒聚合规则上的广泛实验表明，ECA实现了细粒度精度控制，平均误差仅为0.224%，比基线方法提升了高达17倍。攻击能够在不引起明显异常的情况下精确控制模型精度。

Conclusion: 尽管FRL通过离散排名机制增强了安全性，但仍存在ECA这样的细粒度控制攻击漏洞。研究结果强调了需要针对高级投毒攻击开发更强的防御机制，以保护联邦学习系统的安全。

Abstract: Federated Rank Learning (FRL) is a promising Federated Learning (FL) paradigm designed to be resilient against model poisoning attacks due to its discrete, ranking-based update mechanism. Unlike traditional FL methods that rely on model updates, FRL leverages discrete rankings as a communication parameter between clients and the server. This approach significantly reduces communication costs and limits an adversary's ability to scale or optimize malicious updates in the continuous space, thereby enhancing its robustness. This makes FRL particularly appealing for applications where system security and data privacy are crucial, such as web-based auction and bidding platforms. While FRL substantially reduces the attack surface, we demonstrate that it remains vulnerable to a new class of local model poisoning attack, i.e., fine-grained control attacks. We introduce the Edge Control Attack (ECA), the first fine-grained control attack tailored to ranking-based FL frameworks. Unlike conventional denial-of-service (DoS) attacks that cause conspicuous disruptions, ECA enables an adversary to precisely degrade a competitor's accuracy to any target level while maintaining a normal-looking convergence trajectory, thereby avoiding detection. ECA operates in two stages: (i) identifying and manipulating Ascending and Descending Edges to align the global model with the target model, and (ii) widening the selection boundary gap to stabilize the global model at the target accuracy. Extensive experiments across seven benchmark datasets and nine Byzantine-robust aggregation rules (AGRs) show that ECA achieves fine-grained accuracy control with an average error of only 0.224%, outperforming the baseline by up to 17x. Our findings highlight the need for stronger defenses against advanced poisoning attacks. Our code is available at: https://github.com/Chenzh0205/ECA

</details>


### [58] [CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation](https://arxiv.org/abs/2601.14695)
*Yutong Chen,Jiandong Gao,Ji Wu*

Main category: cs.LG

TL;DR: 提出CoScale-RL方法，通过扩展解决方案和rollout计算来提高大型推理模型的训练稳定性和效率


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在困难问题或弱基础模型上训练不稳定且不可预测，当前的后训练扩展策略仍有改进空间

Method: 1) 扩展解决方案：为每个问题收集多个解决方案而非简单扩大数据集；2) 扩展rollout计算以稳定强化学习；3) 使用Re-distillation模型合并技术维持计算效率

Result: 在四个基准测试上平均获得3.76倍准确率提升，显著提高数据和计算效率，无需大量监督微调数据集即可提升模型能力边界

Conclusion: CoScale-RL为改进大型推理模型的推理能力提供了新的扩展方向

Abstract: Training Large Reasoning Model (LRM) is usually unstable and unpredictable, especially on hard problems or weak foundation models. We found that the current post-training scaling strategy can still improve on these cases. We propose CoScale-RL, a novel scaling strategy with better data and computational efficiency. We first scale up solutions to make problems solvable. The core idea is to collect multiple solutions for each problem, rather than simply enlarging the dataset. Then, we scale up rollout computation to stabilize Reinforcement Learning. We further leverage a model merge technique called Re-distillation to sustain or even improve computational efficiency when scaling up. Our method significantly improves data and computational efficiency, with an average 3.76$\times$ accuracy improvement on four benchmarks. CoScale-RL is able to improve an LRM's ability boundary without an extensive SFT dataset. Our method provides a new scaling direction to further improve LRM's reasoning ability.

</details>


### [59] [Case-Guided Sequential Assay Planning in Drug Discovery](https://arxiv.org/abs/2601.14710)
*Tianchi Chen,Jan Bima,Sean L. Wu,Otto Ritter,Bingjia Yang,Xiang Yu*

Main category: cs.LG

TL;DR: 提出IBMDP框架，用于药物发现中无模拟器的实验序列优化，通过隐式贝叶斯模型和历史数据相似性实现高效规划，相比传统方法节省92%资源。


<details>
  <summary>Details</summary>
Motivation: 药物发现中的实验序列规划面临严重不确定性和资源约束，标准强化学习缺乏环境模拟器或转移数据，只能依赖静态历史数据库。

Method: 引入隐式贝叶斯马尔可夫决策过程（IBMDP），构建基于案例引导的隐式转移动态模型，使用相似历史结果形成非参数信念分布，通过贝叶斯信念更新和集成MCTS规划生成稳定策略。

Result: 在真实世界CNS药物发现任务中，IBMDP相比现有启发式方法减少92%资源消耗；在合成环境中，与可计算最优策略的匹配度显著高于确定性值迭代替代方案。

Conclusion: IBMDP为数据丰富但模拟器稀缺领域的顺序实验设计提供了实用解决方案，其集成规划器优于基于相同相似性模型的确定性值迭代方法。

Abstract: Optimally sequencing experimental assays in drug discovery is a high-stakes planning problem under severe uncertainty and resource constraints. A primary obstacle for standard reinforcement learning (RL) is the absence of an explicit environment simulator or transition data $(s, a, s')$; planning must rely solely on a static database of historical outcomes. We introduce the Implicit Bayesian Markov Decision Process (IBMDP), a model-based RL framework designed for such simulator-free settings. IBMDP constructs a case-guided implicit model of transition dynamics by forming a nonparametric belief distribution using similar historical outcomes. This mechanism enables Bayesian belief updating as evidence accumulates and employs ensemble MCTS planning to generate stable policies that balance information gain toward desired outcomes with resource efficiency. We validate IBMDP through comprehensive experiments. On a real-world central nervous system (CNS) drug discovery task, IBMDP reduced resource consumption by up to 92\% compared to established heuristics while maintaining decision confidence. To rigorously assess decision quality, we also benchmarked IBMDP in a synthetic environment with a computable optimal policy. Our framework achieves significantly higher alignment with this optimal policy than a deterministic value iteration alternative that uses the same similarity-based model, demonstrating the superiority of our ensemble planner. IBMDP offers a practical solution for sequential experimental design in data-rich but simulator-poor domains.

</details>


### [60] [PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning](https://arxiv.org/abs/2601.14716)
*Yao Lu,Dengdong Fan,Jianzheng Nie,Fan Xu,Jie Chen,Bin Zhou,Yonghong Tian*

Main category: cs.LG

TL;DR: PCL-Reasoner-V1.5是基于Qwen2.5-32B构建的320亿参数数学推理大语言模型，采用监督微调加强化学习训练，创新性地使用离线RL方法提升训练稳定性和效率，在AIME数学竞赛数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个专门用于数学推理的高性能大语言模型，解决现有在线强化学习方法（如GRPO）在训练稳定性和效率方面的不足，探索离线强化学习作为更优的训练范式。

Method: 基于Qwen2.5-32B架构构建320亿参数模型，采用两阶段训练：1）监督微调（SFT）阶段；2）强化学习（RL）阶段，创新性地使用离线RL方法替代传统的在线RL方法，所有实验在华为昇腾910C NPU上进行。

Result: 在AIME 2024数据集上达到90.9%的平均准确率，在AIME 2025数据集上达到85.6%的平均准确率，在基于Qwen2.5-32B后训练的模型中达到最先进的性能，证明了离线RL方法的优越性。

Conclusion: 离线强化学习为LLM的推理能力提升提供了一个稳定且高效的训练范式，PCL-Reasoner-V1.5在数学推理任务上表现出色，验证了该方法的有效性。

Abstract: We present PCL-Reasoner-V1.5, a 32-billion-parameter large language model (LLM) for mathematical reasoning. The model is built upon Qwen2.5-32B and refined via supervised fine-tuning (SFT) followed by reinforcement learning (RL). A central innovation is our proposed offline RL method, which provides superior training stability and efficiency over standard online RL methods such as GRPO. Our model achieves state-of-the-art performance among models post-trained on Qwen2.5-32B, attaining average accuracies of 90.9% on AIME 2024 and 85.6% on AIME 2025. Our work demonstrates offline RL as a stable and efficient paradigm for advancing reasoning in LLMs. All experiments were conducted on Huawei Ascend 910C NPUs.

</details>


### [61] [FSX: Message Flow Sensitivity Enhanced Structural Explainer for Graph Neural Networks](https://arxiv.org/abs/2601.14730)
*Bizu Feng,Zhimu Yang,Shaode Yu,Zixin Hu*

Main category: cs.LG

TL;DR: FSX是一个新颖的GNN可解释性框架，通过结合内部消息流分析和合作博弈方法，高效生成高保真度的结构解释，揭示模型预测背后的结构逻辑。


<details>
  <summary>Details</summary>
Motivation: 现有GNN可解释性方法存在权衡：基于梯度的方法计算高效但忽略结构交互，而博弈论方法能捕捉交互但计算开销大且可能偏离模型真实推理路径。需要一种能兼顾效率和准确性的解释方法。

Method: FSX采用混合框架：1）通过流敏感性分析识别关键消息流（单次前向传播中模拟局部节点扰动）；2）将敏感度排名的流投影到输入图定义语义子图；3）在每个子图中进行流感知合作博弈，通过类Shapley值公平评估节点贡献，同时考虑节点特征重要性和其在维持/破坏关键流中的作用。

Result: 在多个数据集和GNN架构上的广泛评估表明，FSX实现了优越的解释保真度，同时显著减少运行时间，并能前所未有地洞察模型预测背后的结构逻辑。

Conclusion: FSX成功解决了现有GNN可解释性方法的权衡问题，通过结合内部消息流分析和外部图数据的合作博弈方法，提供高效、高保真的结构解释，揭示了重要子结构如何通过控制关键内部计算路径的稳定性来施加影响。

Abstract: Despite the widespread success of Graph Neural Networks (GNNs), understanding the reasons behind their specific predictions remains challenging. Existing explainability methods face a trade-off that gradient-based approaches are computationally efficient but often ignore structural interactions, while game-theoretic techniques capture interactions at the cost of high computational overhead and potential deviation from the model's true reasoning path. To address this gap, we propose FSX (Message Flow Sensitivity Enhanced Structural Explainer), a novel hybrid framework that synergistically combines the internal message flows of the model with a cooperative game approach applied to the external graph data. FSX first identifies critical message flows via a novel flow-sensitivity analysis: during a single forward pass, it simulates localized node perturbations and measures the resulting changes in message flow intensities. These sensitivity-ranked flows are then projected onto the input graph to define compact, semantically meaningful subgraphs. Within each subgraph, a flow-aware cooperative game is conducted, where node contributions are evaluated fairly through a Shapley-like value that incorporates both node-feature importance and their roles in sustaining or destabilizing the identified critical flows. Extensive evaluation across multiple datasets and GNN architectures demonstrates that FSX achieves superior explanation fidelity with significantly reduced runtime, while providing unprecedented insights into the structural logic underlying model predictions--specifically, how important sub-structures exert influence by governing the stability of key internal computational pathways.

</details>


### [62] [Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models](https://arxiv.org/abs/2601.14758)
*Injin Kong,Hyoungjoon Lee,Yohan Jo*

Main category: cs.LG

TL;DR: 论文通过对比分析自回归模型(ARMs)与其对应的掩码扩散模型(MDMs)，揭示了扩散后训练引发的"机制转变"：MDMs在处理局部因果依赖任务时保留自回归电路，但在全局规划任务中放弃初始路径，进行重新布线并增强早期层处理。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索将预训练自回归模型后训练为掩码扩散模型这一成本效益策略引发的内部算法转变。核心问题是：后训练的MDMs是否真正获得了双向推理能力，还是仅仅重新包装了自回归启发式方法。

Method: 采用对比电路分析方法，比较自回归模型(ARMs)与其对应的掩码扩散模型(MDMs)。分析关注任务结构性质对机制转变的影响，从结构和语义两个维度进行考察。

Result: 研究发现：1) 结构上，对于局部因果依赖主导的任务，MDMs基本保留自回归电路；对于全局规划任务，MDMs放弃初始路径，表现出明显的重新布线特征，特别是早期层处理增加。2) 语义上，观察到从ARMs中尖锐、局部化的专业化向MDMs中分布式集成的转变。

Conclusion: 扩散后训练不仅仅是调整模型参数，而是从根本上重新组织内部计算以支持非顺序的全局规划。这表明MDMs确实获得了真正的双向推理能力，而不仅仅是重新包装自回归启发式方法。

Abstract: Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic "mechanism shift" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning.

</details>


### [63] [Anytime Optimal Decision Tree Learning with Continuous Features](https://arxiv.org/abs/2601.14765)
*Harold Kiossou,Pierre Schaus,Siegfried Nijssen*

Main category: cs.LG

TL;DR: 提出了一种基于有限差异搜索的决策树学习算法，改善了现有最优决策树算法在连续特征上的实时性能


<details>
  <summary>Details</summary>
Motivation: 现有最优决策树算法在处理连续特征时，虽然能找到最优解，但深度优先搜索策略导致实时性能差，早期中断时得到的树往往高度不平衡且次优

Method: 采用有限差异搜索策略，将计算努力更均匀地分配到整个树结构中，而不是像深度优先搜索那样先完全优化左子树再探索右子树

Result: 实验结果表明，该方法在实时性能方面优于现有算法，在任何中断点都能提供高质量的决策树

Conclusion: 提出的有限差异搜索方法解决了现有最优决策树算法在处理连续特征时的实时性能问题，实现了既完整又具有良好实时性能的决策树学习

Abstract: In recent years, significant progress has been made on algorithms for learning optimal decision trees, primarily in the context of binary features. Extending these methods to continuous features remains substantially more challenging due to the large number of potential splits for each feature. Recently, an elegant exact algorithm was proposed for learning optimal decision trees with continuous features; however, the rapidly increasing computational time limits its practical applicability to shallow depths (typically 3 or 4). It relies on a depth-first search optimization strategy that fully optimizes the left subtree of each split before exploring the corresponding right subtree. While effective in finding optimal solutions given sufficient time, this strategy can lead to poor anytime behavior: when interrupted early, the best-found tree is often highly unbalanced and suboptimal. In such cases, purely greedy methods such as C4.5 may, paradoxically, yield better solutions. To address this limitation, we propose an anytime, yet complete approach leveraging limited discrepancy search, distributing the computational effort more evenly across the entire tree structure, and thus ensuring that a high-quality decision tree is available at any interruption point. Experimental results show that our approach outperforms the existing one in terms of anytime performance.

</details>


### [64] [Statistical Learning Theory for Distributional Classification](https://arxiv.org/abs/2601.14818)
*Christian Fiedler*

Main category: cs.LG

TL;DR: 该论文研究在分布输入的两阶段采样设置下的监督学习问题，特别关注使用支持向量机（SVM）和核均值嵌入（KME）进行分类的理论分析，建立了新的oracle不等式、一致性结果和学习率分析。


<details>
  <summary>Details</summary>
Motivation: 在基于学习的医学筛查或因果学习等应用中，输入是概率分布，但在学习阶段只能获得这些分布的样本而非分布本身。现有方法使用核均值嵌入将分布嵌入希尔伯特空间，然后应用SVM等标准核方法，但缺乏充分的理论分析。

Method: 采用核均值嵌入将分布或样本嵌入希尔伯特空间，然后应用支持向量机进行分类。建立了新的理论分析框架，包括oracle不等式、一致性证明和学习率分析。特别针对使用铰链损失和高斯核的SVM，提出了噪声假设的新变体。

Result: 建立了新的oracle不等式，推导了一致性结果和学习率。针对高斯核和铰链损失的SVM，在提出的噪声假设下获得了学习率。开发了高斯核在希尔伯特空间上的新特征空间表示等独立有用的技术工具。

Conclusion: 该工作为分布输入的两阶段采样设置下的SVM分类提供了系统的理论分析框架，建立了理论保证并开发了有用的技术工具，对核方法在分布数据学习中的应用具有重要意义。

Abstract: In supervised learning with distributional inputs in the two-stage sampling setup, relevant to applications like learning-based medical screening or causal learning, the inputs (which are probability distributions) are not accessible in the learning phase, but only samples thereof. This problem is particularly amenable to kernel-based learning methods, where the distributions or samples are first embedded into a Hilbert space, often using kernel mean embeddings (KMEs), and then a standard kernel method like Support Vector Machines (SVMs) is applied, using a kernel defined on the embedding Hilbert space. In this work, we contribute to the theoretical analysis of this latter approach, with a particular focus on classification with distributional inputs using SVMs. We establish a new oracle inequality and derive consistency and learning rate results. Furthermore, for SVMs using the hinge loss and Gaussian kernels, we formulate a novel variant of an established noise assumption from the binary classification literature, under which we can establish learning rates. Finally, some of our technical tools like a new feature space for Gaussian kernels on Hilbert spaces are of independent interest.

</details>


### [65] [From Observation to Prediction: LSTM for Vehicle Lane Change Forecasting on Highway On/Off-Ramps](https://arxiv.org/abs/2601.14848)
*Mohamed Abouras,Catherine M. Elias*

Main category: cs.LG

TL;DR: 该研究使用多层LSTM架构，基于无人机数据集预测高速公路匝道区域的车辆行为，在4秒预测范围内取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 高速公路匝道区域（上下匝道）是研究较少的道路路段，这些区域引入了更高程度的交通交互变化。预测这些区域的车辆行为可以减少不确定性影响并提高道路安全性。

Method: 使用多层LSTM（长短期记忆）架构训练匝道区域模型，基于ExiD无人机数据集。研究比较了匝道区域与直线高速公路路段的差异，测试了不同的预测时间范围和不同模型工作流程。

Result: 结果显示在最多4秒的预测时间范围内表现良好：匝道区域的最大预测准确率约为76%，而一般高速公路场景的最大预测准确率达到94%。

Conclusion: 多层LSTM架构在预测高速公路匝道区域车辆行为方面显示出巨大潜力，特别是在4秒以内的预测范围内，这有助于提高道路安全和减少交通不确定性。

Abstract: On and off-ramps are understudied road sections even though they introduce a higher level of variation in highway interactions. Predicting vehicles' behavior in these areas can decrease the impact of uncertainty and increase road safety. In this paper, the difference between this Area of Interest (AoI) and a straight highway section is studied. Multi-layered LSTM architecture to train the AoI model with ExiD drone dataset is utilized. In the process, different prediction horizons and different models' workflow are tested. The results show great promise on horizons up to 4 seconds with prediction accuracy starting from about 76% for the AoI and 94% for the general highway scenarios on the maximum horizon.

</details>


### [66] [Adaptive Exponential Integration for Stable Gaussian Mixture Black-Box Variational Inference](https://arxiv.org/abs/2601.14855)
*Baojun Che,Yifan Chen,Daniel Zhengyu Huang,Xinying Mao,Weijie Wang*

Main category: cs.LG

TL;DR: 提出了一种稳定高效的BBVI框架，结合自然梯度、指数积分器和自适应步长，用于高斯混合族后验近似


<details>
  <summary>Details</summary>
Motivation: 黑盒变分推断（BBVI）使用高斯混合族可以灵活近似复杂后验分布，但标准数值优化方法存在不稳定和低效问题

Method: 结合三个关键组件：1）通过自然梯度公式进行仿射不变预处理；2）无条件保持协方差矩阵正定性的指数积分器；3）确保稳定性并适应不同阶段的自适应步长

Result: 对于高斯后验，在无噪声设置下证明了指数收敛，在蒙特卡洛估计下证明了几乎必然收敛；数值实验在多模态分布、Neal多尺度漏斗和基于PDE的贝叶斯反问题中验证了有效性

Conclusion: 提出的方法具有自然流形优化和镜像下降的联系，为BBVI提供了稳定高效的优化框架

Abstract: Black-box variational inference (BBVI) with Gaussian mixture families offers a flexible approach for approximating complex posterior distributions without requiring gradients of the target density. However, standard numerical optimization methods often suffer from instability and inefficiency. We develop a stable and efficient framework that combines three key components: (1) affine-invariant preconditioning via natural gradient formulations, (2) an exponential integrator that unconditionally preserves the positive definiteness of covariance matrices, and (3) adaptive time stepping to ensure stability and to accommodate distinct warm-up and convergence phases. The proposed approach has natural connections to manifold optimization and mirror descent. For Gaussian posteriors, we prove exponential convergence in the noise-free setting and almost-sure convergence under Monte Carlo estimation, rigorously justifying the necessity of adaptive time stepping. Numerical experiments on multimodal distributions, Neal's multiscale funnel, and a PDE-based Bayesian inverse problem for Darcy flow demonstrate the effectiveness of the proposed method.

</details>


### [67] [Strategic Doctrine Language Models (sdLM): A Learning-System Framework for Doctrinal Consistency and Geopolitical Forecasting](https://arxiv.org/abs/2601.14862)
*Olaf Yunus Laitinen Imanov,Taner Yilmaz,Derya Umut Kulali*

Main category: cs.LG

TL;DR: sdLM框架通过多文档注意力、时间编码和教义一致性层，提升战略推理的长时预测和计划合理性，减少教义违规


<details>
  <summary>Details</summary>
Motivation: 解决多文档战略推理中教义一致性约束和校准不确定性的问题，提高长期预测准确性和计划可信度

Method: 结合多文档注意力机制、时间编码和教义一致性层，构建战略教义语言模型框架

Result: 在战略场景专家评分、教义一致性评估和地缘政治预测三个基准测试中，sdLM表现优于通用LLM基线，在长期判断上与人类专家竞争力相当

Conclusion: sdLM框架有效提升战略推理质量，减少教义违规，具有实际部署价值，通过消融实验和扩展趋势分析明确了各组件贡献

Abstract: We introduce Strategic Doctrine Language Models (sdLM), a learning-system framework for multi-document strategic reasoning with doctrinal consistency constraints and calibrated uncertainty. The approach combines multi-document attention, temporal encoding, and a doctrine-consistency layer to improve long-horizon forecasting and plan plausibility while reducing severe doctrinal violations. We evaluate sdLM using (i) expert-panel scoring of strategic scenarios (N=47), (ii) doctrine consistency on 336 doctrine publications (12,847 statements), and (iii) geopolitical forecasting on 127 historical counterfactuals (1945-2020) across 12-60 month horizons. Across these benchmarks, sdLM achieves higher strategic quality and better calibration than strong general-purpose LLM baselines, and remains competitive with human experts on long-horizon judgments. We further report ablations, scaling trends, and deployment-oriented performance/latency characteristics to clarify which components drive improvements and how they translate to operational settings.

</details>


### [68] [Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models](https://arxiv.org/abs/2601.14917)
*Giorgia Rigamonti,Mirko Paolo Barbato,Davide Marelli,Paolo Napoletano*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的个性化血糖预测方法，通过利用患者特定数据提高预测准确性，特别关注个体差异对预测效果的影响。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴血糖监测设备和移动健康应用的普及，准确的血糖预测对于增强自动化胰岛素输送和决策支持系统至关重要。传统通用模型无法充分考虑个体差异，需要开发能够适应个体变异性的个性化预测方法。

Method: 采用深度学习框架，提出个性化血糖预测方法。比较了留一受试者交叉验证与微调策略，评估它们对患者特定动态的建模能力。进行了多模态患者特定方法与传统仅使用CGM方法的对比实验，并通过消融研究探索了不同训练数据量对模型性能的影响。

Result: 个性化模型显著改善了不良事件的预测能力，能够实现更精确和及时的干预。研究确定了有效个性化所需的最小数据量，这对于现实世界中数据收集困难的应用场景具有重要意义。

Conclusion: 自适应、个性化的血糖预测模型具有推动下一代糖尿病管理的潜力，特别是在可穿戴和移动健康平台中，能够增强面向消费者的糖尿病护理解决方案。

Abstract: Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions.

</details>


### [69] [Communication-Efficient Multi-Modal Edge Inference via Uncertainty-Aware Distributed Learning](https://arxiv.org/abs/2601.14942)
*Hang Zhao,Hongru Li,Dongfang Xu,Shenghui Song,Khaled B. Letaief*

Main category: cs.LG

TL;DR: 提出三阶段通信感知分布式学习框架，用于多模态边缘推理，通过自监督学习、分布式微调和不确定性引导反馈机制，在减少通信开销的同时提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多模态边缘推理面临两大挑战：1) 多模态特性导致带宽受限无线链路上的通信开销过大；2) 在变化的信道和噪声多模态输入下鲁棒性有限。需要一种既能提高训练推理效率又能保持无线信道鲁棒性的解决方案。

Method: 三阶段框架：阶段I - 设备端本地多模态自监督学习，无需设备-服务器交换，获得共享和模态特定编码器；阶段II - 分布式微调与集中式证据融合，校准每个模态的不确定性并可靠聚合受噪声或信道衰落影响的特征；阶段III - 不确定性引导反馈机制，为不确定样本选择性请求额外特征，优化通信-准确率权衡。

Result: 在RGB-深度室内场景分类实验中，该框架以更少的训练通信轮次获得更高准确率，对模态退化或信道变化保持鲁棒性，优于现有的自监督和完全监督基线方法。

Conclusion: 提出的三阶段通信感知分布式学习框架有效解决了多模态边缘推理的通信效率和鲁棒性问题，通过自监督学习减少通信开销，通过证据融合提高鲁棒性，通过不确定性引导反馈优化通信-准确率权衡。

Abstract: Semantic communication is emerging as a key enabler for distributed edge intelligence due to its capability to convey task-relevant meaning. However, achieving communication-efficient training and robust inference over wireless links remains challenging. This challenge is further exacerbated for multi-modal edge inference (MMEI) by two factors: 1) prohibitive communication overhead for distributed learning over bandwidth-limited wireless links, due to the \emph{multi-modal} nature of the system; and 2) limited robustness under varying channels and noisy multi-modal inputs. In this paper, we propose a three-stage communication-aware distributed learning framework to improve training and inference efficiency while maintaining robustness over wireless channels. In Stage~I, devices perform local multi-modal self-supervised learning to obtain shared and modality-specific encoders without device--server exchange, thereby reducing the communication cost. In Stage~II, distributed fine-tuning with centralized evidential fusion calibrates per-modality uncertainty and reliably aggregates features distorted by noise or channel fading. In Stage~III, an uncertainty-guided feedback mechanism selectively requests additional features for uncertain samples, optimizing the communication--accuracy tradeoff in the distributed setting. Experiments on RGB--depth indoor scene classification show that the proposed framework attains higher accuracy with far fewer training communication rounds and remains robust to modality degradation or channel variation, outperforming existing self-supervised and fully supervised baselines.

</details>


### [70] [InstructTime++: Time Series Classification with Multimodal Language Modeling via Implicit Feature Enhancement](https://arxiv.org/abs/2601.14968)
*Mingyue Cheng,Xiaoyu Tao,Huajian Zhang,Qi Liu,Enhong Chen*

Main category: cs.LG

TL;DR: InstructTime++：将时间序列分类重构为多模态生成任务，通过离散化时间序列、对齐投影和生成式自监督预训练，结合隐式特征建模提升性能


<details>
  <summary>Details</summary>
Motivation: 现有时间序列分类方法采用判别式范式，直接将输入序列映射到one-hot编码的类别标签。这种方法难以融入上下文特征，也无法捕捉类别间的语义关系。

Method: 1. 将时间序列分类重构为多模态生成任务：连续数值序列、上下文文本特征和任务指令作为多模态输入，类别标签作为语言模型生成的文本输出
2. 引入时间序列离散化模块：将连续序列转换为离散时间标记
3. 对齐投影层和生成式自监督预训练策略：增强跨模态表示对齐
4. InstructTime++扩展：加入隐式特征建模，使用专门工具包挖掘原始时间序列和上下文输入中的信息模式（统计特征提取和视觉语言图像描述），将其转换为文本描述进行集成

Result: 在多个基准数据集上的广泛实验证明了InstructTime++的优越性能

Conclusion: 通过将时间序列分类重构为多模态生成任务，并结合隐式特征建模，InstructTime++能够有效融入上下文特征并捕捉类别语义关系，显著提升了分类性能

Abstract: Most existing time series classification methods adopt a discriminative paradigm that maps input sequences directly to one-hot encoded class labels. While effective, this paradigm struggles to incorporate contextual features and fails to capture semantic relationships among classes. To address these limitations, we propose InstructTime, a novel framework that reformulates time series classification as a multimodal generative task. Specifically, continuous numerical sequences, contextual textual features, and task instructions are treated as multimodal inputs, while class labels are generated as textual outputs by tuned language models. To bridge the modality gap, InstructTime introduces a time series discretization module that converts continuous sequences into discrete temporal tokens, together with an alignment projection layer and a generative self-supervised pre-training strategy to enhance cross-modal representation alignment. Building upon this framework, we further propose InstructTime++, which extends InstructTime by incorporating implicit feature modeling to compensate for the limited inductive bias of language models. InstructTime++ leverages specialized toolkits to mine informative implicit patterns from raw time series and contextual inputs, including statistical feature extraction and vision-language-based image captioning, and translates them into textual descriptions for seamless integration. Extensive experiments on multiple benchmark datasets demonstrate the superior performance of InstructTime++.

</details>


### [71] [Multimodal Rumor Detection Enhanced by External Evidence and Forgery Features](https://arxiv.org/abs/2601.14954)
*Han Li,Hua Sun*

Main category: cs.LG

TL;DR: 本文提出了一种结合外部证据和伪造特征的多模态谣言检测模型，通过双对比学习模块和门控自适应特征缩放融合机制，在微博和Twitter数据集上优于主流基线方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中图文混合传播的信息常被谣言利用，特别是深层语义不匹配的谣言（图像和文本表面一致但实际存在矛盾）难以检测。现有多模态谣言检测方法存在特征提取有限、噪声对齐、融合策略不灵活等问题，且忽略了验证复杂谣言所需的外部事实证据。

Method: 1. 使用ResNet34视觉编码器和BERT文本编码器；2. 伪造特征模块通过傅里叶变换提取频域痕迹和压缩伪影；3. 利用BLIP生成图像描述，桥接图像和文本语义空间；4. 双对比学习模块计算文本-图像和文本-描述对的对比损失；5. 门控自适应特征缩放融合机制动态调整多模态融合并减少冗余。

Result: 在微博和Twitter数据集上的实验表明，该模型在宏观准确率、召回率和F1分数方面优于主流基线方法。

Conclusion: 提出的结合外部证据和伪造特征的多模态谣言检测模型能有效检测深层语义不匹配的谣言，通过改进的特征提取、对比学习和自适应融合机制，在多模态谣言检测任务中表现出优越性能。

Abstract: Social media increasingly disseminates information through mixed image text posts, but rumors often exploit subtle inconsistencies and forged content, making detection based solely on post content difficult. Deep semantic mismatch rumors, which superficially align images and texts, pose particular challenges and threaten online public opinion. Existing multimodal rumor detection methods improve cross modal modeling but suffer from limited feature extraction, noisy alignment, and inflexible fusion strategies, while ignoring external factual evidence necessary for verifying complex rumors. To address these limitations, we propose a multimodal rumor detection model enhanced with external evidence and forgery features. The model uses a ResNet34 visual encoder, a BERT text encoder, and a forgery feature module extracting frequency-domain traces and compression artifacts via Fourier transformation. BLIP-generated image descriptions bridge image and text semantic spaces. A dual contrastive learning module computes contrastive losses between text image and text description pairs, improving detection of semantic inconsistencies. A gated adaptive feature-scaling fusion mechanism dynamically adjusts multimodal fusion and reduces redundancy. Experiments on Weibo and Twitter datasets demonstrate that our model outperforms mainstream baselines in macro accuracy, recall, and F1 score.

</details>


### [72] [Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning](https://arxiv.org/abs/2601.15086)
*Oleg Shchendrigin,Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: 论文提出了一个测试强化学习智能体记忆重写能力的基准，发现经典循环模型在现代结构化记忆和基于Transformer的智能体失败的情况下表现更好。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的有效决策需要既稳定又自适应的记忆：环境会随时间变化，智能体必须在长时间内保留相关信息，同时在情况变化时更新或覆盖过时内容。现有的强化学习基准和记忆增强智能体主要关注记忆保留，而同样重要的记忆重写能力在很大程度上未被探索。

Method: 引入了一个在部分可观测性下测试持续记忆更新的基准（智能体必须依赖记忆而非当前观察），并比较了循环模型、基于Transformer的模型和结构化记忆架构。

Result: 实验表明，尽管经典循环模型简单，但在记忆重写任务中表现出比现代结构化记忆更大的灵活性和鲁棒性。结构化记忆仅在狭窄条件下成功，而基于Transformer的智能体往往在非平凡保留情况下失败。

Conclusion: 这些发现揭示了当前方法的基本局限性，强调了需要平衡稳定保留和自适应更新的记忆机制。该工作突出了这一被忽视的挑战，引入了评估基准，并为设计具有明确可训练遗忘机制的未来强化学习智能体提供了见解。

Abstract: Effective decision-making in the real world depends on memory that is both stable and adaptive: environments change over time, and agents must retain relevant information over long horizons while also updating or overwriting outdated content when circumstances shift. Existing Reinforcement Learning (RL) benchmarks and memory-augmented agents focus primarily on retention, leaving the equally critical ability of memory rewriting largely unexplored. To address this gap, we introduce a benchmark that explicitly tests continual memory updating under partial observability, i.e. the natural setting where an agent must rely on memory rather than current observations, and use it to compare recurrent, transformer-based, and structured memory architectures. Our experiments reveal that classic recurrent models, despite their simplicity, demonstrate greater flexibility and robustness in memory rewriting tasks than modern structured memories, which succeed only under narrow conditions, and transformer-based agents, which often fail beyond trivial retention cases. These findings expose a fundamental limitation of current approaches and emphasize the necessity of memory mechanisms that balance stable retention with adaptive updating. Our work highlights this overlooked challenge, introduces benchmarks to evaluate it, and offers insights for designing future RL agents with explicit and trainable forgetting mechanisms. Code: https://quartz-admirer.github.io/Memory-Rewriting/

</details>


### [73] [Lineup Regularized Adjusted Plus-Minus (L-RAPM): Basketball Lineup Ratings with Informed Priors](https://arxiv.org/abs/2601.15000)
*Christos Petridis,Konstantinos Pelechrinis*

Main category: cs.LG

TL;DR: 该论文提出了一种回归方法L-RAPM，用于评估篮球阵容表现，通过控制对手阵容影响并利用球员信息来提高预测准确性，特别是在数据稀疏的情况下效果更明显。


<details>
  <summary>Details</summary>
Motivation: 篮球等运动中识别表现良好的阵容组合是体育分析的重要任务，但频繁换人导致数据高度稀疏（NBA球队每赛季使用600多个阵容，每个阵容平均只有25-30次进攻回合），现有统计数据噪声大、预测价值低，且目前没有公开研究解决此问题。

Method: 提出基于回归的方法L-RAPM，该方法控制每个阵容面对的对手阵容影响，同时利用组成阵容的球员信息来评估阵容表现。

Result: 实验表明，L-RAPM比当前使用的基线方法具有更好的预测能力，且随着阵容样本量变小，这种改进效果更加明显。

Conclusion: L-RAPM方法能够有效解决篮球阵容评估中的数据稀疏问题，提供更准确的阵容表现预测，特别是在数据有限的情况下表现更优。

Abstract: Identifying combinations of players (that is, lineups) in basketball - and other sports - that perform well when they play together is one of the most important tasks in sports analytics. One of the main challenges associated with this task is the frequent substitutions that occur during a game, which results in highly sparse data. In particular, a National Basketball Association (NBA) team will use more than 600 lineups during a season, which translates to an average lineup having seen the court in approximately 25-30 possessions. Inevitably, any statistics that one collects for these lineups are going to be noisy, with low predictive value. Yet, there is no existing work (in the public at least) that addresses this problem. In this work, we propose a regression-based approach that controls for the opposition faced by each lineup, while it also utilizes information about the players making up the lineups. Our experiments show that L-RAPM provides improved predictive power than the currently used baseline, and this improvement increases as the sample size for the lineups gets smaller.

</details>


### [74] [Auditing Language Model Unlearning via Information Decomposition](https://arxiv.org/abs/2601.15111)
*Anmol Goel,Alan Ritter,Iryna Gurevych*

Main category: cs.LG

TL;DR: 当前机器学习遗忘方法存在关键局限：尽管遗忘算法表面成功，但被遗忘数据的信息仍能从内部表示中线性解码。论文引入基于部分信息分解的信息论框架来审计遗忘效果，发现冗余信息构成残留知识，并提出基于表示的风险评分来缓解隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 揭示当前语言模型遗忘方法的关键局限性：尽管遗忘算法在表面上看起来成功，但被遗忘数据的信息仍然可以从模型的内部表示中线性解码出来，这表明存在隐私泄露风险。需要建立系统化的评估框架来审计遗忘效果。

Method: 引入基于部分信息分解（PID）的可解释信息论框架来审计遗忘效果。通过比较遗忘前后模型的表示，将与被遗忘数据的互信息分解为不同组件，形式化定义遗忘知识和残留知识的概念。分析发现冗余信息（两个模型共享的部分）构成残留知识，并提出基于表示的风险评分来指导推理时对敏感输入的弃权。

Result: 分析显示冗余信息（两个模型共享的部分）构成残留知识，在遗忘后仍然存在，并且与已知对抗重建攻击的易感性相关。基于这些洞察，提出了基于表示的风险评分，可以在推理时指导对敏感输入的弃权，提供缓解隐私泄露的实际机制。

Conclusion: 该工作为机器学习遗忘引入了原则性的表示层面审计方法，提供了理论洞察和可操作工具，有助于语言模型更安全地部署。通过信息论框架揭示了当前遗忘方法的局限性，并提出了实用的缓解措施。

Abstract: We expose a critical limitation in current approaches to machine unlearning in language models: despite the apparent success of unlearning algorithms, information about the forgotten data remains linearly decodable from internal representations. To systematically assess this discrepancy, we introduce an interpretable, information-theoretic framework for auditing unlearning using Partial Information Decomposition (PID). By comparing model representations before and after unlearning, we decompose the mutual information with the forgotten data into distinct components, formalizing the notions of unlearned and residual knowledge. Our analysis reveals that redundant information, shared across both models, constitutes residual knowledge that persists post-unlearning and correlates with susceptibility to known adversarial reconstruction attacks. Leveraging these insights, we propose a representation-based risk score that can guide abstention on sensitive inputs at inference time, providing a practical mechanism to mitigate privacy leakage. Our work introduces a principled, representation-level audit for unlearning, offering theoretical insight and actionable tools for safer deployment of language models.

</details>


### [75] [RadixMLP - Intra-batch Deduplication for Causal Transformers](https://arxiv.org/abs/2601.15013)
*Michael Feil,Julius Lipp*

Main category: cs.LG

TL;DR: RadixMLP是一种针对因果Transformer模型批量推理的技术，通过利用MLP、LayerNorm等组件的逐位置特性，消除共享前缀的冗余计算，显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 因果Transformer模型的批量推理工作负载经常处理具有共享前缀的序列（如系统提示、少样本示例等），但标准推理引擎将每个序列独立处理，对相同的共享前缀进行冗余的MLP激活计算。

Method: RadixMLP将批次动态映射到前缀树中，将共享片段收集到压缩表示中进行逐位置计算，仅在注意力边界处将结果分散回各个序列。该技术是无状态的，在单次前向传播中完成。

Result: 在MS MARCO v1.1的Qwen3模型（0.6B到8B参数）端到端服务基准测试中，RadixMLP在实际重排序工作负载中实现了1.44-1.59倍加速，在具有更长共享前缀的合成基准测试中达到5倍加速。

Conclusion: RadixMLP通过消除共享前缀的冗余计算，显著提升了因果Transformer模型的批量推理效率，特别是在处理具有共同前缀的序列时效果显著。

Abstract: Batch inference workloads for causal transformer models frequently process sequences that share common prefixes, such as system prompts, few-shot examples, or shared queries. Standard inference engines treat each sequence independently, redundantly recomputing identical MLP activations for every copy of the shared prefix. We introduce RadixMLP, a technique that exploits the position-wise nature of MLPs, LayerNorms, linear projections, and embeddings to eliminate this redundancy. RadixMLP dynamically maps batches to a prefix trie, gathering shared segments into a compressed representation for position-wise computation and scattering results back only at attention boundaries. RadixMLP is stateless and operates within a single forward pass. In end-to-end serving benchmarks on MS~MARCO v1.1 with Qwen3 models (0.6B to 8B parameters), RadixMLP achieves 1.44-1.59$\times$ speedups in realistic reranking workloads, with up to $5\times$ speedups on synthetic benchmarks with longer shared prefixes. Our code is available at https://github.com/michaelfeil/radix-mlp.

</details>


### [76] [Overcoming In-Memory Bottlenecks in Graph Foundation Models via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.15124)
*Haonan Yuan,Qingyun Sun,Jiacheng Tao,Xingcheng Fu,Jianxin Li*

Main category: cs.LG

TL;DR: RAG-GFM：基于检索增强生成的图基础模型，通过将知识从参数中卸载到外部存储来解决现有图基础模型的内存瓶颈问题，实现更高效的知识表示和下游任务适应。


<details>
  <summary>Details</summary>
Motivation: 现有图基础模型（GFMs）存在内存瓶颈问题：它们试图将知识编码到模型参数中，这限制了语义容量，引入了严重的损失压缩和冲突，并且以阻碍高效适应的方式将图表示与知识纠缠在一起，影响了可扩展性和可解释性。

Method: 提出RAG-GFM模型，采用检索增强生成方法。构建双模态统一检索模块：基于前缀结构文本的语义存储和基于中心性基元的结构存储。设计双视图对齐目标来保留异构信息，对比两种模态以捕获内容和关系模式。通过上下文增强进行下游适应，使用检索到的文本和基元作为上下文证据来丰富支持实例。

Result: 在五个基准图数据集上的广泛实验表明，RAG-GFM在跨领域节点和图分类任务中持续优于13个最先进的基线方法，实现了卓越的有效性和效率。

Conclusion: RAG-GFM通过将知识从参数中卸载并补充参数化学习，解决了图基础模型的内存瓶颈问题，为图学习提供了更高效、可扩展和可解释的解决方案。

Abstract: Graph Foundation Models (GFMs) have emerged as a frontier in graph learning, which are expected to deliver transferable representations across diverse tasks. However, GFMs remain constrained by in-memory bottlenecks: they attempt to encode knowledge into model parameters, which limits semantic capacity, introduces heavy lossy compression with conflicts, and entangles graph representation with the knowledge in ways that hinder efficient adaptation, undermining scalability and interpretability. In this work,we propose RAG-GFM, a Retrieval-Augmented Generation aided Graph Foundation Model that offloads knowledge from parameters and complements parameterized learning. To externalize graph knowledge, we build a dual-modal unified retrieval module, where a semantic store from prefix-structured text and a structural store from centrality-based motif. To preserve heterogeneous information, we design a dual-view alignment objective that contrasts both modalities to capture both content and relational patterns. To enable efficient downstream adaptation, we perform in-context augmentation to enrich supporting instances with retrieved texts and motifs as contextual evidence. Extensive experiments on five benchmark graph datasets demonstrate that RAG-GFM consistently outperforms 13 state-of-the-art baselines in both cross-domain node and graph classification, achieving superior effectiveness and efficiency.

</details>


### [77] [Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control](https://arxiv.org/abs/2601.15015)
*Jannis Becktepe,Aleksandra Franz,Nils Thuerey,Sebastian Peitz*

Main category: cs.LG

TL;DR: FluidGym：首个独立、完全可微的强化学习主动流控制基准套件，基于PyTorch和GPU加速的PICT求解器，无需外部CFD软件，提供标准化评估协议。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在主动流控制领域的研究进展难以评估，因为现有研究使用异构的观测和执行方案、数值设置和评估协议。现有基准严重依赖外部CFD求解器，不完全可微，且对3D和多智能体支持有限。

Method: 构建基于PyTorch和GPU加速PICT求解器的FluidGym基准套件，完全在单一Python栈中运行，无需外部CFD软件，提供标准化评估协议，支持3D和多智能体场景。

Result: 提供了基于PPO和SAC的基线结果，发布了所有环境、数据集和训练模型作为公共资源，建立了可扩展的学习型流控制研究基础。

Conclusion: FluidGym解决了现有基准的局限性，实现了控制方法的系统比较，为基于学习的流控制研究提供了可扩展的基础设施，所有资源已公开。

Abstract: Reinforcement learning (RL) has shown promising results in active flow control (AFC), yet progress in the field remains difficult to assess as existing studies rely on heterogeneous observation and actuation schemes, numerical setups, and evaluation protocols. Current AFC benchmarks attempt to address these issues but heavily rely on external computational fluid dynamics (CFD) solvers, are not fully differentiable, and provide limited 3D and multi-agent support. To overcome these limitations, we introduce FluidGym, the first standalone, fully differentiable benchmark suite for RL in AFC. Built entirely in PyTorch on top of the GPU-accelerated PICT solver, FluidGym runs in a single Python stack, requires no external CFD software, and provides standardized evaluation protocols. We present baseline results with PPO and SAC and release all environments, datasets, and trained models as public resources. FluidGym enables systematic comparison of control methods, establishes a scalable foundation for future research in learning-based flow control, and is available at https://github.com/safe-autonomous-systems/fluidgym.

</details>


### [78] [Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data](https://arxiv.org/abs/2601.15158)
*Yuval Ran-Milo,Yotam Alexander,Shahar Mendel,Nadav Cohen*

Main category: cs.LG

TL;DR: 该研究揭示了Transformer模型在仅通过最终答案正确性进行强化学习训练时，如何自发发展出中间推理步骤（思维链）能力的机制。通过分析单层Transformer在合成图遍历任务上的梯度流动力学，证明了稀疏奖励如何驱动模型学习可解释的迭代算法。


<details>
  <summary>Details</summary>
Motivation: 尽管基于结果监督的强化学习训练Transformer能够自发产生思维链推理能力，但稀疏奖励如何驱动梯度下降发现这种系统性推理的机制尚不清楚。研究者希望理解这一现象背后的数学原理和动态过程。

Method: 使用单层Transformer在合成图遍历任务上进行分析，该任务无法在没有思维链的情况下解决，但存在简单的迭代解。通过理论分析梯度流动力学，证明仅基于最终答案正确性的训练如何收敛到结构化、可解释的算法。同时研究了分布特性对学习的影响，特别是"简单示例"（需要较少推理步骤的实例）的关键作用。

Result: 理论证明：尽管仅训练最终答案正确性，梯度流会驱动模型收敛到逐顶点迭代遍历图的结构化算法。发现"简单示例"的质量分布对学习至关重要：当训练分布包含足够多的简单实例时，模型学习到可泛化的遍历策略，能够外推到更长的链；当这种分布消失时，基于梯度的学习变得不可行。实验验证了理论结果在合成数据和真实世界语言模型数学推理任务上的适用性。

Conclusion: 该研究为理解Transformer在稀疏奖励下如何发展思维链推理能力提供了理论框架。关键发现是训练数据中"简单示例"的分布质量决定了模型能否学习到可泛化的推理策略。这些理论见解对设计更有效的强化学习训练策略和提升语言模型推理能力具有重要意义。

Abstract: Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought (CoT) but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, gradient flow drives the model to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of "simple examples": instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler instances, the model learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, gradient-based learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings.

</details>


### [79] [Mixture-of-Experts Models in Vision: Routing, Optimization, and Generalization](https://arxiv.org/abs/2601.15021)
*Adam Rokah,Daniel Veress,Caleb Caulk,Sourav Sharan*

Main category: cs.LG

TL;DR: 该研究在图像分类任务中比较了密集模型、SoftMoE和SparseMoE三种架构，发现MoE变体在CIFAR10上获得略高的验证准确率，但条件计算在实际硬件上未带来推理加速。


<details>
  <summary>Details</summary>
Motivation: 研究MoE架构在图像分类任务中的行为，而非传统的大语言模型扩展场景，重点关注预测性能、专家利用率和泛化特性。

Method: 在CIFAR10数据集上，在可比模型容量下比较密集、SoftMoE和SparseMoE分类器头；使用正则化保持专家平衡；通过Hessian矩阵的锐度指标（最大特征值和迹）分析泛化；进行损失曲面扰动分析；评估实际推理效率。

Result: 两种MoE变体比密集基线获得略高的验证准确率，同时通过正则化避免了专家崩溃；SoftMoE显示出更高的锐度指标，而密集和SparseMoE处于相似的曲率状态；条件计算在当前硬件规模下未实现推理加速。

Conclusion: MoE架构在图像分类中能获得性能提升并保持专家平衡，但实际推理效率受硬件限制；锐度指标揭示了模型间的曲率差异，但未直接解释验证准确率；需要进一步研究MoE在不同任务和规模下的行为。

Abstract: Mixture-of-Experts (MoE) architectures enable conditional computation by routing inputs to multiple expert subnetworks and are often motivated as a mechanism for scaling large language models. In this project, we instead study MoE behavior in an image classification setting, focusing on predictive performance, expert utilization, and generalization. We compare dense, SoftMoE, and SparseMoE classifier heads on the CIFAR10 dataset under comparable model capacity. Both MoE variants achieve slightly higher validation accuracy than the dense baseline while maintaining balanced expert utilization through regularization, avoiding expert collapse. To analyze generalization, we compute Hessian-based sharpness metrics at convergence, including the largest eigenvalue and trace of the loss Hessian, evaluated on both training and test data. We find that SoftMoE exhibits higher sharpness by these metrics, while Dense and SparseMoE lie in a similar curvature regime, despite all models achieving comparable generalization performance. Complementary loss surface perturbation analyses reveal qualitative differences in non-local behavior under finite parameter perturbations between dense and MoE models, which help contextualize curvature-based measurements without directly explaining validation accuracy. We further evaluate empirical inference efficiency and show that naively implemented conditional routing does not yield inference speedups on modern hardware at this scale, highlighting the gap between theoretical and realized efficiency in sparse MoE models.

</details>


### [80] [Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism](https://arxiv.org/abs/2601.15249)
*Garrett G. Wen,Buxin Su,Natalie Collina,Zhun Deng,Weijie Su*

Main category: cs.LG

TL;DR: 作者提出了一种基于等渗机制的作者辅助最佳论文评选方法，通过作者对自身论文的排名评估来调整原始评审分数，从而提高奖项评选质量。


<details>
  <summary>Details</summary>
Motivation: NeurIPS、ICML等AI顶会每年收到数万篇投稿，评审工作量巨大，最佳论文奖项的评选质量难以保证且争议不断。需要一种更可靠的方法来改进奖项评选过程。

Method: 采用等渗机制让作者对自己的投稿进行排名评估，利用这些排名信息调整原始评审分数，从而更准确地估计论文的真实质量。该方法还扩展到处理作者重叠的情况。

Result: 理论证明当作者的效用函数是凸可加函数时，作者有动机如实报告；在作者只有单一配额（只能提名一篇论文）时，即使效用函数只是非递减可加函数也能保证真实性。使用ICLR（2019-2023）和NeurIPS（2021-2023）的公开评审数据进行验证，模拟结果显示该方法显著提高了奖项论文的评选质量。

Conclusion: 作者辅助的等渗机制能够有效改进最佳论文奖项的评选过程，在更宽松的假设条件下保证作者如实报告，显著提升奖项论文的质量。

Abstract: Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards.

</details>


### [81] [Field-Space Autoencoder for Scalable Climate Emulators](https://arxiv.org/abs/2601.15102)
*Johannes Meuer,Maximilian Witte,Étiénne Plésiat,Thomas Ludwig,Christopher Kadow*

Main category: cs.LG

TL;DR: 提出Field-Space Autoencoder框架，通过球面压缩模型解决千米尺度地球系统模型计算成本高、输出数据量大的问题，支持零样本超分辨率和生成扩散模型训练。


<details>
  <summary>Details</summary>
Motivation: 千米尺度地球系统模型虽然能捕捉局部气候变化，但计算成本极高且产生PB级输出，限制了其在概率风险评估等应用中的实用性。

Method: 提出Field-Space Autoencoder框架，基于球面压缩模型，使用Field-Space Attention直接在原生气候模型输出上操作，避免将球面数据强制映射到欧几里得网格造成的几何失真。该方法生成结构化压缩场，作为下游生成仿真的良好基线，并能进行零样本超分辨率。

Result: 该方法比卷积基线显著更好地保持物理结构，能够将低分辨率大集合和稀缺高分辨率数据映射到共享表示中。训练在压缩场上的生成扩散模型能同时从丰富的低分辨率数据学习内部变异性，从稀疏的高分辨率数据学习精细尺度物理。

Conclusion: 该工作弥合了低分辨率集合统计的高数据量与高分辨率物理细节稀缺性之间的差距，为气候仿真提供了可扩展的解决方案。

Abstract: Kilometer-scale Earth system models are essential for capturing local climate change. However, these models are computationally expensive and produce petabyte-scale outputs, which limits their utility for applications such as probabilistic risk assessment. Here, we present the Field-Space Autoencoder, a scalable climate emulation framework based on a spherical compression model that overcomes these challenges. By utilizing Field-Space Attention, the model efficiently operates on native climate model output and therefore avoids geometric distortions caused by forcing spherical data onto Euclidean grids. This approach preserves physical structures significantly better than convolutional baselines. By producing a structured compressed field, it serves as a good baseline for downstream generative emulation. In addition, the model can perform zero-shot super-resolution that maps low-resolution large ensembles and scarce high-resolution data into a shared representation. We train a generative diffusion model on these compressed fields. The model can simultaneously learn internal variability from abundant low-resolution data and fine-scale physics from sparse high-resolution data. Our work bridges the gap between the high volume of low-resolution ensemble statistics and the scarcity of high-resolution physical detail.

</details>


### [82] [CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning](https://arxiv.org/abs/2601.15141)
*Tianshi Xu,Yuteng Chen,Meng Li*

Main category: cs.LG

TL;DR: CLEANER提出了一种利用LLM内在自校正能力来净化强化学习轨迹的方法，通过相似性感知自适应回滚机制，用成功的自校正替换执行失败，解决了参数受限模型在探索阶段的噪声轨迹问题。


<details>
  <summary>Details</summary>
Motivation: 参数受限的大型语言模型（4B-7B）在强化学习探索阶段经常出现执行失败，产生噪声轨迹，导致信用分配问题。现有方法面临两难：密集奖励容易引发奖励黑客行为，而过采样则计算成本过高。

Method: CLEANER利用模型内在自校正能力，在数据收集阶段直接消除错误污染上下文。核心是相似性感知自适应回滚机制，根据语义相似度自适应调节替换粒度，从浅层执行修复到深层推理替换，构建纯净轨迹。

Result: 在AIME24/25、GPQA和LiveCodeBench上的实验结果显示，相比基线平均准确率分别提升6%、3%和5%。CLEANER仅用三分之一训练步数就能达到最先进性能。

Conclusion: 轨迹净化是高效智能体强化学习的可扩展解决方案，通过训练自净化路径，模型能够内化正确的推理模式而非错误恢复循环。

Abstract: Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise leads to a critical credit assignment issue, where erroneous actions are inadvertently reinforced alongside successful outcomes. Existing mitigations face a dilemma: dense rewards often trigger reward hacking, while supersampling incurs prohibitive computational costs. To address these challenges, we propose CLEANER. Distinct from external filtering methods, CLEANER exploits the model's intrinsic self-correction capabilities to eliminate error-contaminated context directly during data collection. At its core, the Similarity-Aware Adaptive Rollback (SAAR) mechanism autonomously constructs clean, purified trajectories by retrospectively replacing failures with successful self-corrections. Based on semantic similarity, SAAR adaptively regulates replacement granularity from shallow execution repairs to deep reasoning substitutions. By training on these self-purified paths, the model internalizes correct reasoning patterns rather than error-recovery loops. Empirical results on AIME24/25, GPQA, and LiveCodeBench show average accuracy gains of 6%, 3%, and 5% over baselines. Notably, CLEANER matches state-of-the-art performance using only one-third of the training steps, highlighting trajectory purification as a scalable solution for efficient agentic RL. Our models and code are available at GitHub

</details>


### [83] [ZENITH: Automated Gradient Norm Informed Stochastic Optimization](https://arxiv.org/abs/2601.15212)
*Dhrubo Saha*

Main category: cs.LG

TL;DR: ZENITH优化器通过梯度范数的时间演化自适应调整学习率，无需手动调度，在多个视觉任务中实现更高精度和更快训练速度。


<details>
  <summary>Details</summary>
Motivation: 现有自适应优化器存在计算内存开销大、与正则化不兼容、学习率选择次优等问题，需要手动调整学习率调度。

Method: 提出ZENITH优化器，利用梯度范数的时间演化信息来自适应调整学习率，实现零开销的自动学习率调度。

Result: 在6种CNN架构和6个基准测试中，ZENITH在更短的挂钟时间内获得更高测试精度；在MS COCO的目标检测、关键点检测和实例分割任务中，使用R-CNN模型获得更优的mAP。

Conclusion: ZENITH优化器通过梯度范数演化自适应调整学习率，解决了现有自适应优化器的局限性，实现了更好的泛化性能和训练效率。

Abstract: Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.

</details>
